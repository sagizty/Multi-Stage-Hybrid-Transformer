{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of MSHT k5_Train.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-1_HUut4YYm5"},"source":["## This is the official training Script of MSHT\n","* Use google colab pro+ (high RAM+GPU)\n","* we use the P100 GPU for the Experiments\n","\n","## The code and Training process along with all record are Open-Source\n","* Our github page: https://github.com/sagizty/Multi-Stage-Hybrid-Transformer\n","* The dataset is not publicly aviliable\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZnbrNSoSXFm5","executionInfo":{"elapsed":671,"status":"ok","timestamp":1635404575899,"user":{"displayName":"Rush MSHT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17678018738220178064"},"user_tz":-480},"outputId":"0db86797-1e2d-4b95-8e6f-d72ec4ea063f"},"source":["# check GPU\n","!nvidia-smi"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Oct 28 07:02:55 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.29.05    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9GPOn5gcykA","executionInfo":{"elapsed":14,"status":"ok","timestamp":1635404576699,"user":{"displayName":"Rush MSHT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17678018738220178064"},"user_tz":-480},"outputId":"5ffc6c56-2e0b-4bf1-9e55-a45378d7787c"},"source":["!date --date='+8 hour'  # CST time zone"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Oct 28 15:02:56 UTC 2021\n"]}]},{"cell_type":"markdown","metadata":{"id":"nZKz8QDpIdj3"},"source":["## Mount the Github\n","get the code from Github official page\n","\n","ref: https://blog.csdn.net/u011119817/article/details/108722832\n","ref: https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token"]},{"cell_type":"code","metadata":{"id":"2oT4q-sJIgEp"},"source":["import os\n","# GitHub user\n","user = 'zhanglab2021'\n","# GitHub personal-access-token (this has been revoke already, use your own)\n","password = '(this has been revoke already, use your own)'\n","os.environ['GITHUB_AUTH'] = user + ':' + password"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fbnpeHYUgsJz"},"source":["## Mount Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3obRNrIaffjK","executionInfo":{"elapsed":21900,"status":"ok","timestamp":1635404598594,"user":{"displayName":"Rush MSHT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17678018738220178064"},"user_tz":-480},"outputId":"ea70273d-4e0d-4c43-b634-ff9ab8ffa772"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"BYevYeMFYmlx"},"source":["## create file-system enviroment\n","* mount your google drive first\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ePtQFcQCEPlu","executionInfo":{"elapsed":87123,"status":"ok","timestamp":1635404685712,"user":{"displayName":"Rush MSHT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17678018738220178064"},"user_tz":-480},"outputId":"d12b4518-2fc5-4116-fc63-b6c73ac6ea9a"},"source":["# create file-system enviroment\n","# mount the google drive first\n","# https://drive.google.com/drive/u/1/my-drive\n","\n","# clear colab path\n","!rm -rf /data\n","!rm -rf /home/pancreatic-cancer-project\n","\n","# create path\n","!mkdir /home/pancreatic-cancer-project\n","!mkdir /home/pancreatic-cancer-project/runs\n","!mkdir /home/pancreatic-cancer-project/code\n","!mkdir /home/pancreatic-cancer-project/saved_models\n","!mkdir /home/pancreatic-cancer-project/imaging_results\n","\n","!mkdir /data\n","!mkdir /data/pancreatic-cancer-project\n","!mkdir /data/pancreatic-cancer-project/dataset\n","\n","print('Folder Tree Creation completed!')\n","\n","# get latest code from Github official page\n","!git clone https://$GITHUB_AUTH@github.com/sagizty/Multi-Stage-Hybrid-Transformer.git /home/pancreatic-cancer-project/code\n","print('code transfer from github completed!')\n","\n","# copy runs if u want to compare\n","# !cp -r /content/drive/MyDrive/MSHT_offcial_result/runs/* /home/pancreatic-cancer-project/runs\n","# print('tensorboard log transfer completed!')\n","\n","# get the pretrained models\n","!cp -r /content/drive/MyDrive/MSHT_offcial_result/saved_models/PC_Hybrid2_384_PreTrain_000.pth /home/pancreatic-cancer-project/saved_models\n","print('model state dicts transfered')\n","\n","# get the ROSE dataset\n","# by its zip\n","!cp /content/drive/MyDrive/dataset/k5_dataset.zip /data/pancreatic-cancer-project/\n","# unzip\n","!unzip -q /data/pancreatic-cancer-project/k5_dataset.zip -d /data/pancreatic-cancer-project/\n","\n","# alter the path\n","!mv /data/pancreatic-cancer-project/k5_dataset/* /data/pancreatic-cancer-project/dataset\n","!rm -rf /data/pancreatic-cancer-project/k5_dataset /data/pancreatic-cancer-project/k5_dataset.zip\n","print('data transfer completed!')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Folder Tree Creation completed!\n","Cloning into '/home/pancreatic-cancer-project/code'...\n","remote: Enumerating objects: 157, done.\u001b[K\n","remote: Counting objects: 100% (157/157), done.\u001b[K\n","remote: Compressing objects: 100% (152/152), done.\u001b[K\n","remote: Total 157 (delta 72), reused 0 (delta 0), pack-reused 0\u001b[K\n","Receiving objects: 100% (157/157), 377.45 KiB | 5.39 MiB/s, done.\n","Resolving deltas: 100% (72/72), done.\n","code transfer from github completed!\n","model state dicts transfered\n","data transfer completed!\n"]}]},{"cell_type":"markdown","metadata":{"id":"xLxxHGq_wwwL"},"source":["## Arrange the working enviorment"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1Yb2b6TGF4r","executionInfo":{"elapsed":11232,"status":"ok","timestamp":1635404696933,"user":{"displayName":"Rush MSHT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17678018738220178064"},"user_tz":-480},"outputId":"86f905bb-b429-44b3-b806-10fd5938606a"},"source":["# change working dir\n","import os\n","os.chdir(\"/home/pancreatic-cancer-project/code\")\n","!pwd\n","\n","# get packages\n","!pip install tensorboardX\n","!pip install timm\n","!pip install notifyemail\n","!pip install ttach\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/home/pancreatic-cancer-project/code\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n","\u001b[K     |████████████████████████████████| 124 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.4\n","Collecting timm\n","  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu111)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n","Installing collected packages: timm\n","Successfully installed timm-0.4.12\n","Collecting notifyemail\n","  Downloading notifyemail-1.0.2-py3-none-any.whl (31 kB)\n","Installing collected packages: notifyemail\n","Successfully installed notifyemail-1.0.2\n","Collecting ttach\n","  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n","Installing collected packages: ttach\n","Successfully installed ttach-0.0.3\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87Owjg_pN2yD","executionInfo":{"elapsed":14,"status":"ok","timestamp":1635404696934,"user":{"displayName":"Rush MSHT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17678018738220178064"},"user_tz":-480},"outputId":"acd15571-f825-4955-acd5-80cc0ff99d0b"},"source":["!python --version"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.7.12\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpEVUWwqK79D","executionInfo":{"elapsed":788,"status":"ok","timestamp":1635404697718,"user":{"displayName":"Rush MSHT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17678018738220178064"},"user_tz":-480},"outputId":"74461a0f-c26e-45c0-f660-74e6d5cd75e1"},"source":["!pip list"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Package                       Version\n","----------------------------- --------------\n","absl-py                       0.12.0\n","alabaster                     0.7.12\n","albumentations                0.1.12\n","altair                        4.1.0\n","appdirs                       1.4.4\n","argcomplete                   1.12.3\n","argon2-cffi                   21.1.0\n","arviz                         0.11.4\n","astor                         0.8.1\n","astropy                       4.3.1\n","astunparse                    1.6.3\n","atari-py                      0.2.9\n","atomicwrites                  1.4.0\n","attrs                         21.2.0\n","audioread                     2.1.9\n","autograd                      1.3\n","Babel                         2.9.1\n","backcall                      0.2.0\n","beautifulsoup4                4.6.3\n","bleach                        4.1.0\n","blis                          0.4.1\n","bokeh                         2.3.3\n","Bottleneck                    1.3.2\n","branca                        0.4.2\n","bs4                           0.0.1\n","CacheControl                  0.12.6\n","cached-property               1.5.2\n","cachetools                    4.2.4\n","catalogue                     1.0.0\n","certifi                       2021.5.30\n","cffi                          1.14.6\n","cftime                        1.5.1\n","chardet                       3.0.4\n","charset-normalizer            2.0.7\n","clang                         5.0\n","click                         7.1.2\n","cloudpickle                   1.3.0\n","cmake                         3.12.0\n","cmdstanpy                     0.9.5\n","colorcet                      2.0.6\n","colorlover                    0.3.0\n","community                     1.0.0b1\n","contextlib2                   0.5.5\n","convertdate                   2.3.2\n","coverage                      3.7.1\n","coveralls                     0.5\n","crcmod                        1.7\n","cufflinks                     0.17.3\n","cupy-cuda111                  9.4.0\n","cvxopt                        1.2.7\n","cvxpy                         1.0.31\n","cycler                        0.10.0\n","cymem                         2.0.5\n","Cython                        0.29.24\n","daft                          0.0.4\n","dask                          2.12.0\n","datascience                   0.10.6\n","debugpy                       1.0.0\n","decorator                     4.4.2\n","defusedxml                    0.7.1\n","descartes                     1.1.0\n","dill                          0.3.4\n","distributed                   1.25.3\n","dlib                          19.18.0\n","dm-tree                       0.1.6\n","docopt                        0.6.2\n","docutils                      0.17.1\n","dopamine-rl                   1.0.5\n","earthengine-api               0.1.284\n","easydict                      1.9\n","ecos                          2.0.7.post1\n","editdistance                  0.5.3\n","en-core-web-sm                2.2.5\n","entrypoints                   0.3\n","ephem                         4.1\n","et-xmlfile                    1.1.0\n","fa2                           0.3.5\n","fastai                        1.0.61\n","fastdtw                       0.3.4\n","fastprogress                  1.0.0\n","fastrlock                     0.6\n","fbprophet                     0.7.1\n","feather-format                0.4.1\n","filelock                      3.3.0\n","firebase-admin                4.4.0\n","fix-yahoo-finance             0.0.22\n","Flask                         1.1.4\n","flatbuffers                   1.12\n","folium                        0.8.3\n","future                        0.16.0\n","gast                          0.4.0\n","GDAL                          2.2.2\n","gdown                         3.6.4\n","gensim                        3.6.0\n","geographiclib                 1.52\n","geopy                         1.17.0\n","gin-config                    0.4.0\n","glob2                         0.7\n","google                        2.0.3\n","google-api-core               1.26.3\n","google-api-python-client      1.12.8\n","google-auth                   1.35.0\n","google-auth-httplib2          0.0.4\n","google-auth-oauthlib          0.4.6\n","google-cloud-bigquery         1.21.0\n","google-cloud-bigquery-storage 1.1.0\n","google-cloud-core             1.0.3\n","google-cloud-datastore        1.8.0\n","google-cloud-firestore        1.7.0\n","google-cloud-language         1.2.0\n","google-cloud-storage          1.18.1\n","google-cloud-translate        1.5.0\n","google-colab                  1.0.0\n","google-pasta                  0.2.0\n","google-resumable-media        0.4.1\n","googleapis-common-protos      1.53.0\n","googledrivedownloader         0.4\n","graphviz                      0.10.1\n","greenlet                      1.1.2\n","grpcio                        1.41.0\n","gspread                       3.0.1\n","gspread-dataframe             3.0.8\n","gym                           0.17.3\n","h5py                          3.1.0\n","HeapDict                      1.0.1\n","hijri-converter               2.2.2\n","holidays                      0.10.5.2\n","holoviews                     1.14.6\n","html5lib                      1.0.1\n","httpimport                    0.5.18\n","httplib2                      0.17.4\n","httplib2shim                  0.0.3\n","humanize                      0.5.1\n","hyperopt                      0.1.2\n","ideep4py                      2.0.0.post3\n","idna                          2.10\n","imageio                       2.4.1\n","imagesize                     1.2.0\n","imbalanced-learn              0.4.3\n","imblearn                      0.0\n","imgaug                        0.2.9\n","importlib-metadata            4.8.1\n","importlib-resources           5.2.2\n","imutils                       0.5.4\n","inflect                       2.1.0\n","iniconfig                     1.1.1\n","intel-openmp                  2021.4.0\n","intervaltree                  2.1.0\n","ipykernel                     4.10.1\n","ipython                       5.5.0\n","ipython-genutils              0.2.0\n","ipython-sql                   0.3.9\n","ipywidgets                    7.6.5\n","itsdangerous                  1.1.0\n","jax                           0.2.21\n","jaxlib                        0.1.71+cuda111\n","jdcal                         1.4.1\n","jedi                          0.18.0\n","jieba                         0.42.1\n","Jinja2                        2.11.3\n","joblib                        1.0.1\n","jpeg4py                       0.1.4\n","jsonschema                    2.6.0\n","jupyter                       1.0.0\n","jupyter-client                5.3.5\n","jupyter-console               5.2.0\n","jupyter-core                  4.8.1\n","jupyterlab-pygments           0.1.2\n","jupyterlab-widgets            1.0.2\n","kaggle                        1.5.12\n","kapre                         0.3.5\n","keras                         2.6.0\n","Keras-Preprocessing           1.1.2\n","keras-vis                     0.4.1\n","kiwisolver                    1.3.2\n","korean-lunar-calendar         0.2.1\n","librosa                       0.8.1\n","lightgbm                      2.2.3\n","llvmlite                      0.34.0\n","lmdb                          0.99\n","LunarCalendar                 0.0.9\n","lxml                          4.2.6\n","Markdown                      3.3.4\n","MarkupSafe                    2.0.1\n","matplotlib                    3.2.2\n","matplotlib-inline             0.1.3\n","matplotlib-venn               0.11.6\n","missingno                     0.5.0\n","mistune                       0.8.4\n","mizani                        0.6.0\n","mkl                           2019.0\n","mlxtend                       0.14.0\n","more-itertools                8.10.0\n","moviepy                       0.2.3.5\n","mpmath                        1.2.1\n","msgpack                       1.0.2\n","multiprocess                  0.70.12.2\n","multitasking                  0.0.9\n","murmurhash                    1.0.5\n","music21                       5.5.0\n","natsort                       5.5.0\n","nbclient                      0.5.4\n","nbconvert                     5.6.1\n","nbformat                      5.1.3\n","nest-asyncio                  1.5.1\n","netCDF4                       1.5.7\n","networkx                      2.6.3\n","nibabel                       3.0.2\n","nltk                          3.2.5\n","notebook                      5.3.1\n","notifyemail                   1.0.2\n","numba                         0.51.2\n","numexpr                       2.7.3\n","numpy                         1.19.5\n","nvidia-ml-py3                 7.352.0\n","oauth2client                  4.1.3\n","oauthlib                      3.1.1\n","okgrade                       0.4.3\n","opencv-contrib-python         4.1.2.30\n","opencv-python                 4.1.2.30\n","openpyxl                      2.5.9\n","opt-einsum                    3.3.0\n","osqp                          0.6.2.post0\n","packaging                     21.0\n","palettable                    3.3.0\n","pandas                        1.1.5\n","pandas-datareader             0.9.0\n","pandas-gbq                    0.13.3\n","pandas-profiling              1.4.1\n","pandocfilters                 1.5.0\n","panel                         0.12.1\n","param                         1.11.1\n","parso                         0.8.2\n","pathlib                       1.0.1\n","patsy                         0.5.2\n","pep517                        0.11.0\n","pexpect                       4.8.0\n","pickleshare                   0.7.5\n","Pillow                        7.1.2\n","pip                           21.1.3\n","pip-tools                     6.2.0\n","plac                          1.1.3\n","plotly                        4.4.1\n","plotnine                      0.6.0\n","pluggy                        0.7.1\n","pooch                         1.5.1\n","portpicker                    1.3.9\n","prefetch-generator            1.0.1\n","preshed                       3.0.5\n","prettytable                   2.2.1\n","progressbar2                  3.38.0\n","prometheus-client             0.11.0\n","promise                       2.3\n","prompt-toolkit                1.0.18\n","protobuf                      3.17.3\n","psutil                        5.4.8\n","psycopg2                      2.7.6.1\n","ptyprocess                    0.7.0\n","py                            1.10.0\n","pyarrow                       3.0.0\n","pyasn1                        0.4.8\n","pyasn1-modules                0.2.8\n","pycocotools                   2.0.2\n","pycparser                     2.20\n","pyct                          0.4.8\n","pydata-google-auth            1.2.0\n","pydot                         1.3.0\n","pydot-ng                      2.0.0\n","pydotplus                     2.0.2\n","PyDrive                       1.3.1\n","pyemd                         0.5.1\n","pyerfa                        2.0.0\n","pyglet                        1.5.0\n","Pygments                      2.6.1\n","pygobject                     3.26.1\n","pymc3                         3.11.4\n","PyMeeus                       0.5.11\n","pymongo                       3.12.0\n","pymystem3                     0.2.0\n","PyOpenGL                      3.1.5\n","pyparsing                     2.4.7\n","pyrsistent                    0.18.0\n","pysndfile                     1.3.8\n","PySocks                       1.7.1\n","pystan                        2.19.1.1\n","pytest                        3.6.4\n","python-apt                    0.0.0\n","python-chess                  0.23.11\n","python-dateutil               2.8.2\n","python-louvain                0.15\n","python-slugify                5.0.2\n","python-utils                  2.5.6\n","pytz                          2018.9\n","pyviz-comms                   2.1.0\n","PyWavelets                    1.1.1\n","PyYAML                        3.13\n","pyzmq                         22.3.0\n","qdldl                         0.1.5.post0\n","qtconsole                     5.1.1\n","QtPy                          1.11.2\n","regex                         2019.12.20\n","requests                      2.23.0\n","requests-oauthlib             1.3.0\n","resampy                       0.2.2\n","retrying                      1.3.3\n","rpy2                          3.4.5\n","rsa                           4.7.2\n","scikit-image                  0.16.2\n","scikit-learn                  0.22.2.post1\n","scipy                         1.4.1\n","screen-resolution-extra       0.0.0\n","scs                           2.1.4\n","seaborn                       0.11.2\n","semver                        2.13.0\n","Send2Trash                    1.8.0\n","setuptools                    57.4.0\n","setuptools-git                1.2\n","Shapely                       1.7.1\n","simplegeneric                 0.8.1\n","six                           1.15.0\n","sklearn                       0.0\n","sklearn-pandas                1.8.0\n","smart-open                    5.2.1\n","snowballstemmer               2.1.0\n","sortedcontainers              2.4.0\n","SoundFile                     0.10.3.post1\n","spacy                         2.2.4\n","Sphinx                        1.8.5\n","sphinxcontrib-serializinghtml 1.1.5\n","sphinxcontrib-websupport      1.2.4\n","SQLAlchemy                    1.4.25\n","sqlparse                      0.4.2\n","srsly                         1.0.5\n","statsmodels                   0.10.2\n","sympy                         1.7.1\n","tables                        3.4.4\n","tabulate                      0.8.9\n","tblib                         1.7.0\n","tensorboard                   2.6.0\n","tensorboard-data-server       0.6.1\n","tensorboard-plugin-wit        1.8.0\n","tensorboardX                  2.4\n","tensorflow                    2.6.0\n","tensorflow-datasets           4.0.1\n","tensorflow-estimator          2.6.0\n","tensorflow-gcs-config         2.6.0\n","tensorflow-hub                0.12.0\n","tensorflow-metadata           1.2.0\n","tensorflow-probability        0.14.1\n","termcolor                     1.1.0\n","terminado                     0.12.1\n","testpath                      0.5.0\n","text-unidecode                1.3\n","textblob                      0.15.3\n","Theano-PyMC                   1.1.2\n","thinc                         7.4.0\n","tifffile                      2021.10.12\n","timm                          0.4.12\n","toml                          0.10.2\n","tomli                         1.2.1\n","toolz                         0.11.1\n","torch                         1.9.0+cu111\n","torchsummary                  1.5.1\n","torchtext                     0.10.0\n","torchvision                   0.10.0+cu111\n","tornado                       5.1.1\n","tqdm                          4.62.3\n","traitlets                     5.1.0\n","ttach                         0.0.3\n","tweepy                        3.10.0\n","typeguard                     2.7.1\n","typing-extensions             3.7.4.3\n","tzlocal                       1.5.1\n","uritemplate                   3.0.1\n","urllib3                       1.24.3\n","vega-datasets                 0.9.0\n","wasabi                        0.8.2\n","wcwidth                       0.2.5\n","webencodings                  0.5.1\n","Werkzeug                      1.0.1\n","wheel                         0.37.0\n","widgetsnbextension            3.5.1\n","wordcloud                     1.5.0\n","wrapt                         1.12.1\n","xarray                        0.18.2\n","xgboost                       0.90\n","xkit                          0.0.0\n","xlrd                          1.1.0\n","xlwt                          1.3.0\n","yellowbrick                   0.9.1\n","zict                          2.0.0\n","zipp                          3.6.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"h31KAx1ZZEl9"},"source":["## Start Training\n","* by command line\n","* use argparse to set down hyper-parameter\n","\n","* 5-fold experiment is used here"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"bnCOfr2pXjs4","outputId":"fb455853-38f1-41b1-d6f6-8caae3764617"},"source":["!python Train.py --model_idx Hybrid2_384_401_PT_lf25_b8_k1 --lr 0.00001 --lrf 0.25 --enable_notify --enable_tensorboard --Pre_Trained_model_path /home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_PreTrain_000.pth --dataroot /data/pancreatic-cancer-project/dataset/fold_1 --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/runs"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Notify is waiting for reboost\n","*****************LOG_Cache_2021_10_28_07_05*****************\n","start monitoring:)\n","notify started\n","notify_frontend reboosted!\n","log_root_path log\n","mail_user tum9598@163.com\n","default_reciving_list ['tum9598@163.com']\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path='/home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_PreTrain_000.pth', att_module='SimAM', attn_drop_rate=0.0, backbone_PT_off=False, batch_size=8, check_minibatch=None, cls_token_off=False, dataroot='/data/pancreatic-cancer-project/dataset/fold_1', draw_root='/home/pancreatic-cancer-project/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=True, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=-1, intake_epochs=0, lr=1e-05, lrf=0.25, model_idx='Hybrid2_384_401_PT_lf25_b8_k1', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, pos_embedding_off=False)\n","we dont have more GPU idx here, try to use gpu_idx=0\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[ 2.1666e-01, -4.7421e-01,  1.8033e-01,  3.0284e-01, -4.8657e-01,\n","         -6.5892e-01,  6.7286e-01, -9.4735e-01,  1.8332e-03,  1.1280e+00,\n","          6.0691e-01,  4.4678e-01,  1.0305e+00,  2.6081e-01, -8.9324e-01,\n","          9.0739e-01,  3.3736e-01, -8.4321e-01, -5.3484e-01, -2.6153e-01,\n","          1.1813e-01,  5.8210e-01, -9.1074e-02,  5.5711e-02, -5.0008e-01,\n","          5.0046e-01,  2.2023e-01,  3.8575e-01, -3.6419e-01,  1.8775e-01,\n","         -1.0013e+00,  9.7029e-01, -8.9606e-01,  5.8526e-01, -6.0324e-02,\n","          2.8680e-01, -1.7486e-01, -5.7358e-02, -2.3304e-02, -8.9619e-02,\n","         -5.2647e-01,  7.6940e-01,  4.0491e-01, -1.8638e-01,  1.2026e+00,\n","         -2.9995e-01, -3.0298e-01, -5.5280e-01, -3.2249e-01,  5.9502e-01,\n","         -4.3468e-01,  1.0191e+00,  1.4346e-01,  1.5864e-01,  7.4061e-01,\n","         -3.8455e-01, -1.1300e+00,  4.2022e-01, -7.5100e-01, -4.4431e-01,\n","         -3.2544e-01,  4.3934e-01,  2.9867e-01,  1.0853e-01,  4.0149e-01,\n","          4.8915e-01,  6.2100e-02, -7.2858e-01, -8.0314e-02,  6.3522e-02,\n","          9.2666e-01, -4.2381e-01, -3.6368e-01,  1.6887e-02, -5.2490e-01,\n","         -5.2767e-01, -2.1943e-01,  5.2008e-01,  4.3857e-01, -6.1164e-01,\n","         -4.1595e-01,  2.7936e-01,  7.3350e-01,  7.9244e-01, -1.7026e-01,\n","          1.6747e-01, -6.8064e-02, -7.3537e-02, -1.0140e+00,  8.4919e-02,\n","         -4.0062e-01,  1.6448e+00, -9.2639e-01,  2.0900e-01, -1.8306e-01,\n","          5.8141e-01,  3.8690e-01, -6.2016e-01,  4.9578e-01,  1.0685e+00,\n","          8.6109e-02,  1.3977e-01,  6.8784e-01, -8.0958e-01,  2.0807e-01,\n","         -4.6999e-01, -1.7971e-01, -8.4584e-02,  6.8367e-01,  8.3208e-01,\n","          5.2042e-01, -4.3107e-01, -4.5932e-01, -4.8616e-01, -4.6352e-01,\n","         -3.3450e-01,  4.8264e-01, -2.5343e-01,  4.8577e-02, -2.6356e-01,\n","          1.0537e+00, -1.1945e-01, -1.7415e+00, -5.0386e-01, -2.2265e-01,\n","          3.1367e-01, -1.4120e+00, -3.5089e-01, -1.9413e-01,  5.0706e-02,\n","          1.0555e+00,  1.0856e-01,  4.9621e-01, -3.9441e-01,  3.0980e-01,\n","          1.5954e-01, -2.2117e-01,  4.4933e-01, -1.4019e-01,  3.3464e-01,\n","         -8.0265e-01,  7.6930e-01,  3.9676e-01, -2.3813e-01,  5.8820e-01,\n","         -2.5222e-01, -2.2237e-01, -5.7166e-01, -6.9520e-01, -8.6945e-01,\n","         -1.9836e-01, -5.2389e-01, -6.6921e-01, -9.6664e-01, -2.1290e-01,\n","          3.6217e-02,  5.8212e-01,  7.6754e-01,  6.3949e-01, -7.3677e-01,\n","          1.2266e+00, -1.0001e-01, -2.8125e-01, -8.0921e-01,  1.1078e+00,\n","          1.0405e+00, -3.8854e-01,  5.2377e-01,  4.7812e-01, -6.1291e-02,\n","         -6.7650e-01, -9.9664e-01, -7.8526e-01, -2.5582e-01,  8.0009e-01,\n","          1.6076e-01,  1.3886e-01,  5.7681e-01,  3.2688e-01, -1.0707e+00,\n","         -7.5648e-01,  3.7256e-01,  7.4912e-01,  1.5014e-01,  5.6243e-01,\n","          6.6609e-01,  3.8102e-01,  4.9880e-01,  2.9567e-01,  1.2317e+00,\n","          2.2053e-01,  1.0838e-01, -3.2360e-01, -4.1344e-01,  2.6800e-01,\n","          1.6090e-01,  9.9983e-01,  7.1696e-01,  3.0113e-01,  1.4047e-01,\n","         -2.8635e-01, -2.6977e-02,  1.0585e+00, -4.0660e-01, -4.8512e-01,\n","         -5.6495e-01,  4.2269e-01, -4.4172e-01, -2.9341e-01,  8.9416e-02,\n","          5.7455e-01, -1.5858e-01,  1.9142e-01, -8.2919e-01, -1.1784e-01,\n","         -3.8307e-01, -8.3623e-01, -1.1778e+00,  1.0831e+00,  2.3893e-01,\n","          5.4679e-01,  2.3990e-01, -9.2425e-02,  5.3054e-01, -3.4389e-01,\n","         -1.4973e+00, -3.8203e-01, -4.5449e-01, -2.0671e-01, -1.8606e-02,\n","          6.9127e-01,  1.2140e-01, -7.5049e-01,  2.3656e-01, -9.5200e-02,\n","         -4.1982e-01,  4.5942e-01,  3.1451e-01, -4.4832e-01,  3.2117e-01,\n","          1.5423e-03,  2.6317e-01,  8.3795e-01,  6.1409e-01,  4.5812e-01,\n","         -4.3683e-01, -2.7957e-01,  1.1908e-01,  1.0032e-01,  2.6231e-02,\n","          4.7835e-03,  3.9014e-01,  2.5367e-02, -9.4333e-01,  2.7289e-01,\n","          1.3458e+00, -7.0671e-01, -4.3741e-01,  6.2262e-01, -4.7800e-01,\n","          4.2114e-02, -5.2731e-01,  1.4530e-01,  3.4526e-01, -4.0380e-01,\n","          8.0879e-01,  2.0872e-01, -3.1978e-01, -4.1021e-01,  3.0624e-02,\n","         -9.4838e-01,  1.8232e-01,  8.7393e-01, -2.8509e-01,  2.8806e-01,\n","         -1.0527e-01, -5.5985e-01, -2.3851e-01, -6.7235e-01, -6.8656e-01,\n","          6.0549e-01, -4.0970e-03,  8.3409e-01,  1.6456e-01,  1.7790e-02,\n","         -6.0855e-01, -3.1545e-02, -2.7620e-01,  4.7811e-01,  1.0174e+00,\n","          6.7161e-01,  5.8914e-01, -2.6104e-02,  1.1465e+00,  4.7396e-01,\n","          1.7520e-01, -5.3694e-01, -1.0094e+00,  6.0517e-01, -6.2272e-01,\n","         -1.5679e-01, -8.0598e-01, -8.0097e-02,  1.4145e+00, -1.2229e+00,\n","         -8.1610e-03, -4.1985e-01, -8.1593e-01,  6.1630e-01, -6.2003e-01,\n","         -5.1867e-01, -1.3416e-01,  1.1829e-01, -6.4824e-01,  8.1688e-01,\n","          3.5813e-01, -8.2212e-01, -5.4484e-01,  1.0119e-01, -2.3940e-01,\n","          1.0492e+00, -3.2231e-01,  8.8072e-01, -2.0386e-01,  3.4266e-01,\n","         -2.1809e-04, -4.3811e-01, -1.4643e-01, -1.4370e-01,  2.2846e-01,\n","         -4.9339e-01, -3.7553e-02,  8.9154e-01,  1.3907e-01,  9.4544e-02,\n","          2.1967e-01,  1.0154e+00,  4.4208e-01, -4.6395e-01, -9.0063e-01,\n","         -6.6472e-01,  3.4370e-01, -1.0131e+00, -1.3204e+00, -1.0094e+00,\n","         -5.9364e-01, -4.8717e-01,  4.4058e-01,  5.4193e-01,  1.6144e-01,\n","         -7.4380e-01,  1.9032e-01,  2.3118e-02,  2.8254e-01, -3.4857e-01,\n","          1.1796e-01,  4.1222e-01, -1.8240e-01, -2.9825e-01,  1.6421e-01,\n","         -8.3378e-02,  1.9388e-01,  6.3008e-01, -6.3716e-01,  1.5108e+00,\n","          9.1688e-01,  5.8826e-01, -3.2557e-01,  3.7183e-01, -1.6559e+00,\n","         -1.1680e-01, -8.7413e-01, -3.1305e-01,  3.6092e-01,  6.5580e-01,\n","         -8.9679e-01, -5.7921e-01,  1.0326e-01,  1.0422e+00, -5.1449e-01,\n","          9.4280e-01,  4.0336e-01,  2.6656e-01, -3.8148e-01,  1.4276e-01,\n","          1.5177e-02, -9.5266e-01, -5.7478e-01, -7.0650e-01, -6.0620e-01,\n","          1.6522e-01,  7.8339e-01,  2.7598e-02,  6.0522e-01,  6.7714e-02,\n","         -2.0373e-01,  5.2184e-01, -2.0795e-01, -1.4365e-01,  6.2235e-01,\n","         -2.1461e-01,  9.8679e-02,  4.0264e-01,  9.4615e-01, -7.1391e-01,\n","         -5.0820e-02, -5.5782e-01,  8.4015e-01, -2.4695e-01,  2.0569e-01,\n","         -1.0167e+00, -4.0228e-01,  1.1637e+00, -2.4513e-01,  9.5664e-02,\n","          2.8576e-01,  1.1327e+00,  1.8957e-01, -7.1850e-01,  4.4865e-01,\n","          3.5293e-01,  4.0419e-01,  1.1109e+00,  1.3175e+00,  2.4401e-02,\n","          3.7667e-01, -2.5981e-01, -2.6797e-01,  1.5575e+00,  4.9660e-02,\n","          1.1472e-01, -1.1175e-02,  3.6860e-01,  6.4207e-01, -1.0836e-04,\n","         -6.2095e-01,  2.5976e-01,  3.8648e-01,  1.0039e+00,  5.3080e-01,\n","         -9.1269e-01,  1.0460e+00, -3.9773e-01,  4.7867e-01,  3.3357e-01,\n","          1.6247e-01, -8.7713e-03,  7.6417e-01, -1.5434e+00,  3.6742e-01,\n","         -1.7368e-01, -1.3163e+00,  1.3577e+00, -1.0784e-01, -1.1486e-01,\n","          1.2644e+00, -3.4705e-01,  2.6563e-01,  2.8580e-01, -2.3911e-01,\n","         -5.8467e-01, -4.9897e-01,  2.1585e-01,  1.4748e+00, -4.4899e-01,\n","          8.8774e-01, -1.6235e-01, -2.7376e-01, -7.1224e-01, -1.3764e-01,\n","          3.6147e-01,  6.7793e-01,  6.9520e-01,  2.7143e-01,  5.9280e-01,\n","          5.4819e-01,  4.9856e-01,  1.2604e+00,  2.9709e-01,  2.6040e-01,\n","         -5.8097e-01,  1.5439e-01,  8.0847e-01, -3.0217e-01,  6.4507e-01,\n","          2.2922e-02,  2.3991e-01,  1.2384e+00, -2.2171e-01, -7.0928e-03,\n","          1.9838e-01,  8.3678e-01, -8.5981e-01, -2.8568e-01,  1.9095e-01,\n","         -5.9930e-01,  3.4530e-01,  1.7907e-01, -5.8533e-01, -3.9108e-01,\n","          1.3534e-01, -3.9534e-01,  2.9089e-01,  1.1026e-01,  2.2106e-01,\n","         -8.9309e-02, -3.6811e-01, -2.6436e-01, -4.2888e-01, -1.5628e-01,\n","          3.5117e-01,  5.9574e-01,  1.6612e-01, -3.4786e-01, -2.6749e-01,\n","         -8.0357e-02,  9.3936e-01, -1.1385e+00,  6.2440e-01,  9.5759e-01,\n","         -4.1871e-01, -3.5787e-01, -3.8892e-01,  4.0981e-01, -3.9806e-01,\n","         -1.7236e-01,  2.1272e-01,  3.7206e-01,  7.2732e-01, -4.1594e-01,\n","          4.6727e-01, -8.8528e-01, -9.8807e-01, -1.5185e-01,  4.2987e-01,\n","         -1.7785e-01, -5.0763e-01, -8.4378e-01,  6.2516e-01,  4.7258e-01,\n","          7.2423e-01,  8.7806e-01,  4.1242e-01, -1.4148e-01, -5.0299e-01,\n","          7.8564e-01,  7.9717e-02, -6.8691e-02, -2.9585e-01, -3.4100e-01,\n","          5.4962e-01,  6.2462e-02, -1.0496e+00,  3.7820e-01,  9.5406e-01,\n","         -8.6697e-01,  3.3542e-01,  1.3459e-01,  1.1273e-01, -6.4730e-01,\n","         -3.3621e-01,  2.6752e-01,  2.4378e-01, -2.2441e-01,  2.6785e-01,\n","         -5.9391e-01, -4.1546e-01, -7.9487e-01, -2.9756e-01,  5.7530e-01,\n","          7.3612e-01, -1.3985e+00,  1.2317e+00,  7.2213e-01, -5.8227e-01,\n","         -1.0673e-01,  5.7164e-01,  1.5425e-01,  1.0895e+00,  1.2320e+00,\n","         -2.9984e-01, -8.0997e-01, -8.0534e-01,  2.7615e-01, -1.0259e-01,\n","         -2.0853e-01,  7.6011e-01, -2.0839e-01, -1.7049e-01, -8.2152e-02,\n","         -7.6952e-01,  5.5893e-01, -4.5167e-02,  2.1071e-01, -1.6695e-01,\n","         -9.4379e-01,  7.0505e-01, -1.0129e+00, -1.4160e+00, -9.1469e-01,\n","          6.5794e-02,  5.9263e-02,  4.3184e-01,  7.7075e-01,  1.1557e+00,\n","         -1.5775e-01, -6.4064e-01, -6.5827e-01, -8.9281e-01,  1.2247e+00,\n","         -7.1033e-02,  1.5717e-01,  2.5382e-01, -5.3365e-01, -4.3624e-01,\n","          8.6912e-02, -2.6298e-01,  1.1626e-01,  8.7539e-01, -1.9012e-01,\n","         -6.6729e-01, -2.3464e-01,  8.6478e-01,  7.2786e-01,  3.3397e-01,\n","         -1.6017e-01, -5.0254e-01, -7.3996e-02, -3.7829e-01, -1.4741e+00,\n","         -8.3302e-01,  3.7283e-01,  2.1826e-01,  2.5692e-02, -6.5851e-01,\n","         -2.9597e-01, -3.3820e-01,  1.3639e+00, -7.7488e-01,  5.1539e-01,\n","         -5.7388e-01, -7.8878e-02,  1.4294e-02, -1.1069e+00, -3.7966e-01,\n","         -8.9033e-01, -1.2349e+00,  8.7038e-01, -9.4274e-01,  7.7459e-01,\n","          2.9489e-03, -5.5035e-01, -4.9410e-01,  1.6765e-01, -8.5204e-01,\n","         -4.2691e-01, -1.8325e-01,  1.5029e+00,  5.1469e-01,  5.7784e-01,\n","         -6.3793e-01, -6.1114e-01, -4.0964e-02, -8.2097e-02, -1.5212e-01,\n","         -1.9229e-01,  3.4257e-01,  3.9545e-02, -9.6416e-02, -1.1933e-02,\n","         -9.0584e-01,  8.6432e-01, -3.7954e-01, -1.8582e-01,  5.3733e-01,\n","         -1.2165e-01,  2.3117e-01,  4.4549e-01,  9.0628e-02, -3.9202e-01,\n","          5.9542e-01, -6.2026e-01,  1.7630e-01, -2.6233e-01, -3.4569e-01,\n","          4.4749e-01, -1.3701e-01,  5.9270e-02, -8.8871e-01, -7.8990e-01,\n","         -8.5382e-01, -2.1154e-01, -1.2771e+00, -9.5926e-03,  8.8370e-01,\n","          7.4744e-01,  6.9917e-01,  1.4780e-01, -2.1493e-01,  3.7231e-01,\n","          9.2370e-02,  1.0832e+00,  3.9699e-01,  1.0125e-01,  7.1224e-01,\n","          6.8133e-01, -8.9262e-01, -1.1712e+00,  2.6976e-01,  5.7062e-01,\n","          4.7347e-01, -9.0269e-01, -7.5984e-02,  1.9798e-02,  4.9426e-01,\n","         -6.8980e-01,  6.2834e-01,  3.1884e-01,  2.1181e-01,  2.9812e-02,\n","         -1.4362e-01,  6.0778e-01,  9.0836e-01,  2.4475e-01,  2.1145e-01,\n","         -3.1287e-01, -1.2203e+00, -2.6419e-01, -4.4693e-01, -4.4690e-02,\n","          6.8615e-01,  4.1714e-01,  5.6715e-01,  1.3130e-02,  4.7644e-01,\n","         -1.9041e-01, -2.4661e-01,  3.8793e-01, -1.3892e-01, -5.6922e-01,\n","         -3.8136e-01,  7.2892e-01, -6.4470e-01, -5.5313e-01,  6.1247e-01,\n","         -1.0014e-01,  4.0849e-01, -1.9521e-01, -5.9512e-01, -6.4988e-02,\n","         -2.7915e-01,  5.3021e-01, -1.6933e-01, -4.2548e-01,  2.4398e-01,\n","         -2.7639e-01,  5.9434e-01,  1.4690e+00,  4.8321e-01,  1.6484e-01,\n","          6.0448e-02, -3.8277e-02,  1.6056e-01,  7.0794e-01, -2.1264e-01,\n","          2.2819e-01,  6.3278e-01,  1.9960e-02, -1.7677e-01,  1.8472e-01,\n","         -3.5790e-01, -2.3733e-01,  1.1483e-02, -9.6668e-01, -5.1292e-01,\n","          1.6635e-01,  1.5496e-01,  1.5968e-01, -6.0187e-01,  7.4434e-01,\n","          2.1636e-01, -1.9631e-02, -1.2121e+00, -1.9568e-01,  4.4568e-01,\n","         -5.8059e-01,  5.7306e-01, -3.5325e-01,  1.2262e+00,  8.5117e-01,\n","         -1.2517e+00,  1.5711e-01, -4.8338e-01, -8.9890e-01, -5.7489e-01,\n","          6.4357e-01, -7.7923e-01,  3.3649e-01,  1.3424e-01, -1.1829e-01,\n","         -2.0373e-01, -2.7749e-01, -1.3068e+00, -5.0447e-01, -4.9479e-01,\n","         -6.8277e-01,  5.1541e-01,  9.5475e-01, -1.2515e-01,  3.1012e-01,\n","         -2.8129e-01,  1.7821e+00,  8.9728e-01, -3.3743e-01,  2.3577e-01,\n","         -1.7557e-01, -1.1398e+00,  9.9451e-01, -9.4415e-01, -6.0988e-01,\n","          1.3445e-01, -3.4160e-01,  5.0410e-01, -3.7131e-01, -1.6956e-01,\n","          3.4758e-01, -4.7118e-01, -4.7098e-01, -2.7183e-01,  8.8055e-01,\n","          1.4070e-01,  2.8334e-01, -2.1244e-01, -8.2920e-02,  6.8698e-01,\n","         -1.3666e+00, -8.1465e-01,  3.3053e-01,  2.8022e-02,  1.4109e-01,\n","         -7.3691e-01,  3.9807e-01,  9.1929e-02, -5.7754e-01, -3.9033e-02,\n","          8.0497e-02, -1.2178e-01, -2.4387e-01,  4.7647e-01, -1.0630e-01,\n","         -1.0826e-01, -2.1110e-03,  3.7709e-01, -1.4875e-01, -1.1374e+00,\n","         -7.6128e-01, -3.7458e-02, -1.8034e-01, -3.6584e-01,  2.2185e-01,\n","         -4.3772e-01, -7.1709e-01,  5.8107e-01,  1.8911e-02,  2.8151e-01,\n","         -5.4206e-01,  8.0032e-01,  9.6944e-01, -2.8757e-01, -1.7112e-01,\n","         -6.1564e-01,  6.8253e-01,  1.6584e-01,  7.0866e-01, -6.5146e-01,\n","         -8.7727e-01,  1.8078e-01,  5.9838e-01,  7.1257e-01,  4.9618e-01,\n","          3.7922e-01,  9.9859e-01,  6.3601e-02,  1.6859e-01,  3.9038e-01,\n","          3.1408e-01, -5.3799e-01,  5.2695e-01, -7.0191e-01, -2.1992e-01,\n","         -1.0359e+00, -6.0567e-01,  2.2677e-01,  1.7703e-01, -1.1606e+00,\n","          2.3550e-01,  5.5554e-01,  1.9281e+00,  1.9194e-01, -8.5557e-01,\n","          4.5519e-02,  4.3140e-01, -1.1850e+00,  2.7465e-01, -3.5207e-01,\n","         -9.3445e-01, -2.0982e-01,  9.0532e-01, -1.1775e+00,  9.8909e-01,\n","         -7.2240e-01,  5.4872e-03,  6.5173e-01,  9.2605e-01,  3.5818e-01,\n","         -7.0264e-02, -5.3810e-01,  6.0329e-01,  7.2034e-02,  4.8261e-01,\n","         -7.4249e-02, -3.4379e-01, -8.3596e-01, -6.9483e-01, -1.6042e-01,\n","         -3.2902e-01, -2.7382e-01, -1.1209e+00, -3.7440e-01, -1.3012e+00,\n","         -1.0944e-02,  6.2558e-01, -2.1302e-01, -1.5804e-01,  1.0750e+00,\n","          1.9843e-01,  1.1140e+00, -1.3254e-01, -2.3597e-01,  6.4282e-01,\n","         -1.4200e-01,  6.1646e-01,  6.9602e-01,  1.4218e-01, -6.0943e-01,\n","         -2.3569e-01,  2.2932e-01,  2.0487e-01, -1.4491e+00, -1.1249e-01,\n","         -8.1519e-01,  2.7957e-01,  2.0120e-01,  8.3839e-01, -9.2751e-01,\n","          4.0007e-01,  1.0488e-02, -5.1090e-01, -4.0092e-02,  4.4054e-02,\n","         -8.8771e-03,  4.2877e-01, -6.0787e-02, -3.7034e-01, -4.1881e-01,\n","          6.2871e-01, -1.8778e-01, -4.2418e-01,  1.6102e-01, -9.5770e-02,\n","         -2.3623e-01,  4.4124e-01, -5.5353e-01, -2.9374e-01, -1.1476e-01,\n","         -2.6253e-01, -4.5752e-01,  9.6869e-01, -4.6147e-04, -5.1060e-01,\n","         -9.5821e-01,  1.0444e+00,  1.0781e+00,  8.4808e-01, -3.7346e-01,\n","          2.9457e-01,  4.7508e-02,  4.4786e-01,  1.0769e+00, -1.7285e-02,\n","         -4.1817e-01,  1.7504e-01, -5.0107e-01, -4.1750e-01, -7.8469e-02,\n","         -6.2529e-02,  7.1313e-01,  3.7026e-01, -5.6427e-01,  9.2629e-03]],\n","       grad_fn=<AddmmBackward>)\n","model is ready now!\n","pretrain model loaded\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 192, 192]           9,408\n","       BatchNorm2d-2         [-1, 64, 192, 192]             128\n","              ReLU-3         [-1, 64, 192, 192]               0\n","         MaxPool2d-4           [-1, 64, 96, 96]               0\n","            Conv2d-5           [-1, 64, 96, 96]           4,096\n","       BatchNorm2d-6           [-1, 64, 96, 96]             128\n","              ReLU-7           [-1, 64, 96, 96]               0\n","            Conv2d-8           [-1, 64, 96, 96]          36,864\n","       BatchNorm2d-9           [-1, 64, 96, 96]             128\n","             ReLU-10           [-1, 64, 96, 96]               0\n","           Conv2d-11          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-12          [-1, 256, 96, 96]             512\n","             ReLU-13          [-1, 256, 96, 96]               0\n","           Conv2d-14          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-15          [-1, 256, 96, 96]             512\n","             ReLU-16          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-17          [-1, 256, 96, 96]               0\n","           Conv2d-18           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-19           [-1, 64, 96, 96]             128\n","             ReLU-20           [-1, 64, 96, 96]               0\n","           Conv2d-21           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-22           [-1, 64, 96, 96]             128\n","             ReLU-23           [-1, 64, 96, 96]               0\n","           Conv2d-24          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-25          [-1, 256, 96, 96]             512\n","             ReLU-26          [-1, 256, 96, 96]               0\n","             ReLU-27          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-28          [-1, 256, 96, 96]               0\n","           Conv2d-29           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-30           [-1, 64, 96, 96]             128\n","             ReLU-31           [-1, 64, 96, 96]               0\n","           Conv2d-32           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-33           [-1, 64, 96, 96]             128\n","             ReLU-34           [-1, 64, 96, 96]               0\n","           Conv2d-35          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-36          [-1, 256, 96, 96]             512\n","             ReLU-37          [-1, 256, 96, 96]               0\n","             ReLU-38          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-39          [-1, 256, 96, 96]               0\n","           Conv2d-40          [-1, 128, 48, 48]          32,768\n","      BatchNorm2d-41          [-1, 128, 48, 48]             256\n","             ReLU-42          [-1, 128, 48, 48]               0\n","           Conv2d-43          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-44          [-1, 128, 48, 48]             256\n","             ReLU-45          [-1, 128, 48, 48]               0\n","           Conv2d-46          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-47          [-1, 512, 48, 48]           1,024\n","             ReLU-48          [-1, 512, 48, 48]               0\n","           Conv2d-49          [-1, 512, 48, 48]         131,072\n","      BatchNorm2d-50          [-1, 512, 48, 48]           1,024\n","             ReLU-51          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-52          [-1, 512, 48, 48]               0\n","           Conv2d-53          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-54          [-1, 128, 48, 48]             256\n","             ReLU-55          [-1, 128, 48, 48]               0\n","           Conv2d-56          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-57          [-1, 128, 48, 48]             256\n","             ReLU-58          [-1, 128, 48, 48]               0\n","           Conv2d-59          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-60          [-1, 512, 48, 48]           1,024\n","             ReLU-61          [-1, 512, 48, 48]               0\n","             ReLU-62          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-63          [-1, 512, 48, 48]               0\n","           Conv2d-64          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-65          [-1, 128, 48, 48]             256\n","             ReLU-66          [-1, 128, 48, 48]               0\n","           Conv2d-67          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-68          [-1, 128, 48, 48]             256\n","             ReLU-69          [-1, 128, 48, 48]               0\n","           Conv2d-70          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-71          [-1, 512, 48, 48]           1,024\n","             ReLU-72          [-1, 512, 48, 48]               0\n","             ReLU-73          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-74          [-1, 512, 48, 48]               0\n","           Conv2d-75          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-76          [-1, 128, 48, 48]             256\n","             ReLU-77          [-1, 128, 48, 48]               0\n","           Conv2d-78          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-79          [-1, 128, 48, 48]             256\n","             ReLU-80          [-1, 128, 48, 48]               0\n","           Conv2d-81          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-82          [-1, 512, 48, 48]           1,024\n","             ReLU-83          [-1, 512, 48, 48]               0\n","             ReLU-84          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-85          [-1, 512, 48, 48]               0\n","           Conv2d-86          [-1, 256, 24, 24]         131,072\n","      BatchNorm2d-87          [-1, 256, 24, 24]             512\n","             ReLU-88          [-1, 256, 24, 24]               0\n","           Conv2d-89          [-1, 256, 24, 24]         589,824\n","      BatchNorm2d-90          [-1, 256, 24, 24]             512\n","             ReLU-91          [-1, 256, 24, 24]               0\n","           Conv2d-92         [-1, 1024, 24, 24]         262,144\n","      BatchNorm2d-93         [-1, 1024, 24, 24]           2,048\n","             ReLU-94         [-1, 1024, 24, 24]               0\n","           Conv2d-95         [-1, 1024, 24, 24]         524,288\n","      BatchNorm2d-96         [-1, 1024, 24, 24]           2,048\n","             ReLU-97         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-98         [-1, 1024, 24, 24]               0\n","           Conv2d-99          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-100          [-1, 256, 24, 24]             512\n","            ReLU-101          [-1, 256, 24, 24]               0\n","          Conv2d-102          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-103          [-1, 256, 24, 24]             512\n","            ReLU-104          [-1, 256, 24, 24]               0\n","          Conv2d-105         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-106         [-1, 1024, 24, 24]           2,048\n","            ReLU-107         [-1, 1024, 24, 24]               0\n","            ReLU-108         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-109         [-1, 1024, 24, 24]               0\n","          Conv2d-110          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-111          [-1, 256, 24, 24]             512\n","            ReLU-112          [-1, 256, 24, 24]               0\n","          Conv2d-113          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-114          [-1, 256, 24, 24]             512\n","            ReLU-115          [-1, 256, 24, 24]               0\n","          Conv2d-116         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-117         [-1, 1024, 24, 24]           2,048\n","            ReLU-118         [-1, 1024, 24, 24]               0\n","            ReLU-119         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-120         [-1, 1024, 24, 24]               0\n","          Conv2d-121          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-122          [-1, 256, 24, 24]             512\n","            ReLU-123          [-1, 256, 24, 24]               0\n","          Conv2d-124          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-125          [-1, 256, 24, 24]             512\n","            ReLU-126          [-1, 256, 24, 24]               0\n","          Conv2d-127         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-128         [-1, 1024, 24, 24]           2,048\n","            ReLU-129         [-1, 1024, 24, 24]               0\n","            ReLU-130         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-131         [-1, 1024, 24, 24]               0\n","          Conv2d-132          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-133          [-1, 256, 24, 24]             512\n","            ReLU-134          [-1, 256, 24, 24]               0\n","          Conv2d-135          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-136          [-1, 256, 24, 24]             512\n","            ReLU-137          [-1, 256, 24, 24]               0\n","          Conv2d-138         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-139         [-1, 1024, 24, 24]           2,048\n","            ReLU-140         [-1, 1024, 24, 24]               0\n","            ReLU-141         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-142         [-1, 1024, 24, 24]               0\n","          Conv2d-143          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-144          [-1, 256, 24, 24]             512\n","            ReLU-145          [-1, 256, 24, 24]               0\n","          Conv2d-146          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-147          [-1, 256, 24, 24]             512\n","            ReLU-148          [-1, 256, 24, 24]               0\n","          Conv2d-149         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-150         [-1, 1024, 24, 24]           2,048\n","            ReLU-151         [-1, 1024, 24, 24]               0\n","            ReLU-152         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-153         [-1, 1024, 24, 24]               0\n","          Conv2d-154          [-1, 512, 12, 12]         524,288\n","     BatchNorm2d-155          [-1, 512, 12, 12]           1,024\n","            ReLU-156          [-1, 512, 12, 12]               0\n","          Conv2d-157          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-158          [-1, 512, 12, 12]           1,024\n","            ReLU-159          [-1, 512, 12, 12]               0\n","          Conv2d-160         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-161         [-1, 2048, 12, 12]           4,096\n","            ReLU-162         [-1, 2048, 12, 12]               0\n","          Conv2d-163         [-1, 2048, 12, 12]       2,097,152\n","     BatchNorm2d-164         [-1, 2048, 12, 12]           4,096\n","            ReLU-165         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-166         [-1, 2048, 12, 12]               0\n","          Conv2d-167          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-168          [-1, 512, 12, 12]           1,024\n","            ReLU-169          [-1, 512, 12, 12]               0\n","          Conv2d-170          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-171          [-1, 512, 12, 12]           1,024\n","            ReLU-172          [-1, 512, 12, 12]               0\n","          Conv2d-173         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-174         [-1, 2048, 12, 12]           4,096\n","            ReLU-175         [-1, 2048, 12, 12]               0\n","            ReLU-176         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-177         [-1, 2048, 12, 12]               0\n","          Conv2d-178          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-179          [-1, 512, 12, 12]           1,024\n","            ReLU-180          [-1, 512, 12, 12]               0\n","          Conv2d-181          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-182          [-1, 512, 12, 12]           1,024\n","            ReLU-183          [-1, 512, 12, 12]               0\n","          Conv2d-184         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-185         [-1, 2048, 12, 12]           4,096\n","            ReLU-186         [-1, 2048, 12, 12]               0\n","            ReLU-187         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-188         [-1, 2048, 12, 12]               0\n","Hybrid_backbone_4-189  [[-1, 256, 96, 96], [-1, 512, 48, 48], [-1, 1024, 24, 24], [-1, 2048, 12, 12]]               0\n","         Sigmoid-190         [-1, 2048, 12, 12]               0\n","    simam_module-191         [-1, 2048, 12, 12]               0\n","          Conv2d-192          [-1, 768, 12, 12]       1,573,632\n","Last_feature_map_Embed-193             [-1, 144, 768]               0\n","         Sigmoid-194          [-1, 256, 96, 96]               0\n","    simam_module-195          [-1, 256, 96, 96]               0\n","       MaxPool2d-196          [-1, 256, 12, 12]               0\n","          Conv2d-197          [-1, 768, 12, 12]         197,376\n","       LayerNorm-198             [-1, 144, 768]           1,536\n","       AvgPool2d-199          [-1, 256, 12, 12]               0\n","          Conv2d-200          [-1, 768, 12, 12]         197,376\n","       LayerNorm-201             [-1, 144, 768]           1,536\n","     Focus_Embed-202  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-203          [-1, 512, 48, 48]               0\n","    simam_module-204          [-1, 512, 48, 48]               0\n","       MaxPool2d-205          [-1, 512, 12, 12]               0\n","          Conv2d-206          [-1, 768, 12, 12]         393,984\n","       LayerNorm-207             [-1, 144, 768]           1,536\n","       AvgPool2d-208          [-1, 512, 12, 12]               0\n","          Conv2d-209          [-1, 768, 12, 12]         393,984\n","       LayerNorm-210             [-1, 144, 768]           1,536\n","     Focus_Embed-211  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-212         [-1, 1024, 24, 24]               0\n","    simam_module-213         [-1, 1024, 24, 24]               0\n","       MaxPool2d-214         [-1, 1024, 12, 12]               0\n","          Conv2d-215          [-1, 768, 12, 12]         787,200\n","       LayerNorm-216             [-1, 144, 768]           1,536\n","       AvgPool2d-217         [-1, 1024, 12, 12]               0\n","          Conv2d-218          [-1, 768, 12, 12]         787,200\n","       LayerNorm-219             [-1, 144, 768]           1,536\n","     Focus_Embed-220  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-221         [-1, 2048, 12, 12]               0\n","    simam_module-222         [-1, 2048, 12, 12]               0\n","       MaxPool2d-223         [-1, 2048, 12, 12]               0\n","          Conv2d-224          [-1, 768, 12, 12]       1,573,632\n","       LayerNorm-225             [-1, 144, 768]           1,536\n","       AvgPool2d-226         [-1, 2048, 12, 12]               0\n","          Conv2d-227          [-1, 768, 12, 12]       1,573,632\n","       LayerNorm-228             [-1, 144, 768]           1,536\n","     Focus_Embed-229  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Dropout-230             [-1, 145, 768]               0\n","         Dropout-231             [-1, 145, 768]               0\n","         Dropout-232             [-1, 145, 768]               0\n","         Dropout-233             [-1, 145, 768]               0\n","         Dropout-234             [-1, 145, 768]               0\n","         Dropout-235             [-1, 145, 768]               0\n","         Dropout-236             [-1, 145, 768]               0\n","         Dropout-237             [-1, 145, 768]               0\n","         Dropout-238             [-1, 145, 768]               0\n","       LayerNorm-239             [-1, 145, 768]           1,536\n","          Linear-240            [-1, 145, 2304]       1,771,776\n","         Dropout-241          [-1, 8, 145, 145]               0\n","          Linear-242             [-1, 145, 768]         590,592\n","         Dropout-243             [-1, 145, 768]               0\n","       Attention-244             [-1, 145, 768]               0\n","        Identity-245             [-1, 145, 768]               0\n","       LayerNorm-246             [-1, 145, 768]           1,536\n","          Linear-247            [-1, 145, 3072]       2,362,368\n","            GELU-248            [-1, 145, 3072]               0\n","         Dropout-249            [-1, 145, 3072]               0\n","          Linear-250             [-1, 145, 768]       2,360,064\n","         Dropout-251             [-1, 145, 768]               0\n","             FFN-252             [-1, 145, 768]               0\n","        Identity-253             [-1, 145, 768]               0\n","       LayerNorm-254             [-1, 145, 768]           1,536\n","          Linear-255             [-1, 145, 768]         590,592\n","          Linear-256             [-1, 145, 768]         590,592\n","          Linear-257             [-1, 145, 768]         590,592\n","         Dropout-258          [-1, 8, 145, 145]               0\n","          Linear-259             [-1, 145, 768]         590,592\n","         Dropout-260             [-1, 145, 768]               0\n","Guided_Attention-261             [-1, 145, 768]               0\n","        Identity-262             [-1, 145, 768]               0\n","       LayerNorm-263             [-1, 145, 768]           1,536\n","          Linear-264            [-1, 145, 3072]       2,362,368\n","            GELU-265            [-1, 145, 3072]               0\n","         Dropout-266            [-1, 145, 3072]               0\n","          Linear-267             [-1, 145, 768]       2,360,064\n","         Dropout-268             [-1, 145, 768]               0\n","             FFN-269             [-1, 145, 768]               0\n","        Identity-270             [-1, 145, 768]               0\n","   Decoder_Block-271             [-1, 145, 768]               0\n","       LayerNorm-272             [-1, 145, 768]           1,536\n","          Linear-273            [-1, 145, 2304]       1,771,776\n","         Dropout-274          [-1, 8, 145, 145]               0\n","          Linear-275             [-1, 145, 768]         590,592\n","         Dropout-276             [-1, 145, 768]               0\n","       Attention-277             [-1, 145, 768]               0\n","        Identity-278             [-1, 145, 768]               0\n","       LayerNorm-279             [-1, 145, 768]           1,536\n","          Linear-280            [-1, 145, 3072]       2,362,368\n","            GELU-281            [-1, 145, 3072]               0\n","         Dropout-282            [-1, 145, 3072]               0\n","          Linear-283             [-1, 145, 768]       2,360,064\n","         Dropout-284             [-1, 145, 768]               0\n","             FFN-285             [-1, 145, 768]               0\n","        Identity-286             [-1, 145, 768]               0\n","       LayerNorm-287             [-1, 145, 768]           1,536\n","          Linear-288             [-1, 145, 768]         590,592\n","          Linear-289             [-1, 145, 768]         590,592\n","          Linear-290             [-1, 145, 768]         590,592\n","         Dropout-291          [-1, 8, 145, 145]               0\n","          Linear-292             [-1, 145, 768]         590,592\n","         Dropout-293             [-1, 145, 768]               0\n","Guided_Attention-294             [-1, 145, 768]               0\n","        Identity-295             [-1, 145, 768]               0\n","       LayerNorm-296             [-1, 145, 768]           1,536\n","          Linear-297            [-1, 145, 3072]       2,362,368\n","            GELU-298            [-1, 145, 3072]               0\n","         Dropout-299            [-1, 145, 3072]               0\n","          Linear-300             [-1, 145, 768]       2,360,064\n","         Dropout-301             [-1, 145, 768]               0\n","             FFN-302             [-1, 145, 768]               0\n","        Identity-303             [-1, 145, 768]               0\n","   Decoder_Block-304             [-1, 145, 768]               0\n","       LayerNorm-305             [-1, 145, 768]           1,536\n","          Linear-306            [-1, 145, 2304]       1,771,776\n","         Dropout-307          [-1, 8, 145, 145]               0\n","          Linear-308             [-1, 145, 768]         590,592\n","         Dropout-309             [-1, 145, 768]               0\n","       Attention-310             [-1, 145, 768]               0\n","        Identity-311             [-1, 145, 768]               0\n","       LayerNorm-312             [-1, 145, 768]           1,536\n","          Linear-313            [-1, 145, 3072]       2,362,368\n","            GELU-314            [-1, 145, 3072]               0\n","         Dropout-315            [-1, 145, 3072]               0\n","          Linear-316             [-1, 145, 768]       2,360,064\n","         Dropout-317             [-1, 145, 768]               0\n","             FFN-318             [-1, 145, 768]               0\n","        Identity-319             [-1, 145, 768]               0\n","       LayerNorm-320             [-1, 145, 768]           1,536\n","          Linear-321             [-1, 145, 768]         590,592\n","          Linear-322             [-1, 145, 768]         590,592\n","          Linear-323             [-1, 145, 768]         590,592\n","         Dropout-324          [-1, 8, 145, 145]               0\n","          Linear-325             [-1, 145, 768]         590,592\n","         Dropout-326             [-1, 145, 768]               0\n","Guided_Attention-327             [-1, 145, 768]               0\n","        Identity-328             [-1, 145, 768]               0\n","       LayerNorm-329             [-1, 145, 768]           1,536\n","          Linear-330            [-1, 145, 3072]       2,362,368\n","            GELU-331            [-1, 145, 3072]               0\n","         Dropout-332            [-1, 145, 3072]               0\n","          Linear-333             [-1, 145, 768]       2,360,064\n","         Dropout-334             [-1, 145, 768]               0\n","             FFN-335             [-1, 145, 768]               0\n","        Identity-336             [-1, 145, 768]               0\n","   Decoder_Block-337             [-1, 145, 768]               0\n","       LayerNorm-338             [-1, 145, 768]           1,536\n","          Linear-339            [-1, 145, 2304]       1,771,776\n","         Dropout-340          [-1, 8, 145, 145]               0\n","          Linear-341             [-1, 145, 768]         590,592\n","         Dropout-342             [-1, 145, 768]               0\n","       Attention-343             [-1, 145, 768]               0\n","        Identity-344             [-1, 145, 768]               0\n","       LayerNorm-345             [-1, 145, 768]           1,536\n","          Linear-346            [-1, 145, 3072]       2,362,368\n","            GELU-347            [-1, 145, 3072]               0\n","         Dropout-348            [-1, 145, 3072]               0\n","          Linear-349             [-1, 145, 768]       2,360,064\n","         Dropout-350             [-1, 145, 768]               0\n","             FFN-351             [-1, 145, 768]               0\n","        Identity-352             [-1, 145, 768]               0\n","       LayerNorm-353             [-1, 145, 768]           1,536\n","          Linear-354             [-1, 145, 768]         590,592\n","          Linear-355             [-1, 145, 768]         590,592\n","          Linear-356             [-1, 145, 768]         590,592\n","         Dropout-357          [-1, 8, 145, 145]               0\n","          Linear-358             [-1, 145, 768]         590,592\n","         Dropout-359             [-1, 145, 768]               0\n","Guided_Attention-360             [-1, 145, 768]               0\n","        Identity-361             [-1, 145, 768]               0\n","       LayerNorm-362             [-1, 145, 768]           1,536\n","          Linear-363            [-1, 145, 3072]       2,362,368\n","            GELU-364            [-1, 145, 3072]               0\n","         Dropout-365            [-1, 145, 3072]               0\n","          Linear-366             [-1, 145, 768]       2,360,064\n","         Dropout-367             [-1, 145, 768]               0\n","             FFN-368             [-1, 145, 768]               0\n","        Identity-369             [-1, 145, 768]               0\n","   Decoder_Block-370             [-1, 145, 768]               0\n","       LayerNorm-371             [-1, 145, 768]           1,536\n","        Identity-372                  [-1, 768]               0\n","          Linear-373                    [-1, 2]           1,538\n","================================================================\n","Total params: 87,704,386\n","Trainable params: 87,704,386\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 372029.91\n","Params size (MB): 334.57\n","Estimated Total Size (MB): 372366.16\n","----------------------------------------------------------------\n","model : Hybrid2_384_401_PT_lf25_b8_k1\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 50 minibatch: 1      time used: 21.006819009780884\n","minibatch AVG loss: 0.7770465588569642\n","Epoch: 1     train index of 50 minibatch: 2      time used: 20.20495629310608\n","minibatch AVG loss: 0.5312426587939263\n","Epoch: 1     train index of 50 minibatch: 3      time used: 19.92425847053528\n","minibatch AVG loss: 0.5018732690811157\n","Epoch: 1     train index of 50 minibatch: 4      time used: 20.011133670806885\n","minibatch AVG loss: 0.4706096479296684\n","Epoch: 1     train index of 50 minibatch: 5      time used: 19.9827823638916\n","minibatch AVG loss: 0.48027938455343244\n","Epoch: 1     train index of 50 minibatch: 6      time used: 19.70240616798401\n","minibatch AVG loss: 0.37899460658431056\n","\n","Epoch: 1  train \n","Loss: 0.5097  Acc: 76.2712\n","negative precision: 77.9817  recall: 87.8301\n","negative sensitivity: 87.8301  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 71.8085\n","negative TP: 1530.0\n","negative TN: 540.0\n","negative FP: 432.0\n","negative FN: 212.0\n","positive precision: 71.8085  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 87.8301\n","positive FPR: 12.1699  NPV: 77.9817\n","positive TP: 540.0\n","positive TN: 1530.0\n","positive FP: 212.0\n","positive FN: 432.0\n","\n","\n","Epoch: 1     val index of 50 minibatch: 1      time used: 11.220596313476562\n","minibatch AVG loss: 0.1364599609375\n","\n","Epoch: 1  val \n","Loss: 0.3364  Acc: 85.7143\n","negative precision: 84.6626  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 69.1358\n","negative FPR: 30.8642  NPV: 88.4211\n","negative TP: 414.0\n","negative TN: 168.0\n","negative FP: 75.0\n","negative FN: 22.0\n","positive precision: 88.4211  recall: 69.1358\n","positive sensitivity: 69.1358  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 84.6626\n","positive TP: 168.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 75.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 50 minibatch: 1      time used: 20.232014656066895\n","minibatch AVG loss: 0.40255492746829985\n","Epoch: 2     train index of 50 minibatch: 2      time used: 19.6154727935791\n","minibatch AVG loss: 0.35061840653419496\n","Epoch: 2     train index of 50 minibatch: 3      time used: 19.25081706047058\n","minibatch AVG loss: 0.4021101984381676\n","Epoch: 2     train index of 50 minibatch: 4      time used: 19.535440921783447\n","minibatch AVG loss: 0.3314268001914024\n","Epoch: 2     train index of 50 minibatch: 5      time used: 19.291913747787476\n","minibatch AVG loss: 0.3719310896098614\n","Epoch: 2     train index of 50 minibatch: 6      time used: 19.573765754699707\n","minibatch AVG loss: 0.24681882798671723\n","\n","Epoch: 2  train \n","Loss: 0.3536  Acc: 86.4038\n","negative precision: 87.9072  recall: 91.3892\n","negative sensitivity: 91.3892  specificity: 77.4691\n","negative FPR: 22.5309  NPV: 83.3887\n","negative TP: 1592.0\n","negative TN: 753.0\n","negative FP: 219.0\n","negative FN: 150.0\n","positive precision: 83.3887  recall: 77.4691\n","positive sensitivity: 77.4691  specificity: 91.3892\n","positive FPR: 8.6108  NPV: 87.9072\n","positive TP: 753.0\n","positive TN: 1592.0\n","positive FP: 150.0\n","positive FN: 219.0\n","\n","\n","Epoch: 2     val index of 50 minibatch: 1      time used: 11.14408540725708\n","minibatch AVG loss: 0.13301366936415435\n","\n","Epoch: 2  val \n","Loss: 0.3198  Acc: 87.1870\n","negative precision: 87.2068  recall: 93.8073\n","negative sensitivity: 93.8073  specificity: 75.3086\n","negative FPR: 24.6914  NPV: 87.1429\n","negative TP: 409.0\n","negative TN: 183.0\n","negative FP: 60.0\n","negative FN: 27.0\n","positive precision: 87.1429  recall: 75.3086\n","positive sensitivity: 75.3086  specificity: 93.8073\n","positive FPR: 6.1927  NPV: 87.2068\n","positive TP: 183.0\n","positive TN: 409.0\n","positive FP: 27.0\n","positive FN: 60.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 50 minibatch: 1      time used: 20.07665705680847\n","minibatch AVG loss: 0.34942041486501696\n","Epoch: 3     train index of 50 minibatch: 2      time used: 19.981261014938354\n","minibatch AVG loss: 0.33454710088670253\n","Epoch: 3     train index of 50 minibatch: 3      time used: 19.276864528656006\n","minibatch AVG loss: 0.38458852618932726\n","Epoch: 3     train index of 50 minibatch: 4      time used: 19.312251091003418\n","minibatch AVG loss: 0.38409750498831274\n","Epoch: 3     train index of 50 minibatch: 5      time used: 19.16904091835022\n","minibatch AVG loss: 0.3350936122238636\n","Epoch: 3     train index of 50 minibatch: 6      time used: 19.463927268981934\n","minibatch AVG loss: 0.3813130784034729\n","\n","Epoch: 3  train \n","Loss: 0.3591  Acc: 85.0774\n","negative precision: 87.3255  recall: 89.7819\n","negative sensitivity: 89.7819  specificity: 76.6461\n","negative FPR: 23.3539  NPV: 80.7151\n","negative TP: 1564.0\n","negative TN: 745.0\n","negative FP: 227.0\n","negative FN: 178.0\n","positive precision: 80.7151  recall: 76.6461\n","positive sensitivity: 76.6461  specificity: 89.7819\n","positive FPR: 10.2181  NPV: 87.3255\n","positive TP: 745.0\n","positive TN: 1564.0\n","positive FP: 178.0\n","positive FN: 227.0\n","\n","\n","Epoch: 3     val index of 50 minibatch: 1      time used: 11.132020235061646\n","minibatch AVG loss: 0.17864232014864684\n","\n","Epoch: 3  val \n","Loss: 0.2391  Acc: 90.5744\n","negative precision: 91.3333  recall: 94.2661\n","negative sensitivity: 94.2661  specificity: 83.9506\n","negative FPR: 16.0494  NPV: 89.0830\n","negative TP: 411.0\n","negative TN: 204.0\n","negative FP: 39.0\n","negative FN: 25.0\n","positive precision: 89.0830  recall: 83.9506\n","positive sensitivity: 83.9506  specificity: 94.2661\n","positive FPR: 5.7339  NPV: 91.3333\n","positive TP: 204.0\n","positive TN: 411.0\n","positive FP: 25.0\n","positive FN: 39.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 50 minibatch: 1      time used: 20.041223764419556\n","minibatch AVG loss: 0.33157059878110884\n","Epoch: 4     train index of 50 minibatch: 2      time used: 19.622199535369873\n","minibatch AVG loss: 0.33088226467370985\n","Epoch: 4     train index of 50 minibatch: 3      time used: 19.531830310821533\n","minibatch AVG loss: 0.3398422974348068\n","Epoch: 4     train index of 50 minibatch: 4      time used: 19.409989595413208\n","minibatch AVG loss: 0.2693491652980447\n","Epoch: 4     train index of 50 minibatch: 5      time used: 19.343129634857178\n","minibatch AVG loss: 0.2936747479066253\n","Epoch: 4     train index of 50 minibatch: 6      time used: 19.231691360473633\n","minibatch AVG loss: 0.26779350951313974\n","\n","Epoch: 4  train \n","Loss: 0.3047  Acc: 87.8777\n","negative precision: 89.4913  recall: 91.9059\n","negative sensitivity: 91.9059  specificity: 80.6584\n","negative FPR: 19.3416  NPV: 84.7568\n","negative TP: 1601.0\n","negative TN: 784.0\n","negative FP: 188.0\n","negative FN: 141.0\n","positive precision: 84.7568  recall: 80.6584\n","positive sensitivity: 80.6584  specificity: 91.9059\n","positive FPR: 8.0941  NPV: 89.4913\n","positive TP: 784.0\n","positive TN: 1601.0\n","positive FP: 141.0\n","positive FN: 188.0\n","\n","\n","Epoch: 4     val index of 50 minibatch: 1      time used: 10.973761558532715\n","minibatch AVG loss: 0.15158482968807221\n","\n","Epoch: 4  val \n","Loss: 0.2334  Acc: 90.8689\n","negative precision: 90.4762  recall: 95.8716\n","negative sensitivity: 95.8716  specificity: 81.8930\n","negative FPR: 18.1070  NPV: 91.7051\n","negative TP: 418.0\n","negative TN: 199.0\n","negative FP: 44.0\n","negative FN: 18.0\n","positive precision: 91.7051  recall: 81.8930\n","positive sensitivity: 81.8930  specificity: 95.8716\n","positive FPR: 4.1284  NPV: 90.4762\n","positive TP: 199.0\n","positive TN: 418.0\n","positive FP: 18.0\n","positive FN: 44.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 50 minibatch: 1      time used: 19.97056794166565\n","minibatch AVG loss: 0.2811636333912611\n","Epoch: 5     train index of 50 minibatch: 2      time used: 19.13171410560608\n","minibatch AVG loss: 0.36047255881130696\n","Epoch: 5     train index of 50 minibatch: 3      time used: 19.640147924423218\n","minibatch AVG loss: 0.3346264309436083\n","Epoch: 5     train index of 50 minibatch: 4      time used: 19.328031539916992\n","minibatch AVG loss: 0.26980390921235087\n","Epoch: 5     train index of 50 minibatch: 5      time used: 19.602766752243042\n","minibatch AVG loss: 0.24751519553363324\n","Epoch: 5     train index of 50 minibatch: 6      time used: 20.32582926750183\n","minibatch AVG loss: 0.2817310632765293\n","\n","Epoch: 5  train \n","Loss: 0.2948  Acc: 88.4672\n","negative precision: 89.9832  recall: 92.3077\n","negative sensitivity: 92.3077  specificity: 81.5844\n","negative FPR: 18.4156  NPV: 85.5448\n","negative TP: 1608.0\n","negative TN: 793.0\n","negative FP: 179.0\n","negative FN: 134.0\n","positive precision: 85.5448  recall: 81.5844\n","positive sensitivity: 81.5844  specificity: 92.3077\n","positive FPR: 7.6923  NPV: 89.9832\n","positive TP: 793.0\n","positive TN: 1608.0\n","positive FP: 134.0\n","positive FN: 179.0\n","\n","\n","Epoch: 5     val index of 50 minibatch: 1      time used: 11.06003475189209\n","minibatch AVG loss: 0.0878801648132503\n","\n","Epoch: 5  val \n","Loss: 0.2614  Acc: 88.6598\n","negative precision: 86.4097  recall: 97.7064\n","negative sensitivity: 97.7064  specificity: 72.4280\n","negative FPR: 27.5720  NPV: 94.6237\n","negative TP: 426.0\n","negative TN: 176.0\n","negative FP: 67.0\n","negative FN: 10.0\n","positive precision: 94.6237  recall: 72.4280\n","positive sensitivity: 72.4280  specificity: 97.7064\n","positive FPR: 2.2936  NPV: 86.4097\n","positive TP: 176.0\n","positive TN: 426.0\n","positive FP: 10.0\n","positive FN: 67.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 50 minibatch: 1      time used: 19.732176542282104\n","minibatch AVG loss: 0.2651646974310279\n","Epoch: 6     train index of 50 minibatch: 2      time used: 19.39472508430481\n","minibatch AVG loss: 0.3278516522794962\n","Epoch: 6     train index of 50 minibatch: 3      time used: 19.640864610671997\n","minibatch AVG loss: 0.31239006713032724\n","Epoch: 6     train index of 50 minibatch: 4      time used: 19.43091893196106\n","minibatch AVG loss: 0.2604485617391765\n","Epoch: 6     train index of 50 minibatch: 5      time used: 20.138060092926025\n","minibatch AVG loss: 0.28037061538547275\n","Epoch: 6     train index of 50 minibatch: 6      time used: 19.678126096725464\n","minibatch AVG loss: 0.21995330948382616\n","\n","Epoch: 6  train \n","Loss: 0.2673  Acc: 89.5726\n","negative precision: 90.7314  recall: 93.2836\n","negative sensitivity: 93.2836  specificity: 82.9218\n","negative FPR: 17.0782  NPV: 87.3239\n","negative TP: 1625.0\n","negative TN: 806.0\n","negative FP: 166.0\n","negative FN: 117.0\n","positive precision: 87.3239  recall: 82.9218\n","positive sensitivity: 82.9218  specificity: 93.2836\n","positive FPR: 6.7164  NPV: 90.7314\n","positive TP: 806.0\n","positive TN: 1625.0\n","positive FP: 117.0\n","positive FN: 166.0\n","\n","\n","Epoch: 6     val index of 50 minibatch: 1      time used: 11.059108972549438\n","minibatch AVG loss: 0.4239613469876349\n","\n","Epoch: 6  val \n","Loss: 0.3038  Acc: 89.5434\n","negative precision: 97.9003  recall: 85.5505\n","negative sensitivity: 85.5505  specificity: 96.7078\n","negative FPR: 3.2922  NPV: 78.8591\n","negative TP: 373.0\n","negative TN: 235.0\n","negative FP: 8.0\n","negative FN: 63.0\n","positive precision: 78.8591  recall: 96.7078\n","positive sensitivity: 96.7078  specificity: 85.5505\n","positive FPR: 14.4495  NPV: 97.9003\n","positive TP: 235.0\n","positive TN: 373.0\n","positive FP: 63.0\n","positive FN: 8.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 50 minibatch: 1      time used: 19.8851797580719\n","minibatch AVG loss: 0.2627042084932327\n","Epoch: 7     train index of 50 minibatch: 2      time used: 19.11192274093628\n","minibatch AVG loss: 0.23845813654363154\n","Epoch: 7     train index of 50 minibatch: 3      time used: 19.500532865524292\n","minibatch AVG loss: 0.24574942128732802\n","Epoch: 7     train index of 50 minibatch: 4      time used: 19.418244123458862\n","minibatch AVG loss: 0.2977258466556668\n","Epoch: 7     train index of 50 minibatch: 5      time used: 18.919495820999146\n","minibatch AVG loss: 0.2553052769601345\n","Epoch: 7     train index of 50 minibatch: 6      time used: 19.280710697174072\n","minibatch AVG loss: 0.2646691082417965\n","\n","Epoch: 7  train \n","Loss: 0.2707  Acc: 88.9462\n","negative precision: 90.5968  recall: 92.3651\n","negative sensitivity: 92.3651  specificity: 82.8189\n","negative FPR: 17.1811  NPV: 85.8209\n","negative TP: 1609.0\n","negative TN: 805.0\n","negative FP: 167.0\n","negative FN: 133.0\n","positive precision: 85.8209  recall: 82.8189\n","positive sensitivity: 82.8189  specificity: 92.3651\n","positive FPR: 7.6349  NPV: 90.5968\n","positive TP: 805.0\n","positive TN: 1609.0\n","positive FP: 133.0\n","positive FN: 167.0\n","\n","\n","Epoch: 7     val index of 50 minibatch: 1      time used: 11.064738988876343\n","minibatch AVG loss: 0.27027895090170206\n","\n","Epoch: 7  val \n","Loss: 0.2289  Acc: 90.7216\n","negative precision: 96.0494  recall: 89.2202\n","negative sensitivity: 89.2202  specificity: 93.4156\n","negative FPR: 6.5844  NPV: 82.8467\n","negative TP: 389.0\n","negative TN: 227.0\n","negative FP: 16.0\n","negative FN: 47.0\n","positive precision: 82.8467  recall: 93.4156\n","positive sensitivity: 93.4156  specificity: 89.2202\n","positive FPR: 10.7798  NPV: 96.0494\n","positive TP: 227.0\n","positive TN: 389.0\n","positive FP: 47.0\n","positive FN: 16.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 50 minibatch: 1      time used: 20.207125186920166\n","minibatch AVG loss: 0.2255888044834137\n","Epoch: 8     train index of 50 minibatch: 2      time used: 19.62531089782715\n","minibatch AVG loss: 0.21855913057923318\n","Epoch: 8     train index of 50 minibatch: 3      time used: 19.99074101448059\n","minibatch AVG loss: 0.20187863342463971\n","Epoch: 8     train index of 50 minibatch: 4      time used: 19.220778703689575\n","minibatch AVG loss: 0.25486500475555657\n","Epoch: 8     train index of 50 minibatch: 5      time used: 19.388931274414062\n","minibatch AVG loss: 0.2153635787963867\n","Epoch: 8     train index of 50 minibatch: 6      time used: 19.95595073699951\n","minibatch AVG loss: 0.20001997020095585\n","\n","Epoch: 8  train \n","Loss: 0.2248  Acc: 91.6728\n","negative precision: 93.1663  recall: 93.9150\n","negative sensitivity: 93.9150  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 88.9353\n","negative TP: 1636.0\n","negative TN: 852.0\n","negative FP: 120.0\n","negative FN: 106.0\n","positive precision: 88.9353  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 93.9150\n","positive FPR: 6.0850  NPV: 93.1663\n","positive TP: 852.0\n","positive TN: 1636.0\n","positive FP: 106.0\n","positive FN: 120.0\n","\n","\n","Epoch: 8     val index of 50 minibatch: 1      time used: 11.189339399337769\n","minibatch AVG loss: 0.2501244878449506\n","\n","Epoch: 8  val \n","Loss: 0.2177  Acc: 90.7216\n","negative precision: 96.7419  recall: 88.5321\n","negative sensitivity: 88.5321  specificity: 94.6502\n","negative FPR: 5.3498  NPV: 82.1429\n","negative TP: 386.0\n","negative TN: 230.0\n","negative FP: 13.0\n","negative FN: 50.0\n","positive precision: 82.1429  recall: 94.6502\n","positive sensitivity: 94.6502  specificity: 88.5321\n","positive FPR: 11.4679  NPV: 96.7419\n","positive TP: 230.0\n","positive TN: 386.0\n","positive FP: 50.0\n","positive FN: 13.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 50 minibatch: 1      time used: 20.079553842544556\n","minibatch AVG loss: 0.2774258604645729\n","Epoch: 9     train index of 50 minibatch: 2      time used: 19.224947452545166\n","minibatch AVG loss: 0.2693441803008318\n","Epoch: 9     train index of 50 minibatch: 3      time used: 19.291521787643433\n","minibatch AVG loss: 0.2214994763955474\n","Epoch: 9     train index of 50 minibatch: 4      time used: 19.359846353530884\n","minibatch AVG loss: 0.22485747184604407\n","Epoch: 9     train index of 50 minibatch: 5      time used: 19.47071123123169\n","minibatch AVG loss: 0.20384292623959482\n","Epoch: 9     train index of 50 minibatch: 6      time used: 19.106967449188232\n","minibatch AVG loss: 0.2467622132599354\n","\n","Epoch: 9  train \n","Loss: 0.2473  Acc: 90.3832\n","negative precision: 91.6714  recall: 93.5132\n","negative sensitivity: 93.5132  specificity: 84.7737\n","negative FPR: 15.2263  NPV: 87.9402\n","negative TP: 1629.0\n","negative TN: 824.0\n","negative FP: 148.0\n","negative FN: 113.0\n","positive precision: 87.9402  recall: 84.7737\n","positive sensitivity: 84.7737  specificity: 93.5132\n","positive FPR: 6.4868  NPV: 91.6714\n","positive TP: 824.0\n","positive TN: 1629.0\n","positive FP: 113.0\n","positive FN: 148.0\n","\n","\n","Epoch: 9     val index of 50 minibatch: 1      time used: 10.993048191070557\n","minibatch AVG loss: 0.13552206969907274\n","\n","Epoch: 9  val \n","Loss: 0.1659  Acc: 92.7835\n","negative precision: 94.2792  recall: 94.4954\n","negative sensitivity: 94.4954  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 90.0826\n","negative TP: 412.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 24.0\n","positive precision: 90.0826  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 94.4954\n","positive FPR: 5.5046  NPV: 94.2792\n","positive TP: 218.0\n","positive TN: 412.0\n","positive FP: 24.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 50 minibatch: 1      time used: 19.843677759170532\n","minibatch AVG loss: 0.1926598458364606\n","Epoch: 10     train index of 50 minibatch: 2      time used: 19.485466241836548\n","minibatch AVG loss: 0.2127337508648634\n","Epoch: 10     train index of 50 minibatch: 3      time used: 19.32175040245056\n","minibatch AVG loss: 0.24474350892007352\n","Epoch: 10     train index of 50 minibatch: 4      time used: 19.36768341064453\n","minibatch AVG loss: 0.17713282214477657\n","Epoch: 10     train index of 50 minibatch: 5      time used: 19.197054147720337\n","minibatch AVG loss: 0.25157234750688073\n","Epoch: 10     train index of 50 minibatch: 6      time used: 19.482988357543945\n","minibatch AVG loss: 0.21546390250325204\n","\n","Epoch: 10  train \n","Loss: 0.2109  Acc: 92.2623\n","negative precision: 93.3258  recall: 94.7187\n","negative sensitivity: 94.7187  specificity: 87.8601\n","negative FPR: 12.1399  NPV: 90.2748\n","negative TP: 1650.0\n","negative TN: 854.0\n","negative FP: 118.0\n","negative FN: 92.0\n","positive precision: 90.2748  recall: 87.8601\n","positive sensitivity: 87.8601  specificity: 94.7187\n","positive FPR: 5.2813  NPV: 93.3258\n","positive TP: 854.0\n","positive TN: 1650.0\n","positive FP: 92.0\n","positive FN: 118.0\n","\n","\n","Epoch: 10     val index of 50 minibatch: 1      time used: 11.028770685195923\n","minibatch AVG loss: 0.18951989203662378\n","\n","Epoch: 10  val \n","Loss: 0.1890  Acc: 92.0471\n","negative precision: 94.2130  recall: 93.3486\n","negative sensitivity: 93.3486  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 88.2591\n","negative TP: 407.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 29.0\n","positive precision: 88.2591  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 93.3486\n","positive FPR: 6.6514  NPV: 94.2130\n","positive TP: 218.0\n","positive TN: 407.0\n","positive FP: 29.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 50 minibatch: 1      time used: 20.15910840034485\n","minibatch AVG loss: 0.12804017337039114\n","Epoch: 11     train index of 50 minibatch: 2      time used: 19.231390953063965\n","minibatch AVG loss: 0.2769928863458335\n","Epoch: 11     train index of 50 minibatch: 3      time used: 19.679479360580444\n","minibatch AVG loss: 0.19860387742519378\n","Epoch: 11     train index of 50 minibatch: 4      time used: 19.421319484710693\n","minibatch AVG loss: 0.2014737663976848\n","Epoch: 11     train index of 50 minibatch: 5      time used: 19.168655395507812\n","minibatch AVG loss: 0.21452221654355527\n","Epoch: 11     train index of 50 minibatch: 6      time used: 19.346241235733032\n","minibatch AVG loss: 0.2562372617051005\n","\n","Epoch: 11  train \n","Loss: 0.2180  Acc: 91.5991\n","negative precision: 93.3562  recall: 93.5706\n","negative sensitivity: 93.5706  specificity: 88.0658\n","negative FPR: 11.9342  NPV: 88.4298\n","negative TP: 1630.0\n","negative TN: 856.0\n","negative FP: 116.0\n","negative FN: 112.0\n","positive precision: 88.4298  recall: 88.0658\n","positive sensitivity: 88.0658  specificity: 93.5706\n","positive FPR: 6.4294  NPV: 93.3562\n","positive TP: 856.0\n","positive TN: 1630.0\n","positive FP: 112.0\n","positive FN: 116.0\n","\n","\n","Epoch: 11     val index of 50 minibatch: 1      time used: 11.078365325927734\n","minibatch AVG loss: 0.09093422841091524\n","\n","Epoch: 11  val \n","Loss: 0.1717  Acc: 93.3726\n","negative precision: 93.5412  recall: 96.3303\n","negative sensitivity: 96.3303  specificity: 88.0658\n","negative FPR: 11.9342  NPV: 93.0435\n","negative TP: 420.0\n","negative TN: 214.0\n","negative FP: 29.0\n","negative FN: 16.0\n","positive precision: 93.0435  recall: 88.0658\n","positive sensitivity: 88.0658  specificity: 96.3303\n","positive FPR: 3.6697  NPV: 93.5412\n","positive TP: 214.0\n","positive TN: 420.0\n","positive FP: 16.0\n","positive FN: 29.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 50 minibatch: 1      time used: 20.036115884780884\n","minibatch AVG loss: 0.1510191412642598\n","Epoch: 12     train index of 50 minibatch: 2      time used: 19.486217498779297\n","minibatch AVG loss: 0.22022478276863694\n","Epoch: 12     train index of 50 minibatch: 3      time used: 19.41449999809265\n","minibatch AVG loss: 0.21829520801082253\n","Epoch: 12     train index of 50 minibatch: 4      time used: 19.406787872314453\n","minibatch AVG loss: 0.19614169493317604\n","Epoch: 12     train index of 50 minibatch: 5      time used: 19.246906280517578\n","minibatch AVG loss: 0.19725833609700202\n","Epoch: 12     train index of 50 minibatch: 6      time used: 19.358341693878174\n","minibatch AVG loss: 0.12413103824481368\n","\n","Epoch: 12  train \n","Loss: 0.1933  Acc: 92.2623\n","negative precision: 93.2280  recall: 94.8335\n","negative sensitivity: 94.8335  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 90.4459\n","negative TP: 1652.0\n","negative TN: 852.0\n","negative FP: 120.0\n","negative FN: 90.0\n","positive precision: 90.4459  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 94.8335\n","positive FPR: 5.1665  NPV: 93.2280\n","positive TP: 852.0\n","positive TN: 1652.0\n","positive FP: 90.0\n","positive FN: 120.0\n","\n","\n","Epoch: 12     val index of 50 minibatch: 1      time used: 10.997161388397217\n","minibatch AVG loss: 0.15801379234471824\n","\n","Epoch: 12  val \n","Loss: 0.1888  Acc: 92.3417\n","negative precision: 94.2396  recall: 93.8073\n","negative sensitivity: 93.8073  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 88.9796\n","negative TP: 409.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 27.0\n","positive precision: 88.9796  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 93.8073\n","positive FPR: 6.1927  NPV: 94.2396\n","positive TP: 218.0\n","positive TN: 409.0\n","positive FP: 27.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 50 minibatch: 1      time used: 19.9077410697937\n","minibatch AVG loss: 0.1583120960276574\n","Epoch: 13     train index of 50 minibatch: 2      time used: 20.143229246139526\n","minibatch AVG loss: 0.18212638458237052\n","Epoch: 13     train index of 50 minibatch: 3      time used: 19.669459581375122\n","minibatch AVG loss: 0.2100476247444749\n","Epoch: 13     train index of 50 minibatch: 4      time used: 19.42519187927246\n","minibatch AVG loss: 0.21506057303398848\n","Epoch: 13     train index of 50 minibatch: 5      time used: 19.10241413116455\n","minibatch AVG loss: 0.15253273893147706\n","Epoch: 13     train index of 50 minibatch: 6      time used: 19.487971305847168\n","minibatch AVG loss: 0.18387638438493015\n","\n","Epoch: 13  train \n","Loss: 0.1801  Acc: 93.1466\n","negative precision: 94.1043  recall: 95.2928\n","negative sensitivity: 95.2928  specificity: 89.3004\n","negative FPR: 10.6996  NPV: 91.3684\n","negative TP: 1660.0\n","negative TN: 868.0\n","negative FP: 104.0\n","negative FN: 82.0\n","positive precision: 91.3684  recall: 89.3004\n","positive sensitivity: 89.3004  specificity: 95.2928\n","positive FPR: 4.7072  NPV: 94.1043\n","positive TP: 868.0\n","positive TN: 1660.0\n","positive FP: 82.0\n","positive FN: 104.0\n","\n","\n","Epoch: 13     val index of 50 minibatch: 1      time used: 11.082156896591187\n","minibatch AVG loss: 0.16367739817826077\n","\n","Epoch: 13  val \n","Loss: 0.1756  Acc: 93.0781\n","negative precision: 95.1276  recall: 94.0367\n","negative sensitivity: 94.0367  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 89.5161\n","negative TP: 410.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 26.0\n","positive precision: 89.5161  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 94.0367\n","positive FPR: 5.9633  NPV: 95.1276\n","positive TP: 222.0\n","positive TN: 410.0\n","positive FP: 26.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 50 minibatch: 1      time used: 19.66621494293213\n","minibatch AVG loss: 0.19042315086349845\n","Epoch: 14     train index of 50 minibatch: 2      time used: 19.55449342727661\n","minibatch AVG loss: 0.15317123662680387\n","Epoch: 14     train index of 50 minibatch: 3      time used: 19.347310304641724\n","minibatch AVG loss: 0.1812303387746215\n","Epoch: 14     train index of 50 minibatch: 4      time used: 19.46407723426819\n","minibatch AVG loss: 0.17100241536274552\n","Epoch: 14     train index of 50 minibatch: 5      time used: 19.503072261810303\n","minibatch AVG loss: 0.1386093381047249\n","Epoch: 14     train index of 50 minibatch: 6      time used: 19.624802112579346\n","minibatch AVG loss: 0.16351339891552924\n","\n","Epoch: 14  train \n","Loss: 0.1615  Acc: 93.5520\n","negative precision: 94.2906  recall: 95.7520\n","negative sensitivity: 95.7520  specificity: 89.6091\n","negative FPR: 10.3909  NPV: 92.1693\n","negative TP: 1668.0\n","negative TN: 871.0\n","negative FP: 101.0\n","negative FN: 74.0\n","positive precision: 92.1693  recall: 89.6091\n","positive sensitivity: 89.6091  specificity: 95.7520\n","positive FPR: 4.2480  NPV: 94.2906\n","positive TP: 871.0\n","positive TN: 1668.0\n","positive FP: 74.0\n","positive FN: 101.0\n","\n","\n","Epoch: 14     val index of 50 minibatch: 1      time used: 11.044768810272217\n","minibatch AVG loss: 0.10212235100596445\n","\n","Epoch: 14  val \n","Loss: 0.2174  Acc: 92.4890\n","negative precision: 91.9390  recall: 96.7890\n","negative sensitivity: 96.7890  specificity: 84.7737\n","negative FPR: 15.2263  NPV: 93.6364\n","negative TP: 422.0\n","negative TN: 206.0\n","negative FP: 37.0\n","negative FN: 14.0\n","positive precision: 93.6364  recall: 84.7737\n","positive sensitivity: 84.7737  specificity: 96.7890\n","positive FPR: 3.2110  NPV: 91.9390\n","positive TP: 206.0\n","positive TN: 422.0\n","positive FP: 14.0\n","positive FN: 37.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 50 minibatch: 1      time used: 20.126001596450806\n","minibatch AVG loss: 0.21921151403337716\n","Epoch: 15     train index of 50 minibatch: 2      time used: 19.37364673614502\n","minibatch AVG loss: 0.19479268297553062\n","Epoch: 15     train index of 50 minibatch: 3      time used: 19.661733865737915\n","minibatch AVG loss: 0.16927970787510277\n","Epoch: 15     train index of 50 minibatch: 4      time used: 19.4493088722229\n","minibatch AVG loss: 0.10719904648140073\n","Epoch: 15     train index of 50 minibatch: 5      time used: 19.67999839782715\n","minibatch AVG loss: 0.18027274028398096\n","Epoch: 15     train index of 50 minibatch: 6      time used: 19.642606258392334\n","minibatch AVG loss: 0.18257953114807607\n","\n","Epoch: 15  train \n","Loss: 0.1777  Acc: 92.9624\n","negative precision: 94.3904  recall: 94.6613\n","negative sensitivity: 94.6613  specificity: 89.9177\n","negative FPR: 10.0823  NPV: 90.3826\n","negative TP: 1649.0\n","negative TN: 874.0\n","negative FP: 98.0\n","negative FN: 93.0\n","positive precision: 90.3826  recall: 89.9177\n","positive sensitivity: 89.9177  specificity: 94.6613\n","positive FPR: 5.3387  NPV: 94.3904\n","positive TP: 874.0\n","positive TN: 1649.0\n","positive FP: 93.0\n","positive FN: 98.0\n","\n","\n","Epoch: 15     val index of 50 minibatch: 1      time used: 11.228747844696045\n","minibatch AVG loss: 0.2671224418599741\n","\n","Epoch: 15  val \n","Loss: 0.2038  Acc: 91.8999\n","negative precision: 97.0370  recall: 90.1376\n","negative sensitivity: 90.1376  specificity: 95.0617\n","negative FPR: 4.9383  NPV: 84.3066\n","negative TP: 393.0\n","negative TN: 231.0\n","negative FP: 12.0\n","negative FN: 43.0\n","positive precision: 84.3066  recall: 95.0617\n","positive sensitivity: 95.0617  specificity: 90.1376\n","positive FPR: 9.8624  NPV: 97.0370\n","positive TP: 231.0\n","positive TN: 393.0\n","positive FP: 43.0\n","positive FN: 12.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 50 minibatch: 1      time used: 20.35259985923767\n","minibatch AVG loss: 0.15971294996328653\n","Epoch: 16     train index of 50 minibatch: 2      time used: 19.601892471313477\n","minibatch AVG loss: 0.16398581201210619\n","Epoch: 16     train index of 50 minibatch: 3      time used: 19.813530683517456\n","minibatch AVG loss: 0.1888888044282794\n","Epoch: 16     train index of 50 minibatch: 4      time used: 19.81645131111145\n","minibatch AVG loss: 0.14951541564427318\n","Epoch: 16     train index of 50 minibatch: 5      time used: 19.452438831329346\n","minibatch AVG loss: 0.1271263524144888\n","Epoch: 16     train index of 50 minibatch: 6      time used: 19.928898334503174\n","minibatch AVG loss: 0.18315533468965442\n","\n","Epoch: 16  train \n","Loss: 0.1611  Acc: 93.5151\n","negative precision: 94.4381  recall: 95.5224\n","negative sensitivity: 95.5224  specificity: 89.9177\n","negative FPR: 10.0823  NPV: 91.8067\n","negative TP: 1664.0\n","negative TN: 874.0\n","negative FP: 98.0\n","negative FN: 78.0\n","positive precision: 91.8067  recall: 89.9177\n","positive sensitivity: 89.9177  specificity: 95.5224\n","positive FPR: 4.4776  NPV: 94.4381\n","positive TP: 874.0\n","positive TN: 1664.0\n","positive FP: 78.0\n","positive FN: 98.0\n","\n","\n","Epoch: 16     val index of 50 minibatch: 1      time used: 11.207242012023926\n","minibatch AVG loss: 0.11952047332961228\n","\n","Epoch: 16  val \n","Loss: 0.1759  Acc: 93.2253\n","negative precision: 94.3182  recall: 95.1835\n","negative sensitivity: 95.1835  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 91.2134\n","negative TP: 415.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 21.0\n","positive precision: 91.2134  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 95.1835\n","positive FPR: 4.8165  NPV: 94.3182\n","positive TP: 218.0\n","positive TN: 415.0\n","positive FP: 21.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 50 minibatch: 1      time used: 20.609690189361572\n","minibatch AVG loss: 0.15102118078619242\n","Epoch: 17     train index of 50 minibatch: 2      time used: 19.50831413269043\n","minibatch AVG loss: 0.15650006119161844\n","Epoch: 17     train index of 50 minibatch: 3      time used: 19.566094636917114\n","minibatch AVG loss: 0.16742766845971346\n","Epoch: 17     train index of 50 minibatch: 4      time used: 19.907670736312866\n","minibatch AVG loss: 0.14225248908624052\n","Epoch: 17     train index of 50 minibatch: 5      time used: 19.769139289855957\n","minibatch AVG loss: 0.13209496224299072\n","Epoch: 17     train index of 50 minibatch: 6      time used: 19.37739634513855\n","minibatch AVG loss: 0.14911570938304067\n","\n","Epoch: 17  train \n","Loss: 0.1517  Acc: 94.1046\n","negative precision: 95.0969  recall: 95.7520\n","negative sensitivity: 95.7520  specificity: 91.1523\n","negative FPR: 8.8477  NPV: 92.2917\n","negative TP: 1668.0\n","negative TN: 886.0\n","negative FP: 86.0\n","negative FN: 74.0\n","positive precision: 92.2917  recall: 91.1523\n","positive sensitivity: 91.1523  specificity: 95.7520\n","positive FPR: 4.2480  NPV: 95.0969\n","positive TP: 886.0\n","positive TN: 1668.0\n","positive FP: 74.0\n","positive FN: 86.0\n","\n","\n","Epoch: 17     val index of 50 minibatch: 1      time used: 11.221569061279297\n","minibatch AVG loss: 0.20734572029556148\n","\n","Epoch: 17  val \n","Loss: 0.1973  Acc: 92.1944\n","negative precision: 94.4316  recall: 93.3486\n","negative sensitivity: 93.3486  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 88.3065\n","negative TP: 407.0\n","negative TN: 219.0\n","negative FP: 24.0\n","negative FN: 29.0\n","positive precision: 88.3065  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 93.3486\n","positive FPR: 6.6514  NPV: 94.4316\n","positive TP: 219.0\n","positive TN: 407.0\n","positive FP: 29.0\n","positive FN: 24.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 50 minibatch: 1      time used: 20.255189180374146\n","minibatch AVG loss: 0.15778107509016992\n","Epoch: 18     train index of 50 minibatch: 2      time used: 19.808223009109497\n","minibatch AVG loss: 0.1741536822915077\n","Epoch: 18     train index of 50 minibatch: 3      time used: 19.758365392684937\n","minibatch AVG loss: 0.15080994520336388\n","Epoch: 18     train index of 50 minibatch: 4      time used: 19.434459686279297\n","minibatch AVG loss: 0.14633367424830795\n","Epoch: 18     train index of 50 minibatch: 5      time used: 20.049937963485718\n","minibatch AVG loss: 0.11403652286157012\n","Epoch: 18     train index of 50 minibatch: 6      time used: 20.025703191757202\n","minibatch AVG loss: 0.12259842593222857\n","\n","Epoch: 18  train \n","Loss: 0.1397  Acc: 94.6942\n","negative precision: 95.7617  recall: 95.9816\n","negative sensitivity: 95.9816  specificity: 92.3868\n","negative FPR: 7.6132  NPV: 92.7686\n","negative TP: 1672.0\n","negative TN: 898.0\n","negative FP: 74.0\n","negative FN: 70.0\n","positive precision: 92.7686  recall: 92.3868\n","positive sensitivity: 92.3868  specificity: 95.9816\n","positive FPR: 4.0184  NPV: 95.7617\n","positive TP: 898.0\n","positive TN: 1672.0\n","positive FP: 70.0\n","positive FN: 74.0\n","\n","\n","Epoch: 18     val index of 50 minibatch: 1      time used: 11.208615064620972\n","minibatch AVG loss: 0.25837497565720696\n","\n","Epoch: 18  val \n","Loss: 0.2306  Acc: 91.3108\n","negative precision: 94.1452  recall: 92.2018\n","negative sensitivity: 92.2018  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 86.5079\n","negative TP: 402.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 34.0\n","positive precision: 86.5079  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 92.2018\n","positive FPR: 7.7982  NPV: 94.1452\n","positive TP: 218.0\n","positive TN: 402.0\n","positive FP: 34.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 50 minibatch: 1      time used: 20.584919214248657\n","minibatch AVG loss: 0.12306438006926328\n","Epoch: 19     train index of 50 minibatch: 2      time used: 19.457576513290405\n","minibatch AVG loss: 0.15485309526789934\n","Epoch: 19     train index of 50 minibatch: 3      time used: 19.918087482452393\n","minibatch AVG loss: 0.10426268523558974\n","Epoch: 19     train index of 50 minibatch: 4      time used: 19.69279956817627\n","minibatch AVG loss: 0.156023865416646\n","Epoch: 19     train index of 50 minibatch: 5      time used: 19.843754291534424\n","minibatch AVG loss: 0.12944280721247195\n","Epoch: 19     train index of 50 minibatch: 6      time used: 19.35791039466858\n","minibatch AVG loss: 0.1475586838182062\n","\n","Epoch: 19  train \n","Loss: 0.1330  Acc: 94.7679\n","negative precision: 95.6100  recall: 96.2687\n","negative sensitivity: 96.2687  specificity: 92.0782\n","negative FPR: 7.9218  NPV: 93.2292\n","negative TP: 1677.0\n","negative TN: 895.0\n","negative FP: 77.0\n","negative FN: 65.0\n","positive precision: 93.2292  recall: 92.0782\n","positive sensitivity: 92.0782  specificity: 96.2687\n","positive FPR: 3.7313  NPV: 95.6100\n","positive TP: 895.0\n","positive TN: 1677.0\n","positive FP: 65.0\n","positive FN: 77.0\n","\n","\n","Epoch: 19     val index of 50 minibatch: 1      time used: 11.0248122215271\n","minibatch AVG loss: 0.1888679737391067\n","\n","Epoch: 19  val \n","Loss: 0.1988  Acc: 92.3417\n","negative precision: 95.7143  recall: 92.2018\n","negative sensitivity: 92.2018  specificity: 92.5926\n","negative FPR: 7.4074  NPV: 86.8726\n","negative TP: 402.0\n","negative TN: 225.0\n","negative FP: 18.0\n","negative FN: 34.0\n","positive precision: 86.8726  recall: 92.5926\n","positive sensitivity: 92.5926  specificity: 92.2018\n","positive FPR: 7.7982  NPV: 95.7143\n","positive TP: 225.0\n","positive TN: 402.0\n","positive FP: 34.0\n","positive FN: 18.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 50 minibatch: 1      time used: 20.305911540985107\n","minibatch AVG loss: 0.14051910290494563\n","Epoch: 20     train index of 50 minibatch: 2      time used: 19.556790590286255\n","minibatch AVG loss: 0.1081644740793854\n","Epoch: 20     train index of 50 minibatch: 3      time used: 19.27016258239746\n","minibatch AVG loss: 0.12236110994359478\n","Epoch: 20     train index of 50 minibatch: 4      time used: 19.299348831176758\n","minibatch AVG loss: 0.12132673665415496\n","Epoch: 20     train index of 50 minibatch: 5      time used: 19.360803365707397\n","minibatch AVG loss: 0.17217991668730975\n","Epoch: 20     train index of 50 minibatch: 6      time used: 19.39496111869812\n","minibatch AVG loss: 0.13838177980855107\n","\n","Epoch: 20  train \n","Loss: 0.1341  Acc: 94.4363\n","negative precision: 95.5352  recall: 95.8094\n","negative sensitivity: 95.8094  specificity: 91.9753\n","negative FPR: 8.0247  NPV: 92.4509\n","negative TP: 1669.0\n","negative TN: 894.0\n","negative FP: 78.0\n","negative FN: 73.0\n","positive precision: 92.4509  recall: 91.9753\n","positive sensitivity: 91.9753  specificity: 95.8094\n","positive FPR: 4.1906  NPV: 95.5352\n","positive TP: 894.0\n","positive TN: 1669.0\n","positive FP: 73.0\n","positive FN: 78.0\n","\n","\n","Epoch: 20     val index of 50 minibatch: 1      time used: 10.985485792160034\n","minibatch AVG loss: 0.12024250025104266\n","\n","Epoch: 20  val \n","Loss: 0.1650  Acc: 93.2253\n","negative precision: 94.5205  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 90.8714\n","negative TP: 414.0\n","negative TN: 219.0\n","negative FP: 24.0\n","negative FN: 22.0\n","positive precision: 90.8714  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 94.5205\n","positive TP: 219.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 24.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 50 minibatch: 1      time used: 20.212629795074463\n","minibatch AVG loss: 0.1130537415947765\n","Epoch: 21     train index of 50 minibatch: 2      time used: 19.385414361953735\n","minibatch AVG loss: 0.1474962090793997\n","Epoch: 21     train index of 50 minibatch: 3      time used: 19.11230444908142\n","minibatch AVG loss: 0.09390749479644\n","Epoch: 21     train index of 50 minibatch: 4      time used: 19.65159273147583\n","minibatch AVG loss: 0.12599034428596498\n","Epoch: 21     train index of 50 minibatch: 5      time used: 19.171536922454834\n","minibatch AVG loss: 0.0976817101193592\n","Epoch: 21     train index of 50 minibatch: 6      time used: 19.421369552612305\n","minibatch AVG loss: 0.14102053808048368\n","\n","Epoch: 21  train \n","Loss: 0.1198  Acc: 95.4679\n","negative precision: 96.4429  recall: 96.4983\n","negative sensitivity: 96.4983  specificity: 93.6214\n","negative FPR: 6.3786  NPV: 93.7178\n","negative TP: 1681.0\n","negative TN: 910.0\n","negative FP: 62.0\n","negative FN: 61.0\n","positive precision: 93.7178  recall: 93.6214\n","positive sensitivity: 93.6214  specificity: 96.4983\n","positive FPR: 3.5017  NPV: 96.4429\n","positive TP: 910.0\n","positive TN: 1681.0\n","positive FP: 61.0\n","positive FN: 62.0\n","\n","\n","Epoch: 21     val index of 50 minibatch: 1      time used: 11.187731266021729\n","minibatch AVG loss: 0.15593136907693406\n","\n","Epoch: 21  val \n","Loss: 0.1716  Acc: 93.5199\n","negative precision: 95.1613  recall: 94.7248\n","negative sensitivity: 94.7248  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 90.6122\n","negative TP: 413.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 23.0\n","positive precision: 90.6122  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 94.7248\n","positive FPR: 5.2752  NPV: 95.1613\n","positive TP: 222.0\n","positive TN: 413.0\n","positive FP: 23.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 50 minibatch: 1      time used: 20.502208471298218\n","minibatch AVG loss: 0.12869046784006058\n","Epoch: 22     train index of 50 minibatch: 2      time used: 19.761771202087402\n","minibatch AVG loss: 0.11420067780651152\n","Epoch: 22     train index of 50 minibatch: 3      time used: 19.788480520248413\n","minibatch AVG loss: 0.1111550996825099\n","Epoch: 22     train index of 50 minibatch: 4      time used: 19.717313289642334\n","minibatch AVG loss: 0.11529325881972909\n","Epoch: 22     train index of 50 minibatch: 5      time used: 19.6028048992157\n","minibatch AVG loss: 0.15630221694242208\n","Epoch: 22     train index of 50 minibatch: 6      time used: 19.60884666442871\n","minibatch AVG loss: 0.15758205177262424\n","\n","Epoch: 22  train \n","Loss: 0.1278  Acc: 94.9153\n","negative precision: 95.9862  recall: 96.0964\n","negative sensitivity: 96.0964  specificity: 92.7984\n","negative FPR: 7.2016  NPV: 92.9897\n","negative TP: 1674.0\n","negative TN: 902.0\n","negative FP: 70.0\n","negative FN: 68.0\n","positive precision: 92.9897  recall: 92.7984\n","positive sensitivity: 92.7984  specificity: 96.0964\n","positive FPR: 3.9036  NPV: 95.9862\n","positive TP: 902.0\n","positive TN: 1674.0\n","positive FP: 68.0\n","positive FN: 70.0\n","\n","\n","Epoch: 22     val index of 50 minibatch: 1      time used: 11.369729995727539\n","minibatch AVG loss: 0.27853848677506904\n","\n","Epoch: 22  val \n","Loss: 0.2168  Acc: 91.7526\n","negative precision: 96.7980  recall: 90.1376\n","negative sensitivity: 90.1376  specificity: 94.6502\n","negative FPR: 5.3498  NPV: 84.2491\n","negative TP: 393.0\n","negative TN: 230.0\n","negative FP: 13.0\n","negative FN: 43.0\n","positive precision: 84.2491  recall: 94.6502\n","positive sensitivity: 94.6502  specificity: 90.1376\n","positive FPR: 9.8624  NPV: 96.7980\n","positive TP: 230.0\n","positive TN: 393.0\n","positive FP: 43.0\n","positive FN: 13.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 50 minibatch: 1      time used: 20.170580625534058\n","minibatch AVG loss: 0.11432798163965345\n","Epoch: 23     train index of 50 minibatch: 2      time used: 19.60135555267334\n","minibatch AVG loss: 0.1031870720628649\n","Epoch: 23     train index of 50 minibatch: 3      time used: 19.703239917755127\n","minibatch AVG loss: 0.062116660014726224\n","Epoch: 23     train index of 50 minibatch: 4      time used: 19.656993865966797\n","minibatch AVG loss: 0.1426103133056313\n","Epoch: 23     train index of 50 minibatch: 5      time used: 19.625696420669556\n","minibatch AVG loss: 0.12560329116880894\n","Epoch: 23     train index of 50 minibatch: 6      time used: 19.734631776809692\n","minibatch AVG loss: 0.12073374600149692\n","\n","Epoch: 23  train \n","Loss: 0.1094  Acc: 95.5785\n","negative precision: 96.5023  recall: 96.6131\n","negative sensitivity: 96.6131  specificity: 93.7243\n","negative FPR: 6.2757  NPV: 93.9175\n","negative TP: 1683.0\n","negative TN: 911.0\n","negative FP: 61.0\n","negative FN: 59.0\n","positive precision: 93.9175  recall: 93.7243\n","positive sensitivity: 93.7243  specificity: 96.6131\n","positive FPR: 3.3869  NPV: 96.5023\n","positive TP: 911.0\n","positive TN: 1683.0\n","positive FP: 59.0\n","positive FN: 61.0\n","\n","\n","Epoch: 23     val index of 50 minibatch: 1      time used: 11.18826961517334\n","minibatch AVG loss: 0.18897778456535888\n","\n","Epoch: 23  val \n","Loss: 0.1800  Acc: 92.1944\n","negative precision: 95.0588  recall: 92.6606\n","negative sensitivity: 92.6606  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 87.4016\n","negative TP: 404.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 32.0\n","positive precision: 87.4016  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 92.6606\n","positive FPR: 7.3394  NPV: 95.0588\n","positive TP: 222.0\n","positive TN: 404.0\n","positive FP: 32.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 50 minibatch: 1      time used: 20.572174787521362\n","minibatch AVG loss: 0.136436660066247\n","Epoch: 24     train index of 50 minibatch: 2      time used: 19.727766513824463\n","minibatch AVG loss: 0.1275362460780889\n","Epoch: 24     train index of 50 minibatch: 3      time used: 19.644137620925903\n","minibatch AVG loss: 0.10027199978008866\n","Epoch: 24     train index of 50 minibatch: 4      time used: 19.882720232009888\n","minibatch AVG loss: 0.12191414403729141\n","Epoch: 24     train index of 50 minibatch: 5      time used: 19.90439248085022\n","minibatch AVG loss: 0.06662175295874477\n","Epoch: 24     train index of 50 minibatch: 6      time used: 19.673049926757812\n","minibatch AVG loss: 0.10226577988360078\n","\n","Epoch: 24  train \n","Loss: 0.1193  Acc: 95.3943\n","negative precision: 96.3324  recall: 96.4983\n","negative sensitivity: 96.4983  specificity: 93.4156\n","negative FPR: 6.5844  NPV: 93.7049\n","negative TP: 1681.0\n","negative TN: 908.0\n","negative FP: 64.0\n","negative FN: 61.0\n","positive precision: 93.7049  recall: 93.4156\n","positive sensitivity: 93.4156  specificity: 96.4983\n","positive FPR: 3.5017  NPV: 96.3324\n","positive TP: 908.0\n","positive TN: 1681.0\n","positive FP: 61.0\n","positive FN: 64.0\n","\n","\n","Epoch: 24     val index of 50 minibatch: 1      time used: 11.303804397583008\n","minibatch AVG loss: 0.10868659613188356\n","\n","Epoch: 24  val \n","Loss: 0.1870  Acc: 93.0781\n","negative precision: 92.9360  recall: 96.5596\n","negative sensitivity: 96.5596  specificity: 86.8313\n","negative FPR: 13.1687  NPV: 93.3628\n","negative TP: 421.0\n","negative TN: 211.0\n","negative FP: 32.0\n","negative FN: 15.0\n","positive precision: 93.3628  recall: 86.8313\n","positive sensitivity: 86.8313  specificity: 96.5596\n","positive FPR: 3.4404  NPV: 92.9360\n","positive TP: 211.0\n","positive TN: 421.0\n","positive FP: 15.0\n","positive FN: 32.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 50 minibatch: 1      time used: 20.50257706642151\n","minibatch AVG loss: 0.11294987480156124\n","Epoch: 25     train index of 50 minibatch: 2      time used: 19.599496603012085\n","minibatch AVG loss: 0.07811018915846944\n","Epoch: 25     train index of 50 minibatch: 3      time used: 19.645156621932983\n","minibatch AVG loss: 0.122829869822599\n","Epoch: 25     train index of 50 minibatch: 4      time used: 20.138731241226196\n","minibatch AVG loss: 0.09711355805397033\n","Epoch: 25     train index of 50 minibatch: 5      time used: 19.68723773956299\n","minibatch AVG loss: 0.1019427940947935\n","Epoch: 25     train index of 50 minibatch: 6      time used: 19.9012131690979\n","minibatch AVG loss: 0.10840835924260318\n","\n","Epoch: 25  train \n","Loss: 0.1001  Acc: 96.2786\n","negative precision: 96.9662  recall: 97.2445\n","negative sensitivity: 97.2445  specificity: 94.5473\n","negative FPR: 5.4527  NPV: 95.0362\n","negative TP: 1694.0\n","negative TN: 919.0\n","negative FP: 53.0\n","negative FN: 48.0\n","positive precision: 95.0362  recall: 94.5473\n","positive sensitivity: 94.5473  specificity: 97.2445\n","positive FPR: 2.7555  NPV: 96.9662\n","positive TP: 919.0\n","positive TN: 1694.0\n","positive FP: 48.0\n","positive FN: 53.0\n","\n","\n","Epoch: 25     val index of 50 minibatch: 1      time used: 11.364330291748047\n","minibatch AVG loss: 0.14406582111841998\n","\n","Epoch: 25  val \n","Loss: 0.1870  Acc: 93.0781\n","negative precision: 94.1043  recall: 95.1835\n","negative sensitivity: 95.1835  specificity: 89.3004\n","negative FPR: 10.6996  NPV: 91.1765\n","negative TP: 415.0\n","negative TN: 217.0\n","negative FP: 26.0\n","negative FN: 21.0\n","positive precision: 91.1765  recall: 89.3004\n","positive sensitivity: 89.3004  specificity: 95.1835\n","positive FPR: 4.8165  NPV: 94.1043\n","positive TP: 217.0\n","positive TN: 415.0\n","positive FP: 21.0\n","positive FN: 26.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 50 minibatch: 1      time used: 20.713818788528442\n","minibatch AVG loss: 0.1194485911494121\n","Epoch: 26     train index of 50 minibatch: 2      time used: 19.4725558757782\n","minibatch AVG loss: 0.08313589590368792\n","Epoch: 26     train index of 50 minibatch: 3      time used: 19.771109104156494\n","minibatch AVG loss: 0.09609693645965307\n","Epoch: 26     train index of 50 minibatch: 4      time used: 19.682685136795044\n","minibatch AVG loss: 0.10533489451976492\n","Epoch: 26     train index of 50 minibatch: 5      time used: 19.47649383544922\n","minibatch AVG loss: 0.0998053774004802\n","Epoch: 26     train index of 50 minibatch: 6      time used: 19.73529624938965\n","minibatch AVG loss: 0.09524690745398402\n","\n","Epoch: 26  train \n","Loss: 0.1022  Acc: 96.2786\n","negative precision: 96.8055  recall: 97.4168\n","negative sensitivity: 97.4168  specificity: 94.2387\n","negative FPR: 5.7613  NPV: 95.3174\n","negative TP: 1697.0\n","negative TN: 916.0\n","negative FP: 56.0\n","negative FN: 45.0\n","positive precision: 95.3174  recall: 94.2387\n","positive sensitivity: 94.2387  specificity: 97.4168\n","positive FPR: 2.5832  NPV: 96.8055\n","positive TP: 916.0\n","positive TN: 1697.0\n","positive FP: 45.0\n","positive FN: 56.0\n","\n","\n","Epoch: 26     val index of 50 minibatch: 1      time used: 11.08132553100586\n","minibatch AVG loss: 0.12316467601463955\n","\n","Epoch: 26  val \n","Loss: 0.1836  Acc: 92.7835\n","negative precision: 92.7152  recall: 96.3303\n","negative sensitivity: 96.3303  specificity: 86.4198\n","negative FPR: 13.5802  NPV: 92.9204\n","negative TP: 420.0\n","negative TN: 210.0\n","negative FP: 33.0\n","negative FN: 16.0\n","positive precision: 92.9204  recall: 86.4198\n","positive sensitivity: 86.4198  specificity: 96.3303\n","positive FPR: 3.6697  NPV: 92.7152\n","positive TP: 210.0\n","positive TN: 420.0\n","positive FP: 16.0\n","positive FN: 33.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 50 minibatch: 1      time used: 20.20547080039978\n","minibatch AVG loss: 0.067490599360317\n","Epoch: 27     train index of 50 minibatch: 2      time used: 19.59928297996521\n","minibatch AVG loss: 0.06677431562682613\n","Epoch: 27     train index of 50 minibatch: 3      time used: 19.118539094924927\n","minibatch AVG loss: 0.15402248991187661\n","Epoch: 27     train index of 50 minibatch: 4      time used: 19.577998876571655\n","minibatch AVG loss: 0.10527390192262828\n","Epoch: 27     train index of 50 minibatch: 5      time used: 19.41754698753357\n","minibatch AVG loss: 0.07794032983481884\n","Epoch: 27     train index of 50 minibatch: 6      time used: 19.394814491271973\n","minibatch AVG loss: 0.06707166512031108\n","\n","Epoch: 27  train \n","Loss: 0.0878  Acc: 96.8681\n","negative precision: 97.3158  recall: 97.8186\n","negative sensitivity: 97.8186  specificity: 95.1646\n","negative FPR: 4.8354  NPV: 96.0540\n","negative TP: 1704.0\n","negative TN: 925.0\n","negative FP: 47.0\n","negative FN: 38.0\n","positive precision: 96.0540  recall: 95.1646\n","positive sensitivity: 95.1646  specificity: 97.8186\n","positive FPR: 2.1814  NPV: 97.3158\n","positive TP: 925.0\n","positive TN: 1704.0\n","positive FP: 38.0\n","positive FN: 47.0\n","\n","\n","Epoch: 27     val index of 50 minibatch: 1      time used: 11.109584331512451\n","minibatch AVG loss: 0.14053326020206441\n","\n","Epoch: 27  val \n","Loss: 0.2077  Acc: 92.7835\n","negative precision: 93.0958  recall: 95.8716\n","negative sensitivity: 95.8716  specificity: 87.2428\n","negative FPR: 12.7572  NPV: 92.1739\n","negative TP: 418.0\n","negative TN: 212.0\n","negative FP: 31.0\n","negative FN: 18.0\n","positive precision: 92.1739  recall: 87.2428\n","positive sensitivity: 87.2428  specificity: 95.8716\n","positive FPR: 4.1284  NPV: 93.0958\n","positive TP: 212.0\n","positive TN: 418.0\n","positive FP: 18.0\n","positive FN: 31.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 50 minibatch: 1      time used: 20.100375175476074\n","minibatch AVG loss: 0.15879494416760281\n","Epoch: 28     train index of 50 minibatch: 2      time used: 19.66472554206848\n","minibatch AVG loss: 0.08420871702954173\n","Epoch: 28     train index of 50 minibatch: 3      time used: 19.51650333404541\n","minibatch AVG loss: 0.05577769623603672\n","Epoch: 28     train index of 50 minibatch: 4      time used: 19.465871572494507\n","minibatch AVG loss: 0.0756643596990034\n","Epoch: 28     train index of 50 minibatch: 5      time used: 19.470624208450317\n","minibatch AVG loss: 0.06177242746809498\n","Epoch: 28     train index of 50 minibatch: 6      time used: 19.64036273956299\n","minibatch AVG loss: 0.07348801699932665\n","\n","Epoch: 28  train \n","Loss: 0.0838  Acc: 96.8312\n","negative precision: 97.3684  recall: 97.7038\n","negative sensitivity: 97.7038  specificity: 95.2675\n","negative FPR: 4.7325  NPV: 95.8592\n","negative TP: 1702.0\n","negative TN: 926.0\n","negative FP: 46.0\n","negative FN: 40.0\n","positive precision: 95.8592  recall: 95.2675\n","positive sensitivity: 95.2675  specificity: 97.7038\n","positive FPR: 2.2962  NPV: 97.3684\n","positive TP: 926.0\n","positive TN: 1702.0\n","positive FP: 40.0\n","positive FN: 46.0\n","\n","\n","Epoch: 28     val index of 50 minibatch: 1      time used: 11.02499794960022\n","minibatch AVG loss: 0.19056745583264273\n","\n","Epoch: 28  val \n","Loss: 0.2187  Acc: 92.1944\n","negative precision: 94.4316  recall: 93.3486\n","negative sensitivity: 93.3486  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 88.3065\n","negative TP: 407.0\n","negative TN: 219.0\n","negative FP: 24.0\n","negative FN: 29.0\n","positive precision: 88.3065  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 93.3486\n","positive FPR: 6.6514  NPV: 94.4316\n","positive TP: 219.0\n","positive TN: 407.0\n","positive FP: 29.0\n","positive FN: 24.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 50 minibatch: 1      time used: 20.113995790481567\n","minibatch AVG loss: 0.09556390055222437\n","Epoch: 29     train index of 50 minibatch: 2      time used: 19.889098167419434\n","minibatch AVG loss: 0.08696634537540376\n","Epoch: 29     train index of 50 minibatch: 3      time used: 19.462713956832886\n","minibatch AVG loss: 0.09985174741130322\n","Epoch: 29     train index of 50 minibatch: 4      time used: 19.404111862182617\n","minibatch AVG loss: 0.09074832216836512\n","Epoch: 29     train index of 50 minibatch: 5      time used: 19.44044804573059\n","minibatch AVG loss: 0.07027889345306904\n","Epoch: 29     train index of 50 minibatch: 6      time used: 19.461808681488037\n","minibatch AVG loss: 0.08244175294879824\n","\n","Epoch: 29  train \n","Loss: 0.0867  Acc: 96.6470\n","negative precision: 97.1984  recall: 97.5890\n","negative sensitivity: 97.5890  specificity: 94.9588\n","negative FPR: 5.0412  NPV: 95.6477\n","negative TP: 1700.0\n","negative TN: 923.0\n","negative FP: 49.0\n","negative FN: 42.0\n","positive precision: 95.6477  recall: 94.9588\n","positive sensitivity: 94.9588  specificity: 97.5890\n","positive FPR: 2.4110  NPV: 97.1984\n","positive TP: 923.0\n","positive TN: 1700.0\n","positive FP: 42.0\n","positive FN: 49.0\n","\n","\n","Epoch: 29     val index of 50 minibatch: 1      time used: 11.018941164016724\n","minibatch AVG loss: 0.2623952538427693\n","\n","Epoch: 29  val \n","Loss: 0.2279  Acc: 92.3417\n","negative precision: 96.3768  recall: 91.5138\n","negative sensitivity: 91.5138  specificity: 93.8272\n","negative FPR: 6.1728  NPV: 86.0377\n","negative TP: 399.0\n","negative TN: 228.0\n","negative FP: 15.0\n","negative FN: 37.0\n","positive precision: 86.0377  recall: 93.8272\n","positive sensitivity: 93.8272  specificity: 91.5138\n","positive FPR: 8.4862  NPV: 96.3768\n","positive TP: 228.0\n","positive TN: 399.0\n","positive FP: 37.0\n","positive FN: 15.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 50 minibatch: 1      time used: 20.113340616226196\n","minibatch AVG loss: 0.1032210797490552\n","Epoch: 30     train index of 50 minibatch: 2      time used: 19.450828313827515\n","minibatch AVG loss: 0.10207743969047442\n","Epoch: 30     train index of 50 minibatch: 3      time used: 19.394274950027466\n","minibatch AVG loss: 0.07742219036445022\n","Epoch: 30     train index of 50 minibatch: 4      time used: 19.796168327331543\n","minibatch AVG loss: 0.1084887167531997\n","Epoch: 30     train index of 50 minibatch: 5      time used: 19.304665565490723\n","minibatch AVG loss: 0.06423447943292558\n","Epoch: 30     train index of 50 minibatch: 6      time used: 19.209781408309937\n","minibatch AVG loss: 0.05883490999694914\n","\n","Epoch: 30  train \n","Loss: 0.0873  Acc: 96.7944\n","negative precision: 97.5302  recall: 97.4742\n","negative sensitivity: 97.4742  specificity: 95.5761\n","negative FPR: 4.4239  NPV: 95.4779\n","negative TP: 1698.0\n","negative TN: 929.0\n","negative FP: 43.0\n","negative FN: 44.0\n","positive precision: 95.4779  recall: 95.5761\n","positive sensitivity: 95.5761  specificity: 97.4742\n","positive FPR: 2.5258  NPV: 97.5302\n","positive TP: 929.0\n","positive TN: 1698.0\n","positive FP: 44.0\n","positive FN: 43.0\n","\n","\n","Epoch: 30     val index of 50 minibatch: 1      time used: 11.078147888183594\n","minibatch AVG loss: 0.05602045519732201\n","\n","Epoch: 30  val \n","Loss: 0.1893  Acc: 93.6672\n","negative precision: 92.2581  recall: 98.3945\n","negative sensitivity: 98.3945  specificity: 85.1852\n","negative FPR: 14.8148  NPV: 96.7290\n","negative TP: 429.0\n","negative TN: 207.0\n","negative FP: 36.0\n","negative FN: 7.0\n","positive precision: 96.7290  recall: 85.1852\n","positive sensitivity: 85.1852  specificity: 98.3945\n","positive FPR: 1.6055  NPV: 92.2581\n","positive TP: 207.0\n","positive TN: 429.0\n","positive FP: 7.0\n","positive FN: 36.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 50 minibatch: 1      time used: 19.659309148788452\n","minibatch AVG loss: 0.09677513217553496\n","Epoch: 31     train index of 50 minibatch: 2      time used: 19.471559762954712\n","minibatch AVG loss: 0.07155694222543389\n","Epoch: 31     train index of 50 minibatch: 3      time used: 19.512038230895996\n","minibatch AVG loss: 0.07385950529482216\n","Epoch: 31     train index of 50 minibatch: 4      time used: 19.44741725921631\n","minibatch AVG loss: 0.05246949783992022\n","Epoch: 31     train index of 50 minibatch: 5      time used: 19.59509825706482\n","minibatch AVG loss: 0.10324117995798587\n","Epoch: 31     train index of 50 minibatch: 6      time used: 19.443105220794678\n","minibatch AVG loss: 0.09255614607129246\n","\n","Epoch: 31  train \n","Loss: 0.0802  Acc: 96.6839\n","negative precision: 97.3624  recall: 97.4742\n","negative sensitivity: 97.4742  specificity: 95.2675\n","negative FPR: 4.7325  NPV: 95.4639\n","negative TP: 1698.0\n","negative TN: 926.0\n","negative FP: 46.0\n","negative FN: 44.0\n","positive precision: 95.4639  recall: 95.2675\n","positive sensitivity: 95.2675  specificity: 97.4742\n","positive FPR: 2.5258  NPV: 97.3624\n","positive TP: 926.0\n","positive TN: 1698.0\n","positive FP: 44.0\n","positive FN: 46.0\n","\n","\n","Epoch: 31     val index of 50 minibatch: 1      time used: 11.105125904083252\n","minibatch AVG loss: 0.12737831353551882\n","\n","Epoch: 31  val \n","Loss: 0.1863  Acc: 93.6672\n","negative precision: 94.5578  recall: 95.6422\n","negative sensitivity: 95.6422  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 92.0168\n","negative TP: 417.0\n","negative TN: 219.0\n","negative FP: 24.0\n","negative FN: 19.0\n","positive precision: 92.0168  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 95.6422\n","positive FPR: 4.3578  NPV: 94.5578\n","positive TP: 219.0\n","positive TN: 417.0\n","positive FP: 19.0\n","positive FN: 24.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 50 minibatch: 1      time used: 20.03978657722473\n","minibatch AVG loss: 0.06736569410888478\n","Epoch: 32     train index of 50 minibatch: 2      time used: 19.535186290740967\n","minibatch AVG loss: 0.04761857744306326\n","Epoch: 32     train index of 50 minibatch: 3      time used: 19.218693494796753\n","minibatch AVG loss: 0.04981155454181135\n","Epoch: 32     train index of 50 minibatch: 4      time used: 19.508373260498047\n","minibatch AVG loss: 0.10280294228694402\n","Epoch: 32     train index of 50 minibatch: 5      time used: 19.249347686767578\n","minibatch AVG loss: 0.09079498600680382\n","Epoch: 32     train index of 50 minibatch: 6      time used: 19.476978302001953\n","minibatch AVG loss: 0.07630357219371944\n","\n","Epoch: 32  train \n","Loss: 0.0692  Acc: 97.3839\n","negative precision: 97.9346  recall: 97.9908\n","negative sensitivity: 97.9908  specificity: 96.2963\n","negative FPR: 3.7037  NPV: 96.3955\n","negative TP: 1707.0\n","negative TN: 936.0\n","negative FP: 36.0\n","negative FN: 35.0\n","positive precision: 96.3955  recall: 96.2963\n","positive sensitivity: 96.2963  specificity: 97.9908\n","positive FPR: 2.0092  NPV: 97.9346\n","positive TP: 936.0\n","positive TN: 1707.0\n","positive FP: 35.0\n","positive FN: 36.0\n","\n","\n","Epoch: 32     val index of 50 minibatch: 1      time used: 11.086171388626099\n","minibatch AVG loss: 0.1283788954564079\n","\n","Epoch: 32  val \n","Loss: 0.1755  Acc: 93.3726\n","negative precision: 94.5330  recall: 95.1835\n","negative sensitivity: 95.1835  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 91.2500\n","negative TP: 415.0\n","negative TN: 219.0\n","negative FP: 24.0\n","negative FN: 21.0\n","positive precision: 91.2500  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 95.1835\n","positive FPR: 4.8165  NPV: 94.5330\n","positive TP: 219.0\n","positive TN: 415.0\n","positive FP: 21.0\n","positive FN: 24.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 50 minibatch: 1      time used: 20.03086233139038\n","minibatch AVG loss: 0.057031395435333254\n","Epoch: 33     train index of 50 minibatch: 2      time used: 19.402533531188965\n","minibatch AVG loss: 0.04794029197888449\n","Epoch: 33     train index of 50 minibatch: 3      time used: 19.395854711532593\n","minibatch AVG loss: 0.08210677787661552\n","Epoch: 33     train index of 50 minibatch: 4      time used: 19.483038663864136\n","minibatch AVG loss: 0.07954090420156718\n","Epoch: 33     train index of 50 minibatch: 5      time used: 19.288048267364502\n","minibatch AVG loss: 0.0985680398112163\n","Epoch: 33     train index of 50 minibatch: 6      time used: 19.16431975364685\n","minibatch AVG loss: 0.07646463840734213\n","\n","Epoch: 33  train \n","Loss: 0.0719  Acc: 96.9418\n","negative precision: 97.5904  recall: 97.6464\n","negative sensitivity: 97.6464  specificity: 95.6790\n","negative FPR: 4.3210  NPV: 95.7775\n","negative TP: 1701.0\n","negative TN: 930.0\n","negative FP: 42.0\n","negative FN: 41.0\n","positive precision: 95.7775  recall: 95.6790\n","positive sensitivity: 95.6790  specificity: 97.6464\n","positive FPR: 2.3536  NPV: 97.5904\n","positive TP: 930.0\n","positive TN: 1701.0\n","positive FP: 41.0\n","positive FN: 42.0\n","\n","\n","Epoch: 33     val index of 50 minibatch: 1      time used: 11.075800895690918\n","minibatch AVG loss: 0.08949536332147545\n","\n","Epoch: 33  val \n","Loss: 0.1983  Acc: 93.8144\n","negative precision: 93.0131  recall: 97.7064\n","negative sensitivity: 97.7064  specificity: 86.8313\n","negative FPR: 13.1687  NPV: 95.4751\n","negative TP: 426.0\n","negative TN: 211.0\n","negative FP: 32.0\n","negative FN: 10.0\n","positive precision: 95.4751  recall: 86.8313\n","positive sensitivity: 86.8313  specificity: 97.7064\n","positive FPR: 2.2936  NPV: 93.0131\n","positive TP: 211.0\n","positive TN: 426.0\n","positive FP: 10.0\n","positive FN: 32.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 50 minibatch: 1      time used: 20.262176513671875\n","minibatch AVG loss: 0.06892812699545176\n","Epoch: 34     train index of 50 minibatch: 2      time used: 19.290812969207764\n","minibatch AVG loss: 0.10331612755078823\n","Epoch: 34     train index of 50 minibatch: 3      time used: 19.276288270950317\n","minibatch AVG loss: 0.05176201863680035\n","Epoch: 34     train index of 50 minibatch: 4      time used: 19.630229473114014\n","minibatch AVG loss: 0.03161035513971001\n","Epoch: 34     train index of 50 minibatch: 5      time used: 19.331591367721558\n","minibatch AVG loss: 0.060597530503291634\n","Epoch: 34     train index of 50 minibatch: 6      time used: 19.600860118865967\n","minibatch AVG loss: 0.05005107491859235\n","\n","Epoch: 34  train \n","Loss: 0.0597  Acc: 97.7524\n","negative precision: 98.1662  recall: 98.3352\n","negative sensitivity: 98.3352  specificity: 96.7078\n","negative FPR: 3.2922  NPV: 97.0072\n","negative TP: 1713.0\n","negative TN: 940.0\n","negative FP: 32.0\n","negative FN: 29.0\n","positive precision: 97.0072  recall: 96.7078\n","positive sensitivity: 96.7078  specificity: 98.3352\n","positive FPR: 1.6648  NPV: 98.1662\n","positive TP: 940.0\n","positive TN: 1713.0\n","positive FP: 29.0\n","positive FN: 32.0\n","\n","\n","Epoch: 34     val index of 50 minibatch: 1      time used: 11.061171770095825\n","minibatch AVG loss: 0.20145858919677267\n","\n","Epoch: 34  val \n","Loss: 0.2071  Acc: 94.1090\n","negative precision: 96.6981  recall: 94.0367\n","negative sensitivity: 94.0367  specificity: 94.2387\n","negative FPR: 5.7613  NPV: 89.8039\n","negative TP: 410.0\n","negative TN: 229.0\n","negative FP: 14.0\n","negative FN: 26.0\n","positive precision: 89.8039  recall: 94.2387\n","positive sensitivity: 94.2387  specificity: 94.0367\n","positive FPR: 5.9633  NPV: 96.6981\n","positive TP: 229.0\n","positive TN: 410.0\n","positive FP: 26.0\n","positive FN: 14.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 50 minibatch: 1      time used: 20.068289756774902\n","minibatch AVG loss: 0.07846904797013848\n","Epoch: 35     train index of 50 minibatch: 2      time used: 19.225777864456177\n","minibatch AVG loss: 0.08544452434871345\n","Epoch: 35     train index of 50 minibatch: 3      time used: 19.29555058479309\n","minibatch AVG loss: 0.04365987771423534\n","Epoch: 35     train index of 50 minibatch: 4      time used: 19.21275019645691\n","minibatch AVG loss: 0.047796313147991897\n","Epoch: 35     train index of 50 minibatch: 5      time used: 19.350261688232422\n","minibatch AVG loss: 0.06353999273385852\n","Epoch: 35     train index of 50 minibatch: 6      time used: 19.361424207687378\n","minibatch AVG loss: 0.08708717814181\n","\n","Epoch: 35  train \n","Loss: 0.0650  Acc: 97.7892\n","negative precision: 98.1672  recall: 98.3927\n","negative sensitivity: 98.3927  specificity: 96.7078\n","negative FPR: 3.2922  NPV: 97.1074\n","negative TP: 1714.0\n","negative TN: 940.0\n","negative FP: 32.0\n","negative FN: 28.0\n","positive precision: 97.1074  recall: 96.7078\n","positive sensitivity: 96.7078  specificity: 98.3927\n","positive FPR: 1.6073  NPV: 98.1672\n","positive TP: 940.0\n","positive TN: 1714.0\n","positive FP: 28.0\n","positive FN: 32.0\n","\n","\n","Epoch: 35     val index of 50 minibatch: 1      time used: 10.973511219024658\n","minibatch AVG loss: 0.16482398575630214\n","\n","Epoch: 35  val \n","Loss: 0.1853  Acc: 92.7835\n","negative precision: 94.8956  recall: 93.8073\n","negative sensitivity: 93.8073  specificity: 90.9465\n","negative FPR: 9.0535  NPV: 89.1129\n","negative TP: 409.0\n","negative TN: 221.0\n","negative FP: 22.0\n","negative FN: 27.0\n","positive precision: 89.1129  recall: 90.9465\n","positive sensitivity: 90.9465  specificity: 93.8073\n","positive FPR: 6.1927  NPV: 94.8956\n","positive TP: 221.0\n","positive TN: 409.0\n","positive FP: 27.0\n","positive FN: 22.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 50 minibatch: 1      time used: 19.81278681755066\n","minibatch AVG loss: 0.0575921470625326\n","Epoch: 36     train index of 50 minibatch: 2      time used: 19.80911636352539\n","minibatch AVG loss: 0.04770628630183637\n","Epoch: 36     train index of 50 minibatch: 3      time used: 19.00924801826477\n","minibatch AVG loss: 0.05721029132138938\n","Epoch: 36     train index of 50 minibatch: 4      time used: 19.402800798416138\n","minibatch AVG loss: 0.06872679667896592\n","Epoch: 36     train index of 50 minibatch: 5      time used: 19.367573022842407\n","minibatch AVG loss: 0.07543851074995472\n","Epoch: 36     train index of 50 minibatch: 6      time used: 19.619516849517822\n","minibatch AVG loss: 0.04956757709616795\n","\n","Epoch: 36  train \n","Loss: 0.0622  Acc: 97.6419\n","negative precision: 97.9429  recall: 98.3927\n","negative sensitivity: 98.3927  specificity: 96.2963\n","negative FPR: 3.7037  NPV: 97.0954\n","negative TP: 1714.0\n","negative TN: 936.0\n","negative FP: 36.0\n","negative FN: 28.0\n","positive precision: 97.0954  recall: 96.2963\n","positive sensitivity: 96.2963  specificity: 98.3927\n","positive FPR: 1.6073  NPV: 97.9429\n","positive TP: 936.0\n","positive TN: 1714.0\n","positive FP: 28.0\n","positive FN: 36.0\n","\n","\n","Epoch: 36     val index of 50 minibatch: 1      time used: 11.043092250823975\n","minibatch AVG loss: 0.19182207753176045\n","\n","Epoch: 36  val \n","Loss: 0.2038  Acc: 92.6362\n","negative precision: 95.7346  recall: 92.6606\n","negative sensitivity: 92.6606  specificity: 92.5926\n","negative FPR: 7.4074  NPV: 87.5486\n","negative TP: 404.0\n","negative TN: 225.0\n","negative FP: 18.0\n","negative FN: 32.0\n","positive precision: 87.5486  recall: 92.5926\n","positive sensitivity: 92.5926  specificity: 92.6606\n","positive FPR: 7.3394  NPV: 95.7346\n","positive TP: 225.0\n","positive TN: 404.0\n","positive FP: 32.0\n","positive FN: 18.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 50 minibatch: 1      time used: 19.878145456314087\n","minibatch AVG loss: 0.0690070030465722\n","Epoch: 37     train index of 50 minibatch: 2      time used: 19.49142813682556\n","minibatch AVG loss: 0.07099967919290066\n","Epoch: 37     train index of 50 minibatch: 3      time used: 19.739058017730713\n","minibatch AVG loss: 0.04198399954708293\n","Epoch: 37     train index of 50 minibatch: 4      time used: 19.4938006401062\n","minibatch AVG loss: 0.039060488956747574\n","Epoch: 37     train index of 50 minibatch: 5      time used: 19.309296131134033\n","minibatch AVG loss: 0.05159763319185004\n","Epoch: 37     train index of 50 minibatch: 6      time used: 19.28909134864807\n","minibatch AVG loss: 0.06341433065594174\n","\n","Epoch: 37  train \n","Loss: 0.0565  Acc: 97.4945\n","negative precision: 98.1588  recall: 97.9334\n","negative sensitivity: 97.9334  specificity: 96.7078\n","negative FPR: 3.2922  NPV: 96.3115\n","negative TP: 1706.0\n","negative TN: 940.0\n","negative FP: 32.0\n","negative FN: 36.0\n","positive precision: 96.3115  recall: 96.7078\n","positive sensitivity: 96.7078  specificity: 97.9334\n","positive FPR: 2.0666  NPV: 98.1588\n","positive TP: 940.0\n","positive TN: 1706.0\n","positive FP: 36.0\n","positive FN: 32.0\n","\n","\n","Epoch: 37     val index of 50 minibatch: 1      time used: 11.104177951812744\n","minibatch AVG loss: 0.2005837215798965\n","\n","Epoch: 37  val \n","Loss: 0.2033  Acc: 93.0781\n","negative precision: 95.9811  recall: 93.1193\n","negative sensitivity: 93.1193  specificity: 93.0041\n","negative FPR: 6.9959  NPV: 88.2812\n","negative TP: 406.0\n","negative TN: 226.0\n","negative FP: 17.0\n","negative FN: 30.0\n","positive precision: 88.2812  recall: 93.0041\n","positive sensitivity: 93.0041  specificity: 93.1193\n","positive FPR: 6.8807  NPV: 95.9811\n","positive TP: 226.0\n","positive TN: 406.0\n","positive FP: 30.0\n","positive FN: 17.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 50 minibatch: 1      time used: 20.184258937835693\n","minibatch AVG loss: 0.03893400554719847\n","Epoch: 38     train index of 50 minibatch: 2      time used: 19.305915594100952\n","minibatch AVG loss: 0.04414724805741571\n","Epoch: 38     train index of 50 minibatch: 3      time used: 19.43242621421814\n","minibatch AVG loss: 0.0614560975623317\n","Epoch: 38     train index of 50 minibatch: 4      time used: 19.40287971496582\n","minibatch AVG loss: 0.031736285637598484\n","Epoch: 38     train index of 50 minibatch: 5      time used: 19.403995275497437\n","minibatch AVG loss: 0.08106467694509774\n","Epoch: 38     train index of 50 minibatch: 6      time used: 19.63746404647827\n","minibatch AVG loss: 0.04785418409854174\n","\n","Epoch: 38  train \n","Loss: 0.0524  Acc: 98.0840\n","negative precision: 98.6751  recall: 98.3352\n","negative sensitivity: 98.3352  specificity: 97.6337\n","negative FPR: 2.3663  NPV: 97.0348\n","negative TP: 1713.0\n","negative TN: 949.0\n","negative FP: 23.0\n","negative FN: 29.0\n","positive precision: 97.0348  recall: 97.6337\n","positive sensitivity: 97.6337  specificity: 98.3352\n","positive FPR: 1.6648  NPV: 98.6751\n","positive TP: 949.0\n","positive TN: 1713.0\n","positive FP: 29.0\n","positive FN: 23.0\n","\n","\n","Epoch: 38     val index of 50 minibatch: 1      time used: 11.32472276687622\n","minibatch AVG loss: 0.10853171659153305\n","\n","Epoch: 38  val \n","Loss: 0.2067  Acc: 93.6672\n","negative precision: 94.3567  recall: 95.8716\n","negative sensitivity: 95.8716  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 92.3729\n","negative TP: 418.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 18.0\n","positive precision: 92.3729  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 95.8716\n","positive FPR: 4.1284  NPV: 94.3567\n","positive TP: 218.0\n","positive TN: 418.0\n","positive FP: 18.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 50 minibatch: 1      time used: 20.463947534561157\n","minibatch AVG loss: 0.0646693655254785\n","Epoch: 39     train index of 50 minibatch: 2      time used: 19.552730560302734\n","minibatch AVG loss: 0.039557525384007024\n","Epoch: 39     train index of 50 minibatch: 3      time used: 19.971768379211426\n","minibatch AVG loss: 0.04376289196312427\n","Epoch: 39     train index of 50 minibatch: 4      time used: 19.940332889556885\n","minibatch AVG loss: 0.03858377409633249\n","Epoch: 39     train index of 50 minibatch: 5      time used: 19.7118878364563\n","minibatch AVG loss: 0.061837077061645686\n","Epoch: 39     train index of 50 minibatch: 6      time used: 19.93324613571167\n","minibatch AVG loss: 0.04320709507679567\n","\n","Epoch: 39  train \n","Loss: 0.0485  Acc: 98.2682\n","negative precision: 98.7349  recall: 98.5649\n","negative sensitivity: 98.5649  specificity: 97.7366\n","negative FPR: 2.2634  NPV: 97.4359\n","negative TP: 1717.0\n","negative TN: 950.0\n","negative FP: 22.0\n","negative FN: 25.0\n","positive precision: 97.4359  recall: 97.7366\n","positive sensitivity: 97.7366  specificity: 98.5649\n","positive FPR: 1.4351  NPV: 98.7349\n","positive TP: 950.0\n","positive TN: 1717.0\n","positive FP: 25.0\n","positive FN: 22.0\n","\n","\n","Epoch: 39     val index of 50 minibatch: 1      time used: 11.450991153717041\n","minibatch AVG loss: 0.15453223449567305\n","\n","Epoch: 39  val \n","Loss: 0.2286  Acc: 92.7835\n","negative precision: 94.4828  recall: 94.2661\n","negative sensitivity: 94.2661  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 89.7541\n","negative TP: 411.0\n","negative TN: 219.0\n","negative FP: 24.0\n","negative FN: 25.0\n","positive precision: 89.7541  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 94.2661\n","positive FPR: 5.7339  NPV: 94.4828\n","positive TP: 219.0\n","positive TN: 411.0\n","positive FP: 25.0\n","positive FN: 24.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 50 minibatch: 1      time used: 20.483842134475708\n","minibatch AVG loss: 0.07085675873793662\n","Epoch: 40     train index of 50 minibatch: 2      time used: 19.479650497436523\n","minibatch AVG loss: 0.024397440981119872\n","Epoch: 40     train index of 50 minibatch: 3      time used: 20.095207452774048\n","minibatch AVG loss: 0.06209690150571987\n","Epoch: 40     train index of 50 minibatch: 4      time used: 19.901911735534668\n","minibatch AVG loss: 0.04855895246611908\n","Epoch: 40     train index of 50 minibatch: 5      time used: 19.62595820426941\n","minibatch AVG loss: 0.06671392026240937\n","Epoch: 40     train index of 50 minibatch: 6      time used: 19.718700408935547\n","minibatch AVG loss: 0.06564809326664545\n","\n","Epoch: 40  train \n","Loss: 0.0549  Acc: 98.0472\n","negative precision: 98.5624  recall: 98.3927\n","negative sensitivity: 98.3927  specificity: 97.4280\n","negative FPR: 2.5720  NPV: 97.1282\n","negative TP: 1714.0\n","negative TN: 947.0\n","negative FP: 25.0\n","negative FN: 28.0\n","positive precision: 97.1282  recall: 97.4280\n","positive sensitivity: 97.4280  specificity: 98.3927\n","positive FPR: 1.6073  NPV: 98.5624\n","positive TP: 947.0\n","positive TN: 1714.0\n","positive FP: 28.0\n","positive FN: 25.0\n","\n","\n","Epoch: 40     val index of 50 minibatch: 1      time used: 11.356831550598145\n","minibatch AVG loss: 0.2259812615521514\n","\n","Epoch: 40  val \n","Loss: 0.2409  Acc: 92.4890\n","negative precision: 94.8718  recall: 93.3486\n","negative sensitivity: 93.3486  specificity: 90.9465\n","negative FPR: 9.0535  NPV: 88.4000\n","negative TP: 407.0\n","negative TN: 221.0\n","negative FP: 22.0\n","negative FN: 29.0\n","positive precision: 88.4000  recall: 90.9465\n","positive sensitivity: 90.9465  specificity: 93.3486\n","positive FPR: 6.6514  NPV: 94.8718\n","positive TP: 221.0\n","positive TN: 407.0\n","positive FP: 29.0\n","positive FN: 22.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 50 minibatch: 1      time used: 20.473488330841064\n","minibatch AVG loss: 0.055835269399685784\n","Epoch: 41     train index of 50 minibatch: 2      time used: 19.642290353775024\n","minibatch AVG loss: 0.03912500369769987\n","Epoch: 41     train index of 50 minibatch: 3      time used: 20.09358835220337\n","minibatch AVG loss: 0.03141223817889113\n","Epoch: 41     train index of 50 minibatch: 4      time used: 20.150733709335327\n","minibatch AVG loss: 0.03122235606482718\n","Epoch: 41     train index of 50 minibatch: 5      time used: 19.884888648986816\n","minibatch AVG loss: 0.06129719353630207\n","Epoch: 41     train index of 50 minibatch: 6      time used: 19.593935251235962\n","minibatch AVG loss: 0.03736848558532074\n","\n","Epoch: 41  train \n","Loss: 0.0464  Acc: 98.3051\n","negative precision: 98.6239  recall: 98.7371\n","negative sensitivity: 98.7371  specificity: 97.5309\n","negative FPR: 2.4691  NPV: 97.7320\n","negative TP: 1720.0\n","negative TN: 948.0\n","negative FP: 24.0\n","negative FN: 22.0\n","positive precision: 97.7320  recall: 97.5309\n","positive sensitivity: 97.5309  specificity: 98.7371\n","positive FPR: 1.2629  NPV: 98.6239\n","positive TP: 948.0\n","positive TN: 1720.0\n","positive FP: 22.0\n","positive FN: 24.0\n","\n","\n","Epoch: 41     val index of 50 minibatch: 1      time used: 11.377102136611938\n","minibatch AVG loss: 0.15700165071975788\n","\n","Epoch: 41  val \n","Loss: 0.2195  Acc: 93.3726\n","negative precision: 94.7368  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 90.5350\n","negative FPR: 9.4650  NPV: 90.9091\n","negative TP: 414.0\n","negative TN: 220.0\n","negative FP: 23.0\n","negative FN: 22.0\n","positive precision: 90.9091  recall: 90.5350\n","positive sensitivity: 90.5350  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 94.7368\n","positive TP: 220.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 50 minibatch: 1      time used: 20.3624005317688\n","minibatch AVG loss: 0.06449687641579657\n","Epoch: 42     train index of 50 minibatch: 2      time used: 20.10870122909546\n","minibatch AVG loss: 0.03236780653183814\n","Epoch: 42     train index of 50 minibatch: 3      time used: 19.71742296218872\n","minibatch AVG loss: 0.05400291685247794\n","Epoch: 42     train index of 50 minibatch: 4      time used: 19.976572036743164\n","minibatch AVG loss: 0.021555702596670015\n","Epoch: 42     train index of 50 minibatch: 5      time used: 19.855682134628296\n","minibatch AVG loss: 0.04641111996606924\n","Epoch: 42     train index of 50 minibatch: 6      time used: 19.84474277496338\n","minibatch AVG loss: 0.02431100295041688\n","\n","Epoch: 42  train \n","Loss: 0.0388  Acc: 98.6367\n","negative precision: 99.0224  recall: 98.8519\n","negative sensitivity: 98.8519  specificity: 98.2510\n","negative FPR: 1.7490  NPV: 97.9487\n","negative TP: 1722.0\n","negative TN: 955.0\n","negative FP: 17.0\n","negative FN: 20.0\n","positive precision: 97.9487  recall: 98.2510\n","positive sensitivity: 98.2510  specificity: 98.8519\n","positive FPR: 1.1481  NPV: 99.0224\n","positive TP: 955.0\n","positive TN: 1722.0\n","positive FP: 20.0\n","positive FN: 17.0\n","\n","\n","Epoch: 42     val index of 50 minibatch: 1      time used: 11.372600078582764\n","minibatch AVG loss: 0.15211914240229818\n","\n","Epoch: 42  val \n","Loss: 0.2242  Acc: 92.9308\n","negative precision: 94.0909  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 89.3004\n","negative FPR: 10.6996  NPV: 90.7950\n","negative TP: 414.0\n","negative TN: 217.0\n","negative FP: 26.0\n","negative FN: 22.0\n","positive precision: 90.7950  recall: 89.3004\n","positive sensitivity: 89.3004  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 94.0909\n","positive TP: 217.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 26.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 50 minibatch: 1      time used: 20.411203622817993\n","minibatch AVG loss: 0.03134805185662117\n","Epoch: 43     train index of 50 minibatch: 2      time used: 19.815868377685547\n","minibatch AVG loss: 0.046315393972327\n","Epoch: 43     train index of 50 minibatch: 3      time used: 20.218238353729248\n","minibatch AVG loss: 0.051705488019506446\n","Epoch: 43     train index of 50 minibatch: 4      time used: 20.12708878517151\n","minibatch AVG loss: 0.05149351280473638\n","Epoch: 43     train index of 50 minibatch: 5      time used: 20.066091537475586\n","minibatch AVG loss: 0.025786823222297243\n","Epoch: 43     train index of 50 minibatch: 6      time used: 19.75413942337036\n","minibatch AVG loss: 0.016653543646680192\n","\n","Epoch: 43  train \n","Loss: 0.0393  Acc: 98.7472\n","negative precision: 99.0805  recall: 98.9667\n","negative sensitivity: 98.9667  specificity: 98.3539\n","negative FPR: 1.6461  NPV: 98.1520\n","negative TP: 1724.0\n","negative TN: 956.0\n","negative FP: 16.0\n","negative FN: 18.0\n","positive precision: 98.1520  recall: 98.3539\n","positive sensitivity: 98.3539  specificity: 98.9667\n","positive FPR: 1.0333  NPV: 99.0805\n","positive TP: 956.0\n","positive TN: 1724.0\n","positive FP: 18.0\n","positive FN: 16.0\n","\n","\n","Epoch: 43     val index of 50 minibatch: 1      time used: 11.375771045684814\n","minibatch AVG loss: 0.10143408601705232\n","\n","Epoch: 43  val \n","Loss: 0.2259  Acc: 93.9617\n","negative precision: 93.7916  recall: 97.0183\n","negative sensitivity: 97.0183  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 94.2982\n","negative TP: 423.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 13.0\n","positive precision: 94.2982  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 97.0183\n","positive FPR: 2.9817  NPV: 93.7916\n","positive TP: 215.0\n","positive TN: 423.0\n","positive FP: 13.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 50 minibatch: 1      time used: 20.56860899925232\n","minibatch AVG loss: 0.036274549826048316\n","Epoch: 44     train index of 50 minibatch: 2      time used: 19.947566986083984\n","minibatch AVG loss: 0.035859446466201914\n","Epoch: 44     train index of 50 minibatch: 3      time used: 19.85358476638794\n","minibatch AVG loss: 0.036503396669868377\n","Epoch: 44     train index of 50 minibatch: 4      time used: 19.59537410736084\n","minibatch AVG loss: 0.042870910759666\n","Epoch: 44     train index of 50 minibatch: 5      time used: 19.465133666992188\n","minibatch AVG loss: 0.04954695721855387\n","Epoch: 44     train index of 50 minibatch: 6      time used: 19.515124559402466\n","minibatch AVG loss: 0.022467368483776225\n","\n","Epoch: 44  train \n","Loss: 0.0393  Acc: 98.7472\n","negative precision: 99.0805  recall: 98.9667\n","negative sensitivity: 98.9667  specificity: 98.3539\n","negative FPR: 1.6461  NPV: 98.1520\n","negative TP: 1724.0\n","negative TN: 956.0\n","negative FP: 16.0\n","negative FN: 18.0\n","positive precision: 98.1520  recall: 98.3539\n","positive sensitivity: 98.3539  specificity: 98.9667\n","positive FPR: 1.0333  NPV: 99.0805\n","positive TP: 956.0\n","positive TN: 1724.0\n","positive FP: 18.0\n","positive FN: 16.0\n","\n","\n","Epoch: 44     val index of 50 minibatch: 1      time used: 11.029934883117676\n","minibatch AVG loss: 0.06667857466989517\n","\n","Epoch: 44  val \n","Loss: 0.2387  Acc: 92.9308\n","negative precision: 91.4530  recall: 98.1651\n","negative sensitivity: 98.1651  specificity: 83.5391\n","negative FPR: 16.4609  NPV: 96.2085\n","negative TP: 428.0\n","negative TN: 203.0\n","negative FP: 40.0\n","negative FN: 8.0\n","positive precision: 96.2085  recall: 83.5391\n","positive sensitivity: 83.5391  specificity: 98.1651\n","positive FPR: 1.8349  NPV: 91.4530\n","positive TP: 203.0\n","positive TN: 428.0\n","positive FP: 8.0\n","positive FN: 40.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 50 minibatch: 1      time used: 20.1888427734375\n","minibatch AVG loss: 0.03889854459499475\n","Epoch: 45     train index of 50 minibatch: 2      time used: 19.55986452102661\n","minibatch AVG loss: 0.026859385037096218\n","Epoch: 45     train index of 50 minibatch: 3      time used: 19.210594415664673\n","minibatch AVG loss: 0.022195106855360792\n","Epoch: 45     train index of 50 minibatch: 4      time used: 19.591776371002197\n","minibatch AVG loss: 0.020474128209752963\n","Epoch: 45     train index of 50 minibatch: 5      time used: 19.687044382095337\n","minibatch AVG loss: 0.014630514715099708\n","Epoch: 45     train index of 50 minibatch: 6      time used: 19.39319372177124\n","minibatch AVG loss: 0.026635423202533273\n","\n","Epoch: 45  train \n","Loss: 0.0270  Acc: 98.9683\n","negative precision: 99.2529  recall: 99.1389\n","negative sensitivity: 99.1389  specificity: 98.6626\n","negative FPR: 1.3374  NPV: 98.4600\n","negative TP: 1727.0\n","negative TN: 959.0\n","negative FP: 13.0\n","negative FN: 15.0\n","positive precision: 98.4600  recall: 98.6626\n","positive sensitivity: 98.6626  specificity: 99.1389\n","positive FPR: 0.8611  NPV: 99.2529\n","positive TP: 959.0\n","positive TN: 1727.0\n","positive FP: 15.0\n","positive FN: 13.0\n","\n","\n","Epoch: 45     val index of 50 minibatch: 1      time used: 11.082704544067383\n","minibatch AVG loss: 0.20447270241340448\n","\n","Epoch: 45  val \n","Loss: 0.2609  Acc: 93.3726\n","negative precision: 95.3596  recall: 94.2661\n","negative sensitivity: 94.2661  specificity: 91.7695\n","negative FPR: 8.2305  NPV: 89.9194\n","negative TP: 411.0\n","negative TN: 223.0\n","negative FP: 20.0\n","negative FN: 25.0\n","positive precision: 89.9194  recall: 91.7695\n","positive sensitivity: 91.7695  specificity: 94.2661\n","positive FPR: 5.7339  NPV: 95.3596\n","positive TP: 223.0\n","positive TN: 411.0\n","positive FP: 25.0\n","positive FN: 20.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 50 minibatch: 1      time used: 19.847323417663574\n","minibatch AVG loss: 0.0220246171153849\n","Epoch: 46     train index of 50 minibatch: 2      time used: 19.763768911361694\n","minibatch AVG loss: 0.01696344994707033\n","Epoch: 46     train index of 50 minibatch: 3      time used: 19.320420026779175\n","minibatch AVG loss: 0.02677079656306887\n","Epoch: 46     train index of 50 minibatch: 4      time used: 19.43300724029541\n","minibatch AVG loss: 0.020586335074040108\n","Epoch: 46     train index of 50 minibatch: 5      time used: 19.45266366004944\n","minibatch AVG loss: 0.05307162670011167\n","Epoch: 46     train index of 50 minibatch: 6      time used: 19.817471742630005\n","minibatch AVG loss: 0.04312164836097509\n","\n","Epoch: 46  train \n","Loss: 0.0302  Acc: 99.0420\n","negative precision: 99.1409  recall: 99.3685\n","negative sensitivity: 99.3685  specificity: 98.4568\n","negative FPR: 1.5432  NPV: 98.8636\n","negative TP: 1731.0\n","negative TN: 957.0\n","negative FP: 15.0\n","negative FN: 11.0\n","positive precision: 98.8636  recall: 98.4568\n","positive sensitivity: 98.4568  specificity: 99.3685\n","positive FPR: 0.6315  NPV: 99.1409\n","positive TP: 957.0\n","positive TN: 1731.0\n","positive FP: 11.0\n","positive FN: 15.0\n","\n","\n","Epoch: 46     val index of 50 minibatch: 1      time used: 11.01391863822937\n","minibatch AVG loss: 0.20927632875944255\n","\n","Epoch: 46  val \n","Loss: 0.2349  Acc: 92.6362\n","negative precision: 95.0935  recall: 93.3486\n","negative sensitivity: 93.3486  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 88.4462\n","negative TP: 407.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 29.0\n","positive precision: 88.4462  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 93.3486\n","positive FPR: 6.6514  NPV: 95.0935\n","positive TP: 222.0\n","positive TN: 407.0\n","positive FP: 29.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 50 minibatch: 1      time used: 19.79798674583435\n","minibatch AVG loss: 0.07540748788393102\n","Epoch: 47     train index of 50 minibatch: 2      time used: 19.541417598724365\n","minibatch AVG loss: 0.04555095438845456\n","Epoch: 47     train index of 50 minibatch: 3      time used: 19.67996120452881\n","minibatch AVG loss: 0.038802613607258535\n","Epoch: 47     train index of 50 minibatch: 4      time used: 19.398967266082764\n","minibatch AVG loss: 0.06537076701875776\n","Epoch: 47     train index of 50 minibatch: 5      time used: 19.459609508514404\n","minibatch AVG loss: 0.029931766806403175\n","Epoch: 47     train index of 50 minibatch: 6      time used: 19.238270044326782\n","minibatch AVG loss: 0.053934467333601785\n","\n","Epoch: 47  train \n","Loss: 0.0499  Acc: 97.9735\n","negative precision: 98.5049  recall: 98.3352\n","negative sensitivity: 98.3352  specificity: 97.3251\n","negative FPR: 2.6749  NPV: 97.0256\n","negative TP: 1713.0\n","negative TN: 946.0\n","negative FP: 26.0\n","negative FN: 29.0\n","positive precision: 97.0256  recall: 97.3251\n","positive sensitivity: 97.3251  specificity: 98.3352\n","positive FPR: 1.6648  NPV: 98.5049\n","positive TP: 946.0\n","positive TN: 1713.0\n","positive FP: 29.0\n","positive FN: 26.0\n","\n","\n","Epoch: 47     val index of 50 minibatch: 1      time used: 11.075619459152222\n","minibatch AVG loss: 0.11218506545501442\n","\n","Epoch: 47  val \n","Loss: 0.2248  Acc: 92.7835\n","negative precision: 93.2886  recall: 95.6422\n","negative sensitivity: 95.6422  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 91.8103\n","negative TP: 417.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 19.0\n","positive precision: 91.8103  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 95.6422\n","positive FPR: 4.3578  NPV: 93.2886\n","positive TP: 213.0\n","positive TN: 417.0\n","positive FP: 19.0\n","positive FN: 30.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 50 minibatch: 1      time used: 20.14123225212097\n","minibatch AVG loss: 0.018646197780035435\n","Epoch: 48     train index of 50 minibatch: 2      time used: 19.472140312194824\n","minibatch AVG loss: 0.025702828431967646\n","Epoch: 48     train index of 50 minibatch: 3      time used: 19.478113651275635\n","minibatch AVG loss: 0.03586571315303445\n","Epoch: 48     train index of 50 minibatch: 4      time used: 19.517375707626343\n","minibatch AVG loss: 0.03640336909738835\n","Epoch: 48     train index of 50 minibatch: 5      time used: 19.133543252944946\n","minibatch AVG loss: 0.023905390710569917\n","Epoch: 48     train index of 50 minibatch: 6      time used: 19.767313480377197\n","minibatch AVG loss: 0.0203608240239555\n","\n","Epoch: 48  train \n","Loss: 0.0252  Acc: 98.9315\n","negative precision: 99.1959  recall: 99.1389\n","negative sensitivity: 99.1389  specificity: 98.5597\n","negative FPR: 1.4403  NPV: 98.4584\n","negative TP: 1727.0\n","negative TN: 958.0\n","negative FP: 14.0\n","negative FN: 15.0\n","positive precision: 98.4584  recall: 98.5597\n","positive sensitivity: 98.5597  specificity: 99.1389\n","positive FPR: 0.8611  NPV: 99.1959\n","positive TP: 958.0\n","positive TN: 1727.0\n","positive FP: 15.0\n","positive FN: 14.0\n","\n","\n","Epoch: 48     val index of 50 minibatch: 1      time used: 11.089714765548706\n","minibatch AVG loss: 0.18290250952944917\n","\n","Epoch: 48  val \n","Loss: 0.2409  Acc: 93.8144\n","negative precision: 95.3917  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 91.7695\n","negative FPR: 8.2305  NPV: 91.0204\n","negative TP: 414.0\n","negative TN: 223.0\n","negative FP: 20.0\n","negative FN: 22.0\n","positive precision: 91.0204  recall: 91.7695\n","positive sensitivity: 91.7695  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 95.3917\n","positive TP: 223.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 20.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 50 minibatch: 1      time used: 19.89681363105774\n","minibatch AVG loss: 0.039926522833120544\n","Epoch: 49     train index of 50 minibatch: 2      time used: 19.381593227386475\n","minibatch AVG loss: 0.012009564732725266\n","Epoch: 49     train index of 50 minibatch: 3      time used: 19.49747943878174\n","minibatch AVG loss: 0.05338856869726442\n","Epoch: 49     train index of 50 minibatch: 4      time used: 19.392874479293823\n","minibatch AVG loss: 0.009038705736165865\n","Epoch: 49     train index of 50 minibatch: 5      time used: 19.512796878814697\n","minibatch AVG loss: 0.05497470857517328\n","Epoch: 49     train index of 50 minibatch: 6      time used: 19.160707235336304\n","minibatch AVG loss: 0.04865480316220783\n","\n","Epoch: 49  train \n","Loss: 0.0358  Acc: 98.7104\n","negative precision: 99.0799  recall: 98.9093\n","negative sensitivity: 98.9093  specificity: 98.3539\n","negative FPR: 1.6461  NPV: 98.0513\n","negative TP: 1723.0\n","negative TN: 956.0\n","negative FP: 16.0\n","negative FN: 19.0\n","positive precision: 98.0513  recall: 98.3539\n","positive sensitivity: 98.3539  specificity: 98.9093\n","positive FPR: 1.0907  NPV: 99.0799\n","positive TP: 956.0\n","positive TN: 1723.0\n","positive FP: 19.0\n","positive FN: 16.0\n","\n","\n","Epoch: 49     val index of 50 minibatch: 1      time used: 11.092299461364746\n","minibatch AVG loss: 0.15366728347657044\n","\n","Epoch: 49  val \n","Loss: 0.2154  Acc: 93.2253\n","negative precision: 94.9309  recall: 94.4954\n","negative sensitivity: 94.4954  specificity: 90.9465\n","negative FPR: 9.0535  NPV: 90.2041\n","negative TP: 412.0\n","negative TN: 221.0\n","negative FP: 22.0\n","negative FN: 24.0\n","positive precision: 90.2041  recall: 90.9465\n","positive sensitivity: 90.9465  specificity: 94.4954\n","positive FPR: 5.5046  NPV: 94.9309\n","positive TP: 221.0\n","positive TN: 412.0\n","positive FP: 24.0\n","positive FN: 22.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 50 minibatch: 1      time used: 20.29597234725952\n","minibatch AVG loss: 0.01665756689151749\n","Epoch: 50     train index of 50 minibatch: 2      time used: 19.540785789489746\n","minibatch AVG loss: 0.03800172919291071\n","Epoch: 50     train index of 50 minibatch: 3      time used: 19.336072206497192\n","minibatch AVG loss: 0.03306463716900907\n","Epoch: 50     train index of 50 minibatch: 4      time used: 19.835634231567383\n","minibatch AVG loss: 0.02288268195348792\n","Epoch: 50     train index of 50 minibatch: 5      time used: 20.043070554733276\n","minibatch AVG loss: 0.04245726369379554\n","Epoch: 50     train index of 50 minibatch: 6      time used: 19.430286169052124\n","minibatch AVG loss: 0.05122002889867872\n","\n","Epoch: 50  train \n","Loss: 0.0352  Acc: 98.7104\n","negative precision: 99.1364  recall: 98.8519\n","negative sensitivity: 98.8519  specificity: 98.4568\n","negative FPR: 1.5432  NPV: 97.9529\n","negative TP: 1722.0\n","negative TN: 957.0\n","negative FP: 15.0\n","negative FN: 20.0\n","positive precision: 97.9529  recall: 98.4568\n","positive sensitivity: 98.4568  specificity: 98.8519\n","positive FPR: 1.1481  NPV: 99.1364\n","positive TP: 957.0\n","positive TN: 1722.0\n","positive FP: 20.0\n","positive FN: 15.0\n","\n","\n","Epoch: 50     val index of 50 minibatch: 1      time used: 11.389162302017212\n","minibatch AVG loss: 0.10163377048898838\n","\n","Epoch: 50  val \n","Loss: 0.2158  Acc: 93.6672\n","negative precision: 93.9597  recall: 96.3303\n","negative sensitivity: 96.3303  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 93.1034\n","negative TP: 420.0\n","negative TN: 216.0\n","negative FP: 27.0\n","negative FN: 16.0\n","positive precision: 93.1034  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 96.3303\n","positive FPR: 3.6697  NPV: 93.9597\n","positive TP: 216.0\n","positive TN: 420.0\n","positive FP: 16.0\n","positive FN: 27.0\n","\n","\n","\n","Training complete in 126m 50s\n","Best epoch idx:  34\n","Best epoch train Acc: 97.752395\n","Best epoch val Acc: 94.108984\n","negative precision: 96.6981  recall: 94.0367\n","negative sensitivity: 94.0367  specificity: 94.2387\n","negative FPR: 5.7613  NPV: 89.8039\n","positive precision: 89.8039  recall: 94.2387\n","positive sensitivity: 94.2387  specificity: 94.0367\n","positive FPR: 5.9633  NPV: 96.6981\n","model trained by GPU (idx:0) has been saved at  /home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_401_PT_lf25_b8_k1.pth\n","finished\n","\n","============================================================\n","Processing finished !\n","start time: 2021_10_28  07:05:10\n","end time: 2021_10_28  09:12:20\n","source: e3c8fe55b95c\n","\n","Preparing the email with auto log file :\n"," Train__2021_10_28-07_05_10_log \n","as  .rtf\n","processing log catched\n","server log catched\n","邮件发送失败:  _ssl.c:1074: The handshake operation timed out\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"IxmTlFRIV4lu","outputId":"bae9f223-2cfb-4204-c10a-1bb4b77436a0"},"source":["!python Test.py --model_idx Hybrid2_384_401_PT_lf25_b8_k1 --enable_attention_check --dataroot /data/pancreatic-cancer-project/dataset --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/runs"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[-0.1849,  0.4908]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : Hybrid2_384_401_PT_lf25_b8_k1\n","*********************************setting*************************************\n","Namespace(att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=None, cls_token_off=False, dataroot='/data/pancreatic-cancer-project/dataset', draw_root='/home/pancreatic-cancer-project/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='Hybrid2_384_401_PT_lf25_b8_k1', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 80 minibatch: 1      time used: 2.7299187183380127\n","minibatch AVG loss: 0.15840635249583102\n","Epoch: test     test index of 80 minibatch: 2      time used: 2.543712615966797\n","minibatch AVG loss: 0.5077730861492\n","Epoch: test     test index of 80 minibatch: 3      time used: 2.6265170574188232\n","minibatch AVG loss: 0.28986613685954127\n","Epoch: test     test index of 80 minibatch: 4      time used: 2.5925581455230713\n","minibatch AVG loss: 0.11010733084908679\n","Epoch: test     test index of 80 minibatch: 5      time used: 2.5947563648223877\n","minibatch AVG loss: 0.009047603192561838\n","Epoch: test     test index of 80 minibatch: 6      time used: 2.657339334487915\n","minibatch AVG loss: 0.08609526425952936\n","Epoch: test     test index of 80 minibatch: 7      time used: 2.6589131355285645\n","minibatch AVG loss: 0.05847291191557815\n","Epoch: test     test index of 80 minibatch: 8      time used: 2.6216540336608887\n","minibatch AVG loss: 0.17257851489221138\n","Epoch: test     test index of 80 minibatch: 9      time used: 2.629092216491699\n","minibatch AVG loss: 0.0850622631324768\n","Epoch: test     test index of 80 minibatch: 10      time used: 2.6902925968170166\n","minibatch AVG loss: 0.1152728953492442\n","\n","Epoch:  test \n","Loss: 0.1721  Acc: 94.5691\n","negative precision: 97.1591  recall: 94.3015\n","negative sensitivity: 94.3015  specificity: 95.0495\n","negative FPR: 4.9505  NPV: 90.2821\n","negative TP: 513.0\n","negative TN: 288.0\n","negative FP: 15.0\n","negative FN: 31.0\n","positive precision: 90.2821  recall: 95.0495\n","positive sensitivity: 95.0495  specificity: 94.3015\n","positive FPR: 5.6985  NPV: 97.1591\n","positive TP: 288.0\n","positive TN: 513.0\n","positive FP: 31.0\n","positive FN: 15.0\n","\n","\n","Testing complete in 2m 39s\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"hOpZ7cy8XlX3","outputId":"275958fd-07df-409e-bd91-64fe6e610b02"},"source":["!python Train.py --model_idx Hybrid2_384_401_PT_lf25_b8_k2 --lr 0.00001 --lrf 0.25 --enable_notify --enable_tensorboard --Pre_Trained_model_path /home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_PreTrain_000.pth --dataroot /data/pancreatic-cancer-project/dataset/fold_2 --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/runs"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Notify is waiting for reboost\n","*****************LOG_Cache_2021_10_28_10_05*****************\n","notify started\n","notify_frontend reboosted!\n","log_root_path log\n","mail_user tum9598@163.com\n","start monitoring:)\n","default_reciving_list ['tum9598@163.com']\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path='/home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_PreTrain_000.pth', att_module='SimAM', attn_drop_rate=0.0, backbone_PT_off=False, batch_size=8, check_minibatch=None, cls_token_off=False, dataroot='/data/pancreatic-cancer-project/dataset/fold_2', draw_root='/home/pancreatic-cancer-project/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=True, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=-1, intake_epochs=0, lr=1e-05, lrf=0.25, model_idx='Hybrid2_384_401_PT_lf25_b8_k2', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, pos_embedding_off=False)\n","we dont have more GPU idx here, try to use gpu_idx=0\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[ 2.1666e-01, -4.7421e-01,  1.8033e-01,  3.0284e-01, -4.8657e-01,\n","         -6.5892e-01,  6.7286e-01, -9.4735e-01,  1.8332e-03,  1.1280e+00,\n","          6.0691e-01,  4.4678e-01,  1.0305e+00,  2.6081e-01, -8.9324e-01,\n","          9.0739e-01,  3.3736e-01, -8.4321e-01, -5.3484e-01, -2.6153e-01,\n","          1.1813e-01,  5.8210e-01, -9.1074e-02,  5.5711e-02, -5.0008e-01,\n","          5.0046e-01,  2.2023e-01,  3.8575e-01, -3.6419e-01,  1.8775e-01,\n","         -1.0013e+00,  9.7029e-01, -8.9606e-01,  5.8526e-01, -6.0324e-02,\n","          2.8680e-01, -1.7486e-01, -5.7358e-02, -2.3304e-02, -8.9619e-02,\n","         -5.2647e-01,  7.6940e-01,  4.0491e-01, -1.8638e-01,  1.2026e+00,\n","         -2.9995e-01, -3.0298e-01, -5.5280e-01, -3.2249e-01,  5.9502e-01,\n","         -4.3468e-01,  1.0191e+00,  1.4346e-01,  1.5864e-01,  7.4061e-01,\n","         -3.8455e-01, -1.1300e+00,  4.2022e-01, -7.5100e-01, -4.4431e-01,\n","         -3.2544e-01,  4.3934e-01,  2.9867e-01,  1.0853e-01,  4.0149e-01,\n","          4.8915e-01,  6.2100e-02, -7.2858e-01, -8.0314e-02,  6.3522e-02,\n","          9.2666e-01, -4.2381e-01, -3.6368e-01,  1.6887e-02, -5.2490e-01,\n","         -5.2767e-01, -2.1943e-01,  5.2008e-01,  4.3857e-01, -6.1164e-01,\n","         -4.1595e-01,  2.7936e-01,  7.3350e-01,  7.9244e-01, -1.7026e-01,\n","          1.6747e-01, -6.8064e-02, -7.3537e-02, -1.0140e+00,  8.4919e-02,\n","         -4.0062e-01,  1.6448e+00, -9.2639e-01,  2.0900e-01, -1.8306e-01,\n","          5.8141e-01,  3.8690e-01, -6.2016e-01,  4.9578e-01,  1.0685e+00,\n","          8.6109e-02,  1.3977e-01,  6.8784e-01, -8.0958e-01,  2.0807e-01,\n","         -4.6999e-01, -1.7971e-01, -8.4584e-02,  6.8367e-01,  8.3208e-01,\n","          5.2042e-01, -4.3107e-01, -4.5932e-01, -4.8616e-01, -4.6352e-01,\n","         -3.3450e-01,  4.8264e-01, -2.5343e-01,  4.8577e-02, -2.6356e-01,\n","          1.0537e+00, -1.1945e-01, -1.7415e+00, -5.0386e-01, -2.2265e-01,\n","          3.1367e-01, -1.4120e+00, -3.5089e-01, -1.9413e-01,  5.0706e-02,\n","          1.0555e+00,  1.0856e-01,  4.9621e-01, -3.9441e-01,  3.0980e-01,\n","          1.5954e-01, -2.2117e-01,  4.4933e-01, -1.4019e-01,  3.3464e-01,\n","         -8.0265e-01,  7.6930e-01,  3.9676e-01, -2.3813e-01,  5.8820e-01,\n","         -2.5222e-01, -2.2237e-01, -5.7166e-01, -6.9520e-01, -8.6945e-01,\n","         -1.9836e-01, -5.2389e-01, -6.6921e-01, -9.6664e-01, -2.1290e-01,\n","          3.6217e-02,  5.8212e-01,  7.6754e-01,  6.3949e-01, -7.3677e-01,\n","          1.2266e+00, -1.0001e-01, -2.8125e-01, -8.0921e-01,  1.1078e+00,\n","          1.0405e+00, -3.8854e-01,  5.2377e-01,  4.7812e-01, -6.1291e-02,\n","         -6.7650e-01, -9.9664e-01, -7.8526e-01, -2.5582e-01,  8.0009e-01,\n","          1.6076e-01,  1.3886e-01,  5.7681e-01,  3.2688e-01, -1.0707e+00,\n","         -7.5648e-01,  3.7256e-01,  7.4912e-01,  1.5014e-01,  5.6243e-01,\n","          6.6609e-01,  3.8102e-01,  4.9880e-01,  2.9567e-01,  1.2317e+00,\n","          2.2053e-01,  1.0838e-01, -3.2360e-01, -4.1344e-01,  2.6800e-01,\n","          1.6090e-01,  9.9983e-01,  7.1696e-01,  3.0113e-01,  1.4047e-01,\n","         -2.8635e-01, -2.6977e-02,  1.0585e+00, -4.0660e-01, -4.8512e-01,\n","         -5.6495e-01,  4.2269e-01, -4.4172e-01, -2.9341e-01,  8.9416e-02,\n","          5.7455e-01, -1.5858e-01,  1.9142e-01, -8.2919e-01, -1.1784e-01,\n","         -3.8307e-01, -8.3623e-01, -1.1778e+00,  1.0831e+00,  2.3893e-01,\n","          5.4679e-01,  2.3990e-01, -9.2425e-02,  5.3054e-01, -3.4389e-01,\n","         -1.4973e+00, -3.8203e-01, -4.5449e-01, -2.0671e-01, -1.8606e-02,\n","          6.9127e-01,  1.2140e-01, -7.5049e-01,  2.3656e-01, -9.5200e-02,\n","         -4.1982e-01,  4.5942e-01,  3.1451e-01, -4.4832e-01,  3.2117e-01,\n","          1.5423e-03,  2.6317e-01,  8.3795e-01,  6.1409e-01,  4.5812e-01,\n","         -4.3683e-01, -2.7957e-01,  1.1908e-01,  1.0032e-01,  2.6231e-02,\n","          4.7835e-03,  3.9014e-01,  2.5367e-02, -9.4333e-01,  2.7289e-01,\n","          1.3458e+00, -7.0671e-01, -4.3741e-01,  6.2262e-01, -4.7800e-01,\n","          4.2114e-02, -5.2731e-01,  1.4530e-01,  3.4526e-01, -4.0380e-01,\n","          8.0879e-01,  2.0872e-01, -3.1978e-01, -4.1021e-01,  3.0624e-02,\n","         -9.4838e-01,  1.8232e-01,  8.7393e-01, -2.8509e-01,  2.8806e-01,\n","         -1.0527e-01, -5.5985e-01, -2.3851e-01, -6.7235e-01, -6.8656e-01,\n","          6.0549e-01, -4.0970e-03,  8.3409e-01,  1.6456e-01,  1.7790e-02,\n","         -6.0855e-01, -3.1545e-02, -2.7620e-01,  4.7811e-01,  1.0174e+00,\n","          6.7161e-01,  5.8914e-01, -2.6104e-02,  1.1465e+00,  4.7396e-01,\n","          1.7520e-01, -5.3694e-01, -1.0094e+00,  6.0517e-01, -6.2272e-01,\n","         -1.5679e-01, -8.0598e-01, -8.0097e-02,  1.4145e+00, -1.2229e+00,\n","         -8.1610e-03, -4.1985e-01, -8.1593e-01,  6.1630e-01, -6.2003e-01,\n","         -5.1867e-01, -1.3416e-01,  1.1829e-01, -6.4824e-01,  8.1688e-01,\n","          3.5813e-01, -8.2212e-01, -5.4484e-01,  1.0119e-01, -2.3940e-01,\n","          1.0492e+00, -3.2231e-01,  8.8072e-01, -2.0386e-01,  3.4266e-01,\n","         -2.1809e-04, -4.3811e-01, -1.4643e-01, -1.4370e-01,  2.2846e-01,\n","         -4.9339e-01, -3.7553e-02,  8.9154e-01,  1.3907e-01,  9.4544e-02,\n","          2.1967e-01,  1.0154e+00,  4.4208e-01, -4.6395e-01, -9.0063e-01,\n","         -6.6472e-01,  3.4370e-01, -1.0131e+00, -1.3204e+00, -1.0094e+00,\n","         -5.9364e-01, -4.8717e-01,  4.4058e-01,  5.4193e-01,  1.6144e-01,\n","         -7.4380e-01,  1.9032e-01,  2.3118e-02,  2.8254e-01, -3.4857e-01,\n","          1.1796e-01,  4.1222e-01, -1.8240e-01, -2.9825e-01,  1.6421e-01,\n","         -8.3378e-02,  1.9388e-01,  6.3008e-01, -6.3716e-01,  1.5108e+00,\n","          9.1688e-01,  5.8826e-01, -3.2557e-01,  3.7183e-01, -1.6559e+00,\n","         -1.1680e-01, -8.7413e-01, -3.1305e-01,  3.6092e-01,  6.5580e-01,\n","         -8.9679e-01, -5.7921e-01,  1.0326e-01,  1.0422e+00, -5.1449e-01,\n","          9.4280e-01,  4.0336e-01,  2.6656e-01, -3.8148e-01,  1.4276e-01,\n","          1.5177e-02, -9.5266e-01, -5.7478e-01, -7.0650e-01, -6.0620e-01,\n","          1.6522e-01,  7.8339e-01,  2.7598e-02,  6.0522e-01,  6.7714e-02,\n","         -2.0373e-01,  5.2184e-01, -2.0795e-01, -1.4365e-01,  6.2235e-01,\n","         -2.1461e-01,  9.8679e-02,  4.0264e-01,  9.4615e-01, -7.1391e-01,\n","         -5.0820e-02, -5.5782e-01,  8.4015e-01, -2.4695e-01,  2.0569e-01,\n","         -1.0167e+00, -4.0228e-01,  1.1637e+00, -2.4513e-01,  9.5664e-02,\n","          2.8576e-01,  1.1327e+00,  1.8957e-01, -7.1850e-01,  4.4865e-01,\n","          3.5293e-01,  4.0419e-01,  1.1109e+00,  1.3175e+00,  2.4401e-02,\n","          3.7667e-01, -2.5981e-01, -2.6797e-01,  1.5575e+00,  4.9660e-02,\n","          1.1472e-01, -1.1175e-02,  3.6860e-01,  6.4207e-01, -1.0836e-04,\n","         -6.2095e-01,  2.5976e-01,  3.8648e-01,  1.0039e+00,  5.3080e-01,\n","         -9.1269e-01,  1.0460e+00, -3.9773e-01,  4.7867e-01,  3.3357e-01,\n","          1.6247e-01, -8.7713e-03,  7.6417e-01, -1.5434e+00,  3.6742e-01,\n","         -1.7368e-01, -1.3163e+00,  1.3577e+00, -1.0784e-01, -1.1486e-01,\n","          1.2644e+00, -3.4705e-01,  2.6563e-01,  2.8580e-01, -2.3911e-01,\n","         -5.8467e-01, -4.9897e-01,  2.1585e-01,  1.4748e+00, -4.4899e-01,\n","          8.8774e-01, -1.6235e-01, -2.7376e-01, -7.1224e-01, -1.3764e-01,\n","          3.6147e-01,  6.7793e-01,  6.9520e-01,  2.7143e-01,  5.9280e-01,\n","          5.4819e-01,  4.9856e-01,  1.2604e+00,  2.9709e-01,  2.6040e-01,\n","         -5.8097e-01,  1.5439e-01,  8.0847e-01, -3.0217e-01,  6.4507e-01,\n","          2.2922e-02,  2.3991e-01,  1.2384e+00, -2.2171e-01, -7.0928e-03,\n","          1.9838e-01,  8.3678e-01, -8.5981e-01, -2.8568e-01,  1.9095e-01,\n","         -5.9930e-01,  3.4530e-01,  1.7907e-01, -5.8533e-01, -3.9108e-01,\n","          1.3534e-01, -3.9534e-01,  2.9089e-01,  1.1026e-01,  2.2106e-01,\n","         -8.9309e-02, -3.6811e-01, -2.6436e-01, -4.2888e-01, -1.5628e-01,\n","          3.5117e-01,  5.9574e-01,  1.6612e-01, -3.4786e-01, -2.6749e-01,\n","         -8.0357e-02,  9.3936e-01, -1.1385e+00,  6.2440e-01,  9.5759e-01,\n","         -4.1871e-01, -3.5787e-01, -3.8892e-01,  4.0981e-01, -3.9806e-01,\n","         -1.7236e-01,  2.1272e-01,  3.7206e-01,  7.2732e-01, -4.1594e-01,\n","          4.6727e-01, -8.8528e-01, -9.8807e-01, -1.5185e-01,  4.2987e-01,\n","         -1.7785e-01, -5.0763e-01, -8.4378e-01,  6.2516e-01,  4.7258e-01,\n","          7.2423e-01,  8.7806e-01,  4.1242e-01, -1.4148e-01, -5.0299e-01,\n","          7.8564e-01,  7.9717e-02, -6.8691e-02, -2.9585e-01, -3.4100e-01,\n","          5.4962e-01,  6.2462e-02, -1.0496e+00,  3.7820e-01,  9.5406e-01,\n","         -8.6697e-01,  3.3542e-01,  1.3459e-01,  1.1273e-01, -6.4730e-01,\n","         -3.3621e-01,  2.6752e-01,  2.4378e-01, -2.2441e-01,  2.6785e-01,\n","         -5.9391e-01, -4.1546e-01, -7.9487e-01, -2.9756e-01,  5.7530e-01,\n","          7.3612e-01, -1.3985e+00,  1.2317e+00,  7.2213e-01, -5.8227e-01,\n","         -1.0673e-01,  5.7164e-01,  1.5425e-01,  1.0895e+00,  1.2320e+00,\n","         -2.9984e-01, -8.0997e-01, -8.0534e-01,  2.7615e-01, -1.0259e-01,\n","         -2.0853e-01,  7.6011e-01, -2.0839e-01, -1.7049e-01, -8.2152e-02,\n","         -7.6952e-01,  5.5893e-01, -4.5167e-02,  2.1071e-01, -1.6695e-01,\n","         -9.4379e-01,  7.0505e-01, -1.0129e+00, -1.4160e+00, -9.1469e-01,\n","          6.5794e-02,  5.9263e-02,  4.3184e-01,  7.7075e-01,  1.1557e+00,\n","         -1.5775e-01, -6.4064e-01, -6.5827e-01, -8.9281e-01,  1.2247e+00,\n","         -7.1033e-02,  1.5717e-01,  2.5382e-01, -5.3365e-01, -4.3624e-01,\n","          8.6912e-02, -2.6298e-01,  1.1626e-01,  8.7539e-01, -1.9012e-01,\n","         -6.6729e-01, -2.3464e-01,  8.6478e-01,  7.2786e-01,  3.3397e-01,\n","         -1.6017e-01, -5.0254e-01, -7.3996e-02, -3.7829e-01, -1.4741e+00,\n","         -8.3302e-01,  3.7283e-01,  2.1826e-01,  2.5692e-02, -6.5851e-01,\n","         -2.9597e-01, -3.3820e-01,  1.3639e+00, -7.7488e-01,  5.1539e-01,\n","         -5.7388e-01, -7.8878e-02,  1.4294e-02, -1.1069e+00, -3.7966e-01,\n","         -8.9033e-01, -1.2349e+00,  8.7038e-01, -9.4274e-01,  7.7459e-01,\n","          2.9489e-03, -5.5035e-01, -4.9410e-01,  1.6765e-01, -8.5204e-01,\n","         -4.2691e-01, -1.8325e-01,  1.5029e+00,  5.1469e-01,  5.7784e-01,\n","         -6.3793e-01, -6.1114e-01, -4.0964e-02, -8.2097e-02, -1.5212e-01,\n","         -1.9229e-01,  3.4257e-01,  3.9545e-02, -9.6416e-02, -1.1933e-02,\n","         -9.0584e-01,  8.6432e-01, -3.7954e-01, -1.8582e-01,  5.3733e-01,\n","         -1.2165e-01,  2.3117e-01,  4.4549e-01,  9.0628e-02, -3.9202e-01,\n","          5.9542e-01, -6.2026e-01,  1.7630e-01, -2.6233e-01, -3.4569e-01,\n","          4.4749e-01, -1.3701e-01,  5.9270e-02, -8.8871e-01, -7.8990e-01,\n","         -8.5382e-01, -2.1154e-01, -1.2771e+00, -9.5926e-03,  8.8370e-01,\n","          7.4744e-01,  6.9917e-01,  1.4780e-01, -2.1493e-01,  3.7231e-01,\n","          9.2370e-02,  1.0832e+00,  3.9699e-01,  1.0125e-01,  7.1224e-01,\n","          6.8133e-01, -8.9262e-01, -1.1712e+00,  2.6976e-01,  5.7062e-01,\n","          4.7347e-01, -9.0269e-01, -7.5984e-02,  1.9798e-02,  4.9426e-01,\n","         -6.8980e-01,  6.2834e-01,  3.1884e-01,  2.1181e-01,  2.9812e-02,\n","         -1.4362e-01,  6.0778e-01,  9.0836e-01,  2.4475e-01,  2.1145e-01,\n","         -3.1287e-01, -1.2203e+00, -2.6419e-01, -4.4693e-01, -4.4690e-02,\n","          6.8615e-01,  4.1714e-01,  5.6715e-01,  1.3130e-02,  4.7644e-01,\n","         -1.9041e-01, -2.4661e-01,  3.8793e-01, -1.3892e-01, -5.6922e-01,\n","         -3.8136e-01,  7.2892e-01, -6.4470e-01, -5.5313e-01,  6.1247e-01,\n","         -1.0014e-01,  4.0849e-01, -1.9521e-01, -5.9512e-01, -6.4988e-02,\n","         -2.7915e-01,  5.3021e-01, -1.6933e-01, -4.2548e-01,  2.4398e-01,\n","         -2.7639e-01,  5.9434e-01,  1.4690e+00,  4.8321e-01,  1.6484e-01,\n","          6.0448e-02, -3.8277e-02,  1.6056e-01,  7.0794e-01, -2.1264e-01,\n","          2.2819e-01,  6.3278e-01,  1.9960e-02, -1.7677e-01,  1.8472e-01,\n","         -3.5790e-01, -2.3733e-01,  1.1483e-02, -9.6668e-01, -5.1292e-01,\n","          1.6635e-01,  1.5496e-01,  1.5968e-01, -6.0187e-01,  7.4434e-01,\n","          2.1636e-01, -1.9631e-02, -1.2121e+00, -1.9568e-01,  4.4568e-01,\n","         -5.8059e-01,  5.7306e-01, -3.5325e-01,  1.2262e+00,  8.5117e-01,\n","         -1.2517e+00,  1.5711e-01, -4.8338e-01, -8.9890e-01, -5.7489e-01,\n","          6.4357e-01, -7.7923e-01,  3.3649e-01,  1.3424e-01, -1.1829e-01,\n","         -2.0373e-01, -2.7749e-01, -1.3068e+00, -5.0447e-01, -4.9479e-01,\n","         -6.8277e-01,  5.1541e-01,  9.5475e-01, -1.2515e-01,  3.1012e-01,\n","         -2.8129e-01,  1.7821e+00,  8.9728e-01, -3.3743e-01,  2.3577e-01,\n","         -1.7557e-01, -1.1398e+00,  9.9451e-01, -9.4415e-01, -6.0988e-01,\n","          1.3445e-01, -3.4160e-01,  5.0410e-01, -3.7131e-01, -1.6956e-01,\n","          3.4758e-01, -4.7118e-01, -4.7098e-01, -2.7183e-01,  8.8055e-01,\n","          1.4070e-01,  2.8334e-01, -2.1244e-01, -8.2920e-02,  6.8698e-01,\n","         -1.3666e+00, -8.1465e-01,  3.3053e-01,  2.8022e-02,  1.4109e-01,\n","         -7.3691e-01,  3.9807e-01,  9.1929e-02, -5.7754e-01, -3.9033e-02,\n","          8.0497e-02, -1.2178e-01, -2.4387e-01,  4.7647e-01, -1.0630e-01,\n","         -1.0826e-01, -2.1110e-03,  3.7709e-01, -1.4875e-01, -1.1374e+00,\n","         -7.6128e-01, -3.7458e-02, -1.8034e-01, -3.6584e-01,  2.2185e-01,\n","         -4.3772e-01, -7.1709e-01,  5.8107e-01,  1.8911e-02,  2.8151e-01,\n","         -5.4206e-01,  8.0032e-01,  9.6944e-01, -2.8757e-01, -1.7112e-01,\n","         -6.1564e-01,  6.8253e-01,  1.6584e-01,  7.0866e-01, -6.5146e-01,\n","         -8.7727e-01,  1.8078e-01,  5.9838e-01,  7.1257e-01,  4.9618e-01,\n","          3.7922e-01,  9.9859e-01,  6.3601e-02,  1.6859e-01,  3.9038e-01,\n","          3.1408e-01, -5.3799e-01,  5.2695e-01, -7.0191e-01, -2.1992e-01,\n","         -1.0359e+00, -6.0567e-01,  2.2677e-01,  1.7703e-01, -1.1606e+00,\n","          2.3550e-01,  5.5554e-01,  1.9281e+00,  1.9194e-01, -8.5557e-01,\n","          4.5519e-02,  4.3140e-01, -1.1850e+00,  2.7465e-01, -3.5207e-01,\n","         -9.3445e-01, -2.0982e-01,  9.0532e-01, -1.1775e+00,  9.8909e-01,\n","         -7.2240e-01,  5.4872e-03,  6.5173e-01,  9.2605e-01,  3.5818e-01,\n","         -7.0264e-02, -5.3810e-01,  6.0329e-01,  7.2034e-02,  4.8261e-01,\n","         -7.4249e-02, -3.4379e-01, -8.3596e-01, -6.9483e-01, -1.6042e-01,\n","         -3.2902e-01, -2.7382e-01, -1.1209e+00, -3.7440e-01, -1.3012e+00,\n","         -1.0944e-02,  6.2558e-01, -2.1302e-01, -1.5804e-01,  1.0750e+00,\n","          1.9843e-01,  1.1140e+00, -1.3254e-01, -2.3597e-01,  6.4282e-01,\n","         -1.4200e-01,  6.1646e-01,  6.9602e-01,  1.4218e-01, -6.0943e-01,\n","         -2.3569e-01,  2.2932e-01,  2.0487e-01, -1.4491e+00, -1.1249e-01,\n","         -8.1519e-01,  2.7957e-01,  2.0120e-01,  8.3839e-01, -9.2751e-01,\n","          4.0007e-01,  1.0488e-02, -5.1090e-01, -4.0092e-02,  4.4054e-02,\n","         -8.8771e-03,  4.2877e-01, -6.0787e-02, -3.7034e-01, -4.1881e-01,\n","          6.2871e-01, -1.8778e-01, -4.2418e-01,  1.6102e-01, -9.5770e-02,\n","         -2.3623e-01,  4.4124e-01, -5.5353e-01, -2.9374e-01, -1.1476e-01,\n","         -2.6253e-01, -4.5752e-01,  9.6869e-01, -4.6147e-04, -5.1060e-01,\n","         -9.5821e-01,  1.0444e+00,  1.0781e+00,  8.4808e-01, -3.7346e-01,\n","          2.9457e-01,  4.7508e-02,  4.4786e-01,  1.0769e+00, -1.7285e-02,\n","         -4.1817e-01,  1.7504e-01, -5.0107e-01, -4.1750e-01, -7.8469e-02,\n","         -6.2529e-02,  7.1313e-01,  3.7026e-01, -5.6427e-01,  9.2629e-03]],\n","       grad_fn=<AddmmBackward>)\n","model is ready now!\n","pretrain model loaded\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 192, 192]           9,408\n","       BatchNorm2d-2         [-1, 64, 192, 192]             128\n","              ReLU-3         [-1, 64, 192, 192]               0\n","         MaxPool2d-4           [-1, 64, 96, 96]               0\n","            Conv2d-5           [-1, 64, 96, 96]           4,096\n","       BatchNorm2d-6           [-1, 64, 96, 96]             128\n","              ReLU-7           [-1, 64, 96, 96]               0\n","            Conv2d-8           [-1, 64, 96, 96]          36,864\n","       BatchNorm2d-9           [-1, 64, 96, 96]             128\n","             ReLU-10           [-1, 64, 96, 96]               0\n","           Conv2d-11          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-12          [-1, 256, 96, 96]             512\n","             ReLU-13          [-1, 256, 96, 96]               0\n","           Conv2d-14          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-15          [-1, 256, 96, 96]             512\n","             ReLU-16          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-17          [-1, 256, 96, 96]               0\n","           Conv2d-18           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-19           [-1, 64, 96, 96]             128\n","             ReLU-20           [-1, 64, 96, 96]               0\n","           Conv2d-21           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-22           [-1, 64, 96, 96]             128\n","             ReLU-23           [-1, 64, 96, 96]               0\n","           Conv2d-24          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-25          [-1, 256, 96, 96]             512\n","             ReLU-26          [-1, 256, 96, 96]               0\n","             ReLU-27          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-28          [-1, 256, 96, 96]               0\n","           Conv2d-29           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-30           [-1, 64, 96, 96]             128\n","             ReLU-31           [-1, 64, 96, 96]               0\n","           Conv2d-32           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-33           [-1, 64, 96, 96]             128\n","             ReLU-34           [-1, 64, 96, 96]               0\n","           Conv2d-35          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-36          [-1, 256, 96, 96]             512\n","             ReLU-37          [-1, 256, 96, 96]               0\n","             ReLU-38          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-39          [-1, 256, 96, 96]               0\n","           Conv2d-40          [-1, 128, 48, 48]          32,768\n","      BatchNorm2d-41          [-1, 128, 48, 48]             256\n","             ReLU-42          [-1, 128, 48, 48]               0\n","           Conv2d-43          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-44          [-1, 128, 48, 48]             256\n","             ReLU-45          [-1, 128, 48, 48]               0\n","           Conv2d-46          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-47          [-1, 512, 48, 48]           1,024\n","             ReLU-48          [-1, 512, 48, 48]               0\n","           Conv2d-49          [-1, 512, 48, 48]         131,072\n","      BatchNorm2d-50          [-1, 512, 48, 48]           1,024\n","             ReLU-51          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-52          [-1, 512, 48, 48]               0\n","           Conv2d-53          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-54          [-1, 128, 48, 48]             256\n","             ReLU-55          [-1, 128, 48, 48]               0\n","           Conv2d-56          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-57          [-1, 128, 48, 48]             256\n","             ReLU-58          [-1, 128, 48, 48]               0\n","           Conv2d-59          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-60          [-1, 512, 48, 48]           1,024\n","             ReLU-61          [-1, 512, 48, 48]               0\n","             ReLU-62          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-63          [-1, 512, 48, 48]               0\n","           Conv2d-64          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-65          [-1, 128, 48, 48]             256\n","             ReLU-66          [-1, 128, 48, 48]               0\n","           Conv2d-67          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-68          [-1, 128, 48, 48]             256\n","             ReLU-69          [-1, 128, 48, 48]               0\n","           Conv2d-70          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-71          [-1, 512, 48, 48]           1,024\n","             ReLU-72          [-1, 512, 48, 48]               0\n","             ReLU-73          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-74          [-1, 512, 48, 48]               0\n","           Conv2d-75          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-76          [-1, 128, 48, 48]             256\n","             ReLU-77          [-1, 128, 48, 48]               0\n","           Conv2d-78          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-79          [-1, 128, 48, 48]             256\n","             ReLU-80          [-1, 128, 48, 48]               0\n","           Conv2d-81          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-82          [-1, 512, 48, 48]           1,024\n","             ReLU-83          [-1, 512, 48, 48]               0\n","             ReLU-84          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-85          [-1, 512, 48, 48]               0\n","           Conv2d-86          [-1, 256, 24, 24]         131,072\n","      BatchNorm2d-87          [-1, 256, 24, 24]             512\n","             ReLU-88          [-1, 256, 24, 24]               0\n","           Conv2d-89          [-1, 256, 24, 24]         589,824\n","      BatchNorm2d-90          [-1, 256, 24, 24]             512\n","             ReLU-91          [-1, 256, 24, 24]               0\n","           Conv2d-92         [-1, 1024, 24, 24]         262,144\n","      BatchNorm2d-93         [-1, 1024, 24, 24]           2,048\n","             ReLU-94         [-1, 1024, 24, 24]               0\n","           Conv2d-95         [-1, 1024, 24, 24]         524,288\n","      BatchNorm2d-96         [-1, 1024, 24, 24]           2,048\n","             ReLU-97         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-98         [-1, 1024, 24, 24]               0\n","           Conv2d-99          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-100          [-1, 256, 24, 24]             512\n","            ReLU-101          [-1, 256, 24, 24]               0\n","          Conv2d-102          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-103          [-1, 256, 24, 24]             512\n","            ReLU-104          [-1, 256, 24, 24]               0\n","          Conv2d-105         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-106         [-1, 1024, 24, 24]           2,048\n","            ReLU-107         [-1, 1024, 24, 24]               0\n","            ReLU-108         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-109         [-1, 1024, 24, 24]               0\n","          Conv2d-110          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-111          [-1, 256, 24, 24]             512\n","            ReLU-112          [-1, 256, 24, 24]               0\n","          Conv2d-113          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-114          [-1, 256, 24, 24]             512\n","            ReLU-115          [-1, 256, 24, 24]               0\n","          Conv2d-116         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-117         [-1, 1024, 24, 24]           2,048\n","            ReLU-118         [-1, 1024, 24, 24]               0\n","            ReLU-119         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-120         [-1, 1024, 24, 24]               0\n","          Conv2d-121          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-122          [-1, 256, 24, 24]             512\n","            ReLU-123          [-1, 256, 24, 24]               0\n","          Conv2d-124          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-125          [-1, 256, 24, 24]             512\n","            ReLU-126          [-1, 256, 24, 24]               0\n","          Conv2d-127         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-128         [-1, 1024, 24, 24]           2,048\n","            ReLU-129         [-1, 1024, 24, 24]               0\n","            ReLU-130         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-131         [-1, 1024, 24, 24]               0\n","          Conv2d-132          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-133          [-1, 256, 24, 24]             512\n","            ReLU-134          [-1, 256, 24, 24]               0\n","          Conv2d-135          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-136          [-1, 256, 24, 24]             512\n","            ReLU-137          [-1, 256, 24, 24]               0\n","          Conv2d-138         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-139         [-1, 1024, 24, 24]           2,048\n","            ReLU-140         [-1, 1024, 24, 24]               0\n","            ReLU-141         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-142         [-1, 1024, 24, 24]               0\n","          Conv2d-143          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-144          [-1, 256, 24, 24]             512\n","            ReLU-145          [-1, 256, 24, 24]               0\n","          Conv2d-146          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-147          [-1, 256, 24, 24]             512\n","            ReLU-148          [-1, 256, 24, 24]               0\n","          Conv2d-149         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-150         [-1, 1024, 24, 24]           2,048\n","            ReLU-151         [-1, 1024, 24, 24]               0\n","            ReLU-152         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-153         [-1, 1024, 24, 24]               0\n","          Conv2d-154          [-1, 512, 12, 12]         524,288\n","     BatchNorm2d-155          [-1, 512, 12, 12]           1,024\n","            ReLU-156          [-1, 512, 12, 12]               0\n","          Conv2d-157          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-158          [-1, 512, 12, 12]           1,024\n","            ReLU-159          [-1, 512, 12, 12]               0\n","          Conv2d-160         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-161         [-1, 2048, 12, 12]           4,096\n","            ReLU-162         [-1, 2048, 12, 12]               0\n","          Conv2d-163         [-1, 2048, 12, 12]       2,097,152\n","     BatchNorm2d-164         [-1, 2048, 12, 12]           4,096\n","            ReLU-165         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-166         [-1, 2048, 12, 12]               0\n","          Conv2d-167          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-168          [-1, 512, 12, 12]           1,024\n","            ReLU-169          [-1, 512, 12, 12]               0\n","          Conv2d-170          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-171          [-1, 512, 12, 12]           1,024\n","            ReLU-172          [-1, 512, 12, 12]               0\n","          Conv2d-173         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-174         [-1, 2048, 12, 12]           4,096\n","            ReLU-175         [-1, 2048, 12, 12]               0\n","            ReLU-176         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-177         [-1, 2048, 12, 12]               0\n","          Conv2d-178          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-179          [-1, 512, 12, 12]           1,024\n","            ReLU-180          [-1, 512, 12, 12]               0\n","          Conv2d-181          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-182          [-1, 512, 12, 12]           1,024\n","            ReLU-183          [-1, 512, 12, 12]               0\n","          Conv2d-184         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-185         [-1, 2048, 12, 12]           4,096\n","            ReLU-186         [-1, 2048, 12, 12]               0\n","            ReLU-187         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-188         [-1, 2048, 12, 12]               0\n","Hybrid_backbone_4-189  [[-1, 256, 96, 96], [-1, 512, 48, 48], [-1, 1024, 24, 24], [-1, 2048, 12, 12]]               0\n","         Sigmoid-190         [-1, 2048, 12, 12]               0\n","    simam_module-191         [-1, 2048, 12, 12]               0\n","          Conv2d-192          [-1, 768, 12, 12]       1,573,632\n","Last_feature_map_Embed-193             [-1, 144, 768]               0\n","         Sigmoid-194          [-1, 256, 96, 96]               0\n","    simam_module-195          [-1, 256, 96, 96]               0\n","       MaxPool2d-196          [-1, 256, 12, 12]               0\n","          Conv2d-197          [-1, 768, 12, 12]         197,376\n","       LayerNorm-198             [-1, 144, 768]           1,536\n","       AvgPool2d-199          [-1, 256, 12, 12]               0\n","          Conv2d-200          [-1, 768, 12, 12]         197,376\n","       LayerNorm-201             [-1, 144, 768]           1,536\n","     Focus_Embed-202  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-203          [-1, 512, 48, 48]               0\n","    simam_module-204          [-1, 512, 48, 48]               0\n","       MaxPool2d-205          [-1, 512, 12, 12]               0\n","          Conv2d-206          [-1, 768, 12, 12]         393,984\n","       LayerNorm-207             [-1, 144, 768]           1,536\n","       AvgPool2d-208          [-1, 512, 12, 12]               0\n","          Conv2d-209          [-1, 768, 12, 12]         393,984\n","       LayerNorm-210             [-1, 144, 768]           1,536\n","     Focus_Embed-211  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-212         [-1, 1024, 24, 24]               0\n","    simam_module-213         [-1, 1024, 24, 24]               0\n","       MaxPool2d-214         [-1, 1024, 12, 12]               0\n","          Conv2d-215          [-1, 768, 12, 12]         787,200\n","       LayerNorm-216             [-1, 144, 768]           1,536\n","       AvgPool2d-217         [-1, 1024, 12, 12]               0\n","          Conv2d-218          [-1, 768, 12, 12]         787,200\n","       LayerNorm-219             [-1, 144, 768]           1,536\n","     Focus_Embed-220  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-221         [-1, 2048, 12, 12]               0\n","    simam_module-222         [-1, 2048, 12, 12]               0\n","       MaxPool2d-223         [-1, 2048, 12, 12]               0\n","          Conv2d-224          [-1, 768, 12, 12]       1,573,632\n","       LayerNorm-225             [-1, 144, 768]           1,536\n","       AvgPool2d-226         [-1, 2048, 12, 12]               0\n","          Conv2d-227          [-1, 768, 12, 12]       1,573,632\n","       LayerNorm-228             [-1, 144, 768]           1,536\n","     Focus_Embed-229  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Dropout-230             [-1, 145, 768]               0\n","         Dropout-231             [-1, 145, 768]               0\n","         Dropout-232             [-1, 145, 768]               0\n","         Dropout-233             [-1, 145, 768]               0\n","         Dropout-234             [-1, 145, 768]               0\n","         Dropout-235             [-1, 145, 768]               0\n","         Dropout-236             [-1, 145, 768]               0\n","         Dropout-237             [-1, 145, 768]               0\n","         Dropout-238             [-1, 145, 768]               0\n","       LayerNorm-239             [-1, 145, 768]           1,536\n","          Linear-240            [-1, 145, 2304]       1,771,776\n","         Dropout-241          [-1, 8, 145, 145]               0\n","          Linear-242             [-1, 145, 768]         590,592\n","         Dropout-243             [-1, 145, 768]               0\n","       Attention-244             [-1, 145, 768]               0\n","        Identity-245             [-1, 145, 768]               0\n","       LayerNorm-246             [-1, 145, 768]           1,536\n","          Linear-247            [-1, 145, 3072]       2,362,368\n","            GELU-248            [-1, 145, 3072]               0\n","         Dropout-249            [-1, 145, 3072]               0\n","          Linear-250             [-1, 145, 768]       2,360,064\n","         Dropout-251             [-1, 145, 768]               0\n","             FFN-252             [-1, 145, 768]               0\n","        Identity-253             [-1, 145, 768]               0\n","       LayerNorm-254             [-1, 145, 768]           1,536\n","          Linear-255             [-1, 145, 768]         590,592\n","          Linear-256             [-1, 145, 768]         590,592\n","          Linear-257             [-1, 145, 768]         590,592\n","         Dropout-258          [-1, 8, 145, 145]               0\n","          Linear-259             [-1, 145, 768]         590,592\n","         Dropout-260             [-1, 145, 768]               0\n","Guided_Attention-261             [-1, 145, 768]               0\n","        Identity-262             [-1, 145, 768]               0\n","       LayerNorm-263             [-1, 145, 768]           1,536\n","          Linear-264            [-1, 145, 3072]       2,362,368\n","            GELU-265            [-1, 145, 3072]               0\n","         Dropout-266            [-1, 145, 3072]               0\n","          Linear-267             [-1, 145, 768]       2,360,064\n","         Dropout-268             [-1, 145, 768]               0\n","             FFN-269             [-1, 145, 768]               0\n","        Identity-270             [-1, 145, 768]               0\n","   Decoder_Block-271             [-1, 145, 768]               0\n","       LayerNorm-272             [-1, 145, 768]           1,536\n","          Linear-273            [-1, 145, 2304]       1,771,776\n","         Dropout-274          [-1, 8, 145, 145]               0\n","          Linear-275             [-1, 145, 768]         590,592\n","         Dropout-276             [-1, 145, 768]               0\n","       Attention-277             [-1, 145, 768]               0\n","        Identity-278             [-1, 145, 768]               0\n","       LayerNorm-279             [-1, 145, 768]           1,536\n","          Linear-280            [-1, 145, 3072]       2,362,368\n","            GELU-281            [-1, 145, 3072]               0\n","         Dropout-282            [-1, 145, 3072]               0\n","          Linear-283             [-1, 145, 768]       2,360,064\n","         Dropout-284             [-1, 145, 768]               0\n","             FFN-285             [-1, 145, 768]               0\n","        Identity-286             [-1, 145, 768]               0\n","       LayerNorm-287             [-1, 145, 768]           1,536\n","          Linear-288             [-1, 145, 768]         590,592\n","          Linear-289             [-1, 145, 768]         590,592\n","          Linear-290             [-1, 145, 768]         590,592\n","         Dropout-291          [-1, 8, 145, 145]               0\n","          Linear-292             [-1, 145, 768]         590,592\n","         Dropout-293             [-1, 145, 768]               0\n","Guided_Attention-294             [-1, 145, 768]               0\n","        Identity-295             [-1, 145, 768]               0\n","       LayerNorm-296             [-1, 145, 768]           1,536\n","          Linear-297            [-1, 145, 3072]       2,362,368\n","            GELU-298            [-1, 145, 3072]               0\n","         Dropout-299            [-1, 145, 3072]               0\n","          Linear-300             [-1, 145, 768]       2,360,064\n","         Dropout-301             [-1, 145, 768]               0\n","             FFN-302             [-1, 145, 768]               0\n","        Identity-303             [-1, 145, 768]               0\n","   Decoder_Block-304             [-1, 145, 768]               0\n","       LayerNorm-305             [-1, 145, 768]           1,536\n","          Linear-306            [-1, 145, 2304]       1,771,776\n","         Dropout-307          [-1, 8, 145, 145]               0\n","          Linear-308             [-1, 145, 768]         590,592\n","         Dropout-309             [-1, 145, 768]               0\n","       Attention-310             [-1, 145, 768]               0\n","        Identity-311             [-1, 145, 768]               0\n","       LayerNorm-312             [-1, 145, 768]           1,536\n","          Linear-313            [-1, 145, 3072]       2,362,368\n","            GELU-314            [-1, 145, 3072]               0\n","         Dropout-315            [-1, 145, 3072]               0\n","          Linear-316             [-1, 145, 768]       2,360,064\n","         Dropout-317             [-1, 145, 768]               0\n","             FFN-318             [-1, 145, 768]               0\n","        Identity-319             [-1, 145, 768]               0\n","       LayerNorm-320             [-1, 145, 768]           1,536\n","          Linear-321             [-1, 145, 768]         590,592\n","          Linear-322             [-1, 145, 768]         590,592\n","          Linear-323             [-1, 145, 768]         590,592\n","         Dropout-324          [-1, 8, 145, 145]               0\n","          Linear-325             [-1, 145, 768]         590,592\n","         Dropout-326             [-1, 145, 768]               0\n","Guided_Attention-327             [-1, 145, 768]               0\n","        Identity-328             [-1, 145, 768]               0\n","       LayerNorm-329             [-1, 145, 768]           1,536\n","          Linear-330            [-1, 145, 3072]       2,362,368\n","            GELU-331            [-1, 145, 3072]               0\n","         Dropout-332            [-1, 145, 3072]               0\n","          Linear-333             [-1, 145, 768]       2,360,064\n","         Dropout-334             [-1, 145, 768]               0\n","             FFN-335             [-1, 145, 768]               0\n","        Identity-336             [-1, 145, 768]               0\n","   Decoder_Block-337             [-1, 145, 768]               0\n","       LayerNorm-338             [-1, 145, 768]           1,536\n","          Linear-339            [-1, 145, 2304]       1,771,776\n","         Dropout-340          [-1, 8, 145, 145]               0\n","          Linear-341             [-1, 145, 768]         590,592\n","         Dropout-342             [-1, 145, 768]               0\n","       Attention-343             [-1, 145, 768]               0\n","        Identity-344             [-1, 145, 768]               0\n","       LayerNorm-345             [-1, 145, 768]           1,536\n","          Linear-346            [-1, 145, 3072]       2,362,368\n","            GELU-347            [-1, 145, 3072]               0\n","         Dropout-348            [-1, 145, 3072]               0\n","          Linear-349             [-1, 145, 768]       2,360,064\n","         Dropout-350             [-1, 145, 768]               0\n","             FFN-351             [-1, 145, 768]               0\n","        Identity-352             [-1, 145, 768]               0\n","       LayerNorm-353             [-1, 145, 768]           1,536\n","          Linear-354             [-1, 145, 768]         590,592\n","          Linear-355             [-1, 145, 768]         590,592\n","          Linear-356             [-1, 145, 768]         590,592\n","         Dropout-357          [-1, 8, 145, 145]               0\n","          Linear-358             [-1, 145, 768]         590,592\n","         Dropout-359             [-1, 145, 768]               0\n","Guided_Attention-360             [-1, 145, 768]               0\n","        Identity-361             [-1, 145, 768]               0\n","       LayerNorm-362             [-1, 145, 768]           1,536\n","          Linear-363            [-1, 145, 3072]       2,362,368\n","            GELU-364            [-1, 145, 3072]               0\n","         Dropout-365            [-1, 145, 3072]               0\n","          Linear-366             [-1, 145, 768]       2,360,064\n","         Dropout-367             [-1, 145, 768]               0\n","             FFN-368             [-1, 145, 768]               0\n","        Identity-369             [-1, 145, 768]               0\n","   Decoder_Block-370             [-1, 145, 768]               0\n","       LayerNorm-371             [-1, 145, 768]           1,536\n","        Identity-372                  [-1, 768]               0\n","          Linear-373                    [-1, 2]           1,538\n","================================================================\n","Total params: 87,704,386\n","Trainable params: 87,704,386\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 372029.91\n","Params size (MB): 334.57\n","Estimated Total Size (MB): 372366.16\n","----------------------------------------------------------------\n","model : Hybrid2_384_401_PT_lf25_b8_k2\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 50 minibatch: 1      time used: 21.19180989265442\n","minibatch AVG loss: 0.7806567198038101\n","Epoch: 1     train index of 50 minibatch: 2      time used: 20.83778953552246\n","minibatch AVG loss: 0.6310760593414306\n","Epoch: 1     train index of 50 minibatch: 3      time used: 20.199193000793457\n","minibatch AVG loss: 0.5258408695459366\n","Epoch: 1     train index of 50 minibatch: 4      time used: 20.28956174850464\n","minibatch AVG loss: 0.5056281900405883\n","Epoch: 1     train index of 50 minibatch: 5      time used: 20.391589641571045\n","minibatch AVG loss: 0.46595492750406264\n","Epoch: 1     train index of 50 minibatch: 6      time used: 20.19592833518982\n","minibatch AVG loss: 0.39349132746458054\n","\n","Epoch: 1  train \n","Loss: 0.5333  Acc: 74.3183\n","negative precision: 76.0859  recall: 87.4856\n","negative sensitivity: 87.4856  specificity: 50.7202\n","negative FPR: 49.2798  NPV: 69.3390\n","negative TP: 1524.0\n","negative TN: 493.0\n","negative FP: 479.0\n","negative FN: 218.0\n","positive precision: 69.3390  recall: 50.7202\n","positive sensitivity: 50.7202  specificity: 87.4856\n","positive FPR: 12.5144  NPV: 76.0859\n","positive TP: 493.0\n","positive TN: 1524.0\n","positive FP: 218.0\n","positive FN: 479.0\n","\n","\n","Epoch: 1     val index of 50 minibatch: 1      time used: 11.494170188903809\n","minibatch AVG loss: 0.29123048156499864\n","\n","Epoch: 1  val \n","Loss: 0.3263  Acc: 87.1870\n","negative precision: 89.2135  recall: 91.0550\n","negative sensitivity: 91.0550  specificity: 80.2469\n","negative FPR: 19.7531  NPV: 83.3333\n","negative TP: 397.0\n","negative TN: 195.0\n","negative FP: 48.0\n","negative FN: 39.0\n","positive precision: 83.3333  recall: 80.2469\n","positive sensitivity: 80.2469  specificity: 91.0550\n","positive FPR: 8.9450  NPV: 89.2135\n","positive TP: 195.0\n","positive TN: 397.0\n","positive FP: 39.0\n","positive FN: 48.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 50 minibatch: 1      time used: 20.509221076965332\n","minibatch AVG loss: 0.39776147723197935\n","Epoch: 2     train index of 50 minibatch: 2      time used: 19.618216037750244\n","minibatch AVG loss: 0.3309908828139305\n","Epoch: 2     train index of 50 minibatch: 3      time used: 20.12173318862915\n","minibatch AVG loss: 0.3833150531351566\n","Epoch: 2     train index of 50 minibatch: 4      time used: 19.611653089523315\n","minibatch AVG loss: 0.2980724562332034\n","Epoch: 2     train index of 50 minibatch: 5      time used: 20.083301544189453\n","minibatch AVG loss: 0.3692163467407227\n","Epoch: 2     train index of 50 minibatch: 6      time used: 19.9305260181427\n","minibatch AVG loss: 0.30114472441375256\n","\n","Epoch: 2  train \n","Loss: 0.3509  Acc: 85.5564\n","negative precision: 87.3754  recall: 90.5855\n","negative sensitivity: 90.5855  specificity: 76.5432\n","negative FPR: 23.4568  NPV: 81.9383\n","negative TP: 1578.0\n","negative TN: 744.0\n","negative FP: 228.0\n","negative FN: 164.0\n","positive precision: 81.9383  recall: 76.5432\n","positive sensitivity: 76.5432  specificity: 90.5855\n","positive FPR: 9.4145  NPV: 87.3754\n","positive TP: 744.0\n","positive TN: 1578.0\n","positive FP: 164.0\n","positive FN: 228.0\n","\n","\n","Epoch: 2     val index of 50 minibatch: 1      time used: 11.456419229507446\n","minibatch AVG loss: 0.043066140245646235\n","\n","Epoch: 2  val \n","Loss: 0.3097  Acc: 86.7452\n","negative precision: 83.2692  recall: 99.3119\n","negative sensitivity: 99.3119  specificity: 64.1975\n","negative FPR: 35.8025  NPV: 98.1132\n","negative TP: 433.0\n","negative TN: 156.0\n","negative FP: 87.0\n","negative FN: 3.0\n","positive precision: 98.1132  recall: 64.1975\n","positive sensitivity: 64.1975  specificity: 99.3119\n","positive FPR: 0.6881  NPV: 83.2692\n","positive TP: 156.0\n","positive TN: 433.0\n","positive FP: 3.0\n","positive FN: 87.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 50 minibatch: 1      time used: 20.68928027153015\n","minibatch AVG loss: 0.368272218555212\n","Epoch: 3     train index of 50 minibatch: 2      time used: 19.768360376358032\n","minibatch AVG loss: 0.24591251503676176\n","Epoch: 3     train index of 50 minibatch: 3      time used: 19.617743968963623\n","minibatch AVG loss: 0.43116868525743485\n","Epoch: 3     train index of 50 minibatch: 4      time used: 19.98279356956482\n","minibatch AVG loss: 0.3830123733729124\n","Epoch: 3     train index of 50 minibatch: 5      time used: 19.548171758651733\n","minibatch AVG loss: 0.29360142335295675\n","Epoch: 3     train index of 50 minibatch: 6      time used: 19.303663730621338\n","minibatch AVG loss: 0.32019976787269117\n","\n","Epoch: 3  train \n","Loss: 0.3333  Acc: 86.5144\n","negative precision: 87.8855  recall: 91.6188\n","negative sensitivity: 91.6188  specificity: 77.3663\n","negative FPR: 22.6337  NPV: 83.7416\n","negative TP: 1596.0\n","negative TN: 752.0\n","negative FP: 220.0\n","negative FN: 146.0\n","positive precision: 83.7416  recall: 77.3663\n","positive sensitivity: 77.3663  specificity: 91.6188\n","positive FPR: 8.3812  NPV: 87.8855\n","positive TP: 752.0\n","positive TN: 1596.0\n","positive FP: 146.0\n","positive FN: 220.0\n","\n","\n","Epoch: 3     val index of 50 minibatch: 1      time used: 11.220438241958618\n","minibatch AVG loss: 0.1922388381138444\n","\n","Epoch: 3  val \n","Loss: 0.2020  Acc: 92.6362\n","negative precision: 95.7346  recall: 92.6606\n","negative sensitivity: 92.6606  specificity: 92.5926\n","negative FPR: 7.4074  NPV: 87.5486\n","negative TP: 404.0\n","negative TN: 225.0\n","negative FP: 18.0\n","negative FN: 32.0\n","positive precision: 87.5486  recall: 92.5926\n","positive sensitivity: 92.5926  specificity: 92.6606\n","positive FPR: 7.3394  NPV: 95.7346\n","positive TP: 225.0\n","positive TN: 404.0\n","positive FP: 32.0\n","positive FN: 18.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 50 minibatch: 1      time used: 20.022262573242188\n","minibatch AVG loss: 0.31195498801767824\n","Epoch: 4     train index of 50 minibatch: 2      time used: 19.49247407913208\n","minibatch AVG loss: 0.2693580351397395\n","Epoch: 4     train index of 50 minibatch: 3      time used: 19.192269325256348\n","minibatch AVG loss: 0.34193425126373767\n","Epoch: 4     train index of 50 minibatch: 4      time used: 19.646435976028442\n","minibatch AVG loss: 0.27411087043583393\n","Epoch: 4     train index of 50 minibatch: 5      time used: 19.435278177261353\n","minibatch AVG loss: 0.2701701498031616\n","Epoch: 4     train index of 50 minibatch: 6      time used: 19.539450645446777\n","minibatch AVG loss: 0.28491336762905123\n","\n","Epoch: 4  train \n","Loss: 0.2946  Acc: 88.0987\n","negative precision: 88.9194  recall: 93.0540\n","negative sensitivity: 93.0540  specificity: 79.2181\n","negative FPR: 20.7819  NPV: 86.4198\n","negative TP: 1621.0\n","negative TN: 770.0\n","negative FP: 202.0\n","negative FN: 121.0\n","positive precision: 86.4198  recall: 79.2181\n","positive sensitivity: 79.2181  specificity: 93.0540\n","positive FPR: 6.9460  NPV: 88.9194\n","positive TP: 770.0\n","positive TN: 1621.0\n","positive FP: 121.0\n","positive FN: 202.0\n","\n","\n","Epoch: 4     val index of 50 minibatch: 1      time used: 11.350785970687866\n","minibatch AVG loss: 0.03793749852105975\n","\n","Epoch: 4  val \n","Loss: 0.2400  Acc: 90.5744\n","negative precision: 87.8049  recall: 99.0826\n","negative sensitivity: 99.0826  specificity: 75.3086\n","negative FPR: 24.6914  NPV: 97.8610\n","negative TP: 432.0\n","negative TN: 183.0\n","negative FP: 60.0\n","negative FN: 4.0\n","positive precision: 97.8610  recall: 75.3086\n","positive sensitivity: 75.3086  specificity: 99.0826\n","positive FPR: 0.9174  NPV: 87.8049\n","positive TP: 183.0\n","positive TN: 432.0\n","positive FP: 4.0\n","positive FN: 60.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 50 minibatch: 1      time used: 20.69862651824951\n","minibatch AVG loss: 0.2731039910018444\n","Epoch: 5     train index of 50 minibatch: 2      time used: 20.083706378936768\n","minibatch AVG loss: 0.2924720278382301\n","Epoch: 5     train index of 50 minibatch: 3      time used: 20.010114908218384\n","minibatch AVG loss: 0.29912923093885185\n","Epoch: 5     train index of 50 minibatch: 4      time used: 19.52116370201111\n","minibatch AVG loss: 0.24548317588865756\n","Epoch: 5     train index of 50 minibatch: 5      time used: 19.983145236968994\n","minibatch AVG loss: 0.19754196813330055\n","Epoch: 5     train index of 50 minibatch: 6      time used: 19.572001457214355\n","minibatch AVG loss: 0.2598333264887333\n","\n","Epoch: 5  train \n","Loss: 0.2560  Acc: 90.1253\n","negative precision: 91.2654  recall: 93.5706\n","negative sensitivity: 93.5706  specificity: 83.9506\n","negative FPR: 16.0494  NPV: 87.9310\n","negative TP: 1630.0\n","negative TN: 816.0\n","negative FP: 156.0\n","negative FN: 112.0\n","positive precision: 87.9310  recall: 83.9506\n","positive sensitivity: 83.9506  specificity: 93.5706\n","positive FPR: 6.4294  NPV: 91.2654\n","positive TP: 816.0\n","positive TN: 1630.0\n","positive FP: 112.0\n","positive FN: 156.0\n","\n","\n","Epoch: 5     val index of 50 minibatch: 1      time used: 11.141910314559937\n","minibatch AVG loss: 0.07593456352828071\n","\n","Epoch: 5  val \n","Loss: 0.2134  Acc: 92.1944\n","negative precision: 91.3607  recall: 97.0183\n","negative sensitivity: 97.0183  specificity: 83.5391\n","negative FPR: 16.4609  NPV: 93.9815\n","negative TP: 423.0\n","negative TN: 203.0\n","negative FP: 40.0\n","negative FN: 13.0\n","positive precision: 93.9815  recall: 83.5391\n","positive sensitivity: 83.5391  specificity: 97.0183\n","positive FPR: 2.9817  NPV: 91.3607\n","positive TP: 203.0\n","positive TN: 423.0\n","positive FP: 13.0\n","positive FN: 40.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 50 minibatch: 1      time used: 20.14971137046814\n","minibatch AVG loss: 0.2604050696641207\n","Epoch: 6     train index of 50 minibatch: 2      time used: 19.538480520248413\n","minibatch AVG loss: 0.2594735141843557\n","Epoch: 6     train index of 50 minibatch: 3      time used: 19.324604034423828\n","minibatch AVG loss: 0.2622088746726513\n","Epoch: 6     train index of 50 minibatch: 4      time used: 19.37621545791626\n","minibatch AVG loss: 0.27812075600028036\n","Epoch: 6     train index of 50 minibatch: 5      time used: 19.78144121170044\n","minibatch AVG loss: 0.26259044371545315\n","Epoch: 6     train index of 50 minibatch: 6      time used: 19.040952682495117\n","minibatch AVG loss: 0.23408071614801884\n","\n","Epoch: 6  train \n","Loss: 0.2578  Acc: 89.7568\n","negative precision: 91.3559  recall: 92.8243\n","negative sensitivity: 92.8243  specificity: 84.2593\n","negative FPR: 15.7407  NPV: 86.7585\n","negative TP: 1617.0\n","negative TN: 819.0\n","negative FP: 153.0\n","negative FN: 125.0\n","positive precision: 86.7585  recall: 84.2593\n","positive sensitivity: 84.2593  specificity: 92.8243\n","positive FPR: 7.1757  NPV: 91.3559\n","positive TP: 819.0\n","positive TN: 1617.0\n","positive FP: 125.0\n","positive FN: 153.0\n","\n","\n","Epoch: 6     val index of 50 minibatch: 1      time used: 10.986088752746582\n","minibatch AVG loss: 0.2550976957706734\n","\n","Epoch: 6  val \n","Loss: 0.2336  Acc: 88.9543\n","negative precision: 96.4010  recall: 86.0092\n","negative sensitivity: 86.0092  specificity: 94.2387\n","negative FPR: 5.7613  NPV: 78.9655\n","negative TP: 375.0\n","negative TN: 229.0\n","negative FP: 14.0\n","negative FN: 61.0\n","positive precision: 78.9655  recall: 94.2387\n","positive sensitivity: 94.2387  specificity: 86.0092\n","positive FPR: 13.9908  NPV: 96.4010\n","positive TP: 229.0\n","positive TN: 375.0\n","positive FP: 61.0\n","positive FN: 14.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 50 minibatch: 1      time used: 20.011796474456787\n","minibatch AVG loss: 0.26644828289747235\n","Epoch: 7     train index of 50 minibatch: 2      time used: 19.56067419052124\n","minibatch AVG loss: 0.18841944653540849\n","Epoch: 7     train index of 50 minibatch: 3      time used: 19.269747734069824\n","minibatch AVG loss: 0.23741815686225892\n","Epoch: 7     train index of 50 minibatch: 4      time used: 19.671436071395874\n","minibatch AVG loss: 0.2769609824195504\n","Epoch: 7     train index of 50 minibatch: 5      time used: 19.255751848220825\n","minibatch AVG loss: 0.20193123031407595\n","Epoch: 7     train index of 50 minibatch: 6      time used: 19.420064210891724\n","minibatch AVG loss: 0.2594168450497091\n","\n","Epoch: 7  train \n","Loss: 0.2397  Acc: 90.0516\n","negative precision: 91.3948  recall: 93.2836\n","negative sensitivity: 93.2836  specificity: 84.2593\n","negative FPR: 15.7407  NPV: 87.5000\n","negative TP: 1625.0\n","negative TN: 819.0\n","negative FP: 153.0\n","negative FN: 117.0\n","positive precision: 87.5000  recall: 84.2593\n","positive sensitivity: 84.2593  specificity: 93.2836\n","positive FPR: 6.7164  NPV: 91.3948\n","positive TP: 819.0\n","positive TN: 1625.0\n","positive FP: 117.0\n","positive FN: 153.0\n","\n","\n","Epoch: 7     val index of 50 minibatch: 1      time used: 11.068421840667725\n","minibatch AVG loss: 0.10698272582143545\n","\n","Epoch: 7  val \n","Loss: 0.1626  Acc: 93.8144\n","negative precision: 94.7727  recall: 95.6422\n","negative sensitivity: 95.6422  specificity: 90.5350\n","negative FPR: 9.4650  NPV: 92.0502\n","negative TP: 417.0\n","negative TN: 220.0\n","negative FP: 23.0\n","negative FN: 19.0\n","positive precision: 92.0502  recall: 90.5350\n","positive sensitivity: 90.5350  specificity: 95.6422\n","positive FPR: 4.3578  NPV: 94.7727\n","positive TP: 220.0\n","positive TN: 417.0\n","positive FP: 19.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 50 minibatch: 1      time used: 20.31190586090088\n","minibatch AVG loss: 0.21360936153680085\n","Epoch: 8     train index of 50 minibatch: 2      time used: 19.39112377166748\n","minibatch AVG loss: 0.1768735991232097\n","Epoch: 8     train index of 50 minibatch: 3      time used: 19.611777544021606\n","minibatch AVG loss: 0.25122797571122646\n","Epoch: 8     train index of 50 minibatch: 4      time used: 19.557179927825928\n","minibatch AVG loss: 0.2255626747198403\n","Epoch: 8     train index of 50 minibatch: 5      time used: 19.98646593093872\n","minibatch AVG loss: 0.2144156702980399\n","Epoch: 8     train index of 50 minibatch: 6      time used: 19.291898250579834\n","minibatch AVG loss: 0.19842533715069294\n","\n","Epoch: 8  train \n","Loss: 0.2099  Acc: 91.5254\n","negative precision: 93.0034  recall: 93.8576\n","negative sensitivity: 93.8576  specificity: 87.3457\n","negative FPR: 12.6543  NPV: 88.8075\n","negative TP: 1635.0\n","negative TN: 849.0\n","negative FP: 123.0\n","negative FN: 107.0\n","positive precision: 88.8075  recall: 87.3457\n","positive sensitivity: 87.3457  specificity: 93.8576\n","positive FPR: 6.1424  NPV: 93.0034\n","positive TP: 849.0\n","positive TN: 1635.0\n","positive FP: 107.0\n","positive FN: 123.0\n","\n","\n","Epoch: 8     val index of 50 minibatch: 1      time used: 11.428093671798706\n","minibatch AVG loss: 0.03197388098895317\n","\n","Epoch: 8  val \n","Loss: 0.2455  Acc: 91.3108\n","negative precision: 88.8660  recall: 98.8532\n","negative sensitivity: 98.8532  specificity: 77.7778\n","negative FPR: 22.2222  NPV: 97.4227\n","negative TP: 431.0\n","negative TN: 189.0\n","negative FP: 54.0\n","negative FN: 5.0\n","positive precision: 97.4227  recall: 77.7778\n","positive sensitivity: 77.7778  specificity: 98.8532\n","positive FPR: 1.1468  NPV: 88.8660\n","positive TP: 189.0\n","positive TN: 431.0\n","positive FP: 5.0\n","positive FN: 54.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 50 minibatch: 1      time used: 20.378048181533813\n","minibatch AVG loss: 0.22399029215797783\n","Epoch: 9     train index of 50 minibatch: 2      time used: 19.796261310577393\n","minibatch AVG loss: 0.24063342571258545\n","Epoch: 9     train index of 50 minibatch: 3      time used: 19.693857192993164\n","minibatch AVG loss: 0.20154697809368372\n","Epoch: 9     train index of 50 minibatch: 4      time used: 19.496281385421753\n","minibatch AVG loss: 0.19812618542462587\n","Epoch: 9     train index of 50 minibatch: 5      time used: 19.516615390777588\n","minibatch AVG loss: 0.1947922570258379\n","Epoch: 9     train index of 50 minibatch: 6      time used: 19.89076018333435\n","minibatch AVG loss: 0.2420247745886445\n","\n","Epoch: 9  train \n","Loss: 0.2203  Acc: 90.7148\n","negative precision: 91.9955  recall: 93.6854\n","negative sensitivity: 93.6854  specificity: 85.3909\n","negative FPR: 14.6091  NPV: 88.2979\n","negative TP: 1632.0\n","negative TN: 830.0\n","negative FP: 142.0\n","negative FN: 110.0\n","positive precision: 88.2979  recall: 85.3909\n","positive sensitivity: 85.3909  specificity: 93.6854\n","positive FPR: 6.3146  NPV: 91.9955\n","positive TP: 830.0\n","positive TN: 1632.0\n","positive FP: 110.0\n","positive FN: 142.0\n","\n","\n","Epoch: 9     val index of 50 minibatch: 1      time used: 10.989530324935913\n","minibatch AVG loss: 0.14535219687677453\n","\n","Epoch: 9  val \n","Loss: 0.1803  Acc: 92.6362\n","negative precision: 95.5189  recall: 92.8899\n","negative sensitivity: 92.8899  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 87.8431\n","negative TP: 405.0\n","negative TN: 224.0\n","negative FP: 19.0\n","negative FN: 31.0\n","positive precision: 87.8431  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 92.8899\n","positive FPR: 7.1101  NPV: 95.5189\n","positive TP: 224.0\n","positive TN: 405.0\n","positive FP: 31.0\n","positive FN: 19.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 50 minibatch: 1      time used: 20.14815616607666\n","minibatch AVG loss: 0.18842646247707306\n","Epoch: 10     train index of 50 minibatch: 2      time used: 19.226892232894897\n","minibatch AVG loss: 0.2250708094984293\n","Epoch: 10     train index of 50 minibatch: 3      time used: 19.364686965942383\n","minibatch AVG loss: 0.2396419052220881\n","Epoch: 10     train index of 50 minibatch: 4      time used: 19.64758539199829\n","minibatch AVG loss: 0.19588007003068925\n","Epoch: 10     train index of 50 minibatch: 5      time used: 19.304478645324707\n","minibatch AVG loss: 0.22151978138834238\n","Epoch: 10     train index of 50 minibatch: 6      time used: 19.611677169799805\n","minibatch AVG loss: 0.19179346365854144\n","\n","Epoch: 10  train \n","Loss: 0.2028  Acc: 91.8570\n","negative precision: 93.2840  recall: 94.0873\n","negative sensitivity: 94.0873  specificity: 87.8601\n","negative FPR: 12.1399  NPV: 89.2372\n","negative TP: 1639.0\n","negative TN: 854.0\n","negative FP: 118.0\n","negative FN: 103.0\n","positive precision: 89.2372  recall: 87.8601\n","positive sensitivity: 87.8601  specificity: 94.0873\n","positive FPR: 5.9127  NPV: 93.2840\n","positive TP: 854.0\n","positive TN: 1639.0\n","positive FP: 103.0\n","positive FN: 118.0\n","\n","\n","Epoch: 10     val index of 50 minibatch: 1      time used: 11.339278936386108\n","minibatch AVG loss: 0.1077574215121058\n","\n","Epoch: 10  val \n","Loss: 0.1749  Acc: 93.9617\n","negative precision: 94.3820  recall: 96.3303\n","negative sensitivity: 96.3303  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 93.1624\n","negative TP: 420.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 16.0\n","positive precision: 93.1624  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 96.3303\n","positive FPR: 3.6697  NPV: 94.3820\n","positive TP: 218.0\n","positive TN: 420.0\n","positive FP: 16.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 50 minibatch: 1      time used: 20.373582124710083\n","minibatch AVG loss: 0.17349787006154657\n","Epoch: 11     train index of 50 minibatch: 2      time used: 19.96313786506653\n","minibatch AVG loss: 0.17176772199571133\n","Epoch: 11     train index of 50 minibatch: 3      time used: 19.770551443099976\n","minibatch AVG loss: 0.15810288688167928\n","Epoch: 11     train index of 50 minibatch: 4      time used: 19.55608081817627\n","minibatch AVG loss: 0.22863476160913707\n","Epoch: 11     train index of 50 minibatch: 5      time used: 19.77080488204956\n","minibatch AVG loss: 0.22105431308969856\n","Epoch: 11     train index of 50 minibatch: 6      time used: 19.805275440216064\n","minibatch AVG loss: 0.17682993026450278\n","\n","Epoch: 11  train \n","Loss: 0.1997  Acc: 91.8939\n","negative precision: 93.1896  recall: 94.2595\n","negative sensitivity: 94.2595  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 89.4958\n","negative TP: 1642.0\n","negative TN: 852.0\n","negative FP: 120.0\n","negative FN: 100.0\n","positive precision: 89.4958  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 94.2595\n","positive FPR: 5.7405  NPV: 93.1896\n","positive TP: 852.0\n","positive TN: 1642.0\n","positive FP: 100.0\n","positive FN: 120.0\n","\n","\n","Epoch: 11     val index of 50 minibatch: 1      time used: 11.059184074401855\n","minibatch AVG loss: 0.07994729010155424\n","\n","Epoch: 11  val \n","Loss: 0.1657  Acc: 93.9617\n","negative precision: 93.7916  recall: 97.0183\n","negative sensitivity: 97.0183  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 94.2982\n","negative TP: 423.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 13.0\n","positive precision: 94.2982  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 97.0183\n","positive FPR: 2.9817  NPV: 93.7916\n","positive TP: 215.0\n","positive TN: 423.0\n","positive FP: 13.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 50 minibatch: 1      time used: 20.075498342514038\n","minibatch AVG loss: 0.16669642619788647\n","Epoch: 12     train index of 50 minibatch: 2      time used: 19.326615810394287\n","minibatch AVG loss: 0.21060819676145912\n","Epoch: 12     train index of 50 minibatch: 3      time used: 19.3194797039032\n","minibatch AVG loss: 0.14078013587743043\n","Epoch: 12     train index of 50 minibatch: 4      time used: 19.46577501296997\n","minibatch AVG loss: 0.21519221529364585\n","Epoch: 12     train index of 50 minibatch: 5      time used: 19.39061737060547\n","minibatch AVG loss: 0.1720492359995842\n","Epoch: 12     train index of 50 minibatch: 6      time used: 19.554757595062256\n","minibatch AVG loss: 0.239841216430068\n","\n","Epoch: 12  train \n","Loss: 0.1903  Acc: 92.4466\n","negative precision: 93.7892  recall: 94.4891\n","negative sensitivity: 94.4891  specificity: 88.7860\n","negative FPR: 11.2140  NPV: 89.9896\n","negative TP: 1646.0\n","negative TN: 863.0\n","negative FP: 109.0\n","negative FN: 96.0\n","positive precision: 89.9896  recall: 88.7860\n","positive sensitivity: 88.7860  specificity: 94.4891\n","positive FPR: 5.5109  NPV: 93.7892\n","positive TP: 863.0\n","positive TN: 1646.0\n","positive FP: 96.0\n","positive FN: 109.0\n","\n","\n","Epoch: 12     val index of 50 minibatch: 1      time used: 11.134132862091064\n","minibatch AVG loss: 0.06444290692646973\n","\n","Epoch: 12  val \n","Loss: 0.1636  Acc: 93.5199\n","negative precision: 93.3628  recall: 96.7890\n","negative sensitivity: 96.7890  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 93.8326\n","negative TP: 422.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 14.0\n","positive precision: 93.8326  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 96.7890\n","positive FPR: 3.2110  NPV: 93.3628\n","positive TP: 213.0\n","positive TN: 422.0\n","positive FP: 14.0\n","positive FN: 30.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 50 minibatch: 1      time used: 20.36589550971985\n","minibatch AVG loss: 0.15161354571580887\n","Epoch: 13     train index of 50 minibatch: 2      time used: 19.576504230499268\n","minibatch AVG loss: 0.18178078517317772\n","Epoch: 13     train index of 50 minibatch: 3      time used: 20.77469539642334\n","minibatch AVG loss: 0.17853815460577607\n","Epoch: 13     train index of 50 minibatch: 4      time used: 19.82804226875305\n","minibatch AVG loss: 0.1380579407233745\n","Epoch: 13     train index of 50 minibatch: 5      time used: 19.42672324180603\n","minibatch AVG loss: 0.1849323572963476\n","Epoch: 13     train index of 50 minibatch: 6      time used: 19.496522188186646\n","minibatch AVG loss: 0.1942029993981123\n","\n","Epoch: 13  train \n","Loss: 0.1710  Acc: 92.9624\n","negative precision: 94.2890  recall: 94.7761\n","negative sensitivity: 94.7761  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 90.5504\n","negative TP: 1651.0\n","negative TN: 872.0\n","negative FP: 100.0\n","negative FN: 91.0\n","positive precision: 90.5504  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 94.7761\n","positive FPR: 5.2239  NPV: 94.2890\n","positive TP: 872.0\n","positive TN: 1651.0\n","positive FP: 91.0\n","positive FN: 100.0\n","\n","\n","Epoch: 13     val index of 50 minibatch: 1      time used: 11.126061916351318\n","minibatch AVG loss: 0.13964392789115665\n","\n","Epoch: 13  val \n","Loss: 0.1676  Acc: 94.1090\n","negative precision: 96.6981  recall: 94.0367\n","negative sensitivity: 94.0367  specificity: 94.2387\n","negative FPR: 5.7613  NPV: 89.8039\n","negative TP: 410.0\n","negative TN: 229.0\n","negative FP: 14.0\n","negative FN: 26.0\n","positive precision: 89.8039  recall: 94.2387\n","positive sensitivity: 94.2387  specificity: 94.0367\n","positive FPR: 5.9633  NPV: 96.6981\n","positive TP: 229.0\n","positive TN: 410.0\n","positive FP: 26.0\n","positive FN: 14.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 50 minibatch: 1      time used: 19.90375328063965\n","minibatch AVG loss: 0.15165421715006233\n","Epoch: 14     train index of 50 minibatch: 2      time used: 19.830289125442505\n","minibatch AVG loss: 0.15502802861854434\n","Epoch: 14     train index of 50 minibatch: 3      time used: 19.240253686904907\n","minibatch AVG loss: 0.14349634781479836\n","Epoch: 14     train index of 50 minibatch: 4      time used: 19.669031381607056\n","minibatch AVG loss: 0.16756018914282322\n","Epoch: 14     train index of 50 minibatch: 5      time used: 19.692713260650635\n","minibatch AVG loss: 0.18795878877863287\n","Epoch: 14     train index of 50 minibatch: 6      time used: 19.55635118484497\n","minibatch AVG loss: 0.15503371641039848\n","\n","Epoch: 14  train \n","Loss: 0.1606  Acc: 93.7730\n","negative precision: 95.1234  recall: 95.1780\n","negative sensitivity: 95.1780  specificity: 91.2551\n","negative FPR: 8.7449  NPV: 91.3491\n","negative TP: 1658.0\n","negative TN: 887.0\n","negative FP: 85.0\n","negative FN: 84.0\n","positive precision: 91.3491  recall: 91.2551\n","positive sensitivity: 91.2551  specificity: 95.1780\n","positive FPR: 4.8220  NPV: 95.1234\n","positive TP: 887.0\n","positive TN: 1658.0\n","positive FP: 84.0\n","positive FN: 85.0\n","\n","\n","Epoch: 14     val index of 50 minibatch: 1      time used: 11.181950330734253\n","minibatch AVG loss: 0.150445989180007\n","\n","Epoch: 14  val \n","Loss: 0.1710  Acc: 92.6362\n","negative precision: 96.3942  recall: 91.9725\n","negative sensitivity: 91.9725  specificity: 93.8272\n","negative FPR: 6.1728  NPV: 86.6920\n","negative TP: 401.0\n","negative TN: 228.0\n","negative FP: 15.0\n","negative FN: 35.0\n","positive precision: 86.6920  recall: 93.8272\n","positive sensitivity: 93.8272  specificity: 91.9725\n","positive FPR: 8.0275  NPV: 96.3942\n","positive TP: 228.0\n","positive TN: 401.0\n","positive FP: 35.0\n","positive FN: 15.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 50 minibatch: 1      time used: 20.308186531066895\n","minibatch AVG loss: 0.15224938105791808\n","Epoch: 15     train index of 50 minibatch: 2      time used: 19.522565603256226\n","minibatch AVG loss: 0.16424748301506042\n","Epoch: 15     train index of 50 minibatch: 3      time used: 19.5896635055542\n","minibatch AVG loss: 0.1836985259503126\n","Epoch: 15     train index of 50 minibatch: 4      time used: 19.70276165008545\n","minibatch AVG loss: 0.153559217043221\n","Epoch: 15     train index of 50 minibatch: 5      time used: 19.887238264083862\n","minibatch AVG loss: 0.20751558545976878\n","Epoch: 15     train index of 50 minibatch: 6      time used: 19.187498092651367\n","minibatch AVG loss: 0.16364338714629412\n","\n","Epoch: 15  train \n","Loss: 0.1724  Acc: 93.1466\n","negative precision: 94.5080  recall: 94.8335\n","negative sensitivity: 94.8335  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 90.6832\n","negative TP: 1652.0\n","negative TN: 876.0\n","negative FP: 96.0\n","negative FN: 90.0\n","positive precision: 90.6832  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 94.8335\n","positive FPR: 5.1665  NPV: 94.5080\n","positive TP: 876.0\n","positive TN: 1652.0\n","positive FP: 90.0\n","positive FN: 96.0\n","\n","\n","Epoch: 15     val index of 50 minibatch: 1      time used: 11.127150297164917\n","minibatch AVG loss: 0.048178738987771794\n","\n","Epoch: 15  val \n","Loss: 0.1668  Acc: 93.3726\n","negative precision: 92.5926  recall: 97.4771\n","negative sensitivity: 97.4771  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 95.0000\n","negative TP: 425.0\n","negative TN: 209.0\n","negative FP: 34.0\n","negative FN: 11.0\n","positive precision: 95.0000  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 97.4771\n","positive FPR: 2.5229  NPV: 92.5926\n","positive TP: 209.0\n","positive TN: 425.0\n","positive FP: 11.0\n","positive FN: 34.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 50 minibatch: 1      time used: 19.999165534973145\n","minibatch AVG loss: 0.19583755504339934\n","Epoch: 16     train index of 50 minibatch: 2      time used: 19.806564569473267\n","minibatch AVG loss: 0.1291839598957449\n","Epoch: 16     train index of 50 minibatch: 3      time used: 19.406147956848145\n","minibatch AVG loss: 0.2077055898308754\n","Epoch: 16     train index of 50 minibatch: 4      time used: 19.63568091392517\n","minibatch AVG loss: 0.14645935155451298\n","Epoch: 16     train index of 50 minibatch: 5      time used: 19.875949144363403\n","minibatch AVG loss: 0.17451593618839978\n","Epoch: 16     train index of 50 minibatch: 6      time used: 19.66658663749695\n","minibatch AVG loss: 0.1336818149499595\n","\n","Epoch: 16  train \n","Loss: 0.1642  Acc: 93.6993\n","negative precision: 94.5042  recall: 95.7520\n","negative sensitivity: 95.7520  specificity: 90.0206\n","negative FPR: 9.9794  NPV: 92.2023\n","negative TP: 1668.0\n","negative TN: 875.0\n","negative FP: 97.0\n","negative FN: 74.0\n","positive precision: 92.2023  recall: 90.0206\n","positive sensitivity: 90.0206  specificity: 95.7520\n","positive FPR: 4.2480  NPV: 94.5042\n","positive TP: 875.0\n","positive TN: 1668.0\n","positive FP: 74.0\n","positive FN: 97.0\n","\n","\n","Epoch: 16     val index of 50 minibatch: 1      time used: 11.177918910980225\n","minibatch AVG loss: 0.09554497928183991\n","\n","Epoch: 16  val \n","Loss: 0.1500  Acc: 94.5508\n","negative precision: 96.2877  recall: 95.1835\n","negative sensitivity: 95.1835  specificity: 93.4156\n","negative FPR: 6.5844  NPV: 91.5323\n","negative TP: 415.0\n","negative TN: 227.0\n","negative FP: 16.0\n","negative FN: 21.0\n","positive precision: 91.5323  recall: 93.4156\n","positive sensitivity: 93.4156  specificity: 95.1835\n","positive FPR: 4.8165  NPV: 96.2877\n","positive TP: 227.0\n","positive TN: 415.0\n","positive FP: 21.0\n","positive FN: 16.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 50 minibatch: 1      time used: 19.872161149978638\n","minibatch AVG loss: 0.11628689420875161\n","Epoch: 17     train index of 50 minibatch: 2      time used: 19.830576181411743\n","minibatch AVG loss: 0.1779475886374712\n","Epoch: 17     train index of 50 minibatch: 3      time used: 19.700857400894165\n","minibatch AVG loss: 0.136608583945781\n","Epoch: 17     train index of 50 minibatch: 4      time used: 19.876243352890015\n","minibatch AVG loss: 0.15882348687853665\n","Epoch: 17     train index of 50 minibatch: 5      time used: 19.569719791412354\n","minibatch AVG loss: 0.15345492507331074\n","Epoch: 17     train index of 50 minibatch: 6      time used: 19.50415587425232\n","minibatch AVG loss: 0.1945115602016449\n","\n","Epoch: 17  train \n","Loss: 0.1589  Acc: 93.5888\n","negative precision: 95.0575  recall: 94.9483\n","negative sensitivity: 94.9483  specificity: 91.1523\n","negative FPR: 8.8477  NPV: 90.9651\n","negative TP: 1654.0\n","negative TN: 886.0\n","negative FP: 86.0\n","negative FN: 88.0\n","positive precision: 90.9651  recall: 91.1523\n","positive sensitivity: 91.1523  specificity: 94.9483\n","positive FPR: 5.0517  NPV: 95.0575\n","positive TP: 886.0\n","positive TN: 1654.0\n","positive FP: 88.0\n","positive FN: 86.0\n","\n","\n","Epoch: 17     val index of 50 minibatch: 1      time used: 11.10525393486023\n","minibatch AVG loss: 0.10519098922690319\n","\n","Epoch: 17  val \n","Loss: 0.1411  Acc: 94.4035\n","negative precision: 96.2791  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 93.4156\n","negative FPR: 6.5844  NPV: 91.1647\n","negative TP: 414.0\n","negative TN: 227.0\n","negative FP: 16.0\n","negative FN: 22.0\n","positive precision: 91.1647  recall: 93.4156\n","positive sensitivity: 93.4156  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 96.2791\n","positive TP: 227.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 16.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 50 minibatch: 1      time used: 20.11489987373352\n","minibatch AVG loss: 0.12664073510095478\n","Epoch: 18     train index of 50 minibatch: 2      time used: 19.88236427307129\n","minibatch AVG loss: 0.10382384762633592\n","Epoch: 18     train index of 50 minibatch: 3      time used: 19.70230484008789\n","minibatch AVG loss: 0.14909937216434627\n","Epoch: 18     train index of 50 minibatch: 4      time used: 19.22801899909973\n","minibatch AVG loss: 0.11412344514392317\n","Epoch: 18     train index of 50 minibatch: 5      time used: 19.406975269317627\n","minibatch AVG loss: 0.1086264920886606\n","Epoch: 18     train index of 50 minibatch: 6      time used: 19.467614889144897\n","minibatch AVG loss: 0.1148532642191276\n","\n","Epoch: 18  train \n","Loss: 0.1191  Acc: 95.3574\n","negative precision: 96.3835  recall: 96.3835\n","negative sensitivity: 96.3835  specificity: 93.5185\n","negative FPR: 6.4815  NPV: 93.5185\n","negative TP: 1679.0\n","negative TN: 909.0\n","negative FP: 63.0\n","negative FN: 63.0\n","positive precision: 93.5185  recall: 93.5185\n","positive sensitivity: 93.5185  specificity: 96.3835\n","positive FPR: 3.6165  NPV: 96.3835\n","positive TP: 909.0\n","positive TN: 1679.0\n","positive FP: 63.0\n","positive FN: 63.0\n","\n","\n","Epoch: 18     val index of 50 minibatch: 1      time used: 11.193481683731079\n","minibatch AVG loss: 0.10021186547146499\n","\n","Epoch: 18  val \n","Loss: 0.1829  Acc: 93.5199\n","negative precision: 94.7489  recall: 95.1835\n","negative sensitivity: 95.1835  specificity: 90.5350\n","negative FPR: 9.4650  NPV: 91.2863\n","negative TP: 415.0\n","negative TN: 220.0\n","negative FP: 23.0\n","negative FN: 21.0\n","positive precision: 91.2863  recall: 90.5350\n","positive sensitivity: 90.5350  specificity: 95.1835\n","positive FPR: 4.8165  NPV: 94.7489\n","positive TP: 220.0\n","positive TN: 415.0\n","positive FP: 21.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 50 minibatch: 1      time used: 19.96644616127014\n","minibatch AVG loss: 0.11229801564943045\n","Epoch: 19     train index of 50 minibatch: 2      time used: 20.279518604278564\n","minibatch AVG loss: 0.1602309632138349\n","Epoch: 19     train index of 50 minibatch: 3      time used: 19.710899591445923\n","minibatch AVG loss: 0.1399616320990026\n","Epoch: 19     train index of 50 minibatch: 4      time used: 19.39730930328369\n","minibatch AVG loss: 0.14649835834279656\n","Epoch: 19     train index of 50 minibatch: 5      time used: 20.052547216415405\n","minibatch AVG loss: 0.10800102873705328\n","Epoch: 19     train index of 50 minibatch: 6      time used: 19.528490781784058\n","minibatch AVG loss: 0.12971321291290225\n","\n","Epoch: 19  train \n","Loss: 0.1300  Acc: 94.9153\n","negative precision: 95.9862  recall: 96.0964\n","negative sensitivity: 96.0964  specificity: 92.7984\n","negative FPR: 7.2016  NPV: 92.9897\n","negative TP: 1674.0\n","negative TN: 902.0\n","negative FP: 70.0\n","negative FN: 68.0\n","positive precision: 92.9897  recall: 92.7984\n","positive sensitivity: 92.7984  specificity: 96.0964\n","positive FPR: 3.9036  NPV: 95.9862\n","positive TP: 902.0\n","positive TN: 1674.0\n","positive FP: 68.0\n","positive FN: 70.0\n","\n","\n","Epoch: 19     val index of 50 minibatch: 1      time used: 11.085608720779419\n","minibatch AVG loss: 0.12724964523637028\n","\n","Epoch: 19  val \n","Loss: 0.1601  Acc: 93.5199\n","negative precision: 96.6667  recall: 93.1193\n","negative sensitivity: 93.1193  specificity: 94.2387\n","negative FPR: 5.7613  NPV: 88.4170\n","negative TP: 406.0\n","negative TN: 229.0\n","negative FP: 14.0\n","negative FN: 30.0\n","positive precision: 88.4170  recall: 94.2387\n","positive sensitivity: 94.2387  specificity: 93.1193\n","positive FPR: 6.8807  NPV: 96.6667\n","positive TP: 229.0\n","positive TN: 406.0\n","positive FP: 30.0\n","positive FN: 14.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 50 minibatch: 1      time used: 19.86621618270874\n","minibatch AVG loss: 0.12874166393652559\n","Epoch: 20     train index of 50 minibatch: 2      time used: 19.45098567008972\n","minibatch AVG loss: 0.13091756778769195\n","Epoch: 20     train index of 50 minibatch: 3      time used: 19.446471691131592\n","minibatch AVG loss: 0.17650616653263568\n","Epoch: 20     train index of 50 minibatch: 4      time used: 19.084043741226196\n","minibatch AVG loss: 0.12331287055276334\n","Epoch: 20     train index of 50 minibatch: 5      time used: 19.34342646598816\n","minibatch AVG loss: 0.12588388791307806\n","Epoch: 20     train index of 50 minibatch: 6      time used: 19.071350812911987\n","minibatch AVG loss: 0.12105992341414094\n","\n","Epoch: 20  train \n","Loss: 0.1306  Acc: 95.2100\n","negative precision: 95.8998  recall: 96.6705\n","negative sensitivity: 96.6705  specificity: 92.5926\n","negative FPR: 7.4074  NPV: 93.9457\n","negative TP: 1684.0\n","negative TN: 900.0\n","negative FP: 72.0\n","negative FN: 58.0\n","positive precision: 93.9457  recall: 92.5926\n","positive sensitivity: 92.5926  specificity: 96.6705\n","positive FPR: 3.3295  NPV: 95.8998\n","positive TP: 900.0\n","positive TN: 1684.0\n","positive FP: 58.0\n","positive FN: 72.0\n","\n","\n","Epoch: 20     val index of 50 minibatch: 1      time used: 11.165098667144775\n","minibatch AVG loss: 0.08335024015919772\n","\n","Epoch: 20  val \n","Loss: 0.1603  Acc: 94.2563\n","negative precision: 95.6322  recall: 95.4128\n","negative sensitivity: 95.4128  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 91.8033\n","negative TP: 416.0\n","negative TN: 224.0\n","negative FP: 19.0\n","negative FN: 20.0\n","positive precision: 91.8033  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 95.4128\n","positive FPR: 4.5872  NPV: 95.6322\n","positive TP: 224.0\n","positive TN: 416.0\n","positive FP: 20.0\n","positive FN: 19.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 50 minibatch: 1      time used: 19.897245168685913\n","minibatch AVG loss: 0.15729401433840395\n","Epoch: 21     train index of 50 minibatch: 2      time used: 19.459429502487183\n","minibatch AVG loss: 0.13016484189778565\n","Epoch: 21     train index of 50 minibatch: 3      time used: 19.365374326705933\n","minibatch AVG loss: 0.1282589211501181\n","Epoch: 21     train index of 50 minibatch: 4      time used: 19.36151885986328\n","minibatch AVG loss: 0.1445800107344985\n","Epoch: 21     train index of 50 minibatch: 5      time used: 19.298903465270996\n","minibatch AVG loss: 0.12608665347099304\n","Epoch: 21     train index of 50 minibatch: 6      time used: 19.549949645996094\n","minibatch AVG loss: 0.10224358849227429\n","\n","Epoch: 21  train \n","Loss: 0.1265  Acc: 95.0626\n","negative precision: 96.1009  recall: 96.2113\n","negative sensitivity: 96.2113  specificity: 93.0041\n","negative FPR: 6.9959  NPV: 93.1959\n","negative TP: 1676.0\n","negative TN: 904.0\n","negative FP: 68.0\n","negative FN: 66.0\n","positive precision: 93.1959  recall: 93.0041\n","positive sensitivity: 93.0041  specificity: 96.2113\n","positive FPR: 3.7887  NPV: 96.1009\n","positive TP: 904.0\n","positive TN: 1676.0\n","positive FP: 66.0\n","positive FN: 68.0\n","\n","\n","Epoch: 21     val index of 50 minibatch: 1      time used: 11.0363609790802\n","minibatch AVG loss: 0.1862989040784305\n","\n","Epoch: 21  val \n","Loss: 0.2096  Acc: 93.0781\n","negative precision: 97.0944  recall: 91.9725\n","negative sensitivity: 91.9725  specificity: 95.0617\n","negative FPR: 4.9383  NPV: 86.8421\n","negative TP: 401.0\n","negative TN: 231.0\n","negative FP: 12.0\n","negative FN: 35.0\n","positive precision: 86.8421  recall: 95.0617\n","positive sensitivity: 95.0617  specificity: 91.9725\n","positive FPR: 8.0275  NPV: 97.0944\n","positive TP: 231.0\n","positive TN: 401.0\n","positive FP: 35.0\n","positive FN: 12.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 50 minibatch: 1      time used: 20.15413475036621\n","minibatch AVG loss: 0.15710867792367936\n","Epoch: 22     train index of 50 minibatch: 2      time used: 19.46005368232727\n","minibatch AVG loss: 0.07573837254662066\n","Epoch: 22     train index of 50 minibatch: 3      time used: 19.424644231796265\n","minibatch AVG loss: 0.10607555061113089\n","Epoch: 22     train index of 50 minibatch: 4      time used: 19.577537536621094\n","minibatch AVG loss: 0.16178658919408917\n","Epoch: 22     train index of 50 minibatch: 5      time used: 19.422435522079468\n","minibatch AVG loss: 0.10821776800788939\n","Epoch: 22     train index of 50 minibatch: 6      time used: 19.54559350013733\n","minibatch AVG loss: 0.10888867764733731\n","\n","Epoch: 22  train \n","Loss: 0.1168  Acc: 95.7627\n","negative precision: 96.5123  recall: 96.9001\n","negative sensitivity: 96.9001  specificity: 93.7243\n","negative FPR: 6.2757  NPV: 94.4041\n","negative TP: 1688.0\n","negative TN: 911.0\n","negative FP: 61.0\n","negative FN: 54.0\n","positive precision: 94.4041  recall: 93.7243\n","positive sensitivity: 93.7243  specificity: 96.9001\n","positive FPR: 3.0999  NPV: 96.5123\n","positive TP: 911.0\n","positive TN: 1688.0\n","positive FP: 54.0\n","positive FN: 61.0\n","\n","\n","Epoch: 22     val index of 50 minibatch: 1      time used: 11.17846417427063\n","minibatch AVG loss: 0.21924713446001987\n","\n","Epoch: 22  val \n","Loss: 0.2092  Acc: 92.4890\n","negative precision: 97.0660  recall: 91.0550\n","negative sensitivity: 91.0550  specificity: 95.0617\n","negative FPR: 4.9383  NPV: 85.5556\n","negative TP: 397.0\n","negative TN: 231.0\n","negative FP: 12.0\n","negative FN: 39.0\n","positive precision: 85.5556  recall: 95.0617\n","positive sensitivity: 95.0617  specificity: 91.0550\n","positive FPR: 8.9450  NPV: 97.0660\n","positive TP: 231.0\n","positive TN: 397.0\n","positive FP: 39.0\n","positive FN: 12.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 50 minibatch: 1      time used: 20.62346386909485\n","minibatch AVG loss: 0.11443470219150186\n","Epoch: 23     train index of 50 minibatch: 2      time used: 19.35270357131958\n","minibatch AVG loss: 0.11521496703848243\n","Epoch: 23     train index of 50 minibatch: 3      time used: 19.807398319244385\n","minibatch AVG loss: 0.1008990404382348\n","Epoch: 23     train index of 50 minibatch: 4      time used: 19.531649112701416\n","minibatch AVG loss: 0.08759043755009771\n","Epoch: 23     train index of 50 minibatch: 5      time used: 19.56778073310852\n","minibatch AVG loss: 0.146740288073197\n","Epoch: 23     train index of 50 minibatch: 6      time used: 19.41968321800232\n","minibatch AVG loss: 0.12891679352149368\n","\n","Epoch: 23  train \n","Loss: 0.1150  Acc: 95.5785\n","negative precision: 96.2900  recall: 96.8427\n","negative sensitivity: 96.8427  specificity: 93.3128\n","negative FPR: 6.6872  NPV: 94.2827\n","negative TP: 1687.0\n","negative TN: 907.0\n","negative FP: 65.0\n","negative FN: 55.0\n","positive precision: 94.2827  recall: 93.3128\n","positive sensitivity: 93.3128  specificity: 96.8427\n","positive FPR: 3.1573  NPV: 96.2900\n","positive TP: 907.0\n","positive TN: 1687.0\n","positive FP: 55.0\n","positive FN: 65.0\n","\n","\n","Epoch: 23     val index of 50 minibatch: 1      time used: 11.09298324584961\n","minibatch AVG loss: 0.10694247278413968\n","\n","Epoch: 23  val \n","Loss: 0.1514  Acc: 94.6981\n","negative precision: 96.0829  recall: 95.6422\n","negative sensitivity: 95.6422  specificity: 93.0041\n","negative FPR: 6.9959  NPV: 92.2449\n","negative TP: 417.0\n","negative TN: 226.0\n","negative FP: 17.0\n","negative FN: 19.0\n","positive precision: 92.2449  recall: 93.0041\n","positive sensitivity: 93.0041  specificity: 95.6422\n","positive FPR: 4.3578  NPV: 96.0829\n","positive TP: 226.0\n","positive TN: 417.0\n","positive FP: 19.0\n","positive FN: 17.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 50 minibatch: 1      time used: 20.019343852996826\n","minibatch AVG loss: 0.0897114560380578\n","Epoch: 24     train index of 50 minibatch: 2      time used: 19.582724809646606\n","minibatch AVG loss: 0.11562644758727401\n","Epoch: 24     train index of 50 minibatch: 3      time used: 19.71119976043701\n","minibatch AVG loss: 0.06834866132121534\n","Epoch: 24     train index of 50 minibatch: 4      time used: 19.586501121520996\n","minibatch AVG loss: 0.09126736068399623\n","Epoch: 24     train index of 50 minibatch: 5      time used: 19.5617995262146\n","minibatch AVG loss: 0.10636967457830906\n","Epoch: 24     train index of 50 minibatch: 6      time used: 18.980003833770752\n","minibatch AVG loss: 0.08547326980158687\n","\n","Epoch: 24  train \n","Loss: 0.0991  Acc: 95.9469\n","negative precision: 96.8966  recall: 96.7853\n","negative sensitivity: 96.7853  specificity: 94.4444\n","negative FPR: 5.5556  NPV: 94.2505\n","negative TP: 1686.0\n","negative TN: 918.0\n","negative FP: 54.0\n","negative FN: 56.0\n","positive precision: 94.2505  recall: 94.4444\n","positive sensitivity: 94.4444  specificity: 96.7853\n","positive FPR: 3.2147  NPV: 96.8966\n","positive TP: 918.0\n","positive TN: 1686.0\n","positive FP: 56.0\n","positive FN: 54.0\n","\n","\n","Epoch: 24     val index of 50 minibatch: 1      time used: 11.130000352859497\n","minibatch AVG loss: 0.08503468669776339\n","\n","Epoch: 24  val \n","Loss: 0.1425  Acc: 95.2872\n","negative precision: 95.7014  recall: 97.0183\n","negative sensitivity: 97.0183  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 94.5148\n","negative TP: 423.0\n","negative TN: 224.0\n","negative FP: 19.0\n","negative FN: 13.0\n","positive precision: 94.5148  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 97.0183\n","positive FPR: 2.9817  NPV: 95.7014\n","positive TP: 224.0\n","positive TN: 423.0\n","positive FP: 13.0\n","positive FN: 19.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 50 minibatch: 1      time used: 20.450899124145508\n","minibatch AVG loss: 0.09736478122882546\n","Epoch: 25     train index of 50 minibatch: 2      time used: 19.225711822509766\n","minibatch AVG loss: 0.12355011550243944\n","Epoch: 25     train index of 50 minibatch: 3      time used: 19.652707815170288\n","minibatch AVG loss: 0.10334334173239768\n","Epoch: 25     train index of 50 minibatch: 4      time used: 19.294676542282104\n","minibatch AVG loss: 0.1193097115913406\n","Epoch: 25     train index of 50 minibatch: 5      time used: 19.3570556640625\n","minibatch AVG loss: 0.09333216418046504\n","Epoch: 25     train index of 50 minibatch: 6      time used: 19.7238290309906\n","minibatch AVG loss: 0.05413507510907948\n","\n","Epoch: 25  train \n","Loss: 0.0962  Acc: 96.3891\n","negative precision: 97.0790  recall: 97.3020\n","negative sensitivity: 97.3020  specificity: 94.7531\n","negative FPR: 5.2469  NPV: 95.1446\n","negative TP: 1695.0\n","negative TN: 921.0\n","negative FP: 51.0\n","negative FN: 47.0\n","positive precision: 95.1446  recall: 94.7531\n","positive sensitivity: 94.7531  specificity: 97.3020\n","positive FPR: 2.6980  NPV: 97.0790\n","positive TP: 921.0\n","positive TN: 1695.0\n","positive FP: 47.0\n","positive FN: 51.0\n","\n","\n","Epoch: 25     val index of 50 minibatch: 1      time used: 11.15238642692566\n","minibatch AVG loss: 0.054254855216750004\n","\n","Epoch: 25  val \n","Loss: 0.1591  Acc: 95.1399\n","negative precision: 94.8775  recall: 97.7064\n","negative sensitivity: 97.7064  specificity: 90.5350\n","negative FPR: 9.4650  NPV: 95.6522\n","negative TP: 426.0\n","negative TN: 220.0\n","negative FP: 23.0\n","negative FN: 10.0\n","positive precision: 95.6522  recall: 90.5350\n","positive sensitivity: 90.5350  specificity: 97.7064\n","positive FPR: 2.2936  NPV: 94.8775\n","positive TP: 220.0\n","positive TN: 426.0\n","positive FP: 10.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 50 minibatch: 1      time used: 20.309574365615845\n","minibatch AVG loss: 0.0801780794467777\n","Epoch: 26     train index of 50 minibatch: 2      time used: 19.607833862304688\n","minibatch AVG loss: 0.07536295471945778\n","Epoch: 26     train index of 50 minibatch: 3      time used: 19.33791947364807\n","minibatch AVG loss: 0.09492223467910663\n","Epoch: 26     train index of 50 minibatch: 4      time used: 19.29420757293701\n","minibatch AVG loss: 0.10951983080711215\n","Epoch: 26     train index of 50 minibatch: 5      time used: 19.520402669906616\n","minibatch AVG loss: 0.14738045579753817\n","Epoch: 26     train index of 50 minibatch: 6      time used: 19.72677731513977\n","minibatch AVG loss: 0.08796359681524336\n","\n","Epoch: 26  train \n","Loss: 0.0970  Acc: 96.2049\n","negative precision: 97.0166  recall: 97.0723\n","negative sensitivity: 97.0723  specificity: 94.6502\n","negative FPR: 5.3498  NPV: 94.7477\n","negative TP: 1691.0\n","negative TN: 920.0\n","negative FP: 52.0\n","negative FN: 51.0\n","positive precision: 94.7477  recall: 94.6502\n","positive sensitivity: 94.6502  specificity: 97.0723\n","positive FPR: 2.9277  NPV: 97.0166\n","positive TP: 920.0\n","positive TN: 1691.0\n","positive FP: 51.0\n","positive FN: 52.0\n","\n","\n","Epoch: 26     val index of 50 minibatch: 1      time used: 11.07553219795227\n","minibatch AVG loss: 0.03617735426159925\n","\n","Epoch: 26  val \n","Loss: 0.1897  Acc: 94.2563\n","negative precision: 93.0586  recall: 98.3945\n","negative sensitivity: 98.3945  specificity: 86.8313\n","negative FPR: 13.1687  NPV: 96.7890\n","negative TP: 429.0\n","negative TN: 211.0\n","negative FP: 32.0\n","negative FN: 7.0\n","positive precision: 96.7890  recall: 86.8313\n","positive sensitivity: 86.8313  specificity: 98.3945\n","positive FPR: 1.6055  NPV: 93.0586\n","positive TP: 211.0\n","positive TN: 429.0\n","positive FP: 7.0\n","positive FN: 32.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 50 minibatch: 1      time used: 20.221447706222534\n","minibatch AVG loss: 0.09573637274093925\n","Epoch: 27     train index of 50 minibatch: 2      time used: 19.51646089553833\n","minibatch AVG loss: 0.11224743734812365\n","Epoch: 27     train index of 50 minibatch: 3      time used: 19.568782091140747\n","minibatch AVG loss: 0.09188542754389345\n","Epoch: 27     train index of 50 minibatch: 4      time used: 19.36141610145569\n","minibatch AVG loss: 0.10500804903917015\n","Epoch: 27     train index of 50 minibatch: 5      time used: 19.647255182266235\n","minibatch AVG loss: 0.06171264552045613\n","Epoch: 27     train index of 50 minibatch: 6      time used: 19.611593008041382\n","minibatch AVG loss: 0.12291834032861516\n","\n","Epoch: 27  train \n","Loss: 0.0948  Acc: 96.3891\n","negative precision: 97.2414  recall: 97.1297\n","negative sensitivity: 97.1297  specificity: 95.0617\n","negative FPR: 4.9383  NPV: 94.8665\n","negative TP: 1692.0\n","negative TN: 924.0\n","negative FP: 48.0\n","negative FN: 50.0\n","positive precision: 94.8665  recall: 95.0617\n","positive sensitivity: 95.0617  specificity: 97.1297\n","positive FPR: 2.8703  NPV: 97.2414\n","positive TP: 924.0\n","positive TN: 1692.0\n","positive FP: 50.0\n","positive FN: 48.0\n","\n","\n","Epoch: 27     val index of 50 minibatch: 1      time used: 11.09409475326538\n","minibatch AVG loss: 0.08763248343486339\n","\n","Epoch: 27  val \n","Loss: 0.1601  Acc: 94.8454\n","negative precision: 95.8810  recall: 96.1009\n","negative sensitivity: 96.1009  specificity: 92.5926\n","negative FPR: 7.4074  NPV: 92.9752\n","negative TP: 419.0\n","negative TN: 225.0\n","negative FP: 18.0\n","negative FN: 17.0\n","positive precision: 92.9752  recall: 92.5926\n","positive sensitivity: 92.5926  specificity: 96.1009\n","positive FPR: 3.8991  NPV: 95.8810\n","positive TP: 225.0\n","positive TN: 419.0\n","positive FP: 17.0\n","positive FN: 18.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 50 minibatch: 1      time used: 19.950509786605835\n","minibatch AVG loss: 0.11740593061083927\n","Epoch: 28     train index of 50 minibatch: 2      time used: 19.75634741783142\n","minibatch AVG loss: 0.0991124515607953\n","Epoch: 28     train index of 50 minibatch: 3      time used: 19.39835524559021\n","minibatch AVG loss: 0.06160590272396803\n","Epoch: 28     train index of 50 minibatch: 4      time used: 19.52111530303955\n","minibatch AVG loss: 0.08958184603601695\n","Epoch: 28     train index of 50 minibatch: 5      time used: 19.384114265441895\n","minibatch AVG loss: 0.07987575823441148\n","Epoch: 28     train index of 50 minibatch: 6      time used: 19.601534843444824\n","minibatch AVG loss: 0.11848610610701144\n","\n","Epoch: 28  train \n","Loss: 0.0935  Acc: 96.4628\n","negative precision: 97.2445  recall: 97.2445\n","negative sensitivity: 97.2445  specificity: 95.0617\n","negative FPR: 4.9383  NPV: 95.0617\n","negative TP: 1694.0\n","negative TN: 924.0\n","negative FP: 48.0\n","negative FN: 48.0\n","positive precision: 95.0617  recall: 95.0617\n","positive sensitivity: 95.0617  specificity: 97.2445\n","positive FPR: 2.7555  NPV: 97.2445\n","positive TP: 924.0\n","positive TN: 1694.0\n","positive FP: 48.0\n","positive FN: 48.0\n","\n","\n","Epoch: 28     val index of 50 minibatch: 1      time used: 11.114582300186157\n","minibatch AVG loss: 0.06815243779579759\n","\n","Epoch: 28  val \n","Loss: 0.1942  Acc: 94.9926\n","negative precision: 94.8661  recall: 97.4771\n","negative sensitivity: 97.4771  specificity: 90.5350\n","negative FPR: 9.4650  NPV: 95.2381\n","negative TP: 425.0\n","negative TN: 220.0\n","negative FP: 23.0\n","negative FN: 11.0\n","positive precision: 95.2381  recall: 90.5350\n","positive sensitivity: 90.5350  specificity: 97.4771\n","positive FPR: 2.5229  NPV: 94.8661\n","positive TP: 220.0\n","positive TN: 425.0\n","positive FP: 11.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 50 minibatch: 1      time used: 20.189817667007446\n","minibatch AVG loss: 0.055872105883900076\n","Epoch: 29     train index of 50 minibatch: 2      time used: 19.349563598632812\n","minibatch AVG loss: 0.11118900128640234\n","Epoch: 29     train index of 50 minibatch: 3      time used: 19.63275647163391\n","minibatch AVG loss: 0.05360828627133742\n","Epoch: 29     train index of 50 minibatch: 4      time used: 19.700395584106445\n","minibatch AVG loss: 0.11602607518085278\n","Epoch: 29     train index of 50 minibatch: 5      time used: 19.302040338516235\n","minibatch AVG loss: 0.12301230476237833\n","Epoch: 29     train index of 50 minibatch: 6      time used: 19.579842567443848\n","minibatch AVG loss: 0.14187800766900183\n","\n","Epoch: 29  train \n","Loss: 0.0961  Acc: 96.3891\n","negative precision: 97.1330  recall: 97.2445\n","negative sensitivity: 97.2445  specificity: 94.8560\n","negative FPR: 5.1440  NPV: 95.0515\n","negative TP: 1694.0\n","negative TN: 922.0\n","negative FP: 50.0\n","negative FN: 48.0\n","positive precision: 95.0515  recall: 94.8560\n","positive sensitivity: 94.8560  specificity: 97.2445\n","positive FPR: 2.7555  NPV: 97.1330\n","positive TP: 922.0\n","positive TN: 1694.0\n","positive FP: 48.0\n","positive FN: 50.0\n","\n","\n","Epoch: 29     val index of 50 minibatch: 1      time used: 11.193174600601196\n","minibatch AVG loss: 0.08482331721141236\n","\n","Epoch: 29  val \n","Loss: 0.1734  Acc: 94.1090\n","negative precision: 94.3946  recall: 96.5596\n","negative sensitivity: 96.5596  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 93.5622\n","negative TP: 421.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 15.0\n","positive precision: 93.5622  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 96.5596\n","positive FPR: 3.4404  NPV: 94.3946\n","positive TP: 218.0\n","positive TN: 421.0\n","positive FP: 15.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 50 minibatch: 1      time used: 20.06562638282776\n","minibatch AVG loss: 0.09421742277219891\n","Epoch: 30     train index of 50 minibatch: 2      time used: 19.56809163093567\n","minibatch AVG loss: 0.05482477837940678\n","Epoch: 30     train index of 50 minibatch: 3      time used: 19.463101863861084\n","minibatch AVG loss: 0.11309548556571826\n","Epoch: 30     train index of 50 minibatch: 4      time used: 19.585228204727173\n","minibatch AVG loss: 0.08967334226705134\n","Epoch: 30     train index of 50 minibatch: 5      time used: 19.297024250030518\n","minibatch AVG loss: 0.0671979404054582\n","Epoch: 30     train index of 50 minibatch: 6      time used: 19.554621696472168\n","minibatch AVG loss: 0.08280296925688163\n","\n","Epoch: 30  train \n","Loss: 0.0817  Acc: 97.1997\n","negative precision: 97.7090  recall: 97.9334\n","negative sensitivity: 97.9334  specificity: 95.8848\n","negative FPR: 4.1152  NPV: 96.2810\n","negative TP: 1706.0\n","negative TN: 932.0\n","negative FP: 40.0\n","negative FN: 36.0\n","positive precision: 96.2810  recall: 95.8848\n","positive sensitivity: 95.8848  specificity: 97.9334\n","positive FPR: 2.0666  NPV: 97.7090\n","positive TP: 932.0\n","positive TN: 1706.0\n","positive FP: 36.0\n","positive FN: 40.0\n","\n","\n","Epoch: 30     val index of 50 minibatch: 1      time used: 11.360756158828735\n","minibatch AVG loss: 0.10246468601457309\n","\n","Epoch: 30  val \n","Loss: 0.1786  Acc: 94.1090\n","negative precision: 95.4128  recall: 95.4128\n","negative sensitivity: 95.4128  specificity: 91.7695\n","negative FPR: 8.2305  NPV: 91.7695\n","negative TP: 416.0\n","negative TN: 223.0\n","negative FP: 20.0\n","negative FN: 20.0\n","positive precision: 91.7695  recall: 91.7695\n","positive sensitivity: 91.7695  specificity: 95.4128\n","positive FPR: 4.5872  NPV: 95.4128\n","positive TP: 223.0\n","positive TN: 416.0\n","positive FP: 20.0\n","positive FN: 20.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 50 minibatch: 1      time used: 20.465731382369995\n","minibatch AVG loss: 0.10429762118961662\n","Epoch: 31     train index of 50 minibatch: 2      time used: 19.86255383491516\n","minibatch AVG loss: 0.09882016312330962\n","Epoch: 31     train index of 50 minibatch: 3      time used: 19.846965074539185\n","minibatch AVG loss: 0.08964711009524763\n","Epoch: 31     train index of 50 minibatch: 4      time used: 19.850008010864258\n","minibatch AVG loss: 0.10222844893112779\n","Epoch: 31     train index of 50 minibatch: 5      time used: 19.537114143371582\n","minibatch AVG loss: 0.08399074139073491\n","Epoch: 31     train index of 50 minibatch: 6      time used: 19.70014190673828\n","minibatch AVG loss: 0.06682544952956959\n","\n","Epoch: 31  train \n","Loss: 0.0900  Acc: 97.0892\n","negative precision: 97.7051  recall: 97.7612\n","negative sensitivity: 97.7612  specificity: 95.8848\n","negative FPR: 4.1152  NPV: 95.9835\n","negative TP: 1703.0\n","negative TN: 932.0\n","negative FP: 40.0\n","negative FN: 39.0\n","positive precision: 95.9835  recall: 95.8848\n","positive sensitivity: 95.8848  specificity: 97.7612\n","positive FPR: 2.2388  NPV: 97.7051\n","positive TP: 932.0\n","positive TN: 1703.0\n","positive FP: 39.0\n","positive FN: 40.0\n","\n","\n","Epoch: 31     val index of 50 minibatch: 1      time used: 11.189409494400024\n","minibatch AVG loss: 0.10660905647244362\n","\n","Epoch: 31  val \n","Loss: 0.1576  Acc: 94.5508\n","negative precision: 95.6522  recall: 95.8716\n","negative sensitivity: 95.8716  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 92.5620\n","negative TP: 418.0\n","negative TN: 224.0\n","negative FP: 19.0\n","negative FN: 18.0\n","positive precision: 92.5620  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 95.8716\n","positive FPR: 4.1284  NPV: 95.6522\n","positive TP: 224.0\n","positive TN: 418.0\n","positive FP: 18.0\n","positive FN: 19.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 50 minibatch: 1      time used: 20.332258224487305\n","minibatch AVG loss: 0.10254467911086977\n","Epoch: 32     train index of 50 minibatch: 2      time used: 19.178163528442383\n","minibatch AVG loss: 0.06629470429383218\n","Epoch: 32     train index of 50 minibatch: 3      time used: 19.42723798751831\n","minibatch AVG loss: 0.07018125709611922\n","Epoch: 32     train index of 50 minibatch: 4      time used: 19.682467937469482\n","minibatch AVG loss: 0.0673666447494179\n","Epoch: 32     train index of 50 minibatch: 5      time used: 19.534948587417603\n","minibatch AVG loss: 0.08650140742072836\n","Epoch: 32     train index of 50 minibatch: 6      time used: 19.24234390258789\n","minibatch AVG loss: 0.0480980839044787\n","\n","Epoch: 32  train \n","Loss: 0.0739  Acc: 97.1260\n","negative precision: 97.8161  recall: 97.7038\n","negative sensitivity: 97.7038  specificity: 96.0905\n","negative FPR: 3.9095  NPV: 95.8932\n","negative TP: 1702.0\n","negative TN: 934.0\n","negative FP: 38.0\n","negative FN: 40.0\n","positive precision: 95.8932  recall: 96.0905\n","positive sensitivity: 96.0905  specificity: 97.7038\n","positive FPR: 2.2962  NPV: 97.8161\n","positive TP: 934.0\n","positive TN: 1702.0\n","positive FP: 40.0\n","positive FN: 38.0\n","\n","\n","Epoch: 32     val index of 50 minibatch: 1      time used: 11.070361852645874\n","minibatch AVG loss: 0.10373695501115435\n","\n","Epoch: 32  val \n","Loss: 0.1739  Acc: 94.5508\n","negative precision: 95.6522  recall: 95.8716\n","negative sensitivity: 95.8716  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 92.5620\n","negative TP: 418.0\n","negative TN: 224.0\n","negative FP: 19.0\n","negative FN: 18.0\n","positive precision: 92.5620  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 95.8716\n","positive FPR: 4.1284  NPV: 95.6522\n","positive TP: 224.0\n","positive TN: 418.0\n","positive FP: 18.0\n","positive FN: 19.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 50 minibatch: 1      time used: 20.389070510864258\n","minibatch AVG loss: 0.10061356350779534\n","Epoch: 33     train index of 50 minibatch: 2      time used: 19.19034218788147\n","minibatch AVG loss: 0.0714281841320917\n","Epoch: 33     train index of 50 minibatch: 3      time used: 19.27645993232727\n","minibatch AVG loss: 0.06268551093526184\n","Epoch: 33     train index of 50 minibatch: 4      time used: 19.193029403686523\n","minibatch AVG loss: 0.06703609556192532\n","Epoch: 33     train index of 50 minibatch: 5      time used: 19.332406282424927\n","minibatch AVG loss: 0.09923448935849592\n","Epoch: 33     train index of 50 minibatch: 6      time used: 19.815924167633057\n","minibatch AVG loss: 0.07803071682574228\n","\n","Epoch: 33  train \n","Loss: 0.0750  Acc: 97.0892\n","negative precision: 97.5959  recall: 97.8760\n","negative sensitivity: 97.8760  specificity: 95.6790\n","negative FPR: 4.3210  NPV: 96.1737\n","negative TP: 1705.0\n","negative TN: 930.0\n","negative FP: 42.0\n","negative FN: 37.0\n","positive precision: 96.1737  recall: 95.6790\n","positive sensitivity: 95.6790  specificity: 97.8760\n","positive FPR: 2.1240  NPV: 97.5959\n","positive TP: 930.0\n","positive TN: 1705.0\n","positive FP: 37.0\n","positive FN: 42.0\n","\n","\n","Epoch: 33     val index of 50 minibatch: 1      time used: 11.0657217502594\n","minibatch AVG loss: 0.07434042232413049\n","\n","Epoch: 33  val \n","Loss: 0.1836  Acc: 95.1399\n","negative precision: 94.4812  recall: 98.1651\n","negative sensitivity: 98.1651  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 96.4602\n","negative TP: 428.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 8.0\n","positive precision: 96.4602  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 98.1651\n","positive FPR: 1.8349  NPV: 94.4812\n","positive TP: 218.0\n","positive TN: 428.0\n","positive FP: 8.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 50 minibatch: 1      time used: 20.013477087020874\n","minibatch AVG loss: 0.06295359755167737\n","Epoch: 34     train index of 50 minibatch: 2      time used: 19.660476684570312\n","minibatch AVG loss: 0.07619399928255007\n","Epoch: 34     train index of 50 minibatch: 3      time used: 19.90665912628174\n","minibatch AVG loss: 0.04883971313014626\n","Epoch: 34     train index of 50 minibatch: 4      time used: 20.01604700088501\n","minibatch AVG loss: 0.074821758531034\n","Epoch: 34     train index of 50 minibatch: 5      time used: 19.907424211502075\n","minibatch AVG loss: 0.08176776760956272\n","Epoch: 34     train index of 50 minibatch: 6      time used: 20.330294609069824\n","minibatch AVG loss: 0.06025624030968174\n","\n","Epoch: 34  train \n","Loss: 0.0674  Acc: 97.1997\n","negative precision: 97.9839  recall: 97.6464\n","negative sensitivity: 97.6464  specificity: 96.3992\n","negative FPR: 3.6008  NPV: 95.8078\n","negative TP: 1701.0\n","negative TN: 937.0\n","negative FP: 35.0\n","negative FN: 41.0\n","positive precision: 95.8078  recall: 96.3992\n","positive sensitivity: 96.3992  specificity: 97.6464\n","positive FPR: 2.3536  NPV: 97.9839\n","positive TP: 937.0\n","positive TN: 1701.0\n","positive FP: 41.0\n","positive FN: 35.0\n","\n","\n","Epoch: 34     val index of 50 minibatch: 1      time used: 11.459946632385254\n","minibatch AVG loss: 0.1549344249018759\n","\n","Epoch: 34  val \n","Loss: 0.2060  Acc: 93.3726\n","negative precision: 95.1501  recall: 94.4954\n","negative sensitivity: 94.4954  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 90.2439\n","negative TP: 412.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 24.0\n","positive precision: 90.2439  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 94.4954\n","positive FPR: 5.5046  NPV: 95.1501\n","positive TP: 222.0\n","positive TN: 412.0\n","positive FP: 24.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 50 minibatch: 1      time used: 20.77876305580139\n","minibatch AVG loss: 0.10169213480781764\n","Epoch: 35     train index of 50 minibatch: 2      time used: 20.008939504623413\n","minibatch AVG loss: 0.06719049010891467\n","Epoch: 35     train index of 50 minibatch: 3      time used: 19.84750008583069\n","minibatch AVG loss: 0.06048768100794405\n","Epoch: 35     train index of 50 minibatch: 4      time used: 19.947702646255493\n","minibatch AVG loss: 0.03939530144562013\n","Epoch: 35     train index of 50 minibatch: 5      time used: 20.191734075546265\n","minibatch AVG loss: 0.08717167000053451\n","Epoch: 35     train index of 50 minibatch: 6      time used: 20.058636903762817\n","minibatch AVG loss: 0.06088173834374175\n","\n","Epoch: 35  train \n","Loss: 0.0701  Acc: 97.0892\n","negative precision: 97.7051  recall: 97.7612\n","negative sensitivity: 97.7612  specificity: 95.8848\n","negative FPR: 4.1152  NPV: 95.9835\n","negative TP: 1703.0\n","negative TN: 932.0\n","negative FP: 40.0\n","negative FN: 39.0\n","positive precision: 95.9835  recall: 95.8848\n","positive sensitivity: 95.8848  specificity: 97.7612\n","positive FPR: 2.2388  NPV: 97.7051\n","positive TP: 932.0\n","positive TN: 1703.0\n","positive FP: 39.0\n","positive FN: 40.0\n","\n","\n","Epoch: 35     val index of 50 minibatch: 1      time used: 11.47145414352417\n","minibatch AVG loss: 0.0929602174840693\n","\n","Epoch: 35  val \n","Loss: 0.2084  Acc: 94.9926\n","negative precision: 95.0673  recall: 97.2477\n","negative sensitivity: 97.2477  specificity: 90.9465\n","negative FPR: 9.0535  NPV: 94.8498\n","negative TP: 424.0\n","negative TN: 221.0\n","negative FP: 22.0\n","negative FN: 12.0\n","positive precision: 94.8498  recall: 90.9465\n","positive sensitivity: 90.9465  specificity: 97.2477\n","positive FPR: 2.7523  NPV: 95.0673\n","positive TP: 221.0\n","positive TN: 424.0\n","positive FP: 12.0\n","positive FN: 22.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 50 minibatch: 1      time used: 20.845317125320435\n","minibatch AVG loss: 0.10376815313007683\n","Epoch: 36     train index of 50 minibatch: 2      time used: 20.095964431762695\n","minibatch AVG loss: 0.051780278489459305\n","Epoch: 36     train index of 50 minibatch: 3      time used: 19.667834758758545\n","minibatch AVG loss: 0.05189856258686632\n","Epoch: 36     train index of 50 minibatch: 4      time used: 20.087801218032837\n","minibatch AVG loss: 0.1054875067807734\n","Epoch: 36     train index of 50 minibatch: 5      time used: 20.225269317626953\n","minibatch AVG loss: 0.04345395726617426\n","Epoch: 36     train index of 50 minibatch: 6      time used: 20.01905655860901\n","minibatch AVG loss: 0.037392310821451245\n","\n","Epoch: 36  train \n","Loss: 0.0662  Acc: 97.8998\n","negative precision: 98.3917  recall: 98.3352\n","negative sensitivity: 98.3352  specificity: 97.1193\n","negative FPR: 2.8807  NPV: 97.0195\n","negative TP: 1713.0\n","negative TN: 944.0\n","negative FP: 28.0\n","negative FN: 29.0\n","positive precision: 97.0195  recall: 97.1193\n","positive sensitivity: 97.1193  specificity: 98.3352\n","positive FPR: 1.6648  NPV: 98.3917\n","positive TP: 944.0\n","positive TN: 1713.0\n","positive FP: 29.0\n","positive FN: 28.0\n","\n","\n","Epoch: 36     val index of 50 minibatch: 1      time used: 11.553823232650757\n","minibatch AVG loss: 0.05812550317728892\n","\n","Epoch: 36  val \n","Loss: 0.1751  Acc: 95.4345\n","negative precision: 94.7020  recall: 98.3945\n","negative sensitivity: 98.3945  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 96.9027\n","negative TP: 429.0\n","negative TN: 219.0\n","negative FP: 24.0\n","negative FN: 7.0\n","positive precision: 96.9027  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 98.3945\n","positive FPR: 1.6055  NPV: 94.7020\n","positive TP: 219.0\n","positive TN: 429.0\n","positive FP: 7.0\n","positive FN: 24.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 50 minibatch: 1      time used: 20.85332751274109\n","minibatch AVG loss: 0.08604184489231556\n","Epoch: 37     train index of 50 minibatch: 2      time used: 20.22299599647522\n","minibatch AVG loss: 0.040255349082872274\n","Epoch: 37     train index of 50 minibatch: 3      time used: 20.158349752426147\n","minibatch AVG loss: 0.0561097696213983\n","Epoch: 37     train index of 50 minibatch: 4      time used: 19.878741025924683\n","minibatch AVG loss: 0.06517889915732666\n","Epoch: 37     train index of 50 minibatch: 5      time used: 20.357101917266846\n","minibatch AVG loss: 0.038399516216013584\n","Epoch: 37     train index of 50 minibatch: 6      time used: 20.041426420211792\n","minibatch AVG loss: 0.06300696088117547\n","\n","Epoch: 37  train \n","Loss: 0.0612  Acc: 97.8261\n","negative precision: 98.1132  recall: 98.5075\n","negative sensitivity: 98.5075  specificity: 96.6049\n","negative FPR: 3.3951  NPV: 97.3057\n","negative TP: 1716.0\n","negative TN: 939.0\n","negative FP: 33.0\n","negative FN: 26.0\n","positive precision: 97.3057  recall: 96.6049\n","positive sensitivity: 96.6049  specificity: 98.5075\n","positive FPR: 1.4925  NPV: 98.1132\n","positive TP: 939.0\n","positive TN: 1716.0\n","positive FP: 26.0\n","positive FN: 33.0\n","\n","\n","Epoch: 37     val index of 50 minibatch: 1      time used: 11.555346488952637\n","minibatch AVG loss: 0.16393553886591689\n","\n","Epoch: 37  val \n","Loss: 0.1708  Acc: 93.8144\n","negative precision: 97.3558  recall: 92.8899\n","negative sensitivity: 92.8899  specificity: 95.4733\n","negative FPR: 4.5267  NPV: 88.2129\n","negative TP: 405.0\n","negative TN: 232.0\n","negative FP: 11.0\n","negative FN: 31.0\n","positive precision: 88.2129  recall: 95.4733\n","positive sensitivity: 95.4733  specificity: 92.8899\n","positive FPR: 7.1101  NPV: 97.3558\n","positive TP: 232.0\n","positive TN: 405.0\n","positive FP: 31.0\n","positive FN: 11.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 50 minibatch: 1      time used: 20.54531979560852\n","minibatch AVG loss: 0.05375940949190408\n","Epoch: 38     train index of 50 minibatch: 2      time used: 20.39581274986267\n","minibatch AVG loss: 0.06850568967871368\n","Epoch: 38     train index of 50 minibatch: 3      time used: 19.729787588119507\n","minibatch AVG loss: 0.06437049746746197\n","Epoch: 38     train index of 50 minibatch: 4      time used: 20.007710218429565\n","minibatch AVG loss: 0.026980150667950512\n","Epoch: 38     train index of 50 minibatch: 5      time used: 20.038719177246094\n","minibatch AVG loss: 0.051055736754788084\n","Epoch: 38     train index of 50 minibatch: 6      time used: 20.344200134277344\n","minibatch AVG loss: 0.05408698324579746\n","\n","Epoch: 38  train \n","Loss: 0.0545  Acc: 97.8261\n","negative precision: 98.3899  recall: 98.2204\n","negative sensitivity: 98.2204  specificity: 97.1193\n","negative FPR: 2.8807  NPV: 96.8205\n","negative TP: 1711.0\n","negative TN: 944.0\n","negative FP: 28.0\n","negative FN: 31.0\n","positive precision: 96.8205  recall: 97.1193\n","positive sensitivity: 97.1193  specificity: 98.2204\n","positive FPR: 1.7796  NPV: 98.3899\n","positive TP: 944.0\n","positive TN: 1711.0\n","positive FP: 31.0\n","positive FN: 28.0\n","\n","\n","Epoch: 38     val index of 50 minibatch: 1      time used: 11.624104261398315\n","minibatch AVG loss: 0.0939474078422063\n","\n","Epoch: 38  val \n","Loss: 0.1875  Acc: 94.1090\n","negative precision: 94.7964  recall: 96.1009\n","negative sensitivity: 96.1009  specificity: 90.5350\n","negative FPR: 9.4650  NPV: 92.8270\n","negative TP: 419.0\n","negative TN: 220.0\n","negative FP: 23.0\n","negative FN: 17.0\n","positive precision: 92.8270  recall: 90.5350\n","positive sensitivity: 90.5350  specificity: 96.1009\n","positive FPR: 3.8991  NPV: 94.7964\n","positive TP: 220.0\n","positive TN: 419.0\n","positive FP: 17.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 50 minibatch: 1      time used: 20.791400909423828\n","minibatch AVG loss: 0.05413716990267858\n","Epoch: 39     train index of 50 minibatch: 2      time used: 19.73084044456482\n","minibatch AVG loss: 0.04266583449556492\n","Epoch: 39     train index of 50 minibatch: 3      time used: 20.239279747009277\n","minibatch AVG loss: 0.05591168032842688\n","Epoch: 39     train index of 50 minibatch: 4      time used: 19.653642177581787\n","minibatch AVG loss: 0.076873496780172\n","Epoch: 39     train index of 50 minibatch: 5      time used: 19.82261896133423\n","minibatch AVG loss: 0.05545754841761664\n","Epoch: 39     train index of 50 minibatch: 6      time used: 19.639907598495483\n","minibatch AVG loss: 0.03900575123610906\n","\n","Epoch: 39  train \n","Loss: 0.0534  Acc: 97.8998\n","negative precision: 98.6713  recall: 98.0482\n","negative sensitivity: 98.0482  specificity: 97.6337\n","negative FPR: 2.3663  NPV: 96.5412\n","negative TP: 1708.0\n","negative TN: 949.0\n","negative FP: 23.0\n","negative FN: 34.0\n","positive precision: 96.5412  recall: 97.6337\n","positive sensitivity: 97.6337  specificity: 98.0482\n","positive FPR: 1.9518  NPV: 98.6713\n","positive TP: 949.0\n","positive TN: 1708.0\n","positive FP: 34.0\n","positive FN: 23.0\n","\n","\n","Epoch: 39     val index of 50 minibatch: 1      time used: 11.522462368011475\n","minibatch AVG loss: 0.11822152724827902\n","\n","Epoch: 39  val \n","Loss: 0.1941  Acc: 94.9926\n","negative precision: 96.1009  recall: 96.1009\n","negative sensitivity: 96.1009  specificity: 93.0041\n","negative FPR: 6.9959  NPV: 93.0041\n","negative TP: 419.0\n","negative TN: 226.0\n","negative FP: 17.0\n","negative FN: 17.0\n","positive precision: 93.0041  recall: 93.0041\n","positive sensitivity: 93.0041  specificity: 96.1009\n","positive FPR: 3.8991  NPV: 96.1009\n","positive TP: 226.0\n","positive TN: 419.0\n","positive FP: 17.0\n","positive FN: 17.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 50 minibatch: 1      time used: 20.649503231048584\n","minibatch AVG loss: 0.05976691540214233\n","Epoch: 40     train index of 50 minibatch: 2      time used: 20.012078762054443\n","minibatch AVG loss: 0.03310782177140936\n","Epoch: 40     train index of 50 minibatch: 3      time used: 20.033434629440308\n","minibatch AVG loss: 0.03699990155757405\n","Epoch: 40     train index of 50 minibatch: 4      time used: 20.31390929222107\n","minibatch AVG loss: 0.06329959478229284\n","Epoch: 40     train index of 50 minibatch: 5      time used: 19.98055076599121\n","minibatch AVG loss: 0.04895903753582388\n","Epoch: 40     train index of 50 minibatch: 6      time used: 19.073601722717285\n","minibatch AVG loss: 0.07794324716320261\n","\n","Epoch: 40  train \n","Loss: 0.0536  Acc: 98.0840\n","negative precision: 98.6191  recall: 98.3927\n","negative sensitivity: 98.3927  specificity: 97.5309\n","negative FPR: 2.4691  NPV: 97.1311\n","negative TP: 1714.0\n","negative TN: 948.0\n","negative FP: 24.0\n","negative FN: 28.0\n","positive precision: 97.1311  recall: 97.5309\n","positive sensitivity: 97.5309  specificity: 98.3927\n","positive FPR: 1.6073  NPV: 98.6191\n","positive TP: 948.0\n","positive TN: 1714.0\n","positive FP: 28.0\n","positive FN: 24.0\n","\n","\n","Epoch: 40     val index of 50 minibatch: 1      time used: 11.565816879272461\n","minibatch AVG loss: 0.08425635917214094\n","\n","Epoch: 40  val \n","Loss: 0.1677  Acc: 94.6981\n","negative precision: 95.2489  recall: 96.5596\n","negative sensitivity: 96.5596  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 93.6709\n","negative TP: 421.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 15.0\n","positive precision: 93.6709  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 96.5596\n","positive FPR: 3.4404  NPV: 95.2489\n","positive TP: 222.0\n","positive TN: 421.0\n","positive FP: 15.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 50 minibatch: 1      time used: 20.58833336830139\n","minibatch AVG loss: 0.048628630375023935\n","Epoch: 41     train index of 50 minibatch: 2      time used: 20.070640087127686\n","minibatch AVG loss: 0.06804122109198943\n","Epoch: 41     train index of 50 minibatch: 3      time used: 19.530717849731445\n","minibatch AVG loss: 0.03279265055200085\n","Epoch: 41     train index of 50 minibatch: 4      time used: 19.98150897026062\n","minibatch AVG loss: 0.022445231737801805\n","Epoch: 41     train index of 50 minibatch: 5      time used: 20.116732597351074\n","minibatch AVG loss: 0.030418636811082252\n","Epoch: 41     train index of 50 minibatch: 6      time used: 19.768265962600708\n","minibatch AVG loss: 0.06375888151698746\n","\n","Epoch: 41  train \n","Loss: 0.0443  Acc: 98.4893\n","negative precision: 98.9637  recall: 98.6797\n","negative sensitivity: 98.6797  specificity: 98.1481\n","negative FPR: 1.8519  NPV: 97.6459\n","negative TP: 1719.0\n","negative TN: 954.0\n","negative FP: 18.0\n","negative FN: 23.0\n","positive precision: 97.6459  recall: 98.1481\n","positive sensitivity: 98.1481  specificity: 98.6797\n","positive FPR: 1.3203  NPV: 98.9637\n","positive TP: 954.0\n","positive TN: 1719.0\n","positive FP: 23.0\n","positive FN: 18.0\n","\n","\n","Epoch: 41     val index of 50 minibatch: 1      time used: 11.641332149505615\n","minibatch AVG loss: 0.11193362163048733\n","\n","Epoch: 41  val \n","Loss: 0.1906  Acc: 95.1399\n","negative precision: 96.7517  recall: 95.6422\n","negative sensitivity: 95.6422  specificity: 94.2387\n","negative FPR: 5.7613  NPV: 92.3387\n","negative TP: 417.0\n","negative TN: 229.0\n","negative FP: 14.0\n","negative FN: 19.0\n","positive precision: 92.3387  recall: 94.2387\n","positive sensitivity: 94.2387  specificity: 95.6422\n","positive FPR: 4.3578  NPV: 96.7517\n","positive TP: 229.0\n","positive TN: 417.0\n","positive FP: 19.0\n","positive FN: 14.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 50 minibatch: 1      time used: 20.66673183441162\n","minibatch AVG loss: 0.04806161330081522\n","Epoch: 42     train index of 50 minibatch: 2      time used: 20.18608570098877\n","minibatch AVG loss: 0.05627869134070352\n","Epoch: 42     train index of 50 minibatch: 3      time used: 19.84457755088806\n","minibatch AVG loss: 0.036288486389676106\n","Epoch: 42     train index of 50 minibatch: 4      time used: 20.05786371231079\n","minibatch AVG loss: 0.05484821283258498\n","Epoch: 42     train index of 50 minibatch: 5      time used: 20.028767108917236\n","minibatch AVG loss: 0.06251971236430108\n","Epoch: 42     train index of 50 minibatch: 6      time used: 19.751588106155396\n","minibatch AVG loss: 0.03086884577292949\n","\n","Epoch: 42  train \n","Loss: 0.0498  Acc: 97.9735\n","negative precision: 98.5049  recall: 98.3352\n","negative sensitivity: 98.3352  specificity: 97.3251\n","negative FPR: 2.6749  NPV: 97.0256\n","negative TP: 1713.0\n","negative TN: 946.0\n","negative FP: 26.0\n","negative FN: 29.0\n","positive precision: 97.0256  recall: 97.3251\n","positive sensitivity: 97.3251  specificity: 98.3352\n","positive FPR: 1.6648  NPV: 98.5049\n","positive TP: 946.0\n","positive TN: 1713.0\n","positive FP: 29.0\n","positive FN: 26.0\n","\n","\n","Epoch: 42     val index of 50 minibatch: 1      time used: 11.563461303710938\n","minibatch AVG loss: 0.06924830516705698\n","\n","Epoch: 42  val \n","Loss: 0.2073  Acc: 94.5508\n","negative precision: 94.8315  recall: 96.7890\n","negative sensitivity: 96.7890  specificity: 90.5350\n","negative FPR: 9.4650  NPV: 94.0171\n","negative TP: 422.0\n","negative TN: 220.0\n","negative FP: 23.0\n","negative FN: 14.0\n","positive precision: 94.0171  recall: 90.5350\n","positive sensitivity: 90.5350  specificity: 96.7890\n","positive FPR: 3.2110  NPV: 94.8315\n","positive TP: 220.0\n","positive TN: 422.0\n","positive FP: 14.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 50 minibatch: 1      time used: 20.639917850494385\n","minibatch AVG loss: 0.06730991917313077\n","Epoch: 43     train index of 50 minibatch: 2      time used: 19.899184942245483\n","minibatch AVG loss: 0.042407890586182474\n","Epoch: 43     train index of 50 minibatch: 3      time used: 19.893833875656128\n","minibatch AVG loss: 0.04950278437114321\n","Epoch: 43     train index of 50 minibatch: 4      time used: 20.13566303253174\n","minibatch AVG loss: 0.044277655968908224\n","Epoch: 43     train index of 50 minibatch: 5      time used: 19.791670560836792\n","minibatch AVG loss: 0.03661366529995576\n","Epoch: 43     train index of 50 minibatch: 6      time used: 19.88765597343445\n","minibatch AVG loss: 0.062088094388018364\n","\n","Epoch: 43  train \n","Loss: 0.0474  Acc: 98.6367\n","negative precision: 98.9099  recall: 98.9667\n","negative sensitivity: 98.9667  specificity: 98.0453\n","negative FPR: 1.9547  NPV: 98.1462\n","negative TP: 1724.0\n","negative TN: 953.0\n","negative FP: 19.0\n","negative FN: 18.0\n","positive precision: 98.1462  recall: 98.0453\n","positive sensitivity: 98.0453  specificity: 98.9667\n","positive FPR: 1.0333  NPV: 98.9099\n","positive TP: 953.0\n","positive TN: 1724.0\n","positive FP: 18.0\n","positive FN: 19.0\n","\n","\n","Epoch: 43     val index of 50 minibatch: 1      time used: 11.569849491119385\n","minibatch AVG loss: 0.0916441876492172\n","\n","Epoch: 43  val \n","Loss: 0.1881  Acc: 95.2872\n","negative precision: 96.3303  recall: 96.3303\n","negative sensitivity: 96.3303  specificity: 93.4156\n","negative FPR: 6.5844  NPV: 93.4156\n","negative TP: 420.0\n","negative TN: 227.0\n","negative FP: 16.0\n","negative FN: 16.0\n","positive precision: 93.4156  recall: 93.4156\n","positive sensitivity: 93.4156  specificity: 96.3303\n","positive FPR: 3.6697  NPV: 96.3303\n","positive TP: 227.0\n","positive TN: 420.0\n","positive FP: 16.0\n","positive FN: 16.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 50 minibatch: 1      time used: 20.831854104995728\n","minibatch AVG loss: 0.050654786825180056\n","Epoch: 44     train index of 50 minibatch: 2      time used: 19.687271118164062\n","minibatch AVG loss: 0.03343373889219947\n","Epoch: 44     train index of 50 minibatch: 3      time used: 20.026130437850952\n","minibatch AVG loss: 0.0646638226765208\n","Epoch: 44     train index of 50 minibatch: 4      time used: 19.956252813339233\n","minibatch AVG loss: 0.06205275039421394\n","Epoch: 44     train index of 50 minibatch: 5      time used: 19.985811710357666\n","minibatch AVG loss: 0.04434869343298487\n","Epoch: 44     train index of 50 minibatch: 6      time used: 19.89652442932129\n","minibatch AVG loss: 0.07314471701276488\n","\n","Epoch: 44  train \n","Loss: 0.0536  Acc: 97.9366\n","negative precision: 98.3927  recall: 98.3927\n","negative sensitivity: 98.3927  specificity: 97.1193\n","negative FPR: 2.8807  NPV: 97.1193\n","negative TP: 1714.0\n","negative TN: 944.0\n","negative FP: 28.0\n","negative FN: 28.0\n","positive precision: 97.1193  recall: 97.1193\n","positive sensitivity: 97.1193  specificity: 98.3927\n","positive FPR: 1.6073  NPV: 98.3927\n","positive TP: 944.0\n","positive TN: 1714.0\n","positive FP: 28.0\n","positive FN: 28.0\n","\n","\n","Epoch: 44     val index of 50 minibatch: 1      time used: 11.554307460784912\n","minibatch AVG loss: 0.06141065420088125\n","\n","Epoch: 44  val \n","Loss: 0.1706  Acc: 95.8763\n","negative precision: 95.3333  recall: 98.3945\n","negative sensitivity: 98.3945  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 96.9432\n","negative TP: 429.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 7.0\n","positive precision: 96.9432  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 98.3945\n","positive FPR: 1.6055  NPV: 95.3333\n","positive TP: 222.0\n","positive TN: 429.0\n","positive FP: 7.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 50 minibatch: 1      time used: 20.582544088363647\n","minibatch AVG loss: 0.038225734536536035\n","Epoch: 45     train index of 50 minibatch: 2      time used: 19.40480136871338\n","minibatch AVG loss: 0.034555575461126864\n","Epoch: 45     train index of 50 minibatch: 3      time used: 19.72124934196472\n","minibatch AVG loss: 0.03076169905718416\n","Epoch: 45     train index of 50 minibatch: 4      time used: 20.130151987075806\n","minibatch AVG loss: 0.028695621168008074\n","Epoch: 45     train index of 50 minibatch: 5      time used: 20.144354581832886\n","minibatch AVG loss: 0.016180815366096793\n","Epoch: 45     train index of 50 minibatch: 6      time used: 19.793160915374756\n","minibatch AVG loss: 0.04569043379975483\n","\n","Epoch: 45  train \n","Loss: 0.0365  Acc: 98.5999\n","negative precision: 98.9093  recall: 98.9093\n","negative sensitivity: 98.9093  specificity: 98.0453\n","negative FPR: 1.9547  NPV: 98.0453\n","negative TP: 1723.0\n","negative TN: 953.0\n","negative FP: 19.0\n","negative FN: 19.0\n","positive precision: 98.0453  recall: 98.0453\n","positive sensitivity: 98.0453  specificity: 98.9093\n","positive FPR: 1.0907  NPV: 98.9093\n","positive TP: 953.0\n","positive TN: 1723.0\n","positive FP: 19.0\n","positive FN: 19.0\n","\n","\n","Epoch: 45     val index of 50 minibatch: 1      time used: 11.498058795928955\n","minibatch AVG loss: 0.09540287845313287\n","\n","Epoch: 45  val \n","Loss: 0.1989  Acc: 94.9926\n","negative precision: 95.2703  recall: 97.0183\n","negative sensitivity: 97.0183  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 94.4681\n","negative TP: 423.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 13.0\n","positive precision: 94.4681  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 97.0183\n","positive FPR: 2.9817  NPV: 95.2703\n","positive TP: 222.0\n","positive TN: 423.0\n","positive FP: 13.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 50 minibatch: 1      time used: 20.7389497756958\n","minibatch AVG loss: 0.02884599637996871\n","Epoch: 46     train index of 50 minibatch: 2      time used: 19.78020715713501\n","minibatch AVG loss: 0.04864618593332125\n","Epoch: 46     train index of 50 minibatch: 3      time used: 19.961009979248047\n","minibatch AVG loss: 0.03148672499577515\n","Epoch: 46     train index of 50 minibatch: 4      time used: 20.112922430038452\n","minibatch AVG loss: 0.03305157844326459\n","Epoch: 46     train index of 50 minibatch: 5      time used: 20.003878116607666\n","minibatch AVG loss: 0.034230832164757884\n","Epoch: 46     train index of 50 minibatch: 6      time used: 20.270941257476807\n","minibatch AVG loss: 0.055760778945405036\n","\n","Epoch: 46  train \n","Loss: 0.0394  Acc: 98.5630\n","negative precision: 98.7407  recall: 99.0241\n","negative sensitivity: 99.0241  specificity: 97.7366\n","negative FPR: 2.2634  NPV: 98.2420\n","negative TP: 1725.0\n","negative TN: 950.0\n","negative FP: 22.0\n","negative FN: 17.0\n","positive precision: 98.2420  recall: 97.7366\n","positive sensitivity: 97.7366  specificity: 99.0241\n","positive FPR: 0.9759  NPV: 98.7407\n","positive TP: 950.0\n","positive TN: 1725.0\n","positive FP: 17.0\n","positive FN: 22.0\n","\n","\n","Epoch: 46     val index of 50 minibatch: 1      time used: 11.07246994972229\n","minibatch AVG loss: 0.07881404567560821\n","\n","Epoch: 46  val \n","Loss: 0.1831  Acc: 95.5817\n","negative precision: 95.7207  recall: 97.4771\n","negative sensitivity: 97.4771  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 95.3191\n","negative TP: 425.0\n","negative TN: 224.0\n","negative FP: 19.0\n","negative FN: 11.0\n","positive precision: 95.3191  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 97.4771\n","positive FPR: 2.5229  NPV: 95.7207\n","positive TP: 224.0\n","positive TN: 425.0\n","positive FP: 11.0\n","positive FN: 19.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 50 minibatch: 1      time used: 20.71873378753662\n","minibatch AVG loss: 0.04714065840002149\n","Epoch: 47     train index of 50 minibatch: 2      time used: 19.790977239608765\n","minibatch AVG loss: 0.03866426592110656\n","Epoch: 47     train index of 50 minibatch: 3      time used: 19.796072006225586\n","minibatch AVG loss: 0.020736020407639444\n","Epoch: 47     train index of 50 minibatch: 4      time used: 19.992047786712646\n","minibatch AVG loss: 0.0640590359212365\n","Epoch: 47     train index of 50 minibatch: 5      time used: 20.277732849121094\n","minibatch AVG loss: 0.05965471027884632\n","Epoch: 47     train index of 50 minibatch: 6      time used: 19.873971939086914\n","minibatch AVG loss: 0.03257884106133133\n","\n","Epoch: 47  train \n","Loss: 0.0421  Acc: 98.6735\n","negative precision: 99.0230  recall: 98.9093\n","negative sensitivity: 98.9093  specificity: 98.2510\n","negative FPR: 1.7490  NPV: 98.0493\n","negative TP: 1723.0\n","negative TN: 955.0\n","negative FP: 17.0\n","negative FN: 19.0\n","positive precision: 98.0493  recall: 98.2510\n","positive sensitivity: 98.2510  specificity: 98.9093\n","positive FPR: 1.0907  NPV: 99.0230\n","positive TP: 955.0\n","positive TN: 1723.0\n","positive FP: 19.0\n","positive FN: 17.0\n","\n","\n","Epoch: 47     val index of 50 minibatch: 1      time used: 11.52063775062561\n","minibatch AVG loss: 0.13811153749164076\n","\n","Epoch: 47  val \n","Loss: 0.1777  Acc: 93.9617\n","negative precision: 96.4706  recall: 94.0367\n","negative sensitivity: 94.0367  specificity: 93.8272\n","negative FPR: 6.1728  NPV: 89.7638\n","negative TP: 410.0\n","negative TN: 228.0\n","negative FP: 15.0\n","negative FN: 26.0\n","positive precision: 89.7638  recall: 93.8272\n","positive sensitivity: 93.8272  specificity: 94.0367\n","positive FPR: 5.9633  NPV: 96.4706\n","positive TP: 228.0\n","positive TN: 410.0\n","positive FP: 26.0\n","positive FN: 15.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 50 minibatch: 1      time used: 20.471535205841064\n","minibatch AVG loss: 0.061955609384458515\n","Epoch: 48     train index of 50 minibatch: 2      time used: 20.256650924682617\n","minibatch AVG loss: 0.022881164838327094\n","Epoch: 48     train index of 50 minibatch: 3      time used: 19.87972068786621\n","minibatch AVG loss: 0.03296495988033712\n","Epoch: 48     train index of 50 minibatch: 4      time used: 20.255650281906128\n","minibatch AVG loss: 0.020123898109886795\n","Epoch: 48     train index of 50 minibatch: 5      time used: 19.87321186065674\n","minibatch AVG loss: 0.036194611124228684\n","Epoch: 48     train index of 50 minibatch: 6      time used: 19.969512939453125\n","minibatch AVG loss: 0.04552107478026301\n","\n","Epoch: 48  train \n","Loss: 0.0403  Acc: 98.7472\n","negative precision: 99.0241  recall: 99.0241\n","negative sensitivity: 99.0241  specificity: 98.2510\n","negative FPR: 1.7490  NPV: 98.2510\n","negative TP: 1725.0\n","negative TN: 955.0\n","negative FP: 17.0\n","negative FN: 17.0\n","positive precision: 98.2510  recall: 98.2510\n","positive sensitivity: 98.2510  specificity: 99.0241\n","positive FPR: 0.9759  NPV: 99.0241\n","positive TP: 955.0\n","positive TN: 1725.0\n","positive FP: 17.0\n","positive FN: 17.0\n","\n","\n","Epoch: 48     val index of 50 minibatch: 1      time used: 11.547035217285156\n","minibatch AVG loss: 0.06838325104457908\n","\n","Epoch: 48  val \n","Loss: 0.1762  Acc: 95.5817\n","negative precision: 95.7207  recall: 97.4771\n","negative sensitivity: 97.4771  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 95.3191\n","negative TP: 425.0\n","negative TN: 224.0\n","negative FP: 19.0\n","negative FN: 11.0\n","positive precision: 95.3191  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 97.4771\n","positive FPR: 2.5229  NPV: 95.7207\n","positive TP: 224.0\n","positive TN: 425.0\n","positive FP: 11.0\n","positive FN: 19.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 50 minibatch: 1      time used: 20.354537963867188\n","minibatch AVG loss: 0.02626472890842706\n","Epoch: 49     train index of 50 minibatch: 2      time used: 20.13046169281006\n","minibatch AVG loss: 0.02797924117301591\n","Epoch: 49     train index of 50 minibatch: 3      time used: 19.912058115005493\n","minibatch AVG loss: 0.02211345190415159\n","Epoch: 49     train index of 50 minibatch: 4      time used: 19.97024178504944\n","minibatch AVG loss: 0.04940550551167689\n","Epoch: 49     train index of 50 minibatch: 5      time used: 19.98626971244812\n","minibatch AVG loss: 0.033177825561724605\n","Epoch: 49     train index of 50 minibatch: 6      time used: 20.043481826782227\n","minibatch AVG loss: 0.09838675379287451\n","\n","Epoch: 49  train \n","Loss: 0.0418  Acc: 98.3419\n","negative precision: 98.8486  recall: 98.5649\n","negative sensitivity: 98.5649  specificity: 97.9424\n","negative FPR: 2.0576  NPV: 97.4411\n","negative TP: 1717.0\n","negative TN: 952.0\n","negative FP: 20.0\n","negative FN: 25.0\n","positive precision: 97.4411  recall: 97.9424\n","positive sensitivity: 97.9424  specificity: 98.5649\n","positive FPR: 1.4351  NPV: 98.8486\n","positive TP: 952.0\n","positive TN: 1717.0\n","positive FP: 25.0\n","positive FN: 20.0\n","\n","\n","Epoch: 49     val index of 50 minibatch: 1      time used: 11.552541255950928\n","minibatch AVG loss: 0.07387724566757242\n","\n","Epoch: 49  val \n","Loss: 0.1890  Acc: 94.9926\n","negative precision: 94.6667  recall: 97.7064\n","negative sensitivity: 97.7064  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 95.6332\n","negative TP: 426.0\n","negative TN: 219.0\n","negative FP: 24.0\n","negative FN: 10.0\n","positive precision: 95.6332  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 97.7064\n","positive FPR: 2.2936  NPV: 94.6667\n","positive TP: 219.0\n","positive TN: 426.0\n","positive FP: 10.0\n","positive FN: 24.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 50 minibatch: 1      time used: 20.4960720539093\n","minibatch AVG loss: 0.018106360343517737\n","Epoch: 50     train index of 50 minibatch: 2      time used: 20.00384497642517\n","minibatch AVG loss: 0.035686999519239176\n","Epoch: 50     train index of 50 minibatch: 3      time used: 19.88788604736328\n","minibatch AVG loss: 0.05454996029962786\n","Epoch: 50     train index of 50 minibatch: 4      time used: 19.900314807891846\n","minibatch AVG loss: 0.020834768870845437\n","Epoch: 50     train index of 50 minibatch: 5      time used: 20.052670001983643\n","minibatch AVG loss: 0.029479480108711868\n","Epoch: 50     train index of 50 minibatch: 6      time used: 20.229501485824585\n","minibatch AVG loss: 0.04967618129914626\n","\n","Epoch: 50  train \n","Loss: 0.0375  Acc: 98.5999\n","negative precision: 98.9093  recall: 98.9093\n","negative sensitivity: 98.9093  specificity: 98.0453\n","negative FPR: 1.9547  NPV: 98.0453\n","negative TP: 1723.0\n","negative TN: 953.0\n","negative FP: 19.0\n","negative FN: 19.0\n","positive precision: 98.0453  recall: 98.0453\n","positive sensitivity: 98.0453  specificity: 98.9093\n","positive FPR: 1.0907  NPV: 98.9093\n","positive TP: 953.0\n","positive TN: 1723.0\n","positive FP: 19.0\n","positive FN: 19.0\n","\n","\n","Epoch: 50     val index of 50 minibatch: 1      time used: 11.44966197013855\n","minibatch AVG loss: 0.06058110547804972\n","\n","Epoch: 50  val \n","Loss: 0.2463  Acc: 94.6981\n","negative precision: 93.6681  recall: 98.3945\n","negative sensitivity: 98.3945  specificity: 88.0658\n","negative FPR: 11.9342  NPV: 96.8326\n","negative TP: 429.0\n","negative TN: 214.0\n","negative FP: 29.0\n","negative FN: 7.0\n","positive precision: 96.8326  recall: 88.0658\n","positive sensitivity: 88.0658  specificity: 98.3945\n","positive FPR: 1.6055  NPV: 93.6681\n","positive TP: 214.0\n","positive TN: 429.0\n","positive FP: 7.0\n","positive FN: 29.0\n","\n","\n","\n","Training complete in 127m 54s\n","Best epoch idx:  44\n","Best epoch train Acc: 97.936625\n","Best epoch val Acc: 95.876289\n","negative precision: 95.3333  recall: 98.3945\n","negative sensitivity: 98.3945  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 96.9432\n","positive precision: 96.9432  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 98.3945\n","positive FPR: 1.6055  NPV: 95.3333\n","model trained by GPU (idx:0) has been saved at  /home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_401_PT_lf25_b8_k2.pth\n","finished\n","\n","============================================================\n","Processing finished !\n","start time: 2021_10_28  10:05:16\n","end time: 2021_10_28  12:13:19\n","source: e3c8fe55b95c\n","\n","Preparing the email with auto log file :\n"," Train__2021_10_28-10_05_16_log \n","as  .rtf\n","processing log catched\n","server log catched\n","发送log邮件成功，title:  [e3c8fe55b95c  LOG] Train__2021_10_28-10_05_16_log\n","如果没有，看看垃圾箱:)\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"frgERjE_V63O","outputId":"bc9d516a-886f-488e-c217-a2b381bea48b"},"source":["!python Test.py --model_idx Hybrid2_384_401_PT_lf25_b8_k2 --enable_attention_check --dataroot /data/pancreatic-cancer-project/dataset --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/runs"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[1.0846, 0.6774]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : Hybrid2_384_401_PT_lf25_b8_k2\n","*********************************setting*************************************\n","Namespace(att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=None, cls_token_off=False, dataroot='/data/pancreatic-cancer-project/dataset', draw_root='/home/pancreatic-cancer-project/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='Hybrid2_384_401_PT_lf25_b8_k2', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 80 minibatch: 1      time used: 2.788116693496704\n","minibatch AVG loss: 0.09524526560330741\n","Epoch: test     test index of 80 minibatch: 2      time used: 2.589919090270996\n","minibatch AVG loss: 0.07297606043703127\n","Epoch: test     test index of 80 minibatch: 3      time used: 2.7275965213775635\n","minibatch AVG loss: 0.038141322586943714\n","Epoch: test     test index of 80 minibatch: 4      time used: 2.6670889854431152\n","minibatch AVG loss: 0.010899318190672603\n","Epoch: test     test index of 80 minibatch: 5      time used: 2.710430383682251\n","minibatch AVG loss: 0.0005532268687147735\n","Epoch: test     test index of 80 minibatch: 6      time used: 2.649768829345703\n","minibatch AVG loss: 0.018578869300654333\n","Epoch: test     test index of 80 minibatch: 7      time used: 2.6880338191986084\n","minibatch AVG loss: 0.10684324496201043\n","Epoch: test     test index of 80 minibatch: 8      time used: 2.6300675868988037\n","minibatch AVG loss: 0.21412801810765814\n","Epoch: test     test index of 80 minibatch: 9      time used: 2.6623623371124268\n","minibatch AVG loss: 0.04586729552574979\n","Epoch: test     test index of 80 minibatch: 10      time used: 2.666987895965576\n","minibatch AVG loss: 0.27964289439478307\n","\n","Epoch:  test \n","Loss: 0.1189  Acc: 96.5762\n","negative precision: 96.2298  recall: 98.5294\n","negative sensitivity: 98.5294  specificity: 93.0693\n","negative FPR: 6.9307  NPV: 97.2414\n","negative TP: 536.0\n","negative TN: 282.0\n","negative FP: 21.0\n","negative FN: 8.0\n","positive precision: 97.2414  recall: 93.0693\n","positive sensitivity: 93.0693  specificity: 98.5294\n","positive FPR: 1.4706  NPV: 96.2298\n","positive TP: 282.0\n","positive TN: 536.0\n","positive FP: 8.0\n","positive FN: 21.0\n","\n","\n","Testing complete in 2m 43s\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"0Xc_0ZP5XnHn","outputId":"f0e620c0-dad7-4a4a-d41f-8993f8c64ff4"},"source":["!python Train.py --model_idx Hybrid2_384_401_PT_lf25_b8_k3 --lr 0.00001 --lrf 0.25 --enable_notify --enable_tensorboard --Pre_Trained_model_path /home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_PreTrain_000.pth --dataroot /data/pancreatic-cancer-project/dataset/fold_3 --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/runs"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Notify is waiting for reboost\n","*****************LOG_Cache_2021_10_28_12_16*****************\n","start monitoring:)\n","notify started\n","notify_frontend reboosted!\n","log_root_path log\n","mail_user tum9598@163.com\n","default_reciving_list ['tum9598@163.com']\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path='/home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_PreTrain_000.pth', att_module='SimAM', attn_drop_rate=0.0, backbone_PT_off=False, batch_size=8, check_minibatch=None, cls_token_off=False, dataroot='/data/pancreatic-cancer-project/dataset/fold_3', draw_root='/home/pancreatic-cancer-project/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=True, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=-1, intake_epochs=0, lr=1e-05, lrf=0.25, model_idx='Hybrid2_384_401_PT_lf25_b8_k3', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, pos_embedding_off=False)\n","we dont have more GPU idx here, try to use gpu_idx=0\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[ 2.1666e-01, -4.7421e-01,  1.8033e-01,  3.0284e-01, -4.8657e-01,\n","         -6.5892e-01,  6.7286e-01, -9.4735e-01,  1.8332e-03,  1.1280e+00,\n","          6.0691e-01,  4.4678e-01,  1.0305e+00,  2.6081e-01, -8.9324e-01,\n","          9.0739e-01,  3.3736e-01, -8.4321e-01, -5.3484e-01, -2.6153e-01,\n","          1.1813e-01,  5.8210e-01, -9.1074e-02,  5.5711e-02, -5.0008e-01,\n","          5.0046e-01,  2.2023e-01,  3.8575e-01, -3.6419e-01,  1.8775e-01,\n","         -1.0013e+00,  9.7029e-01, -8.9606e-01,  5.8526e-01, -6.0324e-02,\n","          2.8680e-01, -1.7486e-01, -5.7358e-02, -2.3304e-02, -8.9619e-02,\n","         -5.2647e-01,  7.6940e-01,  4.0491e-01, -1.8638e-01,  1.2026e+00,\n","         -2.9995e-01, -3.0298e-01, -5.5280e-01, -3.2249e-01,  5.9502e-01,\n","         -4.3468e-01,  1.0191e+00,  1.4346e-01,  1.5864e-01,  7.4061e-01,\n","         -3.8455e-01, -1.1300e+00,  4.2022e-01, -7.5100e-01, -4.4431e-01,\n","         -3.2544e-01,  4.3934e-01,  2.9867e-01,  1.0853e-01,  4.0149e-01,\n","          4.8915e-01,  6.2100e-02, -7.2858e-01, -8.0314e-02,  6.3522e-02,\n","          9.2666e-01, -4.2381e-01, -3.6368e-01,  1.6887e-02, -5.2490e-01,\n","         -5.2767e-01, -2.1943e-01,  5.2008e-01,  4.3857e-01, -6.1164e-01,\n","         -4.1595e-01,  2.7936e-01,  7.3350e-01,  7.9244e-01, -1.7026e-01,\n","          1.6747e-01, -6.8064e-02, -7.3537e-02, -1.0140e+00,  8.4919e-02,\n","         -4.0062e-01,  1.6448e+00, -9.2639e-01,  2.0900e-01, -1.8306e-01,\n","          5.8141e-01,  3.8690e-01, -6.2016e-01,  4.9578e-01,  1.0685e+00,\n","          8.6109e-02,  1.3977e-01,  6.8784e-01, -8.0958e-01,  2.0807e-01,\n","         -4.6999e-01, -1.7971e-01, -8.4584e-02,  6.8367e-01,  8.3208e-01,\n","          5.2042e-01, -4.3107e-01, -4.5932e-01, -4.8616e-01, -4.6352e-01,\n","         -3.3450e-01,  4.8264e-01, -2.5343e-01,  4.8577e-02, -2.6356e-01,\n","          1.0537e+00, -1.1945e-01, -1.7415e+00, -5.0386e-01, -2.2265e-01,\n","          3.1367e-01, -1.4120e+00, -3.5089e-01, -1.9413e-01,  5.0706e-02,\n","          1.0555e+00,  1.0856e-01,  4.9621e-01, -3.9441e-01,  3.0980e-01,\n","          1.5954e-01, -2.2117e-01,  4.4933e-01, -1.4019e-01,  3.3464e-01,\n","         -8.0265e-01,  7.6930e-01,  3.9676e-01, -2.3813e-01,  5.8820e-01,\n","         -2.5222e-01, -2.2237e-01, -5.7166e-01, -6.9520e-01, -8.6945e-01,\n","         -1.9836e-01, -5.2389e-01, -6.6921e-01, -9.6664e-01, -2.1290e-01,\n","          3.6217e-02,  5.8212e-01,  7.6754e-01,  6.3949e-01, -7.3677e-01,\n","          1.2266e+00, -1.0001e-01, -2.8125e-01, -8.0921e-01,  1.1078e+00,\n","          1.0405e+00, -3.8854e-01,  5.2377e-01,  4.7812e-01, -6.1291e-02,\n","         -6.7650e-01, -9.9664e-01, -7.8526e-01, -2.5582e-01,  8.0009e-01,\n","          1.6076e-01,  1.3886e-01,  5.7681e-01,  3.2688e-01, -1.0707e+00,\n","         -7.5648e-01,  3.7256e-01,  7.4912e-01,  1.5014e-01,  5.6243e-01,\n","          6.6609e-01,  3.8102e-01,  4.9880e-01,  2.9567e-01,  1.2317e+00,\n","          2.2053e-01,  1.0838e-01, -3.2360e-01, -4.1344e-01,  2.6800e-01,\n","          1.6090e-01,  9.9983e-01,  7.1696e-01,  3.0113e-01,  1.4047e-01,\n","         -2.8635e-01, -2.6977e-02,  1.0585e+00, -4.0660e-01, -4.8512e-01,\n","         -5.6495e-01,  4.2269e-01, -4.4172e-01, -2.9341e-01,  8.9416e-02,\n","          5.7455e-01, -1.5858e-01,  1.9142e-01, -8.2919e-01, -1.1784e-01,\n","         -3.8307e-01, -8.3623e-01, -1.1778e+00,  1.0831e+00,  2.3893e-01,\n","          5.4679e-01,  2.3990e-01, -9.2425e-02,  5.3054e-01, -3.4389e-01,\n","         -1.4973e+00, -3.8203e-01, -4.5449e-01, -2.0671e-01, -1.8606e-02,\n","          6.9127e-01,  1.2140e-01, -7.5049e-01,  2.3656e-01, -9.5200e-02,\n","         -4.1982e-01,  4.5942e-01,  3.1451e-01, -4.4832e-01,  3.2117e-01,\n","          1.5423e-03,  2.6317e-01,  8.3795e-01,  6.1409e-01,  4.5812e-01,\n","         -4.3683e-01, -2.7957e-01,  1.1908e-01,  1.0032e-01,  2.6231e-02,\n","          4.7835e-03,  3.9014e-01,  2.5367e-02, -9.4333e-01,  2.7289e-01,\n","          1.3458e+00, -7.0671e-01, -4.3741e-01,  6.2262e-01, -4.7800e-01,\n","          4.2114e-02, -5.2731e-01,  1.4530e-01,  3.4526e-01, -4.0380e-01,\n","          8.0879e-01,  2.0872e-01, -3.1978e-01, -4.1021e-01,  3.0624e-02,\n","         -9.4838e-01,  1.8232e-01,  8.7393e-01, -2.8509e-01,  2.8806e-01,\n","         -1.0527e-01, -5.5985e-01, -2.3851e-01, -6.7235e-01, -6.8656e-01,\n","          6.0549e-01, -4.0970e-03,  8.3409e-01,  1.6456e-01,  1.7790e-02,\n","         -6.0855e-01, -3.1545e-02, -2.7620e-01,  4.7811e-01,  1.0174e+00,\n","          6.7161e-01,  5.8914e-01, -2.6104e-02,  1.1465e+00,  4.7396e-01,\n","          1.7520e-01, -5.3694e-01, -1.0094e+00,  6.0517e-01, -6.2272e-01,\n","         -1.5679e-01, -8.0598e-01, -8.0097e-02,  1.4145e+00, -1.2229e+00,\n","         -8.1610e-03, -4.1985e-01, -8.1593e-01,  6.1630e-01, -6.2003e-01,\n","         -5.1867e-01, -1.3416e-01,  1.1829e-01, -6.4824e-01,  8.1688e-01,\n","          3.5813e-01, -8.2212e-01, -5.4484e-01,  1.0119e-01, -2.3940e-01,\n","          1.0492e+00, -3.2231e-01,  8.8072e-01, -2.0386e-01,  3.4266e-01,\n","         -2.1809e-04, -4.3811e-01, -1.4643e-01, -1.4370e-01,  2.2846e-01,\n","         -4.9339e-01, -3.7553e-02,  8.9154e-01,  1.3907e-01,  9.4544e-02,\n","          2.1967e-01,  1.0154e+00,  4.4208e-01, -4.6395e-01, -9.0063e-01,\n","         -6.6472e-01,  3.4370e-01, -1.0131e+00, -1.3204e+00, -1.0094e+00,\n","         -5.9364e-01, -4.8717e-01,  4.4058e-01,  5.4193e-01,  1.6144e-01,\n","         -7.4380e-01,  1.9032e-01,  2.3118e-02,  2.8254e-01, -3.4857e-01,\n","          1.1796e-01,  4.1222e-01, -1.8240e-01, -2.9825e-01,  1.6421e-01,\n","         -8.3378e-02,  1.9388e-01,  6.3008e-01, -6.3716e-01,  1.5108e+00,\n","          9.1688e-01,  5.8826e-01, -3.2557e-01,  3.7183e-01, -1.6559e+00,\n","         -1.1680e-01, -8.7413e-01, -3.1305e-01,  3.6092e-01,  6.5580e-01,\n","         -8.9679e-01, -5.7921e-01,  1.0326e-01,  1.0422e+00, -5.1449e-01,\n","          9.4280e-01,  4.0336e-01,  2.6656e-01, -3.8148e-01,  1.4276e-01,\n","          1.5177e-02, -9.5266e-01, -5.7478e-01, -7.0650e-01, -6.0620e-01,\n","          1.6522e-01,  7.8339e-01,  2.7598e-02,  6.0522e-01,  6.7714e-02,\n","         -2.0373e-01,  5.2184e-01, -2.0795e-01, -1.4365e-01,  6.2235e-01,\n","         -2.1461e-01,  9.8679e-02,  4.0264e-01,  9.4615e-01, -7.1391e-01,\n","         -5.0820e-02, -5.5782e-01,  8.4015e-01, -2.4695e-01,  2.0569e-01,\n","         -1.0167e+00, -4.0228e-01,  1.1637e+00, -2.4513e-01,  9.5664e-02,\n","          2.8576e-01,  1.1327e+00,  1.8957e-01, -7.1850e-01,  4.4865e-01,\n","          3.5293e-01,  4.0419e-01,  1.1109e+00,  1.3175e+00,  2.4401e-02,\n","          3.7667e-01, -2.5981e-01, -2.6797e-01,  1.5575e+00,  4.9660e-02,\n","          1.1472e-01, -1.1175e-02,  3.6860e-01,  6.4207e-01, -1.0836e-04,\n","         -6.2095e-01,  2.5976e-01,  3.8648e-01,  1.0039e+00,  5.3080e-01,\n","         -9.1269e-01,  1.0460e+00, -3.9773e-01,  4.7867e-01,  3.3357e-01,\n","          1.6247e-01, -8.7713e-03,  7.6417e-01, -1.5434e+00,  3.6742e-01,\n","         -1.7368e-01, -1.3163e+00,  1.3577e+00, -1.0784e-01, -1.1486e-01,\n","          1.2644e+00, -3.4705e-01,  2.6563e-01,  2.8580e-01, -2.3911e-01,\n","         -5.8467e-01, -4.9897e-01,  2.1585e-01,  1.4748e+00, -4.4899e-01,\n","          8.8774e-01, -1.6235e-01, -2.7376e-01, -7.1224e-01, -1.3764e-01,\n","          3.6147e-01,  6.7793e-01,  6.9520e-01,  2.7143e-01,  5.9280e-01,\n","          5.4819e-01,  4.9856e-01,  1.2604e+00,  2.9709e-01,  2.6040e-01,\n","         -5.8097e-01,  1.5439e-01,  8.0847e-01, -3.0217e-01,  6.4507e-01,\n","          2.2922e-02,  2.3991e-01,  1.2384e+00, -2.2171e-01, -7.0928e-03,\n","          1.9838e-01,  8.3678e-01, -8.5981e-01, -2.8568e-01,  1.9095e-01,\n","         -5.9930e-01,  3.4530e-01,  1.7907e-01, -5.8533e-01, -3.9108e-01,\n","          1.3534e-01, -3.9534e-01,  2.9089e-01,  1.1026e-01,  2.2106e-01,\n","         -8.9309e-02, -3.6811e-01, -2.6436e-01, -4.2888e-01, -1.5628e-01,\n","          3.5117e-01,  5.9574e-01,  1.6612e-01, -3.4786e-01, -2.6749e-01,\n","         -8.0357e-02,  9.3936e-01, -1.1385e+00,  6.2440e-01,  9.5759e-01,\n","         -4.1871e-01, -3.5787e-01, -3.8892e-01,  4.0981e-01, -3.9806e-01,\n","         -1.7236e-01,  2.1272e-01,  3.7206e-01,  7.2732e-01, -4.1594e-01,\n","          4.6727e-01, -8.8528e-01, -9.8807e-01, -1.5185e-01,  4.2987e-01,\n","         -1.7785e-01, -5.0763e-01, -8.4378e-01,  6.2516e-01,  4.7258e-01,\n","          7.2423e-01,  8.7806e-01,  4.1242e-01, -1.4148e-01, -5.0299e-01,\n","          7.8564e-01,  7.9717e-02, -6.8691e-02, -2.9585e-01, -3.4100e-01,\n","          5.4962e-01,  6.2462e-02, -1.0496e+00,  3.7820e-01,  9.5406e-01,\n","         -8.6697e-01,  3.3542e-01,  1.3459e-01,  1.1273e-01, -6.4730e-01,\n","         -3.3621e-01,  2.6752e-01,  2.4378e-01, -2.2441e-01,  2.6785e-01,\n","         -5.9391e-01, -4.1546e-01, -7.9487e-01, -2.9756e-01,  5.7530e-01,\n","          7.3612e-01, -1.3985e+00,  1.2317e+00,  7.2213e-01, -5.8227e-01,\n","         -1.0673e-01,  5.7164e-01,  1.5425e-01,  1.0895e+00,  1.2320e+00,\n","         -2.9984e-01, -8.0997e-01, -8.0534e-01,  2.7615e-01, -1.0259e-01,\n","         -2.0853e-01,  7.6011e-01, -2.0839e-01, -1.7049e-01, -8.2152e-02,\n","         -7.6952e-01,  5.5893e-01, -4.5167e-02,  2.1071e-01, -1.6695e-01,\n","         -9.4379e-01,  7.0505e-01, -1.0129e+00, -1.4160e+00, -9.1469e-01,\n","          6.5794e-02,  5.9263e-02,  4.3184e-01,  7.7075e-01,  1.1557e+00,\n","         -1.5775e-01, -6.4064e-01, -6.5827e-01, -8.9281e-01,  1.2247e+00,\n","         -7.1033e-02,  1.5717e-01,  2.5382e-01, -5.3365e-01, -4.3624e-01,\n","          8.6912e-02, -2.6298e-01,  1.1626e-01,  8.7539e-01, -1.9012e-01,\n","         -6.6729e-01, -2.3464e-01,  8.6478e-01,  7.2786e-01,  3.3397e-01,\n","         -1.6017e-01, -5.0254e-01, -7.3996e-02, -3.7829e-01, -1.4741e+00,\n","         -8.3302e-01,  3.7283e-01,  2.1826e-01,  2.5692e-02, -6.5851e-01,\n","         -2.9597e-01, -3.3820e-01,  1.3639e+00, -7.7488e-01,  5.1539e-01,\n","         -5.7388e-01, -7.8878e-02,  1.4294e-02, -1.1069e+00, -3.7966e-01,\n","         -8.9033e-01, -1.2349e+00,  8.7038e-01, -9.4274e-01,  7.7459e-01,\n","          2.9489e-03, -5.5035e-01, -4.9410e-01,  1.6765e-01, -8.5204e-01,\n","         -4.2691e-01, -1.8325e-01,  1.5029e+00,  5.1469e-01,  5.7784e-01,\n","         -6.3793e-01, -6.1114e-01, -4.0964e-02, -8.2097e-02, -1.5212e-01,\n","         -1.9229e-01,  3.4257e-01,  3.9545e-02, -9.6416e-02, -1.1933e-02,\n","         -9.0584e-01,  8.6432e-01, -3.7954e-01, -1.8582e-01,  5.3733e-01,\n","         -1.2165e-01,  2.3117e-01,  4.4549e-01,  9.0628e-02, -3.9202e-01,\n","          5.9542e-01, -6.2026e-01,  1.7630e-01, -2.6233e-01, -3.4569e-01,\n","          4.4749e-01, -1.3701e-01,  5.9270e-02, -8.8871e-01, -7.8990e-01,\n","         -8.5382e-01, -2.1154e-01, -1.2771e+00, -9.5926e-03,  8.8370e-01,\n","          7.4744e-01,  6.9917e-01,  1.4780e-01, -2.1493e-01,  3.7231e-01,\n","          9.2370e-02,  1.0832e+00,  3.9699e-01,  1.0125e-01,  7.1224e-01,\n","          6.8133e-01, -8.9262e-01, -1.1712e+00,  2.6976e-01,  5.7062e-01,\n","          4.7347e-01, -9.0269e-01, -7.5984e-02,  1.9798e-02,  4.9426e-01,\n","         -6.8980e-01,  6.2834e-01,  3.1884e-01,  2.1181e-01,  2.9812e-02,\n","         -1.4362e-01,  6.0778e-01,  9.0836e-01,  2.4475e-01,  2.1145e-01,\n","         -3.1287e-01, -1.2203e+00, -2.6419e-01, -4.4693e-01, -4.4690e-02,\n","          6.8615e-01,  4.1714e-01,  5.6715e-01,  1.3130e-02,  4.7644e-01,\n","         -1.9041e-01, -2.4661e-01,  3.8793e-01, -1.3892e-01, -5.6922e-01,\n","         -3.8136e-01,  7.2892e-01, -6.4470e-01, -5.5313e-01,  6.1247e-01,\n","         -1.0014e-01,  4.0849e-01, -1.9521e-01, -5.9512e-01, -6.4988e-02,\n","         -2.7915e-01,  5.3021e-01, -1.6933e-01, -4.2548e-01,  2.4398e-01,\n","         -2.7639e-01,  5.9434e-01,  1.4690e+00,  4.8321e-01,  1.6484e-01,\n","          6.0448e-02, -3.8277e-02,  1.6056e-01,  7.0794e-01, -2.1264e-01,\n","          2.2819e-01,  6.3278e-01,  1.9960e-02, -1.7677e-01,  1.8472e-01,\n","         -3.5790e-01, -2.3733e-01,  1.1483e-02, -9.6668e-01, -5.1292e-01,\n","          1.6635e-01,  1.5496e-01,  1.5968e-01, -6.0187e-01,  7.4434e-01,\n","          2.1636e-01, -1.9631e-02, -1.2121e+00, -1.9568e-01,  4.4568e-01,\n","         -5.8059e-01,  5.7306e-01, -3.5325e-01,  1.2262e+00,  8.5117e-01,\n","         -1.2517e+00,  1.5711e-01, -4.8338e-01, -8.9890e-01, -5.7489e-01,\n","          6.4357e-01, -7.7923e-01,  3.3649e-01,  1.3424e-01, -1.1829e-01,\n","         -2.0373e-01, -2.7749e-01, -1.3068e+00, -5.0447e-01, -4.9479e-01,\n","         -6.8277e-01,  5.1541e-01,  9.5475e-01, -1.2515e-01,  3.1012e-01,\n","         -2.8129e-01,  1.7821e+00,  8.9728e-01, -3.3743e-01,  2.3577e-01,\n","         -1.7557e-01, -1.1398e+00,  9.9451e-01, -9.4415e-01, -6.0988e-01,\n","          1.3445e-01, -3.4160e-01,  5.0410e-01, -3.7131e-01, -1.6956e-01,\n","          3.4758e-01, -4.7118e-01, -4.7098e-01, -2.7183e-01,  8.8055e-01,\n","          1.4070e-01,  2.8334e-01, -2.1244e-01, -8.2920e-02,  6.8698e-01,\n","         -1.3666e+00, -8.1465e-01,  3.3053e-01,  2.8022e-02,  1.4109e-01,\n","         -7.3691e-01,  3.9807e-01,  9.1929e-02, -5.7754e-01, -3.9033e-02,\n","          8.0497e-02, -1.2178e-01, -2.4387e-01,  4.7647e-01, -1.0630e-01,\n","         -1.0826e-01, -2.1110e-03,  3.7709e-01, -1.4875e-01, -1.1374e+00,\n","         -7.6128e-01, -3.7458e-02, -1.8034e-01, -3.6584e-01,  2.2185e-01,\n","         -4.3772e-01, -7.1709e-01,  5.8107e-01,  1.8911e-02,  2.8151e-01,\n","         -5.4206e-01,  8.0032e-01,  9.6944e-01, -2.8757e-01, -1.7112e-01,\n","         -6.1564e-01,  6.8253e-01,  1.6584e-01,  7.0866e-01, -6.5146e-01,\n","         -8.7727e-01,  1.8078e-01,  5.9838e-01,  7.1257e-01,  4.9618e-01,\n","          3.7922e-01,  9.9859e-01,  6.3601e-02,  1.6859e-01,  3.9038e-01,\n","          3.1408e-01, -5.3799e-01,  5.2695e-01, -7.0191e-01, -2.1992e-01,\n","         -1.0359e+00, -6.0567e-01,  2.2677e-01,  1.7703e-01, -1.1606e+00,\n","          2.3550e-01,  5.5554e-01,  1.9281e+00,  1.9194e-01, -8.5557e-01,\n","          4.5519e-02,  4.3140e-01, -1.1850e+00,  2.7465e-01, -3.5207e-01,\n","         -9.3445e-01, -2.0982e-01,  9.0532e-01, -1.1775e+00,  9.8909e-01,\n","         -7.2240e-01,  5.4872e-03,  6.5173e-01,  9.2605e-01,  3.5818e-01,\n","         -7.0264e-02, -5.3810e-01,  6.0329e-01,  7.2034e-02,  4.8261e-01,\n","         -7.4249e-02, -3.4379e-01, -8.3596e-01, -6.9483e-01, -1.6042e-01,\n","         -3.2902e-01, -2.7382e-01, -1.1209e+00, -3.7440e-01, -1.3012e+00,\n","         -1.0944e-02,  6.2558e-01, -2.1302e-01, -1.5804e-01,  1.0750e+00,\n","          1.9843e-01,  1.1140e+00, -1.3254e-01, -2.3597e-01,  6.4282e-01,\n","         -1.4200e-01,  6.1646e-01,  6.9602e-01,  1.4218e-01, -6.0943e-01,\n","         -2.3569e-01,  2.2932e-01,  2.0487e-01, -1.4491e+00, -1.1249e-01,\n","         -8.1519e-01,  2.7957e-01,  2.0120e-01,  8.3839e-01, -9.2751e-01,\n","          4.0007e-01,  1.0488e-02, -5.1090e-01, -4.0092e-02,  4.4054e-02,\n","         -8.8771e-03,  4.2877e-01, -6.0787e-02, -3.7034e-01, -4.1881e-01,\n","          6.2871e-01, -1.8778e-01, -4.2418e-01,  1.6102e-01, -9.5770e-02,\n","         -2.3623e-01,  4.4124e-01, -5.5353e-01, -2.9374e-01, -1.1476e-01,\n","         -2.6253e-01, -4.5752e-01,  9.6869e-01, -4.6147e-04, -5.1060e-01,\n","         -9.5821e-01,  1.0444e+00,  1.0781e+00,  8.4808e-01, -3.7346e-01,\n","          2.9457e-01,  4.7508e-02,  4.4786e-01,  1.0769e+00, -1.7285e-02,\n","         -4.1817e-01,  1.7504e-01, -5.0107e-01, -4.1750e-01, -7.8469e-02,\n","         -6.2529e-02,  7.1313e-01,  3.7026e-01, -5.6427e-01,  9.2629e-03]],\n","       grad_fn=<AddmmBackward>)\n","model is ready now!\n","pretrain model loaded\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 192, 192]           9,408\n","       BatchNorm2d-2         [-1, 64, 192, 192]             128\n","              ReLU-3         [-1, 64, 192, 192]               0\n","         MaxPool2d-4           [-1, 64, 96, 96]               0\n","            Conv2d-5           [-1, 64, 96, 96]           4,096\n","       BatchNorm2d-6           [-1, 64, 96, 96]             128\n","              ReLU-7           [-1, 64, 96, 96]               0\n","            Conv2d-8           [-1, 64, 96, 96]          36,864\n","       BatchNorm2d-9           [-1, 64, 96, 96]             128\n","             ReLU-10           [-1, 64, 96, 96]               0\n","           Conv2d-11          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-12          [-1, 256, 96, 96]             512\n","             ReLU-13          [-1, 256, 96, 96]               0\n","           Conv2d-14          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-15          [-1, 256, 96, 96]             512\n","             ReLU-16          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-17          [-1, 256, 96, 96]               0\n","           Conv2d-18           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-19           [-1, 64, 96, 96]             128\n","             ReLU-20           [-1, 64, 96, 96]               0\n","           Conv2d-21           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-22           [-1, 64, 96, 96]             128\n","             ReLU-23           [-1, 64, 96, 96]               0\n","           Conv2d-24          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-25          [-1, 256, 96, 96]             512\n","             ReLU-26          [-1, 256, 96, 96]               0\n","             ReLU-27          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-28          [-1, 256, 96, 96]               0\n","           Conv2d-29           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-30           [-1, 64, 96, 96]             128\n","             ReLU-31           [-1, 64, 96, 96]               0\n","           Conv2d-32           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-33           [-1, 64, 96, 96]             128\n","             ReLU-34           [-1, 64, 96, 96]               0\n","           Conv2d-35          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-36          [-1, 256, 96, 96]             512\n","             ReLU-37          [-1, 256, 96, 96]               0\n","             ReLU-38          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-39          [-1, 256, 96, 96]               0\n","           Conv2d-40          [-1, 128, 48, 48]          32,768\n","      BatchNorm2d-41          [-1, 128, 48, 48]             256\n","             ReLU-42          [-1, 128, 48, 48]               0\n","           Conv2d-43          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-44          [-1, 128, 48, 48]             256\n","             ReLU-45          [-1, 128, 48, 48]               0\n","           Conv2d-46          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-47          [-1, 512, 48, 48]           1,024\n","             ReLU-48          [-1, 512, 48, 48]               0\n","           Conv2d-49          [-1, 512, 48, 48]         131,072\n","      BatchNorm2d-50          [-1, 512, 48, 48]           1,024\n","             ReLU-51          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-52          [-1, 512, 48, 48]               0\n","           Conv2d-53          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-54          [-1, 128, 48, 48]             256\n","             ReLU-55          [-1, 128, 48, 48]               0\n","           Conv2d-56          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-57          [-1, 128, 48, 48]             256\n","             ReLU-58          [-1, 128, 48, 48]               0\n","           Conv2d-59          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-60          [-1, 512, 48, 48]           1,024\n","             ReLU-61          [-1, 512, 48, 48]               0\n","             ReLU-62          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-63          [-1, 512, 48, 48]               0\n","           Conv2d-64          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-65          [-1, 128, 48, 48]             256\n","             ReLU-66          [-1, 128, 48, 48]               0\n","           Conv2d-67          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-68          [-1, 128, 48, 48]             256\n","             ReLU-69          [-1, 128, 48, 48]               0\n","           Conv2d-70          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-71          [-1, 512, 48, 48]           1,024\n","             ReLU-72          [-1, 512, 48, 48]               0\n","             ReLU-73          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-74          [-1, 512, 48, 48]               0\n","           Conv2d-75          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-76          [-1, 128, 48, 48]             256\n","             ReLU-77          [-1, 128, 48, 48]               0\n","           Conv2d-78          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-79          [-1, 128, 48, 48]             256\n","             ReLU-80          [-1, 128, 48, 48]               0\n","           Conv2d-81          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-82          [-1, 512, 48, 48]           1,024\n","             ReLU-83          [-1, 512, 48, 48]               0\n","             ReLU-84          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-85          [-1, 512, 48, 48]               0\n","           Conv2d-86          [-1, 256, 24, 24]         131,072\n","      BatchNorm2d-87          [-1, 256, 24, 24]             512\n","             ReLU-88          [-1, 256, 24, 24]               0\n","           Conv2d-89          [-1, 256, 24, 24]         589,824\n","      BatchNorm2d-90          [-1, 256, 24, 24]             512\n","             ReLU-91          [-1, 256, 24, 24]               0\n","           Conv2d-92         [-1, 1024, 24, 24]         262,144\n","      BatchNorm2d-93         [-1, 1024, 24, 24]           2,048\n","             ReLU-94         [-1, 1024, 24, 24]               0\n","           Conv2d-95         [-1, 1024, 24, 24]         524,288\n","      BatchNorm2d-96         [-1, 1024, 24, 24]           2,048\n","             ReLU-97         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-98         [-1, 1024, 24, 24]               0\n","           Conv2d-99          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-100          [-1, 256, 24, 24]             512\n","            ReLU-101          [-1, 256, 24, 24]               0\n","          Conv2d-102          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-103          [-1, 256, 24, 24]             512\n","            ReLU-104          [-1, 256, 24, 24]               0\n","          Conv2d-105         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-106         [-1, 1024, 24, 24]           2,048\n","            ReLU-107         [-1, 1024, 24, 24]               0\n","            ReLU-108         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-109         [-1, 1024, 24, 24]               0\n","          Conv2d-110          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-111          [-1, 256, 24, 24]             512\n","            ReLU-112          [-1, 256, 24, 24]               0\n","          Conv2d-113          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-114          [-1, 256, 24, 24]             512\n","            ReLU-115          [-1, 256, 24, 24]               0\n","          Conv2d-116         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-117         [-1, 1024, 24, 24]           2,048\n","            ReLU-118         [-1, 1024, 24, 24]               0\n","            ReLU-119         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-120         [-1, 1024, 24, 24]               0\n","          Conv2d-121          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-122          [-1, 256, 24, 24]             512\n","            ReLU-123          [-1, 256, 24, 24]               0\n","          Conv2d-124          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-125          [-1, 256, 24, 24]             512\n","            ReLU-126          [-1, 256, 24, 24]               0\n","          Conv2d-127         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-128         [-1, 1024, 24, 24]           2,048\n","            ReLU-129         [-1, 1024, 24, 24]               0\n","            ReLU-130         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-131         [-1, 1024, 24, 24]               0\n","          Conv2d-132          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-133          [-1, 256, 24, 24]             512\n","            ReLU-134          [-1, 256, 24, 24]               0\n","          Conv2d-135          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-136          [-1, 256, 24, 24]             512\n","            ReLU-137          [-1, 256, 24, 24]               0\n","          Conv2d-138         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-139         [-1, 1024, 24, 24]           2,048\n","            ReLU-140         [-1, 1024, 24, 24]               0\n","            ReLU-141         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-142         [-1, 1024, 24, 24]               0\n","          Conv2d-143          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-144          [-1, 256, 24, 24]             512\n","            ReLU-145          [-1, 256, 24, 24]               0\n","          Conv2d-146          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-147          [-1, 256, 24, 24]             512\n","            ReLU-148          [-1, 256, 24, 24]               0\n","          Conv2d-149         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-150         [-1, 1024, 24, 24]           2,048\n","            ReLU-151         [-1, 1024, 24, 24]               0\n","            ReLU-152         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-153         [-1, 1024, 24, 24]               0\n","          Conv2d-154          [-1, 512, 12, 12]         524,288\n","     BatchNorm2d-155          [-1, 512, 12, 12]           1,024\n","            ReLU-156          [-1, 512, 12, 12]               0\n","          Conv2d-157          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-158          [-1, 512, 12, 12]           1,024\n","            ReLU-159          [-1, 512, 12, 12]               0\n","          Conv2d-160         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-161         [-1, 2048, 12, 12]           4,096\n","            ReLU-162         [-1, 2048, 12, 12]               0\n","          Conv2d-163         [-1, 2048, 12, 12]       2,097,152\n","     BatchNorm2d-164         [-1, 2048, 12, 12]           4,096\n","            ReLU-165         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-166         [-1, 2048, 12, 12]               0\n","          Conv2d-167          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-168          [-1, 512, 12, 12]           1,024\n","            ReLU-169          [-1, 512, 12, 12]               0\n","          Conv2d-170          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-171          [-1, 512, 12, 12]           1,024\n","            ReLU-172          [-1, 512, 12, 12]               0\n","          Conv2d-173         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-174         [-1, 2048, 12, 12]           4,096\n","            ReLU-175         [-1, 2048, 12, 12]               0\n","            ReLU-176         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-177         [-1, 2048, 12, 12]               0\n","          Conv2d-178          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-179          [-1, 512, 12, 12]           1,024\n","            ReLU-180          [-1, 512, 12, 12]               0\n","          Conv2d-181          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-182          [-1, 512, 12, 12]           1,024\n","            ReLU-183          [-1, 512, 12, 12]               0\n","          Conv2d-184         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-185         [-1, 2048, 12, 12]           4,096\n","            ReLU-186         [-1, 2048, 12, 12]               0\n","            ReLU-187         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-188         [-1, 2048, 12, 12]               0\n","Hybrid_backbone_4-189  [[-1, 256, 96, 96], [-1, 512, 48, 48], [-1, 1024, 24, 24], [-1, 2048, 12, 12]]               0\n","         Sigmoid-190         [-1, 2048, 12, 12]               0\n","    simam_module-191         [-1, 2048, 12, 12]               0\n","          Conv2d-192          [-1, 768, 12, 12]       1,573,632\n","Last_feature_map_Embed-193             [-1, 144, 768]               0\n","         Sigmoid-194          [-1, 256, 96, 96]               0\n","    simam_module-195          [-1, 256, 96, 96]               0\n","       MaxPool2d-196          [-1, 256, 12, 12]               0\n","          Conv2d-197          [-1, 768, 12, 12]         197,376\n","       LayerNorm-198             [-1, 144, 768]           1,536\n","       AvgPool2d-199          [-1, 256, 12, 12]               0\n","          Conv2d-200          [-1, 768, 12, 12]         197,376\n","       LayerNorm-201             [-1, 144, 768]           1,536\n","     Focus_Embed-202  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-203          [-1, 512, 48, 48]               0\n","    simam_module-204          [-1, 512, 48, 48]               0\n","       MaxPool2d-205          [-1, 512, 12, 12]               0\n","          Conv2d-206          [-1, 768, 12, 12]         393,984\n","       LayerNorm-207             [-1, 144, 768]           1,536\n","       AvgPool2d-208          [-1, 512, 12, 12]               0\n","          Conv2d-209          [-1, 768, 12, 12]         393,984\n","       LayerNorm-210             [-1, 144, 768]           1,536\n","     Focus_Embed-211  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-212         [-1, 1024, 24, 24]               0\n","    simam_module-213         [-1, 1024, 24, 24]               0\n","       MaxPool2d-214         [-1, 1024, 12, 12]               0\n","          Conv2d-215          [-1, 768, 12, 12]         787,200\n","       LayerNorm-216             [-1, 144, 768]           1,536\n","       AvgPool2d-217         [-1, 1024, 12, 12]               0\n","          Conv2d-218          [-1, 768, 12, 12]         787,200\n","       LayerNorm-219             [-1, 144, 768]           1,536\n","     Focus_Embed-220  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-221         [-1, 2048, 12, 12]               0\n","    simam_module-222         [-1, 2048, 12, 12]               0\n","       MaxPool2d-223         [-1, 2048, 12, 12]               0\n","          Conv2d-224          [-1, 768, 12, 12]       1,573,632\n","       LayerNorm-225             [-1, 144, 768]           1,536\n","       AvgPool2d-226         [-1, 2048, 12, 12]               0\n","          Conv2d-227          [-1, 768, 12, 12]       1,573,632\n","       LayerNorm-228             [-1, 144, 768]           1,536\n","     Focus_Embed-229  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Dropout-230             [-1, 145, 768]               0\n","         Dropout-231             [-1, 145, 768]               0\n","         Dropout-232             [-1, 145, 768]               0\n","         Dropout-233             [-1, 145, 768]               0\n","         Dropout-234             [-1, 145, 768]               0\n","         Dropout-235             [-1, 145, 768]               0\n","         Dropout-236             [-1, 145, 768]               0\n","         Dropout-237             [-1, 145, 768]               0\n","         Dropout-238             [-1, 145, 768]               0\n","       LayerNorm-239             [-1, 145, 768]           1,536\n","          Linear-240            [-1, 145, 2304]       1,771,776\n","         Dropout-241          [-1, 8, 145, 145]               0\n","          Linear-242             [-1, 145, 768]         590,592\n","         Dropout-243             [-1, 145, 768]               0\n","       Attention-244             [-1, 145, 768]               0\n","        Identity-245             [-1, 145, 768]               0\n","       LayerNorm-246             [-1, 145, 768]           1,536\n","          Linear-247            [-1, 145, 3072]       2,362,368\n","            GELU-248            [-1, 145, 3072]               0\n","         Dropout-249            [-1, 145, 3072]               0\n","          Linear-250             [-1, 145, 768]       2,360,064\n","         Dropout-251             [-1, 145, 768]               0\n","             FFN-252             [-1, 145, 768]               0\n","        Identity-253             [-1, 145, 768]               0\n","       LayerNorm-254             [-1, 145, 768]           1,536\n","          Linear-255             [-1, 145, 768]         590,592\n","          Linear-256             [-1, 145, 768]         590,592\n","          Linear-257             [-1, 145, 768]         590,592\n","         Dropout-258          [-1, 8, 145, 145]               0\n","          Linear-259             [-1, 145, 768]         590,592\n","         Dropout-260             [-1, 145, 768]               0\n","Guided_Attention-261             [-1, 145, 768]               0\n","        Identity-262             [-1, 145, 768]               0\n","       LayerNorm-263             [-1, 145, 768]           1,536\n","          Linear-264            [-1, 145, 3072]       2,362,368\n","            GELU-265            [-1, 145, 3072]               0\n","         Dropout-266            [-1, 145, 3072]               0\n","          Linear-267             [-1, 145, 768]       2,360,064\n","         Dropout-268             [-1, 145, 768]               0\n","             FFN-269             [-1, 145, 768]               0\n","        Identity-270             [-1, 145, 768]               0\n","   Decoder_Block-271             [-1, 145, 768]               0\n","       LayerNorm-272             [-1, 145, 768]           1,536\n","          Linear-273            [-1, 145, 2304]       1,771,776\n","         Dropout-274          [-1, 8, 145, 145]               0\n","          Linear-275             [-1, 145, 768]         590,592\n","         Dropout-276             [-1, 145, 768]               0\n","       Attention-277             [-1, 145, 768]               0\n","        Identity-278             [-1, 145, 768]               0\n","       LayerNorm-279             [-1, 145, 768]           1,536\n","          Linear-280            [-1, 145, 3072]       2,362,368\n","            GELU-281            [-1, 145, 3072]               0\n","         Dropout-282            [-1, 145, 3072]               0\n","          Linear-283             [-1, 145, 768]       2,360,064\n","         Dropout-284             [-1, 145, 768]               0\n","             FFN-285             [-1, 145, 768]               0\n","        Identity-286             [-1, 145, 768]               0\n","       LayerNorm-287             [-1, 145, 768]           1,536\n","          Linear-288             [-1, 145, 768]         590,592\n","          Linear-289             [-1, 145, 768]         590,592\n","          Linear-290             [-1, 145, 768]         590,592\n","         Dropout-291          [-1, 8, 145, 145]               0\n","          Linear-292             [-1, 145, 768]         590,592\n","         Dropout-293             [-1, 145, 768]               0\n","Guided_Attention-294             [-1, 145, 768]               0\n","        Identity-295             [-1, 145, 768]               0\n","       LayerNorm-296             [-1, 145, 768]           1,536\n","          Linear-297            [-1, 145, 3072]       2,362,368\n","            GELU-298            [-1, 145, 3072]               0\n","         Dropout-299            [-1, 145, 3072]               0\n","          Linear-300             [-1, 145, 768]       2,360,064\n","         Dropout-301             [-1, 145, 768]               0\n","             FFN-302             [-1, 145, 768]               0\n","        Identity-303             [-1, 145, 768]               0\n","   Decoder_Block-304             [-1, 145, 768]               0\n","       LayerNorm-305             [-1, 145, 768]           1,536\n","          Linear-306            [-1, 145, 2304]       1,771,776\n","         Dropout-307          [-1, 8, 145, 145]               0\n","          Linear-308             [-1, 145, 768]         590,592\n","         Dropout-309             [-1, 145, 768]               0\n","       Attention-310             [-1, 145, 768]               0\n","        Identity-311             [-1, 145, 768]               0\n","       LayerNorm-312             [-1, 145, 768]           1,536\n","          Linear-313            [-1, 145, 3072]       2,362,368\n","            GELU-314            [-1, 145, 3072]               0\n","         Dropout-315            [-1, 145, 3072]               0\n","          Linear-316             [-1, 145, 768]       2,360,064\n","         Dropout-317             [-1, 145, 768]               0\n","             FFN-318             [-1, 145, 768]               0\n","        Identity-319             [-1, 145, 768]               0\n","       LayerNorm-320             [-1, 145, 768]           1,536\n","          Linear-321             [-1, 145, 768]         590,592\n","          Linear-322             [-1, 145, 768]         590,592\n","          Linear-323             [-1, 145, 768]         590,592\n","         Dropout-324          [-1, 8, 145, 145]               0\n","          Linear-325             [-1, 145, 768]         590,592\n","         Dropout-326             [-1, 145, 768]               0\n","Guided_Attention-327             [-1, 145, 768]               0\n","        Identity-328             [-1, 145, 768]               0\n","       LayerNorm-329             [-1, 145, 768]           1,536\n","          Linear-330            [-1, 145, 3072]       2,362,368\n","            GELU-331            [-1, 145, 3072]               0\n","         Dropout-332            [-1, 145, 3072]               0\n","          Linear-333             [-1, 145, 768]       2,360,064\n","         Dropout-334             [-1, 145, 768]               0\n","             FFN-335             [-1, 145, 768]               0\n","        Identity-336             [-1, 145, 768]               0\n","   Decoder_Block-337             [-1, 145, 768]               0\n","       LayerNorm-338             [-1, 145, 768]           1,536\n","          Linear-339            [-1, 145, 2304]       1,771,776\n","         Dropout-340          [-1, 8, 145, 145]               0\n","          Linear-341             [-1, 145, 768]         590,592\n","         Dropout-342             [-1, 145, 768]               0\n","       Attention-343             [-1, 145, 768]               0\n","        Identity-344             [-1, 145, 768]               0\n","       LayerNorm-345             [-1, 145, 768]           1,536\n","          Linear-346            [-1, 145, 3072]       2,362,368\n","            GELU-347            [-1, 145, 3072]               0\n","         Dropout-348            [-1, 145, 3072]               0\n","          Linear-349             [-1, 145, 768]       2,360,064\n","         Dropout-350             [-1, 145, 768]               0\n","             FFN-351             [-1, 145, 768]               0\n","        Identity-352             [-1, 145, 768]               0\n","       LayerNorm-353             [-1, 145, 768]           1,536\n","          Linear-354             [-1, 145, 768]         590,592\n","          Linear-355             [-1, 145, 768]         590,592\n","          Linear-356             [-1, 145, 768]         590,592\n","         Dropout-357          [-1, 8, 145, 145]               0\n","          Linear-358             [-1, 145, 768]         590,592\n","         Dropout-359             [-1, 145, 768]               0\n","Guided_Attention-360             [-1, 145, 768]               0\n","        Identity-361             [-1, 145, 768]               0\n","       LayerNorm-362             [-1, 145, 768]           1,536\n","          Linear-363            [-1, 145, 3072]       2,362,368\n","            GELU-364            [-1, 145, 3072]               0\n","         Dropout-365            [-1, 145, 3072]               0\n","          Linear-366             [-1, 145, 768]       2,360,064\n","         Dropout-367             [-1, 145, 768]               0\n","             FFN-368             [-1, 145, 768]               0\n","        Identity-369             [-1, 145, 768]               0\n","   Decoder_Block-370             [-1, 145, 768]               0\n","       LayerNorm-371             [-1, 145, 768]           1,536\n","        Identity-372                  [-1, 768]               0\n","          Linear-373                    [-1, 2]           1,538\n","================================================================\n","Total params: 87,704,386\n","Trainable params: 87,704,386\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 372029.91\n","Params size (MB): 334.57\n","Estimated Total Size (MB): 372366.16\n","----------------------------------------------------------------\n","model : Hybrid2_384_401_PT_lf25_b8_k3\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 50 minibatch: 1      time used: 21.310428619384766\n","minibatch AVG loss: 0.7775643610954285\n","Epoch: 1     train index of 50 minibatch: 2      time used: 20.418330907821655\n","minibatch AVG loss: 0.6764840638637543\n","Epoch: 1     train index of 50 minibatch: 3      time used: 20.67508554458618\n","minibatch AVG loss: 0.5522320184111595\n","Epoch: 1     train index of 50 minibatch: 4      time used: 20.436463117599487\n","minibatch AVG loss: 0.5269817772507668\n","Epoch: 1     train index of 50 minibatch: 5      time used: 20.114803791046143\n","minibatch AVG loss: 0.5072704963386059\n","Epoch: 1     train index of 50 minibatch: 6      time used: 20.12732458114624\n","minibatch AVG loss: 0.42324299439787866\n","\n","Epoch: 1  train \n","Loss: 0.5633  Acc: 71.9602\n","negative precision: 73.1915  recall: 88.8634\n","negative sensitivity: 88.8634  specificity: 41.6667\n","negative FPR: 58.3333  NPV: 67.6127\n","negative TP: 1548.0\n","negative TN: 405.0\n","negative FP: 567.0\n","negative FN: 194.0\n","positive precision: 67.6127  recall: 41.6667\n","positive sensitivity: 41.6667  specificity: 88.8634\n","positive FPR: 11.1366  NPV: 73.1915\n","positive TP: 405.0\n","positive TN: 1548.0\n","positive FP: 194.0\n","positive FN: 567.0\n","\n","\n","Epoch: 1     val index of 50 minibatch: 1      time used: 11.574734449386597\n","minibatch AVG loss: 0.2579233458638191\n","\n","Epoch: 1  val \n","Loss: 0.3270  Acc: 87.9234\n","negative precision: 89.1593  recall: 92.4312\n","negative sensitivity: 92.4312  specificity: 79.8354\n","negative FPR: 20.1646  NPV: 85.4626\n","negative TP: 403.0\n","negative TN: 194.0\n","negative FP: 49.0\n","negative FN: 33.0\n","positive precision: 85.4626  recall: 79.8354\n","positive sensitivity: 79.8354  specificity: 92.4312\n","positive FPR: 7.5688  NPV: 89.1593\n","positive TP: 194.0\n","positive TN: 403.0\n","positive FP: 33.0\n","positive FN: 49.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 50 minibatch: 1      time used: 20.846467971801758\n","minibatch AVG loss: 0.37119931399822237\n","Epoch: 2     train index of 50 minibatch: 2      time used: 20.210583925247192\n","minibatch AVG loss: 0.4012036482989788\n","Epoch: 2     train index of 50 minibatch: 3      time used: 20.00497817993164\n","minibatch AVG loss: 0.34687079846858976\n","Epoch: 2     train index of 50 minibatch: 4      time used: 20.115668773651123\n","minibatch AVG loss: 0.34261628113687037\n","Epoch: 2     train index of 50 minibatch: 5      time used: 19.97337770462036\n","minibatch AVG loss: 0.38817218080163\n","Epoch: 2     train index of 50 minibatch: 6      time used: 20.227815866470337\n","minibatch AVG loss: 0.2846944074332714\n","\n","Epoch: 2  train \n","Loss: 0.3572  Acc: 85.4090\n","negative precision: 87.2235  recall: 90.5281\n","negative sensitivity: 90.5281  specificity: 76.2346\n","negative FPR: 23.7654  NPV: 81.7881\n","negative TP: 1577.0\n","negative TN: 741.0\n","negative FP: 231.0\n","negative FN: 165.0\n","positive precision: 81.7881  recall: 76.2346\n","positive sensitivity: 76.2346  specificity: 90.5281\n","positive FPR: 9.4719  NPV: 87.2235\n","positive TP: 741.0\n","positive TN: 1577.0\n","positive FP: 165.0\n","positive FN: 231.0\n","\n","\n","Epoch: 2     val index of 50 minibatch: 1      time used: 11.676761865615845\n","minibatch AVG loss: 0.0989511301741004\n","\n","Epoch: 2  val \n","Loss: 0.2627  Acc: 89.5434\n","negative precision: 88.5835  recall: 96.1009\n","negative sensitivity: 96.1009  specificity: 77.7778\n","negative FPR: 22.2222  NPV: 91.7476\n","negative TP: 419.0\n","negative TN: 189.0\n","negative FP: 54.0\n","negative FN: 17.0\n","positive precision: 91.7476  recall: 77.7778\n","positive sensitivity: 77.7778  specificity: 96.1009\n","positive FPR: 3.8991  NPV: 88.5835\n","positive TP: 189.0\n","positive TN: 419.0\n","positive FP: 17.0\n","positive FN: 54.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 50 minibatch: 1      time used: 20.261987686157227\n","minibatch AVG loss: 0.40303376644849775\n","Epoch: 3     train index of 50 minibatch: 2      time used: 19.49514150619507\n","minibatch AVG loss: 0.308309073895216\n","Epoch: 3     train index of 50 minibatch: 3      time used: 20.219871997833252\n","minibatch AVG loss: 0.40732524879276755\n","Epoch: 3     train index of 50 minibatch: 4      time used: 19.89687180519104\n","minibatch AVG loss: 0.3534374465793371\n","Epoch: 3     train index of 50 minibatch: 5      time used: 20.043843269348145\n","minibatch AVG loss: 0.336243277490139\n","Epoch: 3     train index of 50 minibatch: 6      time used: 19.99616003036499\n","minibatch AVG loss: 0.3100960326194763\n","\n","Epoch: 3  train \n","Loss: 0.3446  Acc: 85.1511\n","negative precision: 87.8035  recall: 89.2652\n","negative sensitivity: 89.2652  specificity: 77.7778\n","negative FPR: 22.2222  NPV: 80.1697\n","negative TP: 1555.0\n","negative TN: 756.0\n","negative FP: 216.0\n","negative FN: 187.0\n","positive precision: 80.1697  recall: 77.7778\n","positive sensitivity: 77.7778  specificity: 89.2652\n","positive FPR: 10.7348  NPV: 87.8035\n","positive TP: 756.0\n","positive TN: 1555.0\n","positive FP: 187.0\n","positive FN: 216.0\n","\n","\n","Epoch: 3     val index of 50 minibatch: 1      time used: 11.609581232070923\n","minibatch AVG loss: 0.14782945566810668\n","\n","Epoch: 3  val \n","Loss: 0.2449  Acc: 89.3962\n","negative precision: 89.9123  recall: 94.0367\n","negative sensitivity: 94.0367  specificity: 81.0700\n","negative FPR: 18.9300  NPV: 88.3408\n","negative TP: 410.0\n","negative TN: 197.0\n","negative FP: 46.0\n","negative FN: 26.0\n","positive precision: 88.3408  recall: 81.0700\n","positive sensitivity: 81.0700  specificity: 94.0367\n","positive FPR: 5.9633  NPV: 89.9123\n","positive TP: 197.0\n","positive TN: 410.0\n","positive FP: 26.0\n","positive FN: 46.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 50 minibatch: 1      time used: 20.522599458694458\n","minibatch AVG loss: 0.3003276392072439\n","Epoch: 4     train index of 50 minibatch: 2      time used: 20.162931203842163\n","minibatch AVG loss: 0.34844140127301215\n","Epoch: 4     train index of 50 minibatch: 3      time used: 19.832090377807617\n","minibatch AVG loss: 0.30339618258178236\n","Epoch: 4     train index of 50 minibatch: 4      time used: 19.7031831741333\n","minibatch AVG loss: 0.28897298246622083\n","Epoch: 4     train index of 50 minibatch: 5      time used: 20.023218393325806\n","minibatch AVG loss: 0.27968915544450285\n","Epoch: 4     train index of 50 minibatch: 6      time used: 19.886358976364136\n","minibatch AVG loss: 0.2446957352757454\n","\n","Epoch: 4  train \n","Loss: 0.2977  Acc: 87.7303\n","negative precision: 89.5564  recall: 91.5614\n","negative sensitivity: 91.5614  specificity: 80.8642\n","negative FPR: 19.1358  NPV: 84.2444\n","negative TP: 1595.0\n","negative TN: 786.0\n","negative FP: 186.0\n","negative FN: 147.0\n","positive precision: 84.2444  recall: 80.8642\n","positive sensitivity: 80.8642  specificity: 91.5614\n","positive FPR: 8.4386  NPV: 89.5564\n","positive TP: 786.0\n","positive TN: 1595.0\n","positive FP: 147.0\n","positive FN: 186.0\n","\n","\n","Epoch: 4     val index of 50 minibatch: 1      time used: 11.450681924819946\n","minibatch AVG loss: 0.10732196405529976\n","\n","Epoch: 4  val \n","Loss: 0.2866  Acc: 87.4816\n","negative precision: 84.8907  recall: 97.9358\n","negative sensitivity: 97.9358  specificity: 68.7243\n","negative FPR: 31.2757  NPV: 94.8864\n","negative TP: 427.0\n","negative TN: 167.0\n","negative FP: 76.0\n","negative FN: 9.0\n","positive precision: 94.8864  recall: 68.7243\n","positive sensitivity: 68.7243  specificity: 97.9358\n","positive FPR: 2.0642  NPV: 84.8907\n","positive TP: 167.0\n","positive TN: 427.0\n","positive FP: 9.0\n","positive FN: 76.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 50 minibatch: 1      time used: 20.657727241516113\n","minibatch AVG loss: 0.2715280351415277\n","Epoch: 5     train index of 50 minibatch: 2      time used: 19.820911645889282\n","minibatch AVG loss: 0.3215153931081295\n","Epoch: 5     train index of 50 minibatch: 3      time used: 20.021233320236206\n","minibatch AVG loss: 0.31396157525479795\n","Epoch: 5     train index of 50 minibatch: 4      time used: 19.756142377853394\n","minibatch AVG loss: 0.2702720458060503\n","Epoch: 5     train index of 50 minibatch: 5      time used: 19.801344394683838\n","minibatch AVG loss: 0.3116408780962229\n","Epoch: 5     train index of 50 minibatch: 6      time used: 19.903364658355713\n","minibatch AVG loss: 0.2586842166632414\n","\n","Epoch: 5  train \n","Loss: 0.2882  Acc: 88.2093\n","negative precision: 89.8096  recall: 92.0781\n","negative sensitivity: 92.0781  specificity: 81.2757\n","negative FPR: 18.7243  NPV: 85.1293\n","negative TP: 1604.0\n","negative TN: 790.0\n","negative FP: 182.0\n","negative FN: 138.0\n","positive precision: 85.1293  recall: 81.2757\n","positive sensitivity: 81.2757  specificity: 92.0781\n","positive FPR: 7.9219  NPV: 89.8096\n","positive TP: 790.0\n","positive TN: 1604.0\n","positive FP: 138.0\n","positive FN: 182.0\n","\n","\n","Epoch: 5     val index of 50 minibatch: 1      time used: 11.560724258422852\n","minibatch AVG loss: 0.06551638384233228\n","\n","Epoch: 5  val \n","Loss: 0.2473  Acc: 90.5744\n","negative precision: 88.5892  recall: 97.9358\n","negative sensitivity: 97.9358  specificity: 77.3663\n","negative FPR: 22.6337  NPV: 95.4315\n","negative TP: 427.0\n","negative TN: 188.0\n","negative FP: 55.0\n","negative FN: 9.0\n","positive precision: 95.4315  recall: 77.3663\n","positive sensitivity: 77.3663  specificity: 97.9358\n","positive FPR: 2.0642  NPV: 88.5892\n","positive TP: 188.0\n","positive TN: 427.0\n","positive FP: 9.0\n","positive FN: 55.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 50 minibatch: 1      time used: 20.383263111114502\n","minibatch AVG loss: 0.3012139595299959\n","Epoch: 6     train index of 50 minibatch: 2      time used: 20.22737956047058\n","minibatch AVG loss: 0.2997518064826727\n","Epoch: 6     train index of 50 minibatch: 3      time used: 19.901466369628906\n","minibatch AVG loss: 0.2896086449548602\n","Epoch: 6     train index of 50 minibatch: 4      time used: 20.27112865447998\n","minibatch AVG loss: 0.29651583105325696\n","Epoch: 6     train index of 50 minibatch: 5      time used: 19.78573489189148\n","minibatch AVG loss: 0.25583490818738935\n","Epoch: 6     train index of 50 minibatch: 6      time used: 19.72287130355835\n","minibatch AVG loss: 0.20460673701018095\n","\n","Epoch: 6  train \n","Loss: 0.2707  Acc: 88.9462\n","negative precision: 90.6426  recall: 92.3077\n","negative sensitivity: 92.3077  specificity: 82.9218\n","negative FPR: 17.0782  NPV: 85.7447\n","negative TP: 1608.0\n","negative TN: 806.0\n","negative FP: 166.0\n","negative FN: 134.0\n","positive precision: 85.7447  recall: 82.9218\n","positive sensitivity: 82.9218  specificity: 92.3077\n","positive FPR: 7.6923  NPV: 90.6426\n","positive TP: 806.0\n","positive TN: 1608.0\n","positive FP: 134.0\n","positive FN: 166.0\n","\n","\n","Epoch: 6     val index of 50 minibatch: 1      time used: 11.573447942733765\n","minibatch AVG loss: 0.11502187139354646\n","\n","Epoch: 6  val \n","Loss: 0.2174  Acc: 90.7216\n","negative precision: 91.3525  recall: 94.4954\n","negative sensitivity: 94.4954  specificity: 83.9506\n","negative FPR: 16.0494  NPV: 89.4737\n","negative TP: 412.0\n","negative TN: 204.0\n","negative FP: 39.0\n","negative FN: 24.0\n","positive precision: 89.4737  recall: 83.9506\n","positive sensitivity: 83.9506  specificity: 94.4954\n","positive FPR: 5.5046  NPV: 91.3525\n","positive TP: 204.0\n","positive TN: 412.0\n","positive FP: 24.0\n","positive FN: 39.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 50 minibatch: 1      time used: 20.455941915512085\n","minibatch AVG loss: 0.2632917093485594\n","Epoch: 7     train index of 50 minibatch: 2      time used: 19.953860759735107\n","minibatch AVG loss: 0.20378399111330509\n","Epoch: 7     train index of 50 minibatch: 3      time used: 20.328646898269653\n","minibatch AVG loss: 0.21570751022547482\n","Epoch: 7     train index of 50 minibatch: 4      time used: 19.956600189208984\n","minibatch AVG loss: 0.2993284099549055\n","Epoch: 7     train index of 50 minibatch: 5      time used: 19.807509660720825\n","minibatch AVG loss: 0.24505221407860517\n","Epoch: 7     train index of 50 minibatch: 6      time used: 19.799378871917725\n","minibatch AVG loss: 0.2454228739067912\n","\n","Epoch: 7  train \n","Loss: 0.2493  Acc: 89.6463\n","negative precision: 91.8625  recall: 92.0207\n","negative sensitivity: 92.0207  specificity: 85.3909\n","negative FPR: 14.6091  NPV: 85.6553\n","negative TP: 1603.0\n","negative TN: 830.0\n","negative FP: 142.0\n","negative FN: 139.0\n","positive precision: 85.6553  recall: 85.3909\n","positive sensitivity: 85.3909  specificity: 92.0207\n","positive FPR: 7.9793  NPV: 91.8625\n","positive TP: 830.0\n","positive TN: 1603.0\n","positive FP: 139.0\n","positive FN: 142.0\n","\n","\n","Epoch: 7     val index of 50 minibatch: 1      time used: 11.525134563446045\n","minibatch AVG loss: 0.17537090743426234\n","\n","Epoch: 7  val \n","Loss: 0.2117  Acc: 90.1325\n","negative precision: 93.4118  recall: 91.0550\n","negative sensitivity: 91.0550  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 84.6457\n","negative TP: 397.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 39.0\n","positive precision: 84.6457  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 91.0550\n","positive FPR: 8.9450  NPV: 93.4118\n","positive TP: 215.0\n","positive TN: 397.0\n","positive FP: 39.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 50 minibatch: 1      time used: 20.385427474975586\n","minibatch AVG loss: 0.17579284857958555\n","Epoch: 8     train index of 50 minibatch: 2      time used: 19.955939769744873\n","minibatch AVG loss: 0.2280223565362394\n","Epoch: 8     train index of 50 minibatch: 3      time used: 20.067350387573242\n","minibatch AVG loss: 0.21740492822602392\n","Epoch: 8     train index of 50 minibatch: 4      time used: 20.17657709121704\n","minibatch AVG loss: 0.1991689119488001\n","Epoch: 8     train index of 50 minibatch: 5      time used: 19.918851613998413\n","minibatch AVG loss: 0.23710948277264834\n","Epoch: 8     train index of 50 minibatch: 6      time used: 19.844982385635376\n","minibatch AVG loss: 0.1442790722846985\n","\n","Epoch: 8  train \n","Loss: 0.2040  Acc: 91.2307\n","negative precision: 93.0206  recall: 93.3410\n","negative sensitivity: 93.3410  specificity: 87.4486\n","negative FPR: 12.5514  NPV: 87.9917\n","negative TP: 1626.0\n","negative TN: 850.0\n","negative FP: 122.0\n","negative FN: 116.0\n","positive precision: 87.9917  recall: 87.4486\n","positive sensitivity: 87.4486  specificity: 93.3410\n","positive FPR: 6.6590  NPV: 93.0206\n","positive TP: 850.0\n","positive TN: 1626.0\n","positive FP: 116.0\n","positive FN: 122.0\n","\n","\n","Epoch: 8     val index of 50 minibatch: 1      time used: 11.612343549728394\n","minibatch AVG loss: 0.09376596023328602\n","\n","Epoch: 8  val \n","Loss: 0.2256  Acc: 89.6907\n","negative precision: 88.4454  recall: 96.5596\n","negative sensitivity: 96.5596  specificity: 77.3663\n","negative FPR: 22.6337  NPV: 92.6108\n","negative TP: 421.0\n","negative TN: 188.0\n","negative FP: 55.0\n","negative FN: 15.0\n","positive precision: 92.6108  recall: 77.3663\n","positive sensitivity: 77.3663  specificity: 96.5596\n","positive FPR: 3.4404  NPV: 88.4454\n","positive TP: 188.0\n","positive TN: 421.0\n","positive FP: 15.0\n","positive FN: 55.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 50 minibatch: 1      time used: 19.871556758880615\n","minibatch AVG loss: 0.1793533271551132\n","Epoch: 9     train index of 50 minibatch: 2      time used: 19.711718797683716\n","minibatch AVG loss: 0.21978713069111108\n","Epoch: 9     train index of 50 minibatch: 3      time used: 19.925456762313843\n","minibatch AVG loss: 0.23612114761024713\n","Epoch: 9     train index of 50 minibatch: 4      time used: 20.15092134475708\n","minibatch AVG loss: 0.19570494072511793\n","Epoch: 9     train index of 50 minibatch: 5      time used: 20.0037043094635\n","minibatch AVG loss: 0.12792126595973968\n","Epoch: 9     train index of 50 minibatch: 6      time used: 20.115939617156982\n","minibatch AVG loss: 0.24715249098837375\n","\n","Epoch: 9  train \n","Loss: 0.2102  Acc: 91.5623\n","negative precision: 93.1054  recall: 93.8002\n","negative sensitivity: 93.8002  specificity: 87.5514\n","negative FPR: 12.4486  NPV: 88.7383\n","negative TP: 1634.0\n","negative TN: 851.0\n","negative FP: 121.0\n","negative FN: 108.0\n","positive precision: 88.7383  recall: 87.5514\n","positive sensitivity: 87.5514  specificity: 93.8002\n","positive FPR: 6.1998  NPV: 93.1054\n","positive TP: 851.0\n","positive TN: 1634.0\n","positive FP: 108.0\n","positive FN: 121.0\n","\n","\n","Epoch: 9     val index of 50 minibatch: 1      time used: 11.426308870315552\n","minibatch AVG loss: 0.1582109883800149\n","\n","Epoch: 9  val \n","Loss: 0.2038  Acc: 91.3108\n","negative precision: 92.3596  recall: 94.2661\n","negative sensitivity: 94.2661  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 89.3162\n","negative TP: 411.0\n","negative TN: 209.0\n","negative FP: 34.0\n","negative FN: 25.0\n","positive precision: 89.3162  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 94.2661\n","positive FPR: 5.7339  NPV: 92.3596\n","positive TP: 209.0\n","positive TN: 411.0\n","positive FP: 25.0\n","positive FN: 34.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 50 minibatch: 1      time used: 20.587595224380493\n","minibatch AVG loss: 0.1655058146826923\n","Epoch: 10     train index of 50 minibatch: 2      time used: 19.957398891448975\n","minibatch AVG loss: 0.21766148369759322\n","Epoch: 10     train index of 50 minibatch: 3      time used: 19.953810214996338\n","minibatch AVG loss: 0.21607486981898547\n","Epoch: 10     train index of 50 minibatch: 4      time used: 19.98265790939331\n","minibatch AVG loss: 0.2031947661936283\n","Epoch: 10     train index of 50 minibatch: 5      time used: 19.987120866775513\n","minibatch AVG loss: 0.22755986988544463\n","Epoch: 10     train index of 50 minibatch: 6      time used: 20.058269023895264\n","minibatch AVG loss: 0.22540745534002782\n","\n","Epoch: 10  train \n","Loss: 0.2060  Acc: 91.9676\n","negative precision: 93.2463  recall: 94.3169\n","negative sensitivity: 94.3169  specificity: 87.7572\n","negative FPR: 12.2428  NPV: 89.6008\n","negative TP: 1643.0\n","negative TN: 853.0\n","negative FP: 119.0\n","negative FN: 99.0\n","positive precision: 89.6008  recall: 87.7572\n","positive sensitivity: 87.7572  specificity: 94.3169\n","positive FPR: 5.6831  NPV: 93.2463\n","positive TP: 853.0\n","positive TN: 1643.0\n","positive FP: 99.0\n","positive FN: 119.0\n","\n","\n","Epoch: 10     val index of 50 minibatch: 1      time used: 11.444395303726196\n","minibatch AVG loss: 0.10076228402554989\n","\n","Epoch: 10  val \n","Loss: 0.2225  Acc: 90.5744\n","negative precision: 89.2405  recall: 97.0183\n","negative sensitivity: 97.0183  specificity: 79.0123\n","negative FPR: 20.9877  NPV: 93.6585\n","negative TP: 423.0\n","negative TN: 192.0\n","negative FP: 51.0\n","negative FN: 13.0\n","positive precision: 93.6585  recall: 79.0123\n","positive sensitivity: 79.0123  specificity: 97.0183\n","positive FPR: 2.9817  NPV: 89.2405\n","positive TP: 192.0\n","positive TN: 423.0\n","positive FP: 13.0\n","positive FN: 51.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 50 minibatch: 1      time used: 20.562177181243896\n","minibatch AVG loss: 0.1824665582180023\n","Epoch: 11     train index of 50 minibatch: 2      time used: 19.723740816116333\n","minibatch AVG loss: 0.18814342647790908\n","Epoch: 11     train index of 50 minibatch: 3      time used: 20.022124528884888\n","minibatch AVG loss: 0.15224236755631865\n","Epoch: 11     train index of 50 minibatch: 4      time used: 19.77394127845764\n","minibatch AVG loss: 0.1822546765767038\n","Epoch: 11     train index of 50 minibatch: 5      time used: 19.91345739364624\n","minibatch AVG loss: 0.1732990825921297\n","Epoch: 11     train index of 50 minibatch: 6      time used: 20.164374589920044\n","minibatch AVG loss: 0.2231816114112735\n","\n","Epoch: 11  train \n","Loss: 0.1851  Acc: 92.2255\n","negative precision: 93.6680  recall: 94.2595\n","negative sensitivity: 94.2595  specificity: 88.5802\n","negative FPR: 11.4198  NPV: 89.5942\n","negative TP: 1642.0\n","negative TN: 861.0\n","negative FP: 111.0\n","negative FN: 100.0\n","positive precision: 89.5942  recall: 88.5802\n","positive sensitivity: 88.5802  specificity: 94.2595\n","positive FPR: 5.7405  NPV: 93.6680\n","positive TP: 861.0\n","positive TN: 1642.0\n","positive FP: 100.0\n","positive FN: 111.0\n","\n","\n","Epoch: 11     val index of 50 minibatch: 1      time used: 11.63979458808899\n","minibatch AVG loss: 0.15463971174613106\n","\n","Epoch: 11  val \n","Loss: 0.2328  Acc: 90.2798\n","negative precision: 92.0455  recall: 92.8899\n","negative sensitivity: 92.8899  specificity: 85.5967\n","negative FPR: 14.4033  NPV: 87.0293\n","negative TP: 405.0\n","negative TN: 208.0\n","negative FP: 35.0\n","negative FN: 31.0\n","positive precision: 87.0293  recall: 85.5967\n","positive sensitivity: 85.5967  specificity: 92.8899\n","positive FPR: 7.1101  NPV: 92.0455\n","positive TP: 208.0\n","positive TN: 405.0\n","positive FP: 31.0\n","positive FN: 35.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 50 minibatch: 1      time used: 20.28401803970337\n","minibatch AVG loss: 0.19504083503037692\n","Epoch: 12     train index of 50 minibatch: 2      time used: 19.551361799240112\n","minibatch AVG loss: 0.1412616373039782\n","Epoch: 12     train index of 50 minibatch: 3      time used: 20.032501220703125\n","minibatch AVG loss: 0.19730062467977405\n","Epoch: 12     train index of 50 minibatch: 4      time used: 20.366846084594727\n","minibatch AVG loss: 0.2032974429242313\n","Epoch: 12     train index of 50 minibatch: 5      time used: 19.97605013847351\n","minibatch AVG loss: 0.15165498180314899\n","Epoch: 12     train index of 50 minibatch: 6      time used: 20.00903010368347\n","minibatch AVG loss: 0.1967175174690783\n","\n","Epoch: 12  train \n","Loss: 0.1874  Acc: 92.4466\n","negative precision: 93.4918  recall: 94.8335\n","negative sensitivity: 94.8335  specificity: 88.1687\n","negative FPR: 11.8313  NPV: 90.4963\n","negative TP: 1652.0\n","negative TN: 857.0\n","negative FP: 115.0\n","negative FN: 90.0\n","positive precision: 90.4963  recall: 88.1687\n","positive sensitivity: 88.1687  specificity: 94.8335\n","positive FPR: 5.1665  NPV: 93.4918\n","positive TP: 857.0\n","positive TN: 1652.0\n","positive FP: 90.0\n","positive FN: 115.0\n","\n","\n","Epoch: 12     val index of 50 minibatch: 1      time used: 11.698866844177246\n","minibatch AVG loss: 0.08454988772980869\n","\n","Epoch: 12  val \n","Loss: 0.2229  Acc: 89.9853\n","negative precision: 88.1743  recall: 97.4771\n","negative sensitivity: 97.4771  specificity: 76.5432\n","negative FPR: 23.4568  NPV: 94.4162\n","negative TP: 425.0\n","negative TN: 186.0\n","negative FP: 57.0\n","negative FN: 11.0\n","positive precision: 94.4162  recall: 76.5432\n","positive sensitivity: 76.5432  specificity: 97.4771\n","positive FPR: 2.5229  NPV: 88.1743\n","positive TP: 186.0\n","positive TN: 425.0\n","positive FP: 11.0\n","positive FN: 57.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 50 minibatch: 1      time used: 20.843138456344604\n","minibatch AVG loss: 0.15682462096214295\n","Epoch: 13     train index of 50 minibatch: 2      time used: 20.226903915405273\n","minibatch AVG loss: 0.14760395345278085\n","Epoch: 13     train index of 50 minibatch: 3      time used: 20.322436809539795\n","minibatch AVG loss: 0.18022690752521156\n","Epoch: 13     train index of 50 minibatch: 4      time used: 20.69406008720398\n","minibatch AVG loss: 0.19931948225945234\n","Epoch: 13     train index of 50 minibatch: 5      time used: 20.89210820198059\n","minibatch AVG loss: 0.13970538915134967\n","Epoch: 13     train index of 50 minibatch: 6      time used: 20.66496181488037\n","minibatch AVG loss: 0.19486719265580177\n","\n","Epoch: 13  train \n","Loss: 0.1663  Acc: 93.2940\n","negative precision: 94.5205  recall: 95.0631\n","negative sensitivity: 95.0631  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 91.0603\n","negative TP: 1656.0\n","negative TN: 876.0\n","negative FP: 96.0\n","negative FN: 86.0\n","positive precision: 91.0603  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 95.0631\n","positive FPR: 4.9369  NPV: 94.5205\n","positive TP: 876.0\n","positive TN: 1656.0\n","positive FP: 86.0\n","positive FN: 96.0\n","\n","\n","Epoch: 13     val index of 50 minibatch: 1      time used: 11.815815925598145\n","minibatch AVG loss: 0.17735474368731957\n","\n","Epoch: 13  val \n","Loss: 0.1998  Acc: 93.0781\n","negative precision: 94.7126  recall: 94.4954\n","negative sensitivity: 94.4954  specificity: 90.5350\n","negative FPR: 9.4650  NPV: 90.1639\n","negative TP: 412.0\n","negative TN: 220.0\n","negative FP: 23.0\n","negative FN: 24.0\n","positive precision: 90.1639  recall: 90.5350\n","positive sensitivity: 90.5350  specificity: 94.4954\n","positive FPR: 5.5046  NPV: 94.7126\n","positive TP: 220.0\n","positive TN: 412.0\n","positive FP: 24.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 50 minibatch: 1      time used: 20.911190509796143\n","minibatch AVG loss: 0.14755749515723438\n","Epoch: 14     train index of 50 minibatch: 2      time used: 20.09861183166504\n","minibatch AVG loss: 0.166564427241683\n","Epoch: 14     train index of 50 minibatch: 3      time used: 20.190032720565796\n","minibatch AVG loss: 0.122584337759763\n","Epoch: 14     train index of 50 minibatch: 4      time used: 20.213111400604248\n","minibatch AVG loss: 0.2172749883122742\n","Epoch: 14     train index of 50 minibatch: 5      time used: 20.46047830581665\n","minibatch AVG loss: 0.18578628644347192\n","Epoch: 14     train index of 50 minibatch: 6      time used: 20.072814226150513\n","minibatch AVG loss: 0.1871270121075213\n","\n","Epoch: 14  train \n","Loss: 0.1715  Acc: 93.9573\n","negative precision: 95.0857  recall: 95.5224\n","negative sensitivity: 95.5224  specificity: 91.1523\n","negative FPR: 8.8477  NPV: 91.9087\n","negative TP: 1664.0\n","negative TN: 886.0\n","negative FP: 86.0\n","negative FN: 78.0\n","positive precision: 91.9087  recall: 91.1523\n","positive sensitivity: 91.1523  specificity: 95.5224\n","positive FPR: 4.4776  NPV: 95.0857\n","positive TP: 886.0\n","positive TN: 1664.0\n","positive FP: 78.0\n","positive FN: 86.0\n","\n","\n","Epoch: 14     val index of 50 minibatch: 1      time used: 11.849963426589966\n","minibatch AVG loss: 0.089934615441598\n","\n","Epoch: 14  val \n","Loss: 0.2033  Acc: 91.6053\n","negative precision: 91.4661  recall: 95.8716\n","negative sensitivity: 95.8716  specificity: 83.9506\n","negative FPR: 16.0494  NPV: 91.8919\n","negative TP: 418.0\n","negative TN: 204.0\n","negative FP: 39.0\n","negative FN: 18.0\n","positive precision: 91.8919  recall: 83.9506\n","positive sensitivity: 83.9506  specificity: 95.8716\n","positive FPR: 4.1284  NPV: 91.4661\n","positive TP: 204.0\n","positive TN: 418.0\n","positive FP: 18.0\n","positive FN: 39.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 50 minibatch: 1      time used: 21.14290714263916\n","minibatch AVG loss: 0.17331658095121383\n","Epoch: 15     train index of 50 minibatch: 2      time used: 20.782808303833008\n","minibatch AVG loss: 0.1460297823138535\n","Epoch: 15     train index of 50 minibatch: 3      time used: 19.95512294769287\n","minibatch AVG loss: 0.14736009032465516\n","Epoch: 15     train index of 50 minibatch: 4      time used: 20.402717351913452\n","minibatch AVG loss: 0.12979132419452072\n","Epoch: 15     train index of 50 minibatch: 5      time used: 20.303237199783325\n","minibatch AVG loss: 0.19909003667533398\n","Epoch: 15     train index of 50 minibatch: 6      time used: 20.352099895477295\n","minibatch AVG loss: 0.1985413783043623\n","\n","Epoch: 15  train \n","Loss: 0.1702  Acc: 93.3309\n","negative precision: 94.5745  recall: 95.0631\n","negative sensitivity: 95.0631  specificity: 90.2263\n","negative FPR: 9.7737  NPV: 91.0696\n","negative TP: 1656.0\n","negative TN: 877.0\n","negative FP: 95.0\n","negative FN: 86.0\n","positive precision: 91.0696  recall: 90.2263\n","positive sensitivity: 90.2263  specificity: 95.0631\n","positive FPR: 4.9369  NPV: 94.5745\n","positive TP: 877.0\n","positive TN: 1656.0\n","positive FP: 86.0\n","positive FN: 95.0\n","\n","\n","Epoch: 15     val index of 50 minibatch: 1      time used: 11.753267049789429\n","minibatch AVG loss: 0.3010382205108181\n","\n","Epoch: 15  val \n","Loss: 0.2734  Acc: 89.3962\n","negative precision: 95.0495  recall: 88.0734\n","negative sensitivity: 88.0734  specificity: 91.7695\n","negative FPR: 8.2305  NPV: 81.0909\n","negative TP: 384.0\n","negative TN: 223.0\n","negative FP: 20.0\n","negative FN: 52.0\n","positive precision: 81.0909  recall: 91.7695\n","positive sensitivity: 91.7695  specificity: 88.0734\n","positive FPR: 11.9266  NPV: 95.0495\n","positive TP: 223.0\n","positive TN: 384.0\n","positive FP: 52.0\n","positive FN: 20.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 50 minibatch: 1      time used: 20.657910346984863\n","minibatch AVG loss: 0.22096173660829663\n","Epoch: 16     train index of 50 minibatch: 2      time used: 19.857621908187866\n","minibatch AVG loss: 0.12407708560116588\n","Epoch: 16     train index of 50 minibatch: 3      time used: 19.680881023406982\n","minibatch AVG loss: 0.13514230338390917\n","Epoch: 16     train index of 50 minibatch: 4      time used: 19.960127592086792\n","minibatch AVG loss: 0.12904846739023923\n","Epoch: 16     train index of 50 minibatch: 5      time used: 19.953686714172363\n","minibatch AVG loss: 0.16854670017957687\n","Epoch: 16     train index of 50 minibatch: 6      time used: 20.216335773468018\n","minibatch AVG loss: 0.14643130694981665\n","\n","Epoch: 16  train \n","Loss: 0.1646  Acc: 93.4414\n","negative precision: 94.5330  recall: 95.2928\n","negative sensitivity: 95.2928  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 91.4405\n","negative TP: 1660.0\n","negative TN: 876.0\n","negative FP: 96.0\n","negative FN: 82.0\n","positive precision: 91.4405  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 95.2928\n","positive FPR: 4.7072  NPV: 94.5330\n","positive TP: 876.0\n","positive TN: 1660.0\n","positive FP: 82.0\n","positive FN: 96.0\n","\n","\n","Epoch: 16     val index of 50 minibatch: 1      time used: 11.275140285491943\n","minibatch AVG loss: 0.10906652151723392\n","\n","Epoch: 16  val \n","Loss: 0.1870  Acc: 91.8999\n","negative precision: 92.2395  recall: 95.4128\n","negative sensitivity: 95.4128  specificity: 85.5967\n","negative FPR: 14.4033  NPV: 91.2281\n","negative TP: 416.0\n","negative TN: 208.0\n","negative FP: 35.0\n","negative FN: 20.0\n","positive precision: 91.2281  recall: 85.5967\n","positive sensitivity: 85.5967  specificity: 95.4128\n","positive FPR: 4.5872  NPV: 92.2395\n","positive TP: 208.0\n","positive TN: 416.0\n","positive FP: 20.0\n","positive FN: 35.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 50 minibatch: 1      time used: 20.076314210891724\n","minibatch AVG loss: 0.11346871849149466\n","Epoch: 17     train index of 50 minibatch: 2      time used: 19.70048427581787\n","minibatch AVG loss: 0.15699349265545606\n","Epoch: 17     train index of 50 minibatch: 3      time used: 19.493290185928345\n","minibatch AVG loss: 0.12025697564706206\n","Epoch: 17     train index of 50 minibatch: 4      time used: 19.69853162765503\n","minibatch AVG loss: 0.11509965389966964\n","Epoch: 17     train index of 50 minibatch: 5      time used: 19.65930485725403\n","minibatch AVG loss: 0.13542816459201276\n","Epoch: 17     train index of 50 minibatch: 6      time used: 19.86624026298523\n","minibatch AVG loss: 0.1599207951128483\n","\n","Epoch: 17  train \n","Loss: 0.1294  Acc: 95.3574\n","negative precision: 96.3835  recall: 96.3835\n","negative sensitivity: 96.3835  specificity: 93.5185\n","negative FPR: 6.4815  NPV: 93.5185\n","negative TP: 1679.0\n","negative TN: 909.0\n","negative FP: 63.0\n","negative FN: 63.0\n","positive precision: 93.5185  recall: 93.5185\n","positive sensitivity: 93.5185  specificity: 96.3835\n","positive FPR: 3.6165  NPV: 96.3835\n","positive TP: 909.0\n","positive TN: 1679.0\n","positive FP: 63.0\n","positive FN: 63.0\n","\n","\n","Epoch: 17     val index of 50 minibatch: 1      time used: 11.247756958007812\n","minibatch AVG loss: 0.17656348341493866\n","\n","Epoch: 17  val \n","Loss: 0.2572  Acc: 90.7216\n","negative precision: 92.4829  recall: 93.1193\n","negative sensitivity: 93.1193  specificity: 86.4198\n","negative FPR: 13.5802  NPV: 87.5000\n","negative TP: 406.0\n","negative TN: 210.0\n","negative FP: 33.0\n","negative FN: 30.0\n","positive precision: 87.5000  recall: 86.4198\n","positive sensitivity: 86.4198  specificity: 93.1193\n","positive FPR: 6.8807  NPV: 92.4829\n","positive TP: 210.0\n","positive TN: 406.0\n","positive FP: 30.0\n","positive FN: 33.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 50 minibatch: 1      time used: 20.908804416656494\n","minibatch AVG loss: 0.11147568610496819\n","Epoch: 18     train index of 50 minibatch: 2      time used: 20.086660146713257\n","minibatch AVG loss: 0.15595648617949337\n","Epoch: 18     train index of 50 minibatch: 3      time used: 19.60349154472351\n","minibatch AVG loss: 0.196684457892552\n","Epoch: 18     train index of 50 minibatch: 4      time used: 20.05959677696228\n","minibatch AVG loss: 0.16983325311914085\n","Epoch: 18     train index of 50 minibatch: 5      time used: 20.114482879638672\n","minibatch AVG loss: 0.13128710268065333\n","Epoch: 18     train index of 50 minibatch: 6      time used: 20.042036533355713\n","minibatch AVG loss: 0.13962126671336592\n","\n","Epoch: 18  train \n","Loss: 0.1495  Acc: 94.1415\n","negative precision: 95.3062  recall: 95.5798\n","negative sensitivity: 95.5798  specificity: 91.5638\n","negative FPR: 8.4362  NPV: 92.0372\n","negative TP: 1665.0\n","negative TN: 890.0\n","negative FP: 82.0\n","negative FN: 77.0\n","positive precision: 92.0372  recall: 91.5638\n","positive sensitivity: 91.5638  specificity: 95.5798\n","positive FPR: 4.4202  NPV: 95.3062\n","positive TP: 890.0\n","positive TN: 1665.0\n","positive FP: 77.0\n","positive FN: 82.0\n","\n","\n","Epoch: 18     val index of 50 minibatch: 1      time used: 11.2214834690094\n","minibatch AVG loss: 0.20308842255239143\n","\n","Epoch: 18  val \n","Loss: 0.2126  Acc: 92.4890\n","negative precision: 96.1631  recall: 91.9725\n","negative sensitivity: 91.9725  specificity: 93.4156\n","negative FPR: 6.5844  NPV: 86.6412\n","negative TP: 401.0\n","negative TN: 227.0\n","negative FP: 16.0\n","negative FN: 35.0\n","positive precision: 86.6412  recall: 93.4156\n","positive sensitivity: 93.4156  specificity: 91.9725\n","positive FPR: 8.0275  NPV: 96.1631\n","positive TP: 227.0\n","positive TN: 401.0\n","positive FP: 35.0\n","positive FN: 16.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 50 minibatch: 1      time used: 20.241634368896484\n","minibatch AVG loss: 0.1019529352337122\n","Epoch: 19     train index of 50 minibatch: 2      time used: 19.6472384929657\n","minibatch AVG loss: 0.13198552191723137\n","Epoch: 19     train index of 50 minibatch: 3      time used: 20.20089292526245\n","minibatch AVG loss: 0.13971910419873892\n","Epoch: 19     train index of 50 minibatch: 4      time used: 19.783753156661987\n","minibatch AVG loss: 0.1550889527518302\n","Epoch: 19     train index of 50 minibatch: 5      time used: 19.939801931381226\n","minibatch AVG loss: 0.1357551901973784\n","Epoch: 19     train index of 50 minibatch: 6      time used: 19.649242401123047\n","minibatch AVG loss: 0.15474927509203554\n","\n","Epoch: 19  train \n","Loss: 0.1401  Acc: 94.4363\n","negative precision: 95.5352  recall: 95.8094\n","negative sensitivity: 95.8094  specificity: 91.9753\n","negative FPR: 8.0247  NPV: 92.4509\n","negative TP: 1669.0\n","negative TN: 894.0\n","negative FP: 78.0\n","negative FN: 73.0\n","positive precision: 92.4509  recall: 91.9753\n","positive sensitivity: 91.9753  specificity: 95.8094\n","positive FPR: 4.1906  NPV: 95.5352\n","positive TP: 894.0\n","positive TN: 1669.0\n","positive FP: 73.0\n","positive FN: 78.0\n","\n","\n","Epoch: 19     val index of 50 minibatch: 1      time used: 11.311986923217773\n","minibatch AVG loss: 0.19840779224061408\n","\n","Epoch: 19  val \n","Loss: 0.2150  Acc: 92.4890\n","negative precision: 95.0820  recall: 93.1193\n","negative sensitivity: 93.1193  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 88.0952\n","negative TP: 406.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 30.0\n","positive precision: 88.0952  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 93.1193\n","positive FPR: 6.8807  NPV: 95.0820\n","positive TP: 222.0\n","positive TN: 406.0\n","positive FP: 30.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 50 minibatch: 1      time used: 20.629668474197388\n","minibatch AVG loss: 0.10862236930057406\n","Epoch: 20     train index of 50 minibatch: 2      time used: 19.597119331359863\n","minibatch AVG loss: 0.11722069079056383\n","Epoch: 20     train index of 50 minibatch: 3      time used: 19.98064923286438\n","minibatch AVG loss: 0.13791456636041402\n","Epoch: 20     train index of 50 minibatch: 4      time used: 19.656617641448975\n","minibatch AVG loss: 0.10145325697027147\n","Epoch: 20     train index of 50 minibatch: 5      time used: 20.32425355911255\n","minibatch AVG loss: 0.12096839278005063\n","Epoch: 20     train index of 50 minibatch: 6      time used: 20.681796550750732\n","minibatch AVG loss: 0.11971676436252893\n","\n","Epoch: 20  train \n","Loss: 0.1134  Acc: 95.5785\n","negative precision: 96.3959  recall: 96.7279\n","negative sensitivity: 96.7279  specificity: 93.5185\n","negative FPR: 6.4815  NPV: 94.0994\n","negative TP: 1685.0\n","negative TN: 909.0\n","negative FP: 63.0\n","negative FN: 57.0\n","positive precision: 94.0994  recall: 93.5185\n","positive sensitivity: 93.5185  specificity: 96.7279\n","positive FPR: 3.2721  NPV: 96.3959\n","positive TP: 909.0\n","positive TN: 1685.0\n","positive FP: 57.0\n","positive FN: 63.0\n","\n","\n","Epoch: 20     val index of 50 minibatch: 1      time used: 11.546655416488647\n","minibatch AVG loss: 0.1095736420385947\n","\n","Epoch: 20  val \n","Loss: 0.2154  Acc: 92.3417\n","negative precision: 93.2432  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 90.6383\n","negative TP: 414.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 22.0\n","positive precision: 90.6383  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 93.2432\n","positive TP: 213.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 30.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 50 minibatch: 1      time used: 21.09330940246582\n","minibatch AVG loss: 0.13432751467451454\n","Epoch: 21     train index of 50 minibatch: 2      time used: 19.870085954666138\n","minibatch AVG loss: 0.12582356553524732\n","Epoch: 21     train index of 50 minibatch: 3      time used: 20.62498903274536\n","minibatch AVG loss: 0.10482632076367736\n","Epoch: 21     train index of 50 minibatch: 4      time used: 19.742594242095947\n","minibatch AVG loss: 0.0897709166444838\n","Epoch: 21     train index of 50 minibatch: 5      time used: 19.98342537879944\n","minibatch AVG loss: 0.09336043833056465\n","Epoch: 21     train index of 50 minibatch: 6      time used: 19.79408884048462\n","minibatch AVG loss: 0.0960176488943398\n","\n","Epoch: 21  train \n","Loss: 0.1100  Acc: 95.6522\n","negative precision: 96.5063  recall: 96.7279\n","negative sensitivity: 96.7279  specificity: 93.7243\n","negative FPR: 6.2757  NPV: 94.1116\n","negative TP: 1685.0\n","negative TN: 911.0\n","negative FP: 61.0\n","negative FN: 57.0\n","positive precision: 94.1116  recall: 93.7243\n","positive sensitivity: 93.7243  specificity: 96.7279\n","positive FPR: 3.2721  NPV: 96.5063\n","positive TP: 911.0\n","positive TN: 1685.0\n","positive FP: 57.0\n","positive FN: 61.0\n","\n","\n","Epoch: 21     val index of 50 minibatch: 1      time used: 11.11311149597168\n","minibatch AVG loss: 0.11456304471648764\n","\n","Epoch: 21  val \n","Loss: 0.2148  Acc: 92.9308\n","negative precision: 92.7313  recall: 96.5596\n","negative sensitivity: 96.5596  specificity: 86.4198\n","negative FPR: 13.5802  NPV: 93.3333\n","negative TP: 421.0\n","negative TN: 210.0\n","negative FP: 33.0\n","negative FN: 15.0\n","positive precision: 93.3333  recall: 86.4198\n","positive sensitivity: 86.4198  specificity: 96.5596\n","positive FPR: 3.4404  NPV: 92.7313\n","positive TP: 210.0\n","positive TN: 421.0\n","positive FP: 15.0\n","positive FN: 33.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 50 minibatch: 1      time used: 20.267772912979126\n","minibatch AVG loss: 0.07995079217944294\n","Epoch: 22     train index of 50 minibatch: 2      time used: 19.862380504608154\n","minibatch AVG loss: 0.0953703920985572\n","Epoch: 22     train index of 50 minibatch: 3      time used: 19.809638261795044\n","minibatch AVG loss: 0.12821033018175512\n","Epoch: 22     train index of 50 minibatch: 4      time used: 19.083863496780396\n","minibatch AVG loss: 0.1413804228231311\n","Epoch: 22     train index of 50 minibatch: 5      time used: 19.55758261680603\n","minibatch AVG loss: 0.15749937903136016\n","Epoch: 22     train index of 50 minibatch: 6      time used: 19.735657215118408\n","minibatch AVG loss: 0.09895971508696676\n","\n","Epoch: 22  train \n","Loss: 0.1197  Acc: 95.7996\n","negative precision: 96.4082  recall: 97.0723\n","negative sensitivity: 97.0723  specificity: 93.5185\n","negative FPR: 6.4815  NPV: 94.6875\n","negative TP: 1691.0\n","negative TN: 909.0\n","negative FP: 63.0\n","negative FN: 51.0\n","positive precision: 94.6875  recall: 93.5185\n","positive sensitivity: 93.5185  specificity: 97.0723\n","positive FPR: 2.9277  NPV: 96.4082\n","positive TP: 909.0\n","positive TN: 1691.0\n","positive FP: 51.0\n","positive FN: 63.0\n","\n","\n","Epoch: 22     val index of 50 minibatch: 1      time used: 11.18054723739624\n","minibatch AVG loss: 0.15915950734284706\n","\n","Epoch: 22  val \n","Loss: 0.2087  Acc: 91.6053\n","negative precision: 94.1725  recall: 92.6606\n","negative sensitivity: 92.6606  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 87.2000\n","negative TP: 404.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 32.0\n","positive precision: 87.2000  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 92.6606\n","positive FPR: 7.3394  NPV: 94.1725\n","positive TP: 218.0\n","positive TN: 404.0\n","positive FP: 32.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 50 minibatch: 1      time used: 20.202341318130493\n","minibatch AVG loss: 0.09819864981807769\n","Epoch: 23     train index of 50 minibatch: 2      time used: 19.495790243148804\n","minibatch AVG loss: 0.0978211581055075\n","Epoch: 23     train index of 50 minibatch: 3      time used: 19.500306844711304\n","minibatch AVG loss: 0.09947601394262165\n","Epoch: 23     train index of 50 minibatch: 4      time used: 19.40295648574829\n","minibatch AVG loss: 0.10270877186907455\n","Epoch: 23     train index of 50 minibatch: 5      time used: 19.454644203186035\n","minibatch AVG loss: 0.09211683676112443\n","Epoch: 23     train index of 50 minibatch: 6      time used: 19.397167205810547\n","minibatch AVG loss: 0.1219011164130643\n","\n","Epoch: 23  train \n","Loss: 0.1023  Acc: 96.1680\n","negative precision: 96.9610  recall: 97.0723\n","negative sensitivity: 97.0723  specificity: 94.5473\n","negative FPR: 5.4527  NPV: 94.7423\n","negative TP: 1691.0\n","negative TN: 919.0\n","negative FP: 53.0\n","negative FN: 51.0\n","positive precision: 94.7423  recall: 94.5473\n","positive sensitivity: 94.5473  specificity: 97.0723\n","positive FPR: 2.9277  NPV: 96.9610\n","positive TP: 919.0\n","positive TN: 1691.0\n","positive FP: 51.0\n","positive FN: 53.0\n","\n","\n","Epoch: 23     val index of 50 minibatch: 1      time used: 11.084962129592896\n","minibatch AVG loss: 0.11667733927839435\n","\n","Epoch: 23  val \n","Loss: 0.2394  Acc: 91.6053\n","negative precision: 91.8322  recall: 95.4128\n","negative sensitivity: 95.4128  specificity: 84.7737\n","negative FPR: 15.2263  NPV: 91.1504\n","negative TP: 416.0\n","negative TN: 206.0\n","negative FP: 37.0\n","negative FN: 20.0\n","positive precision: 91.1504  recall: 84.7737\n","positive sensitivity: 84.7737  specificity: 95.4128\n","positive FPR: 4.5872  NPV: 91.8322\n","positive TP: 206.0\n","positive TN: 416.0\n","positive FP: 20.0\n","positive FN: 37.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 50 minibatch: 1      time used: 20.281558513641357\n","minibatch AVG loss: 0.1372024664329365\n","Epoch: 24     train index of 50 minibatch: 2      time used: 19.435434818267822\n","minibatch AVG loss: 0.0756985216960311\n","Epoch: 24     train index of 50 minibatch: 3      time used: 19.38210654258728\n","minibatch AVG loss: 0.10437238863669336\n","Epoch: 24     train index of 50 minibatch: 4      time used: 19.81043553352356\n","minibatch AVG loss: 0.10305312361568213\n","Epoch: 24     train index of 50 minibatch: 5      time used: 19.13056969642639\n","minibatch AVG loss: 0.09489992664195597\n","Epoch: 24     train index of 50 minibatch: 6      time used: 19.21402645111084\n","minibatch AVG loss: 0.13169782171957195\n","\n","Epoch: 24  train \n","Loss: 0.1098  Acc: 95.9101\n","negative precision: 96.6266  recall: 97.0149\n","negative sensitivity: 97.0149  specificity: 93.9300\n","negative FPR: 6.0700  NPV: 94.6114\n","negative TP: 1690.0\n","negative TN: 913.0\n","negative FP: 59.0\n","negative FN: 52.0\n","positive precision: 94.6114  recall: 93.9300\n","positive sensitivity: 93.9300  specificity: 97.0149\n","positive FPR: 2.9851  NPV: 96.6266\n","positive TP: 913.0\n","positive TN: 1690.0\n","positive FP: 52.0\n","positive FN: 59.0\n","\n","\n","Epoch: 24     val index of 50 minibatch: 1      time used: 11.007046222686768\n","minibatch AVG loss: 0.08899636630085297\n","\n","Epoch: 24  val \n","Loss: 0.2123  Acc: 92.9308\n","negative precision: 92.5439  recall: 96.7890\n","negative sensitivity: 96.7890  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 93.7220\n","negative TP: 422.0\n","negative TN: 209.0\n","negative FP: 34.0\n","negative FN: 14.0\n","positive precision: 93.7220  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 96.7890\n","positive FPR: 3.2110  NPV: 92.5439\n","positive TP: 209.0\n","positive TN: 422.0\n","positive FP: 14.0\n","positive FN: 34.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 50 minibatch: 1      time used: 19.914825916290283\n","minibatch AVG loss: 0.11305611308198422\n","Epoch: 25     train index of 50 minibatch: 2      time used: 19.110410451889038\n","minibatch AVG loss: 0.1203172202501446\n","Epoch: 25     train index of 50 minibatch: 3      time used: 19.45951199531555\n","minibatch AVG loss: 0.09936204970581457\n","Epoch: 25     train index of 50 minibatch: 4      time used: 19.16080927848816\n","minibatch AVG loss: 0.08057094783522188\n","Epoch: 25     train index of 50 minibatch: 5      time used: 19.260947704315186\n","minibatch AVG loss: 0.1309110236936249\n","Epoch: 25     train index of 50 minibatch: 6      time used: 19.212945461273193\n","minibatch AVG loss: 0.11600496569648384\n","\n","Epoch: 25  train \n","Loss: 0.1066  Acc: 95.6522\n","negative precision: 96.8822  recall: 96.3261\n","negative sensitivity: 96.3261  specificity: 94.4444\n","negative FPR: 5.5556  NPV: 93.4827\n","negative TP: 1678.0\n","negative TN: 918.0\n","negative FP: 54.0\n","negative FN: 64.0\n","positive precision: 93.4827  recall: 94.4444\n","positive sensitivity: 94.4444  specificity: 96.3261\n","positive FPR: 3.6739  NPV: 96.8822\n","positive TP: 918.0\n","positive TN: 1678.0\n","positive FP: 64.0\n","positive FN: 54.0\n","\n","\n","Epoch: 25     val index of 50 minibatch: 1      time used: 11.056121349334717\n","minibatch AVG loss: 0.1363820393482456\n","\n","Epoch: 25  val \n","Loss: 0.2339  Acc: 91.7526\n","negative precision: 92.4107  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 90.4762\n","negative TP: 414.0\n","negative TN: 209.0\n","negative FP: 34.0\n","negative FN: 22.0\n","positive precision: 90.4762  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 92.4107\n","positive TP: 209.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 34.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 50 minibatch: 1      time used: 19.821935415267944\n","minibatch AVG loss: 0.10806488471804186\n","Epoch: 26     train index of 50 minibatch: 2      time used: 19.684808254241943\n","minibatch AVG loss: 0.09517661886289716\n","Epoch: 26     train index of 50 minibatch: 3      time used: 19.103946924209595\n","minibatch AVG loss: 0.09551472111837939\n","Epoch: 26     train index of 50 minibatch: 4      time used: 19.282342672348022\n","minibatch AVG loss: 0.08319202789105475\n","Epoch: 26     train index of 50 minibatch: 5      time used: 19.345962047576904\n","minibatch AVG loss: 0.09580354236997664\n","Epoch: 26     train index of 50 minibatch: 6      time used: 19.313694715499878\n","minibatch AVG loss: 0.13354954509995878\n","\n","Epoch: 26  train \n","Loss: 0.1001  Acc: 96.2417\n","negative precision: 96.8037  recall: 97.3594\n","negative sensitivity: 97.3594  specificity: 94.2387\n","negative FPR: 5.7613  NPV: 95.2183\n","negative TP: 1696.0\n","negative TN: 916.0\n","negative FP: 56.0\n","negative FN: 46.0\n","positive precision: 95.2183  recall: 94.2387\n","positive sensitivity: 94.2387  specificity: 97.3594\n","positive FPR: 2.6406  NPV: 96.8037\n","positive TP: 916.0\n","positive TN: 1696.0\n","positive FP: 46.0\n","positive FN: 56.0\n","\n","\n","Epoch: 26     val index of 50 minibatch: 1      time used: 11.08353328704834\n","minibatch AVG loss: 0.07621872217830969\n","\n","Epoch: 26  val \n","Loss: 0.2693  Acc: 91.1635\n","negative precision: 89.8305  recall: 97.2477\n","negative sensitivity: 97.2477  specificity: 80.2469\n","negative FPR: 19.7531  NPV: 94.2029\n","negative TP: 424.0\n","negative TN: 195.0\n","negative FP: 48.0\n","negative FN: 12.0\n","positive precision: 94.2029  recall: 80.2469\n","positive sensitivity: 80.2469  specificity: 97.2477\n","positive FPR: 2.7523  NPV: 89.8305\n","positive TP: 195.0\n","positive TN: 424.0\n","positive FP: 12.0\n","positive FN: 48.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 50 minibatch: 1      time used: 20.25986099243164\n","minibatch AVG loss: 0.08466795592568815\n","Epoch: 27     train index of 50 minibatch: 2      time used: 19.62540078163147\n","minibatch AVG loss: 0.07692066467832774\n","Epoch: 27     train index of 50 minibatch: 3      time used: 19.265820264816284\n","minibatch AVG loss: 0.09325739065883681\n","Epoch: 27     train index of 50 minibatch: 4      time used: 19.219269037246704\n","minibatch AVG loss: 0.07671183882746846\n","Epoch: 27     train index of 50 minibatch: 5      time used: 19.30255937576294\n","minibatch AVG loss: 0.06495560827432201\n","Epoch: 27     train index of 50 minibatch: 6      time used: 19.582204341888428\n","minibatch AVG loss: 0.08307798027875833\n","\n","Epoch: 27  train \n","Loss: 0.0820  Acc: 96.8312\n","negative precision: 97.4227  recall: 97.6464\n","negative sensitivity: 97.6464  specificity: 95.3704\n","negative FPR: 4.6296  NPV: 95.7645\n","negative TP: 1701.0\n","negative TN: 927.0\n","negative FP: 45.0\n","negative FN: 41.0\n","positive precision: 95.7645  recall: 95.3704\n","positive sensitivity: 95.3704  specificity: 97.6464\n","positive FPR: 2.3536  NPV: 97.4227\n","positive TP: 927.0\n","positive TN: 1701.0\n","positive FP: 41.0\n","positive FN: 45.0\n","\n","\n","Epoch: 27     val index of 50 minibatch: 1      time used: 11.064706087112427\n","minibatch AVG loss: 0.15987016731029144\n","\n","Epoch: 27  val \n","Loss: 0.2568  Acc: 91.0162\n","negative precision: 92.5170  recall: 93.5780\n","negative sensitivity: 93.5780  specificity: 86.4198\n","negative FPR: 13.5802  NPV: 88.2353\n","negative TP: 408.0\n","negative TN: 210.0\n","negative FP: 33.0\n","negative FN: 28.0\n","positive precision: 88.2353  recall: 86.4198\n","positive sensitivity: 86.4198  specificity: 93.5780\n","positive FPR: 6.4220  NPV: 92.5170\n","positive TP: 210.0\n","positive TN: 408.0\n","positive FP: 28.0\n","positive FN: 33.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 50 minibatch: 1      time used: 19.69857954978943\n","minibatch AVG loss: 0.10194739925209433\n","Epoch: 28     train index of 50 minibatch: 2      time used: 19.667267084121704\n","minibatch AVG loss: 0.1075787912774831\n","Epoch: 28     train index of 50 minibatch: 3      time used: 19.329345226287842\n","minibatch AVG loss: 0.07404094832018018\n","Epoch: 28     train index of 50 minibatch: 4      time used: 19.412006616592407\n","minibatch AVG loss: 0.09230612099869177\n","Epoch: 28     train index of 50 minibatch: 5      time used: 19.211370706558228\n","minibatch AVG loss: 0.06057074810378253\n","Epoch: 28     train index of 50 minibatch: 6      time used: 19.41643524169922\n","minibatch AVG loss: 0.06671916967490688\n","\n","Epoch: 28  train \n","Loss: 0.0849  Acc: 96.7944\n","negative precision: 97.4212  recall: 97.5890\n","negative sensitivity: 97.5890  specificity: 95.3704\n","negative FPR: 4.6296  NPV: 95.6656\n","negative TP: 1700.0\n","negative TN: 927.0\n","negative FP: 45.0\n","negative FN: 42.0\n","positive precision: 95.6656  recall: 95.3704\n","positive sensitivity: 95.3704  specificity: 97.5890\n","positive FPR: 2.4110  NPV: 97.4212\n","positive TP: 927.0\n","positive TN: 1700.0\n","positive FP: 42.0\n","positive FN: 45.0\n","\n","\n","Epoch: 28     val index of 50 minibatch: 1      time used: 11.059260129928589\n","minibatch AVG loss: 0.3996615848541842\n","\n","Epoch: 28  val \n","Loss: 0.3187  Acc: 89.1016\n","negative precision: 96.1735  recall: 86.4679\n","negative sensitivity: 86.4679  specificity: 93.8272\n","negative FPR: 6.1728  NPV: 79.4425\n","negative TP: 377.0\n","negative TN: 228.0\n","negative FP: 15.0\n","negative FN: 59.0\n","positive precision: 79.4425  recall: 93.8272\n","positive sensitivity: 93.8272  specificity: 86.4679\n","positive FPR: 13.5321  NPV: 96.1735\n","positive TP: 228.0\n","positive TN: 377.0\n","positive FP: 59.0\n","positive FN: 15.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 50 minibatch: 1      time used: 19.9720242023468\n","minibatch AVG loss: 0.08374093231512234\n","Epoch: 29     train index of 50 minibatch: 2      time used: 19.439975023269653\n","minibatch AVG loss: 0.10925725859357044\n","Epoch: 29     train index of 50 minibatch: 3      time used: 19.39771866798401\n","minibatch AVG loss: 0.06309604559326544\n","Epoch: 29     train index of 50 minibatch: 4      time used: 19.026716947555542\n","minibatch AVG loss: 0.10916928253136575\n","Epoch: 29     train index of 50 minibatch: 5      time used: 19.588539600372314\n","minibatch AVG loss: 0.07097032628487795\n","Epoch: 29     train index of 50 minibatch: 6      time used: 19.066893100738525\n","minibatch AVG loss: 0.08386414354434236\n","\n","Epoch: 29  train \n","Loss: 0.0851  Acc: 96.9786\n","negative precision: 97.8111  recall: 97.4742\n","negative sensitivity: 97.4742  specificity: 96.0905\n","negative FPR: 3.9095  NPV: 95.5010\n","negative TP: 1698.0\n","negative TN: 934.0\n","negative FP: 38.0\n","negative FN: 44.0\n","positive precision: 95.5010  recall: 96.0905\n","positive sensitivity: 96.0905  specificity: 97.4742\n","positive FPR: 2.5258  NPV: 97.8111\n","positive TP: 934.0\n","positive TN: 1698.0\n","positive FP: 44.0\n","positive FN: 38.0\n","\n","\n","Epoch: 29     val index of 50 minibatch: 1      time used: 11.093438148498535\n","minibatch AVG loss: 0.17166393582709133\n","\n","Epoch: 29  val \n","Loss: 0.2421  Acc: 91.3108\n","negative precision: 93.5335  recall: 92.8899\n","negative sensitivity: 92.8899  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 87.3984\n","negative TP: 405.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 31.0\n","positive precision: 87.3984  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 92.8899\n","positive FPR: 7.1101  NPV: 93.5335\n","positive TP: 215.0\n","positive TN: 405.0\n","positive FP: 31.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 50 minibatch: 1      time used: 19.91566228866577\n","minibatch AVG loss: 0.0865636658319272\n","Epoch: 30     train index of 50 minibatch: 2      time used: 19.41467261314392\n","minibatch AVG loss: 0.06572544962633402\n","Epoch: 30     train index of 50 minibatch: 3      time used: 19.291783332824707\n","minibatch AVG loss: 0.07282602179562674\n","Epoch: 30     train index of 50 minibatch: 4      time used: 19.523793935775757\n","minibatch AVG loss: 0.057839317086618394\n","Epoch: 30     train index of 50 minibatch: 5      time used: 18.846977472305298\n","minibatch AVG loss: 0.1029337658546865\n","Epoch: 30     train index of 50 minibatch: 6      time used: 19.26324200630188\n","minibatch AVG loss: 0.06472440616227687\n","\n","Epoch: 30  train \n","Loss: 0.0754  Acc: 97.0523\n","negative precision: 97.5400  recall: 97.8760\n","negative sensitivity: 97.8760  specificity: 95.5761\n","negative FPR: 4.4239  NPV: 96.1698\n","negative TP: 1705.0\n","negative TN: 929.0\n","negative FP: 43.0\n","negative FN: 37.0\n","positive precision: 96.1698  recall: 95.5761\n","positive sensitivity: 95.5761  specificity: 97.8760\n","positive FPR: 2.1240  NPV: 97.5400\n","positive TP: 929.0\n","positive TN: 1705.0\n","positive FP: 37.0\n","positive FN: 43.0\n","\n","\n","Epoch: 30     val index of 50 minibatch: 1      time used: 11.038032531738281\n","minibatch AVG loss: 0.13253384880983504\n","\n","Epoch: 30  val \n","Loss: 0.2698  Acc: 91.1635\n","negative precision: 90.8696  recall: 95.8716\n","negative sensitivity: 95.8716  specificity: 82.7160\n","negative FPR: 17.2840  NPV: 91.7808\n","negative TP: 418.0\n","negative TN: 201.0\n","negative FP: 42.0\n","negative FN: 18.0\n","positive precision: 91.7808  recall: 82.7160\n","positive sensitivity: 82.7160  specificity: 95.8716\n","positive FPR: 4.1284  NPV: 90.8696\n","positive TP: 201.0\n","positive TN: 418.0\n","positive FP: 18.0\n","positive FN: 42.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 50 minibatch: 1      time used: 20.249410152435303\n","minibatch AVG loss: 0.09964371695881709\n","Epoch: 31     train index of 50 minibatch: 2      time used: 19.090571641921997\n","minibatch AVG loss: 0.07470803681761026\n","Epoch: 31     train index of 50 minibatch: 3      time used: 19.389907836914062\n","minibatch AVG loss: 0.061114721184130756\n","Epoch: 31     train index of 50 minibatch: 4      time used: 19.420807123184204\n","minibatch AVG loss: 0.07828069977811537\n","Epoch: 31     train index of 50 minibatch: 5      time used: 19.26025629043579\n","minibatch AVG loss: 0.07956435766536743\n","Epoch: 31     train index of 50 minibatch: 6      time used: 19.390003442764282\n","minibatch AVG loss: 0.09930125993909314\n","\n","Epoch: 31  train \n","Loss: 0.0848  Acc: 96.6839\n","negative precision: 97.3624  recall: 97.4742\n","negative sensitivity: 97.4742  specificity: 95.2675\n","negative FPR: 4.7325  NPV: 95.4639\n","negative TP: 1698.0\n","negative TN: 926.0\n","negative FP: 46.0\n","negative FN: 44.0\n","positive precision: 95.4639  recall: 95.2675\n","positive sensitivity: 95.2675  specificity: 97.4742\n","positive FPR: 2.5258  NPV: 97.3624\n","positive TP: 926.0\n","positive TN: 1698.0\n","positive FP: 44.0\n","positive FN: 46.0\n","\n","\n","Epoch: 31     val index of 50 minibatch: 1      time used: 11.063412189483643\n","minibatch AVG loss: 0.12473634762689471\n","\n","Epoch: 31  val \n","Loss: 0.2832  Acc: 89.6907\n","negative precision: 89.6104  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 80.2469\n","negative FPR: 19.7531  NPV: 89.8618\n","negative TP: 414.0\n","negative TN: 195.0\n","negative FP: 48.0\n","negative FN: 22.0\n","positive precision: 89.8618  recall: 80.2469\n","positive sensitivity: 80.2469  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 89.6104\n","positive TP: 195.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 48.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 50 minibatch: 1      time used: 20.202943325042725\n","minibatch AVG loss: 0.11832441265694797\n","Epoch: 32     train index of 50 minibatch: 2      time used: 19.13269352912903\n","minibatch AVG loss: 0.06791380467126146\n","Epoch: 32     train index of 50 minibatch: 3      time used: 20.146843910217285\n","minibatch AVG loss: 0.03000974440947175\n","Epoch: 32     train index of 50 minibatch: 4      time used: 19.448622703552246\n","minibatch AVG loss: 0.07305476646404713\n","Epoch: 32     train index of 50 minibatch: 5      time used: 19.39618444442749\n","minibatch AVG loss: 0.0634305233345367\n","Epoch: 32     train index of 50 minibatch: 6      time used: 19.604121923446655\n","minibatch AVG loss: 0.07467317852191627\n","\n","Epoch: 32  train \n","Loss: 0.0710  Acc: 97.1997\n","negative precision: 97.9287  recall: 97.7038\n","negative sensitivity: 97.7038  specificity: 96.2963\n","negative FPR: 3.7037  NPV: 95.9016\n","negative TP: 1702.0\n","negative TN: 936.0\n","negative FP: 36.0\n","negative FN: 40.0\n","positive precision: 95.9016  recall: 96.2963\n","positive sensitivity: 96.2963  specificity: 97.7038\n","positive FPR: 2.2962  NPV: 97.9287\n","positive TP: 936.0\n","positive TN: 1702.0\n","positive FP: 40.0\n","positive FN: 36.0\n","\n","\n","Epoch: 32     val index of 50 minibatch: 1      time used: 11.006953001022339\n","minibatch AVG loss: 0.18554205278167502\n","\n","Epoch: 32  val \n","Loss: 0.2495  Acc: 91.4580\n","negative precision: 93.5484  recall: 93.1193\n","negative sensitivity: 93.1193  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 87.7551\n","negative TP: 406.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 30.0\n","positive precision: 87.7551  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 93.1193\n","positive FPR: 6.8807  NPV: 93.5484\n","positive TP: 215.0\n","positive TN: 406.0\n","positive FP: 30.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 50 minibatch: 1      time used: 19.909494876861572\n","minibatch AVG loss: 0.07904342202353291\n","Epoch: 33     train index of 50 minibatch: 2      time used: 19.53926396369934\n","minibatch AVG loss: 0.04948076362721622\n","Epoch: 33     train index of 50 minibatch: 3      time used: 19.14466142654419\n","minibatch AVG loss: 0.06079759230138734\n","Epoch: 33     train index of 50 minibatch: 4      time used: 19.216993808746338\n","minibatch AVG loss: 0.05377488661557436\n","Epoch: 33     train index of 50 minibatch: 5      time used: 19.71438193321228\n","minibatch AVG loss: 0.08794951149495318\n","Epoch: 33     train index of 50 minibatch: 6      time used: 19.1076717376709\n","minibatch AVG loss: 0.06179658031789586\n","\n","Epoch: 33  train \n","Loss: 0.0644  Acc: 97.0523\n","negative precision: 97.9239  recall: 97.4742\n","negative sensitivity: 97.4742  specificity: 96.2963\n","negative FPR: 3.7037  NPV: 95.5102\n","negative TP: 1698.0\n","negative TN: 936.0\n","negative FP: 36.0\n","negative FN: 44.0\n","positive precision: 95.5102  recall: 96.2963\n","positive sensitivity: 96.2963  specificity: 97.4742\n","positive FPR: 2.5258  NPV: 97.9239\n","positive TP: 936.0\n","positive TN: 1698.0\n","positive FP: 44.0\n","positive FN: 36.0\n","\n","\n","Epoch: 33     val index of 50 minibatch: 1      time used: 10.97525143623352\n","minibatch AVG loss: 0.06800470376758312\n","\n","Epoch: 33  val \n","Loss: 0.3455  Acc: 90.7216\n","negative precision: 89.0985  recall: 97.4771\n","negative sensitivity: 97.4771  specificity: 78.6008\n","negative FPR: 21.3992  NPV: 94.5545\n","negative TP: 425.0\n","negative TN: 191.0\n","negative FP: 52.0\n","negative FN: 11.0\n","positive precision: 94.5545  recall: 78.6008\n","positive sensitivity: 78.6008  specificity: 97.4771\n","positive FPR: 2.5229  NPV: 89.0985\n","positive TP: 191.0\n","positive TN: 425.0\n","positive FP: 11.0\n","positive FN: 52.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 50 minibatch: 1      time used: 19.8251793384552\n","minibatch AVG loss: 0.09915214787470177\n","Epoch: 34     train index of 50 minibatch: 2      time used: 19.388432025909424\n","minibatch AVG loss: 0.06311044400092214\n","Epoch: 34     train index of 50 minibatch: 3      time used: 19.271220922470093\n","minibatch AVG loss: 0.059265446092467755\n","Epoch: 34     train index of 50 minibatch: 4      time used: 19.394453048706055\n","minibatch AVG loss: 0.090886152315652\n","Epoch: 34     train index of 50 minibatch: 5      time used: 19.265203714370728\n","minibatch AVG loss: 0.05996999957133085\n","Epoch: 34     train index of 50 minibatch: 6      time used: 19.633655786514282\n","minibatch AVG loss: 0.049498021833132955\n","\n","Epoch: 34  train \n","Loss: 0.0673  Acc: 97.3102\n","negative precision: 97.9873  recall: 97.8186\n","negative sensitivity: 97.8186  specificity: 96.3992\n","negative FPR: 3.6008  NPV: 96.1026\n","negative TP: 1704.0\n","negative TN: 937.0\n","negative FP: 35.0\n","negative FN: 38.0\n","positive precision: 96.1026  recall: 96.3992\n","positive sensitivity: 96.3992  specificity: 97.8186\n","positive FPR: 2.1814  NPV: 97.9873\n","positive TP: 937.0\n","positive TN: 1704.0\n","positive FP: 38.0\n","positive FN: 35.0\n","\n","\n","Epoch: 34     val index of 50 minibatch: 1      time used: 11.021761178970337\n","minibatch AVG loss: 0.07313296245403762\n","\n","Epoch: 34  val \n","Loss: 0.2607  Acc: 92.9308\n","negative precision: 91.8103  recall: 97.7064\n","negative sensitivity: 97.7064  specificity: 84.3621\n","negative FPR: 15.6379  NPV: 95.3488\n","negative TP: 426.0\n","negative TN: 205.0\n","negative FP: 38.0\n","negative FN: 10.0\n","positive precision: 95.3488  recall: 84.3621\n","positive sensitivity: 84.3621  specificity: 97.7064\n","positive FPR: 2.2936  NPV: 91.8103\n","positive TP: 205.0\n","positive TN: 426.0\n","positive FP: 10.0\n","positive FN: 38.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 50 minibatch: 1      time used: 19.66952157020569\n","minibatch AVG loss: 0.04984497638302855\n","Epoch: 35     train index of 50 minibatch: 2      time used: 19.265870809555054\n","minibatch AVG loss: 0.05031807380728424\n","Epoch: 35     train index of 50 minibatch: 3      time used: 19.485544443130493\n","minibatch AVG loss: 0.06396131042391062\n","Epoch: 35     train index of 50 minibatch: 4      time used: 19.309696197509766\n","minibatch AVG loss: 0.038873851470416415\n","Epoch: 35     train index of 50 minibatch: 5      time used: 19.159770011901855\n","minibatch AVG loss: 0.07572149032377638\n","Epoch: 35     train index of 50 minibatch: 6      time used: 19.21361517906189\n","minibatch AVG loss: 0.05233906955923885\n","\n","Epoch: 35  train \n","Loss: 0.0566  Acc: 97.5682\n","negative precision: 98.0505  recall: 98.1630\n","negative sensitivity: 98.1630  specificity: 96.5021\n","negative FPR: 3.4979  NPV: 96.7010\n","negative TP: 1710.0\n","negative TN: 938.0\n","negative FP: 34.0\n","negative FN: 32.0\n","positive precision: 96.7010  recall: 96.5021\n","positive sensitivity: 96.5021  specificity: 98.1630\n","positive FPR: 1.8370  NPV: 98.0505\n","positive TP: 938.0\n","positive TN: 1710.0\n","positive FP: 32.0\n","positive FN: 34.0\n","\n","\n","Epoch: 35     val index of 50 minibatch: 1      time used: 11.024162530899048\n","minibatch AVG loss: 0.2118908425965492\n","\n","Epoch: 35  val \n","Loss: 0.2417  Acc: 92.6362\n","negative precision: 94.8837  recall: 93.5780\n","negative sensitivity: 93.5780  specificity: 90.9465\n","negative FPR: 9.0535  NPV: 88.7550\n","negative TP: 408.0\n","negative TN: 221.0\n","negative FP: 22.0\n","negative FN: 28.0\n","positive precision: 88.7550  recall: 90.9465\n","positive sensitivity: 90.9465  specificity: 93.5780\n","positive FPR: 6.4220  NPV: 94.8837\n","positive TP: 221.0\n","positive TN: 408.0\n","positive FP: 28.0\n","positive FN: 22.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 50 minibatch: 1      time used: 19.908836841583252\n","minibatch AVG loss: 0.037411575767910106\n","Epoch: 36     train index of 50 minibatch: 2      time used: 19.00091290473938\n","minibatch AVG loss: 0.076882654807996\n","Epoch: 36     train index of 50 minibatch: 3      time used: 19.506205558776855\n","minibatch AVG loss: 0.05274665751261637\n","Epoch: 36     train index of 50 minibatch: 4      time used: 19.24874520301819\n","minibatch AVG loss: 0.05821949531324208\n","Epoch: 36     train index of 50 minibatch: 5      time used: 19.18755531311035\n","minibatch AVG loss: 0.042383451935602355\n","Epoch: 36     train index of 50 minibatch: 6      time used: 19.602524042129517\n","minibatch AVG loss: 0.0320477652119007\n","\n","Epoch: 36  train \n","Loss: 0.0525  Acc: 98.0840\n","negative precision: 98.5632  recall: 98.4501\n","negative sensitivity: 98.4501  specificity: 97.4280\n","negative FPR: 2.5720  NPV: 97.2279\n","negative TP: 1715.0\n","negative TN: 947.0\n","negative FP: 25.0\n","negative FN: 27.0\n","positive precision: 97.2279  recall: 97.4280\n","positive sensitivity: 97.4280  specificity: 98.4501\n","positive FPR: 1.5499  NPV: 98.5632\n","positive TP: 947.0\n","positive TN: 1715.0\n","positive FP: 27.0\n","positive FN: 25.0\n","\n","\n","Epoch: 36     val index of 50 minibatch: 1      time used: 11.072227478027344\n","minibatch AVG loss: 0.1489253595167247\n","\n","Epoch: 36  val \n","Loss: 0.2341  Acc: 92.3417\n","negative precision: 93.2432  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 90.6383\n","negative TP: 414.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 22.0\n","positive precision: 90.6383  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 93.2432\n","positive TP: 213.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 30.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 50 minibatch: 1      time used: 19.793344259262085\n","minibatch AVG loss: 0.05549246977141593\n","Epoch: 37     train index of 50 minibatch: 2      time used: 19.51188063621521\n","minibatch AVG loss: 0.10614937857724727\n","Epoch: 37     train index of 50 minibatch: 3      time used: 19.556244134902954\n","minibatch AVG loss: 0.05454124554526061\n","Epoch: 37     train index of 50 minibatch: 4      time used: 19.36294388771057\n","minibatch AVG loss: 0.047587590013281444\n","Epoch: 37     train index of 50 minibatch: 5      time used: 19.511913537979126\n","minibatch AVG loss: 0.07448191354284063\n","Epoch: 37     train index of 50 minibatch: 6      time used: 19.51970100402832\n","minibatch AVG loss: 0.022994412252446635\n","\n","Epoch: 37  train \n","Loss: 0.0622  Acc: 98.1209\n","negative precision: 98.4527  recall: 98.6223\n","negative sensitivity: 98.6223  specificity: 97.2222\n","negative FPR: 2.7778  NPV: 97.5232\n","negative TP: 1718.0\n","negative TN: 945.0\n","negative FP: 27.0\n","negative FN: 24.0\n","positive precision: 97.5232  recall: 97.2222\n","positive sensitivity: 97.2222  specificity: 98.6223\n","positive FPR: 1.3777  NPV: 98.4527\n","positive TP: 945.0\n","positive TN: 1718.0\n","positive FP: 24.0\n","positive FN: 27.0\n","\n","\n","Epoch: 37     val index of 50 minibatch: 1      time used: 11.15578317642212\n","minibatch AVG loss: 0.16191885313164675\n","\n","Epoch: 37  val \n","Loss: 0.2740  Acc: 92.3417\n","negative precision: 92.6667  recall: 95.6422\n","negative sensitivity: 95.6422  specificity: 86.4198\n","negative FPR: 13.5802  NPV: 91.7031\n","negative TP: 417.0\n","negative TN: 210.0\n","negative FP: 33.0\n","negative FN: 19.0\n","positive precision: 91.7031  recall: 86.4198\n","positive sensitivity: 86.4198  specificity: 95.6422\n","positive FPR: 4.3578  NPV: 92.6667\n","positive TP: 210.0\n","positive TN: 417.0\n","positive FP: 19.0\n","positive FN: 33.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 50 minibatch: 1      time used: 20.328595638275146\n","minibatch AVG loss: 0.10731714153429493\n","Epoch: 38     train index of 50 minibatch: 2      time used: 19.40995979309082\n","minibatch AVG loss: 0.06224059203173965\n","Epoch: 38     train index of 50 minibatch: 3      time used: 19.324551582336426\n","minibatch AVG loss: 0.047895611671265215\n","Epoch: 38     train index of 50 minibatch: 4      time used: 19.783092260360718\n","minibatch AVG loss: 0.04405997417634353\n","Epoch: 38     train index of 50 minibatch: 5      time used: 19.212836503982544\n","minibatch AVG loss: 0.04506335692480207\n","Epoch: 38     train index of 50 minibatch: 6      time used: 19.699752807617188\n","minibatch AVG loss: 0.031687977011315524\n","\n","Epoch: 38  train \n","Loss: 0.0554  Acc: 97.7892\n","negative precision: 98.0571  recall: 98.5075\n","negative sensitivity: 98.5075  specificity: 96.5021\n","negative FPR: 3.4979  NPV: 97.3029\n","negative TP: 1716.0\n","negative TN: 938.0\n","negative FP: 34.0\n","negative FN: 26.0\n","positive precision: 97.3029  recall: 96.5021\n","positive sensitivity: 96.5021  specificity: 98.5075\n","positive FPR: 1.4925  NPV: 98.0571\n","positive TP: 938.0\n","positive TN: 1716.0\n","positive FP: 26.0\n","positive FN: 34.0\n","\n","\n","Epoch: 38     val index of 50 minibatch: 1      time used: 11.162585020065308\n","minibatch AVG loss: 0.1851232427620562\n","\n","Epoch: 38  val \n","Loss: 0.2770  Acc: 92.0471\n","negative precision: 93.2127  recall: 94.4954\n","negative sensitivity: 94.4954  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 89.8734\n","negative TP: 412.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 24.0\n","positive precision: 89.8734  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 94.4954\n","positive FPR: 5.5046  NPV: 93.2127\n","positive TP: 213.0\n","positive TN: 412.0\n","positive FP: 24.0\n","positive FN: 30.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 50 minibatch: 1      time used: 20.1208074092865\n","minibatch AVG loss: 0.06106465827673674\n","Epoch: 39     train index of 50 minibatch: 2      time used: 19.82557725906372\n","minibatch AVG loss: 0.06864056709338912\n","Epoch: 39     train index of 50 minibatch: 3      time used: 19.365338802337646\n","minibatch AVG loss: 0.06712093295529485\n","Epoch: 39     train index of 50 minibatch: 4      time used: 20.088743448257446\n","minibatch AVG loss: 0.028242646616417913\n","Epoch: 39     train index of 50 minibatch: 5      time used: 19.262800931930542\n","minibatch AVG loss: 0.0748135041934438\n","Epoch: 39     train index of 50 minibatch: 6      time used: 19.99855875968933\n","minibatch AVG loss: 0.02390930588589981\n","\n","Epoch: 39  train \n","Loss: 0.0534  Acc: 98.0840\n","negative precision: 98.5632  recall: 98.4501\n","negative sensitivity: 98.4501  specificity: 97.4280\n","negative FPR: 2.5720  NPV: 97.2279\n","negative TP: 1715.0\n","negative TN: 947.0\n","negative FP: 25.0\n","negative FN: 27.0\n","positive precision: 97.2279  recall: 97.4280\n","positive sensitivity: 97.4280  specificity: 98.4501\n","positive FPR: 1.5499  NPV: 98.5632\n","positive TP: 947.0\n","positive TN: 1715.0\n","positive FP: 27.0\n","positive FN: 25.0\n","\n","\n","Epoch: 39     val index of 50 minibatch: 1      time used: 11.159475326538086\n","minibatch AVG loss: 0.13033106195682195\n","\n","Epoch: 39  val \n","Loss: 0.3236  Acc: 90.8689\n","negative precision: 90.1288  recall: 96.3303\n","negative sensitivity: 96.3303  specificity: 81.0700\n","negative FPR: 18.9300  NPV: 92.4883\n","negative TP: 420.0\n","negative TN: 197.0\n","negative FP: 46.0\n","negative FN: 16.0\n","positive precision: 92.4883  recall: 81.0700\n","positive sensitivity: 81.0700  specificity: 96.3303\n","positive FPR: 3.6697  NPV: 90.1288\n","positive TP: 197.0\n","positive TN: 420.0\n","positive FP: 16.0\n","positive FN: 46.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 50 minibatch: 1      time used: 20.26787257194519\n","minibatch AVG loss: 0.046123143393779174\n","Epoch: 40     train index of 50 minibatch: 2      time used: 19.68968415260315\n","minibatch AVG loss: 0.06720515107968822\n","Epoch: 40     train index of 50 minibatch: 3      time used: 19.342302322387695\n","minibatch AVG loss: 0.05498050001682714\n","Epoch: 40     train index of 50 minibatch: 4      time used: 19.620468616485596\n","minibatch AVG loss: 0.04534094396745786\n","Epoch: 40     train index of 50 minibatch: 5      time used: 19.645496129989624\n","minibatch AVG loss: 0.04130067466408946\n","Epoch: 40     train index of 50 minibatch: 6      time used: 19.49906873703003\n","minibatch AVG loss: 0.03251597414258867\n","\n","Epoch: 40  train \n","Loss: 0.0479  Acc: 98.0472\n","negative precision: 98.3954  recall: 98.5649\n","negative sensitivity: 98.5649  specificity: 97.1193\n","negative FPR: 2.8807  NPV: 97.4200\n","negative TP: 1717.0\n","negative TN: 944.0\n","negative FP: 28.0\n","negative FN: 25.0\n","positive precision: 97.4200  recall: 97.1193\n","positive sensitivity: 97.1193  specificity: 98.5649\n","positive FPR: 1.4351  NPV: 98.3954\n","positive TP: 944.0\n","positive TN: 1717.0\n","positive FP: 25.0\n","positive FN: 28.0\n","\n","\n","Epoch: 40     val index of 50 minibatch: 1      time used: 11.200522184371948\n","minibatch AVG loss: 0.18135287570839864\n","\n","Epoch: 40  val \n","Loss: 0.2615  Acc: 91.3108\n","negative precision: 92.9385  recall: 93.5780\n","negative sensitivity: 93.5780  specificity: 87.2428\n","negative FPR: 12.7572  NPV: 88.3333\n","negative TP: 408.0\n","negative TN: 212.0\n","negative FP: 31.0\n","negative FN: 28.0\n","positive precision: 88.3333  recall: 87.2428\n","positive sensitivity: 87.2428  specificity: 93.5780\n","positive FPR: 6.4220  NPV: 92.9385\n","positive TP: 212.0\n","positive TN: 408.0\n","positive FP: 28.0\n","positive FN: 31.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 50 minibatch: 1      time used: 20.45539140701294\n","minibatch AVG loss: 0.06841115645540413\n","Epoch: 41     train index of 50 minibatch: 2      time used: 19.7961688041687\n","minibatch AVG loss: 0.058576301652938124\n","Epoch: 41     train index of 50 minibatch: 3      time used: 20.06966781616211\n","minibatch AVG loss: 0.06074301384855062\n","Epoch: 41     train index of 50 minibatch: 4      time used: 19.482988357543945\n","minibatch AVG loss: 0.02909857974620536\n","Epoch: 41     train index of 50 minibatch: 5      time used: 19.7201087474823\n","minibatch AVG loss: 0.06072619171696715\n","Epoch: 41     train index of 50 minibatch: 6      time used: 19.75077748298645\n","minibatch AVG loss: 0.05623298965161666\n","\n","Epoch: 41  train \n","Loss: 0.0533  Acc: 97.9735\n","negative precision: 98.4492  recall: 98.3927\n","negative sensitivity: 98.3927  specificity: 97.2222\n","negative FPR: 2.7778  NPV: 97.1223\n","negative TP: 1714.0\n","negative TN: 945.0\n","negative FP: 27.0\n","negative FN: 28.0\n","positive precision: 97.1223  recall: 97.2222\n","positive sensitivity: 97.2222  specificity: 98.3927\n","positive FPR: 1.6073  NPV: 98.4492\n","positive TP: 945.0\n","positive TN: 1714.0\n","positive FP: 28.0\n","positive FN: 27.0\n","\n","\n","Epoch: 41     val index of 50 minibatch: 1      time used: 11.232420206069946\n","minibatch AVG loss: 0.1317673054957413\n","\n","Epoch: 41  val \n","Loss: 0.2652  Acc: 93.2253\n","negative precision: 93.3333  recall: 96.3303\n","negative sensitivity: 96.3303  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 93.0131\n","negative TP: 420.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 16.0\n","positive precision: 93.0131  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 96.3303\n","positive FPR: 3.6697  NPV: 93.3333\n","positive TP: 213.0\n","positive TN: 420.0\n","positive FP: 16.0\n","positive FN: 30.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 50 minibatch: 1      time used: 20.607458353042603\n","minibatch AVG loss: 0.05273091607319657\n","Epoch: 42     train index of 50 minibatch: 2      time used: 20.007654190063477\n","minibatch AVG loss: 0.038535407128510994\n","Epoch: 42     train index of 50 minibatch: 3      time used: 20.069663763046265\n","minibatch AVG loss: 0.01874613582098391\n","Epoch: 42     train index of 50 minibatch: 4      time used: 19.97263479232788\n","minibatch AVG loss: 0.05450815452612005\n","Epoch: 42     train index of 50 minibatch: 5      time used: 19.290162563323975\n","minibatch AVG loss: 0.025355302907992153\n","Epoch: 42     train index of 50 minibatch: 6      time used: 19.779759645462036\n","minibatch AVG loss: 0.03299527501396369\n","\n","Epoch: 42  train \n","Loss: 0.0351  Acc: 98.8578\n","negative precision: 99.0820  recall: 99.1389\n","negative sensitivity: 99.1389  specificity: 98.3539\n","negative FPR: 1.6461  NPV: 98.4552\n","negative TP: 1727.0\n","negative TN: 956.0\n","negative FP: 16.0\n","negative FN: 15.0\n","positive precision: 98.4552  recall: 98.3539\n","positive sensitivity: 98.3539  specificity: 99.1389\n","positive FPR: 0.8611  NPV: 99.0820\n","positive TP: 956.0\n","positive TN: 1727.0\n","positive FP: 15.0\n","positive FN: 16.0\n","\n","\n","Epoch: 42     val index of 50 minibatch: 1      time used: 11.16050100326538\n","minibatch AVG loss: 0.1698867580098158\n","\n","Epoch: 42  val \n","Loss: 0.2865  Acc: 92.6362\n","negative precision: 93.6652  recall: 94.9541\n","negative sensitivity: 94.9541  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 90.7173\n","negative TP: 414.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 22.0\n","positive precision: 90.7173  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 94.9541\n","positive FPR: 5.0459  NPV: 93.6652\n","positive TP: 215.0\n","positive TN: 414.0\n","positive FP: 22.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 50 minibatch: 1      time used: 20.164783716201782\n","minibatch AVG loss: 0.02784354620438535\n","Epoch: 43     train index of 50 minibatch: 2      time used: 19.9204740524292\n","minibatch AVG loss: 0.03861130818608217\n","Epoch: 43     train index of 50 minibatch: 3      time used: 19.255282163619995\n","minibatch AVG loss: 0.07413679785910063\n","Epoch: 43     train index of 50 minibatch: 4      time used: 19.339760065078735\n","minibatch AVG loss: 0.035988542621489615\n","Epoch: 43     train index of 50 minibatch: 5      time used: 19.46676731109619\n","minibatch AVG loss: 0.04997853320441209\n","Epoch: 43     train index of 50 minibatch: 6      time used: 19.463749647140503\n","minibatch AVG loss: 0.0329311002639588\n","\n","Epoch: 43  train \n","Loss: 0.0415  Acc: 98.4893\n","negative precision: 98.8512  recall: 98.7945\n","negative sensitivity: 98.7945  specificity: 97.9424\n","negative FPR: 2.0576  NPV: 97.8417\n","negative TP: 1721.0\n","negative TN: 952.0\n","negative FP: 20.0\n","negative FN: 21.0\n","positive precision: 97.8417  recall: 97.9424\n","positive sensitivity: 97.9424  specificity: 98.7945\n","positive FPR: 1.2055  NPV: 98.8512\n","positive TP: 952.0\n","positive TN: 1721.0\n","positive FP: 21.0\n","positive FN: 20.0\n","\n","\n","Epoch: 43     val index of 50 minibatch: 1      time used: 11.107706546783447\n","minibatch AVG loss: 0.22239704036786861\n","\n","Epoch: 43  val \n","Loss: 0.2769  Acc: 92.7835\n","negative precision: 94.8956  recall: 93.8073\n","negative sensitivity: 93.8073  specificity: 90.9465\n","negative FPR: 9.0535  NPV: 89.1129\n","negative TP: 409.0\n","negative TN: 221.0\n","negative FP: 22.0\n","negative FN: 27.0\n","positive precision: 89.1129  recall: 90.9465\n","positive sensitivity: 90.9465  specificity: 93.8073\n","positive FPR: 6.1927  NPV: 94.8956\n","positive TP: 221.0\n","positive TN: 409.0\n","positive FP: 27.0\n","positive FN: 22.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 50 minibatch: 1      time used: 20.399016618728638\n","minibatch AVG loss: 0.04800958350067958\n","Epoch: 44     train index of 50 minibatch: 2      time used: 19.634836435317993\n","minibatch AVG loss: 0.05135111165931448\n","Epoch: 44     train index of 50 minibatch: 3      time used: 19.54110550880432\n","minibatch AVG loss: 0.04163285049144179\n","Epoch: 44     train index of 50 minibatch: 4      time used: 19.698014497756958\n","minibatch AVG loss: 0.033814769459422675\n","Epoch: 44     train index of 50 minibatch: 5      time used: 19.214014530181885\n","minibatch AVG loss: 0.072782131730346\n","Epoch: 44     train index of 50 minibatch: 6      time used: 20.017483234405518\n","minibatch AVG loss: 0.03896119500393979\n","\n","Epoch: 44  train \n","Loss: 0.0482  Acc: 98.0472\n","negative precision: 98.6183  recall: 98.3352\n","negative sensitivity: 98.3352  specificity: 97.5309\n","negative FPR: 2.4691  NPV: 97.0317\n","negative TP: 1713.0\n","negative TN: 948.0\n","negative FP: 24.0\n","negative FN: 29.0\n","positive precision: 97.0317  recall: 97.5309\n","positive sensitivity: 97.5309  specificity: 98.3352\n","positive FPR: 1.6648  NPV: 98.6183\n","positive TP: 948.0\n","positive TN: 1713.0\n","positive FP: 29.0\n","positive FN: 24.0\n","\n","\n","Epoch: 44     val index of 50 minibatch: 1      time used: 11.172467708587646\n","minibatch AVG loss: 0.1628485133520735\n","\n","Epoch: 44  val \n","Loss: 0.3078  Acc: 91.4580\n","negative precision: 91.8142  recall: 95.1835\n","negative sensitivity: 95.1835  specificity: 84.7737\n","negative FPR: 15.2263  NPV: 90.7489\n","negative TP: 415.0\n","negative TN: 206.0\n","negative FP: 37.0\n","negative FN: 21.0\n","positive precision: 90.7489  recall: 84.7737\n","positive sensitivity: 84.7737  specificity: 95.1835\n","positive FPR: 4.8165  NPV: 91.8142\n","positive TP: 206.0\n","positive TN: 415.0\n","positive FP: 21.0\n","positive FN: 37.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 50 minibatch: 1      time used: 20.285334825515747\n","minibatch AVG loss: 0.02665534663014114\n","Epoch: 45     train index of 50 minibatch: 2      time used: 19.356503009796143\n","minibatch AVG loss: 0.032293361970223484\n","Epoch: 45     train index of 50 minibatch: 3      time used: 19.78783106803894\n","minibatch AVG loss: 0.02879202759359032\n","Epoch: 45     train index of 50 minibatch: 4      time used: 19.711981534957886\n","minibatch AVG loss: 0.024077064050361516\n","Epoch: 45     train index of 50 minibatch: 5      time used: 19.260730266571045\n","minibatch AVG loss: 0.023691777677740902\n","Epoch: 45     train index of 50 minibatch: 6      time used: 19.709131002426147\n","minibatch AVG loss: 0.045383852598024535\n","\n","Epoch: 45  train \n","Loss: 0.0317  Acc: 98.8578\n","negative precision: 99.0258  recall: 99.1963\n","negative sensitivity: 99.1963  specificity: 98.2510\n","negative FPR: 1.7490  NPV: 98.5552\n","negative TP: 1728.0\n","negative TN: 955.0\n","negative FP: 17.0\n","negative FN: 14.0\n","positive precision: 98.5552  recall: 98.2510\n","positive sensitivity: 98.2510  specificity: 99.1963\n","positive FPR: 0.8037  NPV: 99.0258\n","positive TP: 955.0\n","positive TN: 1728.0\n","positive FP: 14.0\n","positive FN: 17.0\n","\n","\n","Epoch: 45     val index of 50 minibatch: 1      time used: 11.21414041519165\n","minibatch AVG loss: 0.20189753998856758\n","\n","Epoch: 45  val \n","Loss: 0.2866  Acc: 92.0471\n","negative precision: 93.2127  recall: 94.4954\n","negative sensitivity: 94.4954  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 89.8734\n","negative TP: 412.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 24.0\n","positive precision: 89.8734  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 94.4954\n","positive FPR: 5.5046  NPV: 93.2127\n","positive TP: 213.0\n","positive TN: 412.0\n","positive FP: 24.0\n","positive FN: 30.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 50 minibatch: 1      time used: 20.0716769695282\n","minibatch AVG loss: 0.03237101595615968\n","Epoch: 46     train index of 50 minibatch: 2      time used: 19.521839141845703\n","minibatch AVG loss: 0.026463304455392064\n","Epoch: 46     train index of 50 minibatch: 3      time used: 19.56657862663269\n","minibatch AVG loss: 0.030926496901665813\n","Epoch: 46     train index of 50 minibatch: 4      time used: 19.912746906280518\n","minibatch AVG loss: 0.03328246354241855\n","Epoch: 46     train index of 50 minibatch: 5      time used: 19.388861656188965\n","minibatch AVG loss: 0.029990357069764287\n","Epoch: 46     train index of 50 minibatch: 6      time used: 19.620869159698486\n","minibatch AVG loss: 0.039872332249651664\n","\n","Epoch: 46  train \n","Loss: 0.0310  Acc: 98.8578\n","negative precision: 99.1949  recall: 99.0241\n","negative sensitivity: 99.0241  specificity: 98.5597\n","negative FPR: 1.4403  NPV: 98.2564\n","negative TP: 1725.0\n","negative TN: 958.0\n","negative FP: 14.0\n","negative FN: 17.0\n","positive precision: 98.2564  recall: 98.5597\n","positive sensitivity: 98.5597  specificity: 99.0241\n","positive FPR: 0.9759  NPV: 99.1949\n","positive TP: 958.0\n","positive TN: 1725.0\n","positive FP: 17.0\n","positive FN: 14.0\n","\n","\n","Epoch: 46     val index of 50 minibatch: 1      time used: 11.251346826553345\n","minibatch AVG loss: 0.23429047369761974\n","\n","Epoch: 46  val \n","Loss: 0.2955  Acc: 92.1944\n","negative precision: 94.0230  recall: 93.8073\n","negative sensitivity: 93.8073  specificity: 89.3004\n","negative FPR: 10.6996  NPV: 88.9344\n","negative TP: 409.0\n","negative TN: 217.0\n","negative FP: 26.0\n","negative FN: 27.0\n","positive precision: 88.9344  recall: 89.3004\n","positive sensitivity: 89.3004  specificity: 93.8073\n","positive FPR: 6.1927  NPV: 94.0230\n","positive TP: 217.0\n","positive TN: 409.0\n","positive FP: 27.0\n","positive FN: 26.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 50 minibatch: 1      time used: 20.14728617668152\n","minibatch AVG loss: 0.046928748495993204\n","Epoch: 47     train index of 50 minibatch: 2      time used: 19.445164442062378\n","minibatch AVG loss: 0.0380581285856897\n","Epoch: 47     train index of 50 minibatch: 3      time used: 19.77832818031311\n","minibatch AVG loss: 0.0604903652559733\n","Epoch: 47     train index of 50 minibatch: 4      time used: 19.96230149269104\n","minibatch AVG loss: 0.027525876744184642\n","Epoch: 47     train index of 50 minibatch: 5      time used: 19.454659700393677\n","minibatch AVG loss: 0.03489998781966278\n","Epoch: 47     train index of 50 minibatch: 6      time used: 19.506086111068726\n","minibatch AVG loss: 0.036609735373640435\n","\n","Epoch: 47  train \n","Loss: 0.0393  Acc: 98.5999\n","negative precision: 98.9655  recall: 98.8519\n","negative sensitivity: 98.8519  specificity: 98.1481\n","negative FPR: 1.8519  NPV: 97.9466\n","negative TP: 1722.0\n","negative TN: 954.0\n","negative FP: 18.0\n","negative FN: 20.0\n","positive precision: 97.9466  recall: 98.1481\n","positive sensitivity: 98.1481  specificity: 98.8519\n","positive FPR: 1.1481  NPV: 98.9655\n","positive TP: 954.0\n","positive TN: 1722.0\n","positive FP: 20.0\n","positive FN: 18.0\n","\n","\n","Epoch: 47     val index of 50 minibatch: 1      time used: 11.26097846031189\n","minibatch AVG loss: 0.2855494914711744\n","\n","Epoch: 47  val \n","Loss: 0.3016  Acc: 91.8999\n","negative precision: 95.2494  recall: 91.9725\n","negative sensitivity: 91.9725  specificity: 91.7695\n","negative FPR: 8.2305  NPV: 86.4341\n","negative TP: 401.0\n","negative TN: 223.0\n","negative FP: 20.0\n","negative FN: 35.0\n","positive precision: 86.4341  recall: 91.7695\n","positive sensitivity: 91.7695  specificity: 91.9725\n","positive FPR: 8.0275  NPV: 95.2494\n","positive TP: 223.0\n","positive TN: 401.0\n","positive FP: 35.0\n","positive FN: 20.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 50 minibatch: 1      time used: 20.484429836273193\n","minibatch AVG loss: 0.024802291523083112\n","Epoch: 48     train index of 50 minibatch: 2      time used: 19.706974029541016\n","minibatch AVG loss: 0.05659922339837067\n","Epoch: 48     train index of 50 minibatch: 3      time used: 19.73605728149414\n","minibatch AVG loss: 0.04386091270745965\n","Epoch: 48     train index of 50 minibatch: 4      time used: 20.084550619125366\n","minibatch AVG loss: 0.0606748679606244\n","Epoch: 48     train index of 50 minibatch: 5      time used: 19.71207857131958\n","minibatch AVG loss: 0.03679214004892856\n","Epoch: 48     train index of 50 minibatch: 6      time used: 19.682634592056274\n","minibatch AVG loss: 0.06269174598972313\n","\n","Epoch: 48  train \n","Loss: 0.0447  Acc: 98.2682\n","negative precision: 98.6789  recall: 98.6223\n","negative sensitivity: 98.6223  specificity: 97.6337\n","negative FPR: 2.3663  NPV: 97.5334\n","negative TP: 1718.0\n","negative TN: 949.0\n","negative FP: 23.0\n","negative FN: 24.0\n","positive precision: 97.5334  recall: 97.6337\n","positive sensitivity: 97.6337  specificity: 98.6223\n","positive FPR: 1.3777  NPV: 98.6789\n","positive TP: 949.0\n","positive TN: 1718.0\n","positive FP: 24.0\n","positive FN: 23.0\n","\n","\n","Epoch: 48     val index of 50 minibatch: 1      time used: 11.234047889709473\n","minibatch AVG loss: 0.166506833592357\n","\n","Epoch: 48  val \n","Loss: 0.2891  Acc: 92.7835\n","negative precision: 93.6795  recall: 95.1835\n","negative sensitivity: 95.1835  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 91.1017\n","negative TP: 415.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 21.0\n","positive precision: 91.1017  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 95.1835\n","positive FPR: 4.8165  NPV: 93.6795\n","positive TP: 215.0\n","positive TN: 415.0\n","positive FP: 21.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 50 minibatch: 1      time used: 20.057666063308716\n","minibatch AVG loss: 0.029613311921129936\n","Epoch: 49     train index of 50 minibatch: 2      time used: 19.43270206451416\n","minibatch AVG loss: 0.03482235431263689\n","Epoch: 49     train index of 50 minibatch: 3      time used: 19.139057636260986\n","minibatch AVG loss: 0.029393256825278512\n","Epoch: 49     train index of 50 minibatch: 4      time used: 19.83076763153076\n","minibatch AVG loss: 0.027669084135559387\n","Epoch: 49     train index of 50 minibatch: 5      time used: 20.272295713424683\n","minibatch AVG loss: 0.03629147454048507\n","Epoch: 49     train index of 50 minibatch: 6      time used: 19.648627519607544\n","minibatch AVG loss: 0.04270054498687387\n","\n","Epoch: 49  train \n","Loss: 0.0315  Acc: 99.0052\n","negative precision: 99.3099  recall: 99.1389\n","negative sensitivity: 99.1389  specificity: 98.7654\n","negative FPR: 1.2346  NPV: 98.4615\n","negative TP: 1727.0\n","negative TN: 960.0\n","negative FP: 12.0\n","negative FN: 15.0\n","positive precision: 98.4615  recall: 98.7654\n","positive sensitivity: 98.7654  specificity: 99.1389\n","positive FPR: 0.8611  NPV: 99.3099\n","positive TP: 960.0\n","positive TN: 1727.0\n","positive FP: 15.0\n","positive FN: 12.0\n","\n","\n","Epoch: 49     val index of 50 minibatch: 1      time used: 11.148344278335571\n","minibatch AVG loss: 0.15177912042869138\n","\n","Epoch: 49  val \n","Loss: 0.2783  Acc: 92.1944\n","negative precision: 92.8412  recall: 95.1835\n","negative sensitivity: 95.1835  specificity: 86.8313\n","negative FPR: 13.1687  NPV: 90.9483\n","negative TP: 415.0\n","negative TN: 211.0\n","negative FP: 32.0\n","negative FN: 21.0\n","positive precision: 90.9483  recall: 86.8313\n","positive sensitivity: 86.8313  specificity: 95.1835\n","positive FPR: 4.8165  NPV: 92.8412\n","positive TP: 211.0\n","positive TN: 415.0\n","positive FP: 21.0\n","positive FN: 32.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 50 minibatch: 1      time used: 19.80257487297058\n","minibatch AVG loss: 0.015575530232163147\n","Epoch: 50     train index of 50 minibatch: 2      time used: 19.295650959014893\n","minibatch AVG loss: 0.05501225762360264\n","Epoch: 50     train index of 50 minibatch: 3      time used: 19.831581115722656\n","minibatch AVG loss: 0.04153404615353793\n","Epoch: 50     train index of 50 minibatch: 4      time used: 19.46133518218994\n","minibatch AVG loss: 0.05466642759158276\n","Epoch: 50     train index of 50 minibatch: 5      time used: 19.532427310943604\n","minibatch AVG loss: 0.044759648822946474\n","Epoch: 50     train index of 50 minibatch: 6      time used: 19.131134271621704\n","minibatch AVG loss: 0.037421585351694375\n","\n","Epoch: 50  train \n","Loss: 0.0407  Acc: 98.4156\n","negative precision: 98.6262  recall: 98.9093\n","negative sensitivity: 98.9093  specificity: 97.5309\n","negative FPR: 2.4691  NPV: 98.0352\n","negative TP: 1723.0\n","negative TN: 948.0\n","negative FP: 24.0\n","negative FN: 19.0\n","positive precision: 98.0352  recall: 97.5309\n","positive sensitivity: 97.5309  specificity: 98.9093\n","positive FPR: 1.0907  NPV: 98.6262\n","positive TP: 948.0\n","positive TN: 1723.0\n","positive FP: 19.0\n","positive FN: 24.0\n","\n","\n","Epoch: 50     val index of 50 minibatch: 1      time used: 11.16004490852356\n","minibatch AVG loss: 0.14586595683096676\n","\n","Epoch: 50  val \n","Loss: 0.2825  Acc: 92.7835\n","negative precision: 93.2886  recall: 95.6422\n","negative sensitivity: 95.6422  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 91.8103\n","negative TP: 417.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 19.0\n","positive precision: 91.8103  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 95.6422\n","positive FPR: 4.3578  NPV: 93.2886\n","positive TP: 213.0\n","positive TN: 417.0\n","positive FP: 19.0\n","positive FN: 30.0\n","\n","\n","\n","Training complete in 127m 54s\n","Best epoch idx:  41\n","Best epoch train Acc: 97.973471\n","Best epoch val Acc: 93.225331\n","negative precision: 93.3333  recall: 96.3303\n","negative sensitivity: 96.3303  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 93.0131\n","positive precision: 93.0131  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 96.3303\n","positive FPR: 3.6697  NPV: 93.3333\n","model trained by GPU (idx:0) has been saved at  /home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_401_PT_lf25_b8_k3.pth\n","finished\n","\n","============================================================\n","Processing finished !\n","start time: 2021_10_28  12:16:18\n","end time: 2021_10_28  14:24:21\n","source: e3c8fe55b95c\n","\n","Preparing the email with auto log file :\n"," Train__2021_10_28-12_16_18_log \n","as  .rtf\n","processing log catched\n","server log catched\n","发送log邮件成功，title:  [e3c8fe55b95c  LOG] Train__2021_10_28-12_16_18_log\n","如果没有，看看垃圾箱:)\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"ru5EKyaLV712","outputId":"4bfcfb85-08ba-4707-a243-abe3fd9429f8"},"source":["!python Test.py --model_idx Hybrid2_384_401_PT_lf25_b8_k3 --enable_attention_check --dataroot /data/pancreatic-cancer-project/dataset --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/runs"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[0.4001, 0.0788]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : Hybrid2_384_401_PT_lf25_b8_k3\n","*********************************setting*************************************\n","Namespace(att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=None, cls_token_off=False, dataroot='/data/pancreatic-cancer-project/dataset', draw_root='/home/pancreatic-cancer-project/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='Hybrid2_384_401_PT_lf25_b8_k3', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 80 minibatch: 1      time used: 2.651829242706299\n","minibatch AVG loss: 0.09149881607027055\n","Epoch: test     test index of 80 minibatch: 2      time used: 2.521986961364746\n","minibatch AVG loss: 0.0975915787359554\n","Epoch: test     test index of 80 minibatch: 3      time used: 2.5053818225860596\n","minibatch AVG loss: 0.041251781156597646\n","Epoch: test     test index of 80 minibatch: 4      time used: 2.5462379455566406\n","minibatch AVG loss: 0.041576035954358305\n","Epoch: test     test index of 80 minibatch: 5      time used: 2.637718439102173\n","minibatch AVG loss: 0.001239445767714642\n","Epoch: test     test index of 80 minibatch: 6      time used: 2.5217812061309814\n","minibatch AVG loss: 0.02836348726459619\n","Epoch: test     test index of 80 minibatch: 7      time used: 2.539433717727661\n","minibatch AVG loss: 0.10951722943750611\n","Epoch: test     test index of 80 minibatch: 8      time used: 2.5835258960723877\n","minibatch AVG loss: 0.13585593501315998\n","Epoch: test     test index of 80 minibatch: 9      time used: 2.5391335487365723\n","minibatch AVG loss: 0.0799091386076725\n","Epoch: test     test index of 80 minibatch: 10      time used: 2.509127378463745\n","minibatch AVG loss: 0.20482398308267874\n","\n","Epoch:  test \n","Loss: 0.1332  Acc: 96.3400\n","negative precision: 96.2162  recall: 98.1618\n","negative sensitivity: 98.1618  specificity: 93.0693\n","negative FPR: 6.9307  NPV: 96.5753\n","negative TP: 534.0\n","negative TN: 282.0\n","negative FP: 21.0\n","negative FN: 10.0\n","positive precision: 96.5753  recall: 93.0693\n","positive sensitivity: 93.0693  specificity: 98.1618\n","positive FPR: 1.8382  NPV: 96.2162\n","positive TP: 282.0\n","positive TN: 534.0\n","positive FP: 10.0\n","positive FN: 21.0\n","\n","\n","Testing complete in 2m 35s\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"O354gtNeXovQ","outputId":"69b4ee7f-e7bb-494a-c3f0-cc0d149ccc4f"},"source":["!python Train.py --model_idx Hybrid2_384_401_PT_lf25_b8_k4 --lr 0.00001 --lrf 0.25 --enable_notify --enable_tensorboard --Pre_Trained_model_path /home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_PreTrain_000.pth --dataroot /data/pancreatic-cancer-project/dataset/fold_4 --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/runs"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Notify is waiting for reboost\n","*****************LOG_Cache_2021_10_28_14_27*****************\n","start monitoring:)\n","notify started\n","notify_frontend reboosted!\n","log_root_path log\n","mail_user tum9598@163.com\n","default_reciving_list ['tum9598@163.com']\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path='/home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_PreTrain_000.pth', att_module='SimAM', attn_drop_rate=0.0, backbone_PT_off=False, batch_size=8, check_minibatch=None, cls_token_off=False, dataroot='/data/pancreatic-cancer-project/dataset/fold_4', draw_root='/home/pancreatic-cancer-project/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=True, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=-1, intake_epochs=0, lr=1e-05, lrf=0.25, model_idx='Hybrid2_384_401_PT_lf25_b8_k4', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, pos_embedding_off=False)\n","we dont have more GPU idx here, try to use gpu_idx=0\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[ 2.1666e-01, -4.7421e-01,  1.8033e-01,  3.0284e-01, -4.8657e-01,\n","         -6.5892e-01,  6.7286e-01, -9.4735e-01,  1.8332e-03,  1.1280e+00,\n","          6.0691e-01,  4.4678e-01,  1.0305e+00,  2.6081e-01, -8.9324e-01,\n","          9.0739e-01,  3.3736e-01, -8.4321e-01, -5.3484e-01, -2.6153e-01,\n","          1.1813e-01,  5.8210e-01, -9.1074e-02,  5.5711e-02, -5.0008e-01,\n","          5.0046e-01,  2.2023e-01,  3.8575e-01, -3.6419e-01,  1.8775e-01,\n","         -1.0013e+00,  9.7029e-01, -8.9606e-01,  5.8526e-01, -6.0324e-02,\n","          2.8680e-01, -1.7486e-01, -5.7358e-02, -2.3304e-02, -8.9619e-02,\n","         -5.2647e-01,  7.6940e-01,  4.0491e-01, -1.8638e-01,  1.2026e+00,\n","         -2.9995e-01, -3.0298e-01, -5.5280e-01, -3.2249e-01,  5.9502e-01,\n","         -4.3468e-01,  1.0191e+00,  1.4346e-01,  1.5864e-01,  7.4061e-01,\n","         -3.8455e-01, -1.1300e+00,  4.2022e-01, -7.5100e-01, -4.4431e-01,\n","         -3.2544e-01,  4.3934e-01,  2.9867e-01,  1.0853e-01,  4.0149e-01,\n","          4.8915e-01,  6.2100e-02, -7.2858e-01, -8.0314e-02,  6.3522e-02,\n","          9.2666e-01, -4.2381e-01, -3.6368e-01,  1.6887e-02, -5.2490e-01,\n","         -5.2767e-01, -2.1943e-01,  5.2008e-01,  4.3857e-01, -6.1164e-01,\n","         -4.1595e-01,  2.7936e-01,  7.3350e-01,  7.9244e-01, -1.7026e-01,\n","          1.6747e-01, -6.8064e-02, -7.3537e-02, -1.0140e+00,  8.4919e-02,\n","         -4.0062e-01,  1.6448e+00, -9.2639e-01,  2.0900e-01, -1.8306e-01,\n","          5.8141e-01,  3.8690e-01, -6.2016e-01,  4.9578e-01,  1.0685e+00,\n","          8.6109e-02,  1.3977e-01,  6.8784e-01, -8.0958e-01,  2.0807e-01,\n","         -4.6999e-01, -1.7971e-01, -8.4584e-02,  6.8367e-01,  8.3208e-01,\n","          5.2042e-01, -4.3107e-01, -4.5932e-01, -4.8616e-01, -4.6352e-01,\n","         -3.3450e-01,  4.8264e-01, -2.5343e-01,  4.8577e-02, -2.6356e-01,\n","          1.0537e+00, -1.1945e-01, -1.7415e+00, -5.0386e-01, -2.2265e-01,\n","          3.1367e-01, -1.4120e+00, -3.5089e-01, -1.9413e-01,  5.0706e-02,\n","          1.0555e+00,  1.0856e-01,  4.9621e-01, -3.9441e-01,  3.0980e-01,\n","          1.5954e-01, -2.2117e-01,  4.4933e-01, -1.4019e-01,  3.3464e-01,\n","         -8.0265e-01,  7.6930e-01,  3.9676e-01, -2.3813e-01,  5.8820e-01,\n","         -2.5222e-01, -2.2237e-01, -5.7166e-01, -6.9520e-01, -8.6945e-01,\n","         -1.9836e-01, -5.2389e-01, -6.6921e-01, -9.6664e-01, -2.1290e-01,\n","          3.6217e-02,  5.8212e-01,  7.6754e-01,  6.3949e-01, -7.3677e-01,\n","          1.2266e+00, -1.0001e-01, -2.8125e-01, -8.0921e-01,  1.1078e+00,\n","          1.0405e+00, -3.8854e-01,  5.2377e-01,  4.7812e-01, -6.1291e-02,\n","         -6.7650e-01, -9.9664e-01, -7.8526e-01, -2.5582e-01,  8.0009e-01,\n","          1.6076e-01,  1.3886e-01,  5.7681e-01,  3.2688e-01, -1.0707e+00,\n","         -7.5648e-01,  3.7256e-01,  7.4912e-01,  1.5014e-01,  5.6243e-01,\n","          6.6609e-01,  3.8102e-01,  4.9880e-01,  2.9567e-01,  1.2317e+00,\n","          2.2053e-01,  1.0838e-01, -3.2360e-01, -4.1344e-01,  2.6800e-01,\n","          1.6090e-01,  9.9983e-01,  7.1696e-01,  3.0113e-01,  1.4047e-01,\n","         -2.8635e-01, -2.6977e-02,  1.0585e+00, -4.0660e-01, -4.8512e-01,\n","         -5.6495e-01,  4.2269e-01, -4.4172e-01, -2.9341e-01,  8.9416e-02,\n","          5.7455e-01, -1.5858e-01,  1.9142e-01, -8.2919e-01, -1.1784e-01,\n","         -3.8307e-01, -8.3623e-01, -1.1778e+00,  1.0831e+00,  2.3893e-01,\n","          5.4679e-01,  2.3990e-01, -9.2425e-02,  5.3054e-01, -3.4389e-01,\n","         -1.4973e+00, -3.8203e-01, -4.5449e-01, -2.0671e-01, -1.8606e-02,\n","          6.9127e-01,  1.2140e-01, -7.5049e-01,  2.3656e-01, -9.5200e-02,\n","         -4.1982e-01,  4.5942e-01,  3.1451e-01, -4.4832e-01,  3.2117e-01,\n","          1.5423e-03,  2.6317e-01,  8.3795e-01,  6.1409e-01,  4.5812e-01,\n","         -4.3683e-01, -2.7957e-01,  1.1908e-01,  1.0032e-01,  2.6231e-02,\n","          4.7835e-03,  3.9014e-01,  2.5367e-02, -9.4333e-01,  2.7289e-01,\n","          1.3458e+00, -7.0671e-01, -4.3741e-01,  6.2262e-01, -4.7800e-01,\n","          4.2114e-02, -5.2731e-01,  1.4530e-01,  3.4526e-01, -4.0380e-01,\n","          8.0879e-01,  2.0872e-01, -3.1978e-01, -4.1021e-01,  3.0624e-02,\n","         -9.4838e-01,  1.8232e-01,  8.7393e-01, -2.8509e-01,  2.8806e-01,\n","         -1.0527e-01, -5.5985e-01, -2.3851e-01, -6.7235e-01, -6.8656e-01,\n","          6.0549e-01, -4.0970e-03,  8.3409e-01,  1.6456e-01,  1.7790e-02,\n","         -6.0855e-01, -3.1545e-02, -2.7620e-01,  4.7811e-01,  1.0174e+00,\n","          6.7161e-01,  5.8914e-01, -2.6104e-02,  1.1465e+00,  4.7396e-01,\n","          1.7520e-01, -5.3694e-01, -1.0094e+00,  6.0517e-01, -6.2272e-01,\n","         -1.5679e-01, -8.0598e-01, -8.0097e-02,  1.4145e+00, -1.2229e+00,\n","         -8.1610e-03, -4.1985e-01, -8.1593e-01,  6.1630e-01, -6.2003e-01,\n","         -5.1867e-01, -1.3416e-01,  1.1829e-01, -6.4824e-01,  8.1688e-01,\n","          3.5813e-01, -8.2212e-01, -5.4484e-01,  1.0119e-01, -2.3940e-01,\n","          1.0492e+00, -3.2231e-01,  8.8072e-01, -2.0386e-01,  3.4266e-01,\n","         -2.1809e-04, -4.3811e-01, -1.4643e-01, -1.4370e-01,  2.2846e-01,\n","         -4.9339e-01, -3.7553e-02,  8.9154e-01,  1.3907e-01,  9.4544e-02,\n","          2.1967e-01,  1.0154e+00,  4.4208e-01, -4.6395e-01, -9.0063e-01,\n","         -6.6472e-01,  3.4370e-01, -1.0131e+00, -1.3204e+00, -1.0094e+00,\n","         -5.9364e-01, -4.8717e-01,  4.4058e-01,  5.4193e-01,  1.6144e-01,\n","         -7.4380e-01,  1.9032e-01,  2.3118e-02,  2.8254e-01, -3.4857e-01,\n","          1.1796e-01,  4.1222e-01, -1.8240e-01, -2.9825e-01,  1.6421e-01,\n","         -8.3378e-02,  1.9388e-01,  6.3008e-01, -6.3716e-01,  1.5108e+00,\n","          9.1688e-01,  5.8826e-01, -3.2557e-01,  3.7183e-01, -1.6559e+00,\n","         -1.1680e-01, -8.7413e-01, -3.1305e-01,  3.6092e-01,  6.5580e-01,\n","         -8.9679e-01, -5.7921e-01,  1.0326e-01,  1.0422e+00, -5.1449e-01,\n","          9.4280e-01,  4.0336e-01,  2.6656e-01, -3.8148e-01,  1.4276e-01,\n","          1.5177e-02, -9.5266e-01, -5.7478e-01, -7.0650e-01, -6.0620e-01,\n","          1.6522e-01,  7.8339e-01,  2.7598e-02,  6.0522e-01,  6.7714e-02,\n","         -2.0373e-01,  5.2184e-01, -2.0795e-01, -1.4365e-01,  6.2235e-01,\n","         -2.1461e-01,  9.8679e-02,  4.0264e-01,  9.4615e-01, -7.1391e-01,\n","         -5.0820e-02, -5.5782e-01,  8.4015e-01, -2.4695e-01,  2.0569e-01,\n","         -1.0167e+00, -4.0228e-01,  1.1637e+00, -2.4513e-01,  9.5664e-02,\n","          2.8576e-01,  1.1327e+00,  1.8957e-01, -7.1850e-01,  4.4865e-01,\n","          3.5293e-01,  4.0419e-01,  1.1109e+00,  1.3175e+00,  2.4401e-02,\n","          3.7667e-01, -2.5981e-01, -2.6797e-01,  1.5575e+00,  4.9660e-02,\n","          1.1472e-01, -1.1175e-02,  3.6860e-01,  6.4207e-01, -1.0836e-04,\n","         -6.2095e-01,  2.5976e-01,  3.8648e-01,  1.0039e+00,  5.3080e-01,\n","         -9.1269e-01,  1.0460e+00, -3.9773e-01,  4.7867e-01,  3.3357e-01,\n","          1.6247e-01, -8.7713e-03,  7.6417e-01, -1.5434e+00,  3.6742e-01,\n","         -1.7368e-01, -1.3163e+00,  1.3577e+00, -1.0784e-01, -1.1486e-01,\n","          1.2644e+00, -3.4705e-01,  2.6563e-01,  2.8580e-01, -2.3911e-01,\n","         -5.8467e-01, -4.9897e-01,  2.1585e-01,  1.4748e+00, -4.4899e-01,\n","          8.8774e-01, -1.6235e-01, -2.7376e-01, -7.1224e-01, -1.3764e-01,\n","          3.6147e-01,  6.7793e-01,  6.9520e-01,  2.7143e-01,  5.9280e-01,\n","          5.4819e-01,  4.9856e-01,  1.2604e+00,  2.9709e-01,  2.6040e-01,\n","         -5.8097e-01,  1.5439e-01,  8.0847e-01, -3.0217e-01,  6.4507e-01,\n","          2.2922e-02,  2.3991e-01,  1.2384e+00, -2.2171e-01, -7.0928e-03,\n","          1.9838e-01,  8.3678e-01, -8.5981e-01, -2.8568e-01,  1.9095e-01,\n","         -5.9930e-01,  3.4530e-01,  1.7907e-01, -5.8533e-01, -3.9108e-01,\n","          1.3534e-01, -3.9534e-01,  2.9089e-01,  1.1026e-01,  2.2106e-01,\n","         -8.9309e-02, -3.6811e-01, -2.6436e-01, -4.2888e-01, -1.5628e-01,\n","          3.5117e-01,  5.9574e-01,  1.6612e-01, -3.4786e-01, -2.6749e-01,\n","         -8.0357e-02,  9.3936e-01, -1.1385e+00,  6.2440e-01,  9.5759e-01,\n","         -4.1871e-01, -3.5787e-01, -3.8892e-01,  4.0981e-01, -3.9806e-01,\n","         -1.7236e-01,  2.1272e-01,  3.7206e-01,  7.2732e-01, -4.1594e-01,\n","          4.6727e-01, -8.8528e-01, -9.8807e-01, -1.5185e-01,  4.2987e-01,\n","         -1.7785e-01, -5.0763e-01, -8.4378e-01,  6.2516e-01,  4.7258e-01,\n","          7.2423e-01,  8.7806e-01,  4.1242e-01, -1.4148e-01, -5.0299e-01,\n","          7.8564e-01,  7.9717e-02, -6.8691e-02, -2.9585e-01, -3.4100e-01,\n","          5.4962e-01,  6.2462e-02, -1.0496e+00,  3.7820e-01,  9.5406e-01,\n","         -8.6697e-01,  3.3542e-01,  1.3459e-01,  1.1273e-01, -6.4730e-01,\n","         -3.3621e-01,  2.6752e-01,  2.4378e-01, -2.2441e-01,  2.6785e-01,\n","         -5.9391e-01, -4.1546e-01, -7.9487e-01, -2.9756e-01,  5.7530e-01,\n","          7.3612e-01, -1.3985e+00,  1.2317e+00,  7.2213e-01, -5.8227e-01,\n","         -1.0673e-01,  5.7164e-01,  1.5425e-01,  1.0895e+00,  1.2320e+00,\n","         -2.9984e-01, -8.0997e-01, -8.0534e-01,  2.7615e-01, -1.0259e-01,\n","         -2.0853e-01,  7.6011e-01, -2.0839e-01, -1.7049e-01, -8.2152e-02,\n","         -7.6952e-01,  5.5893e-01, -4.5167e-02,  2.1071e-01, -1.6695e-01,\n","         -9.4379e-01,  7.0505e-01, -1.0129e+00, -1.4160e+00, -9.1469e-01,\n","          6.5794e-02,  5.9263e-02,  4.3184e-01,  7.7075e-01,  1.1557e+00,\n","         -1.5775e-01, -6.4064e-01, -6.5827e-01, -8.9281e-01,  1.2247e+00,\n","         -7.1033e-02,  1.5717e-01,  2.5382e-01, -5.3365e-01, -4.3624e-01,\n","          8.6912e-02, -2.6298e-01,  1.1626e-01,  8.7539e-01, -1.9012e-01,\n","         -6.6729e-01, -2.3464e-01,  8.6478e-01,  7.2786e-01,  3.3397e-01,\n","         -1.6017e-01, -5.0254e-01, -7.3996e-02, -3.7829e-01, -1.4741e+00,\n","         -8.3302e-01,  3.7283e-01,  2.1826e-01,  2.5692e-02, -6.5851e-01,\n","         -2.9597e-01, -3.3820e-01,  1.3639e+00, -7.7488e-01,  5.1539e-01,\n","         -5.7388e-01, -7.8878e-02,  1.4294e-02, -1.1069e+00, -3.7966e-01,\n","         -8.9033e-01, -1.2349e+00,  8.7038e-01, -9.4274e-01,  7.7459e-01,\n","          2.9489e-03, -5.5035e-01, -4.9410e-01,  1.6765e-01, -8.5204e-01,\n","         -4.2691e-01, -1.8325e-01,  1.5029e+00,  5.1469e-01,  5.7784e-01,\n","         -6.3793e-01, -6.1114e-01, -4.0964e-02, -8.2097e-02, -1.5212e-01,\n","         -1.9229e-01,  3.4257e-01,  3.9545e-02, -9.6416e-02, -1.1933e-02,\n","         -9.0584e-01,  8.6432e-01, -3.7954e-01, -1.8582e-01,  5.3733e-01,\n","         -1.2165e-01,  2.3117e-01,  4.4549e-01,  9.0628e-02, -3.9202e-01,\n","          5.9542e-01, -6.2026e-01,  1.7630e-01, -2.6233e-01, -3.4569e-01,\n","          4.4749e-01, -1.3701e-01,  5.9270e-02, -8.8871e-01, -7.8990e-01,\n","         -8.5382e-01, -2.1154e-01, -1.2771e+00, -9.5926e-03,  8.8370e-01,\n","          7.4744e-01,  6.9917e-01,  1.4780e-01, -2.1493e-01,  3.7231e-01,\n","          9.2370e-02,  1.0832e+00,  3.9699e-01,  1.0125e-01,  7.1224e-01,\n","          6.8133e-01, -8.9262e-01, -1.1712e+00,  2.6976e-01,  5.7062e-01,\n","          4.7347e-01, -9.0269e-01, -7.5984e-02,  1.9798e-02,  4.9426e-01,\n","         -6.8980e-01,  6.2834e-01,  3.1884e-01,  2.1181e-01,  2.9812e-02,\n","         -1.4362e-01,  6.0778e-01,  9.0836e-01,  2.4475e-01,  2.1145e-01,\n","         -3.1287e-01, -1.2203e+00, -2.6419e-01, -4.4693e-01, -4.4690e-02,\n","          6.8615e-01,  4.1714e-01,  5.6715e-01,  1.3130e-02,  4.7644e-01,\n","         -1.9041e-01, -2.4661e-01,  3.8793e-01, -1.3892e-01, -5.6922e-01,\n","         -3.8136e-01,  7.2892e-01, -6.4470e-01, -5.5313e-01,  6.1247e-01,\n","         -1.0014e-01,  4.0849e-01, -1.9521e-01, -5.9512e-01, -6.4988e-02,\n","         -2.7915e-01,  5.3021e-01, -1.6933e-01, -4.2548e-01,  2.4398e-01,\n","         -2.7639e-01,  5.9434e-01,  1.4690e+00,  4.8321e-01,  1.6484e-01,\n","          6.0448e-02, -3.8277e-02,  1.6056e-01,  7.0794e-01, -2.1264e-01,\n","          2.2819e-01,  6.3278e-01,  1.9960e-02, -1.7677e-01,  1.8472e-01,\n","         -3.5790e-01, -2.3733e-01,  1.1483e-02, -9.6668e-01, -5.1292e-01,\n","          1.6635e-01,  1.5496e-01,  1.5968e-01, -6.0187e-01,  7.4434e-01,\n","          2.1636e-01, -1.9631e-02, -1.2121e+00, -1.9568e-01,  4.4568e-01,\n","         -5.8059e-01,  5.7306e-01, -3.5325e-01,  1.2262e+00,  8.5117e-01,\n","         -1.2517e+00,  1.5711e-01, -4.8338e-01, -8.9890e-01, -5.7489e-01,\n","          6.4357e-01, -7.7923e-01,  3.3649e-01,  1.3424e-01, -1.1829e-01,\n","         -2.0373e-01, -2.7749e-01, -1.3068e+00, -5.0447e-01, -4.9479e-01,\n","         -6.8277e-01,  5.1541e-01,  9.5475e-01, -1.2515e-01,  3.1012e-01,\n","         -2.8129e-01,  1.7821e+00,  8.9728e-01, -3.3743e-01,  2.3577e-01,\n","         -1.7557e-01, -1.1398e+00,  9.9451e-01, -9.4415e-01, -6.0988e-01,\n","          1.3445e-01, -3.4160e-01,  5.0410e-01, -3.7131e-01, -1.6956e-01,\n","          3.4758e-01, -4.7118e-01, -4.7098e-01, -2.7183e-01,  8.8055e-01,\n","          1.4070e-01,  2.8334e-01, -2.1244e-01, -8.2920e-02,  6.8698e-01,\n","         -1.3666e+00, -8.1465e-01,  3.3053e-01,  2.8022e-02,  1.4109e-01,\n","         -7.3691e-01,  3.9807e-01,  9.1929e-02, -5.7754e-01, -3.9033e-02,\n","          8.0497e-02, -1.2178e-01, -2.4387e-01,  4.7647e-01, -1.0630e-01,\n","         -1.0826e-01, -2.1110e-03,  3.7709e-01, -1.4875e-01, -1.1374e+00,\n","         -7.6128e-01, -3.7458e-02, -1.8034e-01, -3.6584e-01,  2.2185e-01,\n","         -4.3772e-01, -7.1709e-01,  5.8107e-01,  1.8911e-02,  2.8151e-01,\n","         -5.4206e-01,  8.0032e-01,  9.6944e-01, -2.8757e-01, -1.7112e-01,\n","         -6.1564e-01,  6.8253e-01,  1.6584e-01,  7.0866e-01, -6.5146e-01,\n","         -8.7727e-01,  1.8078e-01,  5.9838e-01,  7.1257e-01,  4.9618e-01,\n","          3.7922e-01,  9.9859e-01,  6.3601e-02,  1.6859e-01,  3.9038e-01,\n","          3.1408e-01, -5.3799e-01,  5.2695e-01, -7.0191e-01, -2.1992e-01,\n","         -1.0359e+00, -6.0567e-01,  2.2677e-01,  1.7703e-01, -1.1606e+00,\n","          2.3550e-01,  5.5554e-01,  1.9281e+00,  1.9194e-01, -8.5557e-01,\n","          4.5519e-02,  4.3140e-01, -1.1850e+00,  2.7465e-01, -3.5207e-01,\n","         -9.3445e-01, -2.0982e-01,  9.0532e-01, -1.1775e+00,  9.8909e-01,\n","         -7.2240e-01,  5.4872e-03,  6.5173e-01,  9.2605e-01,  3.5818e-01,\n","         -7.0264e-02, -5.3810e-01,  6.0329e-01,  7.2034e-02,  4.8261e-01,\n","         -7.4249e-02, -3.4379e-01, -8.3596e-01, -6.9483e-01, -1.6042e-01,\n","         -3.2902e-01, -2.7382e-01, -1.1209e+00, -3.7440e-01, -1.3012e+00,\n","         -1.0944e-02,  6.2558e-01, -2.1302e-01, -1.5804e-01,  1.0750e+00,\n","          1.9843e-01,  1.1140e+00, -1.3254e-01, -2.3597e-01,  6.4282e-01,\n","         -1.4200e-01,  6.1646e-01,  6.9602e-01,  1.4218e-01, -6.0943e-01,\n","         -2.3569e-01,  2.2932e-01,  2.0487e-01, -1.4491e+00, -1.1249e-01,\n","         -8.1519e-01,  2.7957e-01,  2.0120e-01,  8.3839e-01, -9.2751e-01,\n","          4.0007e-01,  1.0488e-02, -5.1090e-01, -4.0092e-02,  4.4054e-02,\n","         -8.8771e-03,  4.2877e-01, -6.0787e-02, -3.7034e-01, -4.1881e-01,\n","          6.2871e-01, -1.8778e-01, -4.2418e-01,  1.6102e-01, -9.5770e-02,\n","         -2.3623e-01,  4.4124e-01, -5.5353e-01, -2.9374e-01, -1.1476e-01,\n","         -2.6253e-01, -4.5752e-01,  9.6869e-01, -4.6147e-04, -5.1060e-01,\n","         -9.5821e-01,  1.0444e+00,  1.0781e+00,  8.4808e-01, -3.7346e-01,\n","          2.9457e-01,  4.7508e-02,  4.4786e-01,  1.0769e+00, -1.7285e-02,\n","         -4.1817e-01,  1.7504e-01, -5.0107e-01, -4.1750e-01, -7.8469e-02,\n","         -6.2529e-02,  7.1313e-01,  3.7026e-01, -5.6427e-01,  9.2629e-03]],\n","       grad_fn=<AddmmBackward>)\n","model is ready now!\n","pretrain model loaded\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 192, 192]           9,408\n","       BatchNorm2d-2         [-1, 64, 192, 192]             128\n","              ReLU-3         [-1, 64, 192, 192]               0\n","         MaxPool2d-4           [-1, 64, 96, 96]               0\n","            Conv2d-5           [-1, 64, 96, 96]           4,096\n","       BatchNorm2d-6           [-1, 64, 96, 96]             128\n","              ReLU-7           [-1, 64, 96, 96]               0\n","            Conv2d-8           [-1, 64, 96, 96]          36,864\n","       BatchNorm2d-9           [-1, 64, 96, 96]             128\n","             ReLU-10           [-1, 64, 96, 96]               0\n","           Conv2d-11          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-12          [-1, 256, 96, 96]             512\n","             ReLU-13          [-1, 256, 96, 96]               0\n","           Conv2d-14          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-15          [-1, 256, 96, 96]             512\n","             ReLU-16          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-17          [-1, 256, 96, 96]               0\n","           Conv2d-18           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-19           [-1, 64, 96, 96]             128\n","             ReLU-20           [-1, 64, 96, 96]               0\n","           Conv2d-21           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-22           [-1, 64, 96, 96]             128\n","             ReLU-23           [-1, 64, 96, 96]               0\n","           Conv2d-24          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-25          [-1, 256, 96, 96]             512\n","             ReLU-26          [-1, 256, 96, 96]               0\n","             ReLU-27          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-28          [-1, 256, 96, 96]               0\n","           Conv2d-29           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-30           [-1, 64, 96, 96]             128\n","             ReLU-31           [-1, 64, 96, 96]               0\n","           Conv2d-32           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-33           [-1, 64, 96, 96]             128\n","             ReLU-34           [-1, 64, 96, 96]               0\n","           Conv2d-35          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-36          [-1, 256, 96, 96]             512\n","             ReLU-37          [-1, 256, 96, 96]               0\n","             ReLU-38          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-39          [-1, 256, 96, 96]               0\n","           Conv2d-40          [-1, 128, 48, 48]          32,768\n","      BatchNorm2d-41          [-1, 128, 48, 48]             256\n","             ReLU-42          [-1, 128, 48, 48]               0\n","           Conv2d-43          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-44          [-1, 128, 48, 48]             256\n","             ReLU-45          [-1, 128, 48, 48]               0\n","           Conv2d-46          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-47          [-1, 512, 48, 48]           1,024\n","             ReLU-48          [-1, 512, 48, 48]               0\n","           Conv2d-49          [-1, 512, 48, 48]         131,072\n","      BatchNorm2d-50          [-1, 512, 48, 48]           1,024\n","             ReLU-51          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-52          [-1, 512, 48, 48]               0\n","           Conv2d-53          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-54          [-1, 128, 48, 48]             256\n","             ReLU-55          [-1, 128, 48, 48]               0\n","           Conv2d-56          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-57          [-1, 128, 48, 48]             256\n","             ReLU-58          [-1, 128, 48, 48]               0\n","           Conv2d-59          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-60          [-1, 512, 48, 48]           1,024\n","             ReLU-61          [-1, 512, 48, 48]               0\n","             ReLU-62          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-63          [-1, 512, 48, 48]               0\n","           Conv2d-64          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-65          [-1, 128, 48, 48]             256\n","             ReLU-66          [-1, 128, 48, 48]               0\n","           Conv2d-67          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-68          [-1, 128, 48, 48]             256\n","             ReLU-69          [-1, 128, 48, 48]               0\n","           Conv2d-70          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-71          [-1, 512, 48, 48]           1,024\n","             ReLU-72          [-1, 512, 48, 48]               0\n","             ReLU-73          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-74          [-1, 512, 48, 48]               0\n","           Conv2d-75          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-76          [-1, 128, 48, 48]             256\n","             ReLU-77          [-1, 128, 48, 48]               0\n","           Conv2d-78          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-79          [-1, 128, 48, 48]             256\n","             ReLU-80          [-1, 128, 48, 48]               0\n","           Conv2d-81          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-82          [-1, 512, 48, 48]           1,024\n","             ReLU-83          [-1, 512, 48, 48]               0\n","             ReLU-84          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-85          [-1, 512, 48, 48]               0\n","           Conv2d-86          [-1, 256, 24, 24]         131,072\n","      BatchNorm2d-87          [-1, 256, 24, 24]             512\n","             ReLU-88          [-1, 256, 24, 24]               0\n","           Conv2d-89          [-1, 256, 24, 24]         589,824\n","      BatchNorm2d-90          [-1, 256, 24, 24]             512\n","             ReLU-91          [-1, 256, 24, 24]               0\n","           Conv2d-92         [-1, 1024, 24, 24]         262,144\n","      BatchNorm2d-93         [-1, 1024, 24, 24]           2,048\n","             ReLU-94         [-1, 1024, 24, 24]               0\n","           Conv2d-95         [-1, 1024, 24, 24]         524,288\n","      BatchNorm2d-96         [-1, 1024, 24, 24]           2,048\n","             ReLU-97         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-98         [-1, 1024, 24, 24]               0\n","           Conv2d-99          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-100          [-1, 256, 24, 24]             512\n","            ReLU-101          [-1, 256, 24, 24]               0\n","          Conv2d-102          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-103          [-1, 256, 24, 24]             512\n","            ReLU-104          [-1, 256, 24, 24]               0\n","          Conv2d-105         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-106         [-1, 1024, 24, 24]           2,048\n","            ReLU-107         [-1, 1024, 24, 24]               0\n","            ReLU-108         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-109         [-1, 1024, 24, 24]               0\n","          Conv2d-110          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-111          [-1, 256, 24, 24]             512\n","            ReLU-112          [-1, 256, 24, 24]               0\n","          Conv2d-113          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-114          [-1, 256, 24, 24]             512\n","            ReLU-115          [-1, 256, 24, 24]               0\n","          Conv2d-116         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-117         [-1, 1024, 24, 24]           2,048\n","            ReLU-118         [-1, 1024, 24, 24]               0\n","            ReLU-119         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-120         [-1, 1024, 24, 24]               0\n","          Conv2d-121          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-122          [-1, 256, 24, 24]             512\n","            ReLU-123          [-1, 256, 24, 24]               0\n","          Conv2d-124          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-125          [-1, 256, 24, 24]             512\n","            ReLU-126          [-1, 256, 24, 24]               0\n","          Conv2d-127         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-128         [-1, 1024, 24, 24]           2,048\n","            ReLU-129         [-1, 1024, 24, 24]               0\n","            ReLU-130         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-131         [-1, 1024, 24, 24]               0\n","          Conv2d-132          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-133          [-1, 256, 24, 24]             512\n","            ReLU-134          [-1, 256, 24, 24]               0\n","          Conv2d-135          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-136          [-1, 256, 24, 24]             512\n","            ReLU-137          [-1, 256, 24, 24]               0\n","          Conv2d-138         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-139         [-1, 1024, 24, 24]           2,048\n","            ReLU-140         [-1, 1024, 24, 24]               0\n","            ReLU-141         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-142         [-1, 1024, 24, 24]               0\n","          Conv2d-143          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-144          [-1, 256, 24, 24]             512\n","            ReLU-145          [-1, 256, 24, 24]               0\n","          Conv2d-146          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-147          [-1, 256, 24, 24]             512\n","            ReLU-148          [-1, 256, 24, 24]               0\n","          Conv2d-149         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-150         [-1, 1024, 24, 24]           2,048\n","            ReLU-151         [-1, 1024, 24, 24]               0\n","            ReLU-152         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-153         [-1, 1024, 24, 24]               0\n","          Conv2d-154          [-1, 512, 12, 12]         524,288\n","     BatchNorm2d-155          [-1, 512, 12, 12]           1,024\n","            ReLU-156          [-1, 512, 12, 12]               0\n","          Conv2d-157          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-158          [-1, 512, 12, 12]           1,024\n","            ReLU-159          [-1, 512, 12, 12]               0\n","          Conv2d-160         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-161         [-1, 2048, 12, 12]           4,096\n","            ReLU-162         [-1, 2048, 12, 12]               0\n","          Conv2d-163         [-1, 2048, 12, 12]       2,097,152\n","     BatchNorm2d-164         [-1, 2048, 12, 12]           4,096\n","            ReLU-165         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-166         [-1, 2048, 12, 12]               0\n","          Conv2d-167          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-168          [-1, 512, 12, 12]           1,024\n","            ReLU-169          [-1, 512, 12, 12]               0\n","          Conv2d-170          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-171          [-1, 512, 12, 12]           1,024\n","            ReLU-172          [-1, 512, 12, 12]               0\n","          Conv2d-173         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-174         [-1, 2048, 12, 12]           4,096\n","            ReLU-175         [-1, 2048, 12, 12]               0\n","            ReLU-176         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-177         [-1, 2048, 12, 12]               0\n","          Conv2d-178          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-179          [-1, 512, 12, 12]           1,024\n","            ReLU-180          [-1, 512, 12, 12]               0\n","          Conv2d-181          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-182          [-1, 512, 12, 12]           1,024\n","            ReLU-183          [-1, 512, 12, 12]               0\n","          Conv2d-184         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-185         [-1, 2048, 12, 12]           4,096\n","            ReLU-186         [-1, 2048, 12, 12]               0\n","            ReLU-187         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-188         [-1, 2048, 12, 12]               0\n","Hybrid_backbone_4-189  [[-1, 256, 96, 96], [-1, 512, 48, 48], [-1, 1024, 24, 24], [-1, 2048, 12, 12]]               0\n","         Sigmoid-190         [-1, 2048, 12, 12]               0\n","    simam_module-191         [-1, 2048, 12, 12]               0\n","          Conv2d-192          [-1, 768, 12, 12]       1,573,632\n","Last_feature_map_Embed-193             [-1, 144, 768]               0\n","         Sigmoid-194          [-1, 256, 96, 96]               0\n","    simam_module-195          [-1, 256, 96, 96]               0\n","       MaxPool2d-196          [-1, 256, 12, 12]               0\n","          Conv2d-197          [-1, 768, 12, 12]         197,376\n","       LayerNorm-198             [-1, 144, 768]           1,536\n","       AvgPool2d-199          [-1, 256, 12, 12]               0\n","          Conv2d-200          [-1, 768, 12, 12]         197,376\n","       LayerNorm-201             [-1, 144, 768]           1,536\n","     Focus_Embed-202  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-203          [-1, 512, 48, 48]               0\n","    simam_module-204          [-1, 512, 48, 48]               0\n","       MaxPool2d-205          [-1, 512, 12, 12]               0\n","          Conv2d-206          [-1, 768, 12, 12]         393,984\n","       LayerNorm-207             [-1, 144, 768]           1,536\n","       AvgPool2d-208          [-1, 512, 12, 12]               0\n","          Conv2d-209          [-1, 768, 12, 12]         393,984\n","       LayerNorm-210             [-1, 144, 768]           1,536\n","     Focus_Embed-211  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-212         [-1, 1024, 24, 24]               0\n","    simam_module-213         [-1, 1024, 24, 24]               0\n","       MaxPool2d-214         [-1, 1024, 12, 12]               0\n","          Conv2d-215          [-1, 768, 12, 12]         787,200\n","       LayerNorm-216             [-1, 144, 768]           1,536\n","       AvgPool2d-217         [-1, 1024, 12, 12]               0\n","          Conv2d-218          [-1, 768, 12, 12]         787,200\n","       LayerNorm-219             [-1, 144, 768]           1,536\n","     Focus_Embed-220  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-221         [-1, 2048, 12, 12]               0\n","    simam_module-222         [-1, 2048, 12, 12]               0\n","       MaxPool2d-223         [-1, 2048, 12, 12]               0\n","          Conv2d-224          [-1, 768, 12, 12]       1,573,632\n","       LayerNorm-225             [-1, 144, 768]           1,536\n","       AvgPool2d-226         [-1, 2048, 12, 12]               0\n","          Conv2d-227          [-1, 768, 12, 12]       1,573,632\n","       LayerNorm-228             [-1, 144, 768]           1,536\n","     Focus_Embed-229  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Dropout-230             [-1, 145, 768]               0\n","         Dropout-231             [-1, 145, 768]               0\n","         Dropout-232             [-1, 145, 768]               0\n","         Dropout-233             [-1, 145, 768]               0\n","         Dropout-234             [-1, 145, 768]               0\n","         Dropout-235             [-1, 145, 768]               0\n","         Dropout-236             [-1, 145, 768]               0\n","         Dropout-237             [-1, 145, 768]               0\n","         Dropout-238             [-1, 145, 768]               0\n","       LayerNorm-239             [-1, 145, 768]           1,536\n","          Linear-240            [-1, 145, 2304]       1,771,776\n","         Dropout-241          [-1, 8, 145, 145]               0\n","          Linear-242             [-1, 145, 768]         590,592\n","         Dropout-243             [-1, 145, 768]               0\n","       Attention-244             [-1, 145, 768]               0\n","        Identity-245             [-1, 145, 768]               0\n","       LayerNorm-246             [-1, 145, 768]           1,536\n","          Linear-247            [-1, 145, 3072]       2,362,368\n","            GELU-248            [-1, 145, 3072]               0\n","         Dropout-249            [-1, 145, 3072]               0\n","          Linear-250             [-1, 145, 768]       2,360,064\n","         Dropout-251             [-1, 145, 768]               0\n","             FFN-252             [-1, 145, 768]               0\n","        Identity-253             [-1, 145, 768]               0\n","       LayerNorm-254             [-1, 145, 768]           1,536\n","          Linear-255             [-1, 145, 768]         590,592\n","          Linear-256             [-1, 145, 768]         590,592\n","          Linear-257             [-1, 145, 768]         590,592\n","         Dropout-258          [-1, 8, 145, 145]               0\n","          Linear-259             [-1, 145, 768]         590,592\n","         Dropout-260             [-1, 145, 768]               0\n","Guided_Attention-261             [-1, 145, 768]               0\n","        Identity-262             [-1, 145, 768]               0\n","       LayerNorm-263             [-1, 145, 768]           1,536\n","          Linear-264            [-1, 145, 3072]       2,362,368\n","            GELU-265            [-1, 145, 3072]               0\n","         Dropout-266            [-1, 145, 3072]               0\n","          Linear-267             [-1, 145, 768]       2,360,064\n","         Dropout-268             [-1, 145, 768]               0\n","             FFN-269             [-1, 145, 768]               0\n","        Identity-270             [-1, 145, 768]               0\n","   Decoder_Block-271             [-1, 145, 768]               0\n","       LayerNorm-272             [-1, 145, 768]           1,536\n","          Linear-273            [-1, 145, 2304]       1,771,776\n","         Dropout-274          [-1, 8, 145, 145]               0\n","          Linear-275             [-1, 145, 768]         590,592\n","         Dropout-276             [-1, 145, 768]               0\n","       Attention-277             [-1, 145, 768]               0\n","        Identity-278             [-1, 145, 768]               0\n","       LayerNorm-279             [-1, 145, 768]           1,536\n","          Linear-280            [-1, 145, 3072]       2,362,368\n","            GELU-281            [-1, 145, 3072]               0\n","         Dropout-282            [-1, 145, 3072]               0\n","          Linear-283             [-1, 145, 768]       2,360,064\n","         Dropout-284             [-1, 145, 768]               0\n","             FFN-285             [-1, 145, 768]               0\n","        Identity-286             [-1, 145, 768]               0\n","       LayerNorm-287             [-1, 145, 768]           1,536\n","          Linear-288             [-1, 145, 768]         590,592\n","          Linear-289             [-1, 145, 768]         590,592\n","          Linear-290             [-1, 145, 768]         590,592\n","         Dropout-291          [-1, 8, 145, 145]               0\n","          Linear-292             [-1, 145, 768]         590,592\n","         Dropout-293             [-1, 145, 768]               0\n","Guided_Attention-294             [-1, 145, 768]               0\n","        Identity-295             [-1, 145, 768]               0\n","       LayerNorm-296             [-1, 145, 768]           1,536\n","          Linear-297            [-1, 145, 3072]       2,362,368\n","            GELU-298            [-1, 145, 3072]               0\n","         Dropout-299            [-1, 145, 3072]               0\n","          Linear-300             [-1, 145, 768]       2,360,064\n","         Dropout-301             [-1, 145, 768]               0\n","             FFN-302             [-1, 145, 768]               0\n","        Identity-303             [-1, 145, 768]               0\n","   Decoder_Block-304             [-1, 145, 768]               0\n","       LayerNorm-305             [-1, 145, 768]           1,536\n","          Linear-306            [-1, 145, 2304]       1,771,776\n","         Dropout-307          [-1, 8, 145, 145]               0\n","          Linear-308             [-1, 145, 768]         590,592\n","         Dropout-309             [-1, 145, 768]               0\n","       Attention-310             [-1, 145, 768]               0\n","        Identity-311             [-1, 145, 768]               0\n","       LayerNorm-312             [-1, 145, 768]           1,536\n","          Linear-313            [-1, 145, 3072]       2,362,368\n","            GELU-314            [-1, 145, 3072]               0\n","         Dropout-315            [-1, 145, 3072]               0\n","          Linear-316             [-1, 145, 768]       2,360,064\n","         Dropout-317             [-1, 145, 768]               0\n","             FFN-318             [-1, 145, 768]               0\n","        Identity-319             [-1, 145, 768]               0\n","       LayerNorm-320             [-1, 145, 768]           1,536\n","          Linear-321             [-1, 145, 768]         590,592\n","          Linear-322             [-1, 145, 768]         590,592\n","          Linear-323             [-1, 145, 768]         590,592\n","         Dropout-324          [-1, 8, 145, 145]               0\n","          Linear-325             [-1, 145, 768]         590,592\n","         Dropout-326             [-1, 145, 768]               0\n","Guided_Attention-327             [-1, 145, 768]               0\n","        Identity-328             [-1, 145, 768]               0\n","       LayerNorm-329             [-1, 145, 768]           1,536\n","          Linear-330            [-1, 145, 3072]       2,362,368\n","            GELU-331            [-1, 145, 3072]               0\n","         Dropout-332            [-1, 145, 3072]               0\n","          Linear-333             [-1, 145, 768]       2,360,064\n","         Dropout-334             [-1, 145, 768]               0\n","             FFN-335             [-1, 145, 768]               0\n","        Identity-336             [-1, 145, 768]               0\n","   Decoder_Block-337             [-1, 145, 768]               0\n","       LayerNorm-338             [-1, 145, 768]           1,536\n","          Linear-339            [-1, 145, 2304]       1,771,776\n","         Dropout-340          [-1, 8, 145, 145]               0\n","          Linear-341             [-1, 145, 768]         590,592\n","         Dropout-342             [-1, 145, 768]               0\n","       Attention-343             [-1, 145, 768]               0\n","        Identity-344             [-1, 145, 768]               0\n","       LayerNorm-345             [-1, 145, 768]           1,536\n","          Linear-346            [-1, 145, 3072]       2,362,368\n","            GELU-347            [-1, 145, 3072]               0\n","         Dropout-348            [-1, 145, 3072]               0\n","          Linear-349             [-1, 145, 768]       2,360,064\n","         Dropout-350             [-1, 145, 768]               0\n","             FFN-351             [-1, 145, 768]               0\n","        Identity-352             [-1, 145, 768]               0\n","       LayerNorm-353             [-1, 145, 768]           1,536\n","          Linear-354             [-1, 145, 768]         590,592\n","          Linear-355             [-1, 145, 768]         590,592\n","          Linear-356             [-1, 145, 768]         590,592\n","         Dropout-357          [-1, 8, 145, 145]               0\n","          Linear-358             [-1, 145, 768]         590,592\n","         Dropout-359             [-1, 145, 768]               0\n","Guided_Attention-360             [-1, 145, 768]               0\n","        Identity-361             [-1, 145, 768]               0\n","       LayerNorm-362             [-1, 145, 768]           1,536\n","          Linear-363            [-1, 145, 3072]       2,362,368\n","            GELU-364            [-1, 145, 3072]               0\n","         Dropout-365            [-1, 145, 3072]               0\n","          Linear-366             [-1, 145, 768]       2,360,064\n","         Dropout-367             [-1, 145, 768]               0\n","             FFN-368             [-1, 145, 768]               0\n","        Identity-369             [-1, 145, 768]               0\n","   Decoder_Block-370             [-1, 145, 768]               0\n","       LayerNorm-371             [-1, 145, 768]           1,536\n","        Identity-372                  [-1, 768]               0\n","          Linear-373                    [-1, 2]           1,538\n","================================================================\n","Total params: 87,704,386\n","Trainable params: 87,704,386\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 372029.91\n","Params size (MB): 334.57\n","Estimated Total Size (MB): 372366.16\n","----------------------------------------------------------------\n","model : Hybrid2_384_401_PT_lf25_b8_k4\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 50 minibatch: 1      time used: 20.757307767868042\n","minibatch AVG loss: 0.6604903182387352\n","Epoch: 1     train index of 50 minibatch: 2      time used: 20.316863536834717\n","minibatch AVG loss: 0.541789713203907\n","Epoch: 1     train index of 50 minibatch: 3      time used: 20.216737031936646\n","minibatch AVG loss: 0.46843326777219774\n","Epoch: 1     train index of 50 minibatch: 4      time used: 19.810752630233765\n","minibatch AVG loss: 0.4735132691264152\n","Epoch: 1     train index of 50 minibatch: 5      time used: 19.859403610229492\n","minibatch AVG loss: 0.4031081534922123\n","Epoch: 1     train index of 50 minibatch: 6      time used: 19.853930711746216\n","minibatch AVG loss: 0.33375197306275367\n","\n","Epoch: 1  train \n","Loss: 0.4698  Acc: 78.9687\n","negative precision: 81.4378  recall: 87.0912\n","negative sensitivity: 87.0912  specificity: 64.4033\n","negative FPR: 35.5967  NPV: 73.5605\n","negative TP: 1518.0\n","negative TN: 626.0\n","negative FP: 346.0\n","negative FN: 225.0\n","positive precision: 73.5605  recall: 64.4033\n","positive sensitivity: 64.4033  specificity: 87.0912\n","positive FPR: 12.9088  NPV: 81.4378\n","positive TP: 626.0\n","positive TN: 1518.0\n","positive FP: 225.0\n","positive FN: 346.0\n","\n","\n","Epoch: 1     val index of 50 minibatch: 1      time used: 11.320761919021606\n","minibatch AVG loss: 0.1242702229321003\n","\n","Epoch: 1  val \n","Loss: 0.2504  Acc: 89.6755\n","negative precision: 89.4168  recall: 95.1724\n","negative sensitivity: 95.1724  specificity: 79.8354\n","negative FPR: 20.1646  NPV: 90.2326\n","negative TP: 414.0\n","negative TN: 194.0\n","negative FP: 49.0\n","negative FN: 21.0\n","positive precision: 90.2326  recall: 79.8354\n","positive sensitivity: 79.8354  specificity: 95.1724\n","positive FPR: 4.8276  NPV: 89.4168\n","positive TP: 194.0\n","positive TN: 414.0\n","positive FP: 21.0\n","positive FN: 49.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 50 minibatch: 1      time used: 20.25829315185547\n","minibatch AVG loss: 0.359374203979969\n","Epoch: 2     train index of 50 minibatch: 2      time used: 19.524707794189453\n","minibatch AVG loss: 0.30269846923649313\n","Epoch: 2     train index of 50 minibatch: 3      time used: 19.352721691131592\n","minibatch AVG loss: 0.39429390504956247\n","Epoch: 2     train index of 50 minibatch: 4      time used: 19.855165004730225\n","minibatch AVG loss: 0.3574755930900574\n","Epoch: 2     train index of 50 minibatch: 5      time used: 19.36420965194702\n","minibatch AVG loss: 0.2993731118738651\n","Epoch: 2     train index of 50 minibatch: 6      time used: 19.57858920097351\n","minibatch AVG loss: 0.3747362467646599\n","\n","Epoch: 2  train \n","Loss: 0.3436  Acc: 86.0773\n","negative precision: 87.8536  recall: 90.8778\n","negative sensitivity: 90.8778  specificity: 77.4691\n","negative FPR: 22.5309  NPV: 82.5658\n","negative TP: 1584.0\n","negative TN: 753.0\n","negative FP: 219.0\n","negative FN: 159.0\n","positive precision: 82.5658  recall: 77.4691\n","positive sensitivity: 77.4691  specificity: 90.8778\n","positive FPR: 9.1222  NPV: 87.8536\n","positive TP: 753.0\n","positive TN: 1584.0\n","positive FP: 159.0\n","positive FN: 219.0\n","\n","\n","Epoch: 2     val index of 50 minibatch: 1      time used: 11.091870546340942\n","minibatch AVG loss: 0.02839838228188455\n","\n","Epoch: 2  val \n","Loss: 0.3426  Acc: 89.5280\n","negative precision: 86.4000  recall: 99.3103\n","negative sensitivity: 99.3103  specificity: 72.0165\n","negative FPR: 27.9835  NPV: 98.3146\n","negative TP: 432.0\n","negative TN: 175.0\n","negative FP: 68.0\n","negative FN: 3.0\n","positive precision: 98.3146  recall: 72.0165\n","positive sensitivity: 72.0165  specificity: 99.3103\n","positive FPR: 0.6897  NPV: 86.4000\n","positive TP: 175.0\n","positive TN: 432.0\n","positive FP: 3.0\n","positive FN: 68.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 50 minibatch: 1      time used: 20.25339651107788\n","minibatch AVG loss: 0.28523224763572214\n","Epoch: 3     train index of 50 minibatch: 2      time used: 19.929548740386963\n","minibatch AVG loss: 0.3270092895627022\n","Epoch: 3     train index of 50 minibatch: 3      time used: 19.354724645614624\n","minibatch AVG loss: 0.31843991212546824\n","Epoch: 3     train index of 50 minibatch: 4      time used: 19.414628505706787\n","minibatch AVG loss: 0.24833443708717823\n","Epoch: 3     train index of 50 minibatch: 5      time used: 19.731995105743408\n","minibatch AVG loss: 0.3291893921419978\n","Epoch: 3     train index of 50 minibatch: 6      time used: 19.556995391845703\n","minibatch AVG loss: 0.3176944835484028\n","\n","Epoch: 3  train \n","Loss: 0.3104  Acc: 88.0663\n","negative precision: 89.7034  recall: 91.9679\n","negative sensitivity: 91.9679  specificity: 81.0700\n","negative FPR: 18.9300  NPV: 84.9138\n","negative TP: 1603.0\n","negative TN: 788.0\n","negative FP: 184.0\n","negative FN: 140.0\n","positive precision: 84.9138  recall: 81.0700\n","positive sensitivity: 81.0700  specificity: 91.9679\n","positive FPR: 8.0321  NPV: 89.7034\n","positive TP: 788.0\n","positive TN: 1603.0\n","positive FP: 140.0\n","positive FN: 184.0\n","\n","\n","Epoch: 3     val index of 50 minibatch: 1      time used: 11.1688551902771\n","minibatch AVG loss: 0.1785326673090458\n","\n","Epoch: 3  val \n","Loss: 0.2257  Acc: 91.5929\n","negative precision: 92.9545  recall: 94.0230\n","negative sensitivity: 94.0230  specificity: 87.2428\n","negative FPR: 12.7572  NPV: 89.0756\n","negative TP: 409.0\n","negative TN: 212.0\n","negative FP: 31.0\n","negative FN: 26.0\n","positive precision: 89.0756  recall: 87.2428\n","positive sensitivity: 87.2428  specificity: 94.0230\n","positive FPR: 5.9770  NPV: 92.9545\n","positive TP: 212.0\n","positive TN: 409.0\n","positive FP: 26.0\n","positive FN: 31.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 50 minibatch: 1      time used: 20.32291603088379\n","minibatch AVG loss: 0.3442429567873478\n","Epoch: 4     train index of 50 minibatch: 2      time used: 19.636390924453735\n","minibatch AVG loss: 0.290633612498641\n","Epoch: 4     train index of 50 minibatch: 3      time used: 19.65373134613037\n","minibatch AVG loss: 0.29039619863033295\n","Epoch: 4     train index of 50 minibatch: 4      time used: 19.470311164855957\n","minibatch AVG loss: 0.3159668316692114\n","Epoch: 4     train index of 50 minibatch: 5      time used: 19.755003452301025\n","minibatch AVG loss: 0.3343294483423233\n","Epoch: 4     train index of 50 minibatch: 6      time used: 19.267330646514893\n","minibatch AVG loss: 0.2772729022055864\n","\n","Epoch: 4  train \n","Loss: 0.2991  Acc: 88.3610\n","negative precision: 89.5291  recall: 92.7137\n","negative sensitivity: 92.7137  specificity: 80.5556\n","negative FPR: 19.4444  NPV: 86.0440\n","negative TP: 1616.0\n","negative TN: 783.0\n","negative FP: 189.0\n","negative FN: 127.0\n","positive precision: 86.0440  recall: 80.5556\n","positive sensitivity: 80.5556  specificity: 92.7137\n","positive FPR: 7.2863  NPV: 89.5291\n","positive TP: 783.0\n","positive TN: 1616.0\n","positive FP: 127.0\n","positive FN: 189.0\n","\n","\n","Epoch: 4     val index of 50 minibatch: 1      time used: 11.406148433685303\n","minibatch AVG loss: 0.16224374923855067\n","\n","Epoch: 4  val \n","Loss: 0.1979  Acc: 90.5605\n","negative precision: 92.8406  recall: 92.4138\n","negative sensitivity: 92.4138  specificity: 87.2428\n","negative FPR: 12.7572  NPV: 86.5306\n","negative TP: 402.0\n","negative TN: 212.0\n","negative FP: 31.0\n","negative FN: 33.0\n","positive precision: 86.5306  recall: 87.2428\n","positive sensitivity: 87.2428  specificity: 92.4138\n","positive FPR: 7.5862  NPV: 92.8406\n","positive TP: 212.0\n","positive TN: 402.0\n","positive FP: 33.0\n","positive FN: 31.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 50 minibatch: 1      time used: 21.069778442382812\n","minibatch AVG loss: 0.3074163285270333\n","Epoch: 5     train index of 50 minibatch: 2      time used: 19.42857265472412\n","minibatch AVG loss: 0.2961848180741072\n","Epoch: 5     train index of 50 minibatch: 3      time used: 19.665568828582764\n","minibatch AVG loss: 0.24380211792886258\n","Epoch: 5     train index of 50 minibatch: 4      time used: 19.520930290222168\n","minibatch AVG loss: 0.258967359457165\n","Epoch: 5     train index of 50 minibatch: 5      time used: 19.692505359649658\n","minibatch AVG loss: 0.28605084285140037\n","Epoch: 5     train index of 50 minibatch: 6      time used: 19.518585681915283\n","minibatch AVG loss: 0.20053794087842106\n","\n","Epoch: 5  train \n","Loss: 0.2597  Acc: 90.0184\n","negative precision: 91.4882  recall: 93.1153\n","negative sensitivity: 93.1153  specificity: 84.4650\n","negative FPR: 15.5350  NPV: 87.2476\n","negative TP: 1623.0\n","negative TN: 821.0\n","negative FP: 151.0\n","negative FN: 120.0\n","positive precision: 87.2476  recall: 84.4650\n","positive sensitivity: 84.4650  specificity: 93.1153\n","positive FPR: 6.8847  NPV: 91.4882\n","positive TP: 821.0\n","positive TN: 1623.0\n","positive FP: 120.0\n","positive FN: 151.0\n","\n","\n","Epoch: 5     val index of 50 minibatch: 1      time used: 11.27027940750122\n","minibatch AVG loss: 0.1056874284055084\n","\n","Epoch: 5  val \n","Loss: 0.1842  Acc: 91.5929\n","negative precision: 91.6300  recall: 95.6322\n","negative sensitivity: 95.6322  specificity: 84.3621\n","negative FPR: 15.6379  NPV: 91.5179\n","negative TP: 416.0\n","negative TN: 205.0\n","negative FP: 38.0\n","negative FN: 19.0\n","positive precision: 91.5179  recall: 84.3621\n","positive sensitivity: 84.3621  specificity: 95.6322\n","positive FPR: 4.3678  NPV: 91.6300\n","positive TP: 205.0\n","positive TN: 416.0\n","positive FP: 19.0\n","positive FN: 38.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 50 minibatch: 1      time used: 20.160736083984375\n","minibatch AVG loss: 0.3166406315937638\n","Epoch: 6     train index of 50 minibatch: 2      time used: 19.39403486251831\n","minibatch AVG loss: 0.27469394866377117\n","Epoch: 6     train index of 50 minibatch: 3      time used: 19.77112627029419\n","minibatch AVG loss: 0.22121876664459705\n","Epoch: 6     train index of 50 minibatch: 4      time used: 19.540552377700806\n","minibatch AVG loss: 0.2631076836585999\n","Epoch: 6     train index of 50 minibatch: 5      time used: 19.401480197906494\n","minibatch AVG loss: 0.21858103334903717\n","Epoch: 6     train index of 50 minibatch: 6      time used: 19.745704174041748\n","minibatch AVG loss: 0.23085548017174007\n","\n","Epoch: 6  train \n","Loss: 0.2527  Acc: 89.9448\n","negative precision: 92.1445  recall: 92.1974\n","negative sensitivity: 92.1974  specificity: 85.9053\n","negative FPR: 14.0947  NPV: 85.9938\n","negative TP: 1607.0\n","negative TN: 835.0\n","negative FP: 137.0\n","negative FN: 136.0\n","positive precision: 85.9938  recall: 85.9053\n","positive sensitivity: 85.9053  specificity: 92.1974\n","positive FPR: 7.8026  NPV: 92.1445\n","positive TP: 835.0\n","positive TN: 1607.0\n","positive FP: 136.0\n","positive FN: 137.0\n","\n","\n","Epoch: 6     val index of 50 minibatch: 1      time used: 11.168622970581055\n","minibatch AVG loss: 0.04634462102549151\n","\n","Epoch: 6  val \n","Loss: 0.2869  Acc: 90.1180\n","negative precision: 88.1743  recall: 97.7011\n","negative sensitivity: 97.7011  specificity: 76.5432\n","negative FPR: 23.4568  NPV: 94.8980\n","negative TP: 425.0\n","negative TN: 186.0\n","negative FP: 57.0\n","negative FN: 10.0\n","positive precision: 94.8980  recall: 76.5432\n","positive sensitivity: 76.5432  specificity: 97.7011\n","positive FPR: 2.2989  NPV: 88.1743\n","positive TP: 186.0\n","positive TN: 425.0\n","positive FP: 10.0\n","positive FN: 57.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 50 minibatch: 1      time used: 20.377601385116577\n","minibatch AVG loss: 0.25253905285149814\n","Epoch: 7     train index of 50 minibatch: 2      time used: 19.321436643600464\n","minibatch AVG loss: 0.23236464828252792\n","Epoch: 7     train index of 50 minibatch: 3      time used: 19.603339672088623\n","minibatch AVG loss: 0.2026068939641118\n","Epoch: 7     train index of 50 minibatch: 4      time used: 19.443376779556274\n","minibatch AVG loss: 0.23979717567563058\n","Epoch: 7     train index of 50 minibatch: 5      time used: 19.1989905834198\n","minibatch AVG loss: 0.21717002749443054\n","Epoch: 7     train index of 50 minibatch: 6      time used: 19.325329065322876\n","minibatch AVG loss: 0.21752201955765485\n","\n","Epoch: 7  train \n","Loss: 0.2307  Acc: 90.7919\n","negative precision: 92.2467  recall: 93.5169\n","negative sensitivity: 93.5169  specificity: 85.9053\n","negative FPR: 14.0947  NPV: 88.0802\n","negative TP: 1630.0\n","negative TN: 835.0\n","negative FP: 137.0\n","negative FN: 113.0\n","positive precision: 88.0802  recall: 85.9053\n","positive sensitivity: 85.9053  specificity: 93.5169\n","positive FPR: 6.4831  NPV: 92.2467\n","positive TP: 835.0\n","positive TN: 1630.0\n","positive FP: 113.0\n","positive FN: 137.0\n","\n","\n","Epoch: 7     val index of 50 minibatch: 1      time used: 11.204322814941406\n","minibatch AVG loss: 0.10441217581741512\n","\n","Epoch: 7  val \n","Loss: 0.2039  Acc: 91.1504\n","negative precision: 90.3226  recall: 96.5517\n","negative sensitivity: 96.5517  specificity: 81.4815\n","negative FPR: 18.5185  NPV: 92.9577\n","negative TP: 420.0\n","negative TN: 198.0\n","negative FP: 45.0\n","negative FN: 15.0\n","positive precision: 92.9577  recall: 81.4815\n","positive sensitivity: 81.4815  specificity: 96.5517\n","positive FPR: 3.4483  NPV: 90.3226\n","positive TP: 198.0\n","positive TN: 420.0\n","positive FP: 15.0\n","positive FN: 45.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 50 minibatch: 1      time used: 20.125885725021362\n","minibatch AVG loss: 0.2582047108188272\n","Epoch: 8     train index of 50 minibatch: 2      time used: 19.365440845489502\n","minibatch AVG loss: 0.23875655345618724\n","Epoch: 8     train index of 50 minibatch: 3      time used: 19.53189730644226\n","minibatch AVG loss: 0.20072974257171153\n","Epoch: 8     train index of 50 minibatch: 4      time used: 19.84791088104248\n","minibatch AVG loss: 0.2531343074887991\n","Epoch: 8     train index of 50 minibatch: 5      time used: 19.406448364257812\n","minibatch AVG loss: 0.2056162029504776\n","Epoch: 8     train index of 50 minibatch: 6      time used: 19.367313623428345\n","minibatch AVG loss: 0.24330176021903754\n","\n","Epoch: 8  train \n","Loss: 0.2282  Acc: 90.8287\n","negative precision: 92.2990  recall: 93.5169\n","negative sensitivity: 93.5169  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 88.0927\n","negative TP: 1630.0\n","negative TN: 836.0\n","negative FP: 136.0\n","negative FN: 113.0\n","positive precision: 88.0927  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 93.5169\n","positive FPR: 6.4831  NPV: 92.2990\n","positive TP: 836.0\n","positive TN: 1630.0\n","positive FP: 113.0\n","positive FN: 136.0\n","\n","\n","Epoch: 8     val index of 50 minibatch: 1      time used: 11.189246416091919\n","minibatch AVG loss: 0.10546571405604482\n","\n","Epoch: 8  val \n","Loss: 0.1647  Acc: 92.6254\n","negative precision: 93.6508  recall: 94.9425\n","negative sensitivity: 94.9425  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 90.7173\n","negative TP: 413.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 22.0\n","positive precision: 90.7173  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 94.9425\n","positive FPR: 5.0575  NPV: 93.6508\n","positive TP: 215.0\n","positive TN: 413.0\n","positive FP: 22.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 50 minibatch: 1      time used: 20.037819147109985\n","minibatch AVG loss: 0.2215898664109409\n","Epoch: 9     train index of 50 minibatch: 2      time used: 19.79275918006897\n","minibatch AVG loss: 0.17025682250037788\n","Epoch: 9     train index of 50 minibatch: 3      time used: 19.349291801452637\n","minibatch AVG loss: 0.2507271024398506\n","Epoch: 9     train index of 50 minibatch: 4      time used: 19.858423471450806\n","minibatch AVG loss: 0.26801243104040623\n","Epoch: 9     train index of 50 minibatch: 5      time used: 19.41960334777832\n","minibatch AVG loss: 0.21002935979515314\n","Epoch: 9     train index of 50 minibatch: 6      time used: 19.741955041885376\n","minibatch AVG loss: 0.26141395680606366\n","\n","Epoch: 9  train \n","Loss: 0.2245  Acc: 91.1971\n","negative precision: 92.7273  recall: 93.6317\n","negative sensitivity: 93.6317  specificity: 86.8313\n","negative FPR: 13.1687  NPV: 88.3770\n","negative TP: 1632.0\n","negative TN: 844.0\n","negative FP: 128.0\n","negative FN: 111.0\n","positive precision: 88.3770  recall: 86.8313\n","positive sensitivity: 86.8313  specificity: 93.6317\n","positive FPR: 6.3683  NPV: 92.7273\n","positive TP: 844.0\n","positive TN: 1632.0\n","positive FP: 111.0\n","positive FN: 128.0\n","\n","\n","Epoch: 9     val index of 50 minibatch: 1      time used: 11.301294088363647\n","minibatch AVG loss: 0.1161135849962011\n","\n","Epoch: 9  val \n","Loss: 0.1820  Acc: 91.7404\n","negative precision: 92.2049  recall: 95.1724\n","negative sensitivity: 95.1724  specificity: 85.5967\n","negative FPR: 14.4033  NPV: 90.8297\n","negative TP: 414.0\n","negative TN: 208.0\n","negative FP: 35.0\n","negative FN: 21.0\n","positive precision: 90.8297  recall: 85.5967\n","positive sensitivity: 85.5967  specificity: 95.1724\n","positive FPR: 4.8276  NPV: 92.2049\n","positive TP: 208.0\n","positive TN: 414.0\n","positive FP: 21.0\n","positive FN: 35.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 50 minibatch: 1      time used: 20.207502126693726\n","minibatch AVG loss: 0.1971672412008047\n","Epoch: 10     train index of 50 minibatch: 2      time used: 19.907358169555664\n","minibatch AVG loss: 0.18446712132543325\n","Epoch: 10     train index of 50 minibatch: 3      time used: 19.709601879119873\n","minibatch AVG loss: 0.19581517377868296\n","Epoch: 10     train index of 50 minibatch: 4      time used: 19.71198606491089\n","minibatch AVG loss: 0.18002633947879076\n","Epoch: 10     train index of 50 minibatch: 5      time used: 19.51695442199707\n","minibatch AVG loss: 0.2222086488083005\n","Epoch: 10     train index of 50 minibatch: 6      time used: 19.632596969604492\n","minibatch AVG loss: 0.20242576647549868\n","\n","Epoch: 10  train \n","Loss: 0.2019  Acc: 91.8232\n","negative precision: 93.2840  recall: 94.0333\n","negative sensitivity: 94.0333  specificity: 87.8601\n","negative FPR: 12.1399  NPV: 89.1441\n","negative TP: 1639.0\n","negative TN: 854.0\n","negative FP: 118.0\n","negative FN: 104.0\n","positive precision: 89.1441  recall: 87.8601\n","positive sensitivity: 87.8601  specificity: 94.0333\n","positive FPR: 5.9667  NPV: 93.2840\n","positive TP: 854.0\n","positive TN: 1639.0\n","positive FP: 104.0\n","positive FN: 118.0\n","\n","\n","Epoch: 10     val index of 50 minibatch: 1      time used: 11.257323741912842\n","minibatch AVG loss: 0.08841556501574814\n","\n","Epoch: 10  val \n","Loss: 0.1960  Acc: 91.2979\n","negative precision: 90.8696  recall: 96.0920\n","negative sensitivity: 96.0920  specificity: 82.7160\n","negative FPR: 17.2840  NPV: 92.2018\n","negative TP: 418.0\n","negative TN: 201.0\n","negative FP: 42.0\n","negative FN: 17.0\n","positive precision: 92.2018  recall: 82.7160\n","positive sensitivity: 82.7160  specificity: 96.0920\n","positive FPR: 3.9080  NPV: 90.8696\n","positive TP: 201.0\n","positive TN: 418.0\n","positive FP: 17.0\n","positive FN: 42.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 50 minibatch: 1      time used: 20.2140793800354\n","minibatch AVG loss: 0.19415749838575722\n","Epoch: 11     train index of 50 minibatch: 2      time used: 19.414984703063965\n","minibatch AVG loss: 0.1681285380385816\n","Epoch: 11     train index of 50 minibatch: 3      time used: 19.606784105300903\n","minibatch AVG loss: 0.18040951332077385\n","Epoch: 11     train index of 50 minibatch: 4      time used: 19.662044286727905\n","minibatch AVG loss: 0.16067099679261446\n","Epoch: 11     train index of 50 minibatch: 5      time used: 19.31664490699768\n","minibatch AVG loss: 0.21456182230263948\n","Epoch: 11     train index of 50 minibatch: 6      time used: 19.921618223190308\n","minibatch AVG loss: 0.210806728862226\n","\n","Epoch: 11  train \n","Loss: 0.1858  Acc: 92.5599\n","negative precision: 94.1042  recall: 94.3201\n","negative sensitivity: 94.3201  specificity: 89.4033\n","negative FPR: 10.5967  NPV: 89.7727\n","negative TP: 1644.0\n","negative TN: 869.0\n","negative FP: 103.0\n","negative FN: 99.0\n","positive precision: 89.7727  recall: 89.4033\n","positive sensitivity: 89.4033  specificity: 94.3201\n","positive FPR: 5.6799  NPV: 94.1042\n","positive TP: 869.0\n","positive TN: 1644.0\n","positive FP: 99.0\n","positive FN: 103.0\n","\n","\n","Epoch: 11     val index of 50 minibatch: 1      time used: 11.19939112663269\n","minibatch AVG loss: 0.14894159474031768\n","\n","Epoch: 11  val \n","Loss: 0.2101  Acc: 92.3304\n","negative precision: 94.0230  recall: 94.0230\n","negative sensitivity: 94.0230  specificity: 89.3004\n","negative FPR: 10.6996  NPV: 89.3004\n","negative TP: 409.0\n","negative TN: 217.0\n","negative FP: 26.0\n","negative FN: 26.0\n","positive precision: 89.3004  recall: 89.3004\n","positive sensitivity: 89.3004  specificity: 94.0230\n","positive FPR: 5.9770  NPV: 94.0230\n","positive TP: 217.0\n","positive TN: 409.0\n","positive FP: 26.0\n","positive FN: 26.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 50 minibatch: 1      time used: 20.340029001235962\n","minibatch AVG loss: 0.22893039278686048\n","Epoch: 12     train index of 50 minibatch: 2      time used: 19.499252319335938\n","minibatch AVG loss: 0.09656532761640847\n","Epoch: 12     train index of 50 minibatch: 3      time used: 19.260883331298828\n","minibatch AVG loss: 0.19878730637021363\n","Epoch: 12     train index of 50 minibatch: 4      time used: 19.802405834197998\n","minibatch AVG loss: 0.23438781848177315\n","Epoch: 12     train index of 50 minibatch: 5      time used: 19.36418652534485\n","minibatch AVG loss: 0.17320808036252855\n","Epoch: 12     train index of 50 minibatch: 6      time used: 19.829816341400146\n","minibatch AVG loss: 0.18468869172036648\n","\n","Epoch: 12  train \n","Loss: 0.1859  Acc: 92.5599\n","negative precision: 93.6544  recall: 94.8365\n","negative sensitivity: 94.8365  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 90.5263\n","negative TP: 1653.0\n","negative TN: 860.0\n","negative FP: 112.0\n","negative FN: 90.0\n","positive precision: 90.5263  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 94.8365\n","positive FPR: 5.1635  NPV: 93.6544\n","positive TP: 860.0\n","positive TN: 1653.0\n","positive FP: 90.0\n","positive FN: 112.0\n","\n","\n","Epoch: 12     val index of 50 minibatch: 1      time used: 11.234843492507935\n","minibatch AVG loss: 0.1434762070060242\n","\n","Epoch: 12  val \n","Loss: 0.2162  Acc: 91.2979\n","negative precision: 92.3423  recall: 94.2529\n","negative sensitivity: 94.2529  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 89.3162\n","negative TP: 410.0\n","negative TN: 209.0\n","negative FP: 34.0\n","negative FN: 25.0\n","positive precision: 89.3162  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 94.2529\n","positive FPR: 5.7471  NPV: 92.3423\n","positive TP: 209.0\n","positive TN: 410.0\n","positive FP: 25.0\n","positive FN: 34.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 50 minibatch: 1      time used: 20.355031728744507\n","minibatch AVG loss: 0.17405809707939623\n","Epoch: 13     train index of 50 minibatch: 2      time used: 19.669498682022095\n","minibatch AVG loss: 0.15454221235588192\n","Epoch: 13     train index of 50 minibatch: 3      time used: 19.210320472717285\n","minibatch AVG loss: 0.18368227103725077\n","Epoch: 13     train index of 50 minibatch: 4      time used: 19.70025610923767\n","minibatch AVG loss: 0.17971201494336128\n","Epoch: 13     train index of 50 minibatch: 5      time used: 19.72998332977295\n","minibatch AVG loss: 0.11356855154968798\n","Epoch: 13     train index of 50 minibatch: 6      time used: 19.454540014266968\n","minibatch AVG loss: 0.18576045649126172\n","\n","Epoch: 13  train \n","Loss: 0.1703  Acc: 93.5175\n","negative precision: 94.2405  recall: 95.7544\n","negative sensitivity: 95.7544  specificity: 89.5062\n","negative FPR: 10.4938  NPV: 92.1610\n","negative TP: 1669.0\n","negative TN: 870.0\n","negative FP: 102.0\n","negative FN: 74.0\n","positive precision: 92.1610  recall: 89.5062\n","positive sensitivity: 89.5062  specificity: 95.7544\n","positive FPR: 4.2456  NPV: 94.2405\n","positive TP: 870.0\n","positive TN: 1669.0\n","positive FP: 74.0\n","positive FN: 102.0\n","\n","\n","Epoch: 13     val index of 50 minibatch: 1      time used: 11.167150497436523\n","minibatch AVG loss: 0.14268071366706864\n","\n","Epoch: 13  val \n","Loss: 0.1586  Acc: 93.3628\n","negative precision: 95.5607  recall: 94.0230\n","negative sensitivity: 94.0230  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 89.6000\n","negative TP: 409.0\n","negative TN: 224.0\n","negative FP: 19.0\n","negative FN: 26.0\n","positive precision: 89.6000  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 94.0230\n","positive FPR: 5.9770  NPV: 95.5607\n","positive TP: 224.0\n","positive TN: 409.0\n","positive FP: 26.0\n","positive FN: 19.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 50 minibatch: 1      time used: 20.16244626045227\n","minibatch AVG loss: 0.15243004677351565\n","Epoch: 14     train index of 50 minibatch: 2      time used: 19.636324644088745\n","minibatch AVG loss: 0.14645761754363776\n","Epoch: 14     train index of 50 minibatch: 3      time used: 19.656599283218384\n","minibatch AVG loss: 0.19851524954661726\n","Epoch: 14     train index of 50 minibatch: 4      time used: 19.64394736289978\n","minibatch AVG loss: 0.14147552030393853\n","Epoch: 14     train index of 50 minibatch: 5      time used: 19.39440369606018\n","minibatch AVG loss: 0.19443106653168798\n","Epoch: 14     train index of 50 minibatch: 6      time used: 19.937664031982422\n","minibatch AVG loss: 0.1720551341958344\n","\n","Epoch: 14  train \n","Loss: 0.1683  Acc: 93.7753\n","negative precision: 94.7159  recall: 95.6397\n","negative sensitivity: 95.6397  specificity: 90.4321\n","negative FPR: 9.5679  NPV: 92.0419\n","negative TP: 1667.0\n","negative TN: 879.0\n","negative FP: 93.0\n","negative FN: 76.0\n","positive precision: 92.0419  recall: 90.4321\n","positive sensitivity: 90.4321  specificity: 95.6397\n","positive FPR: 4.3603  NPV: 94.7159\n","positive TP: 879.0\n","positive TN: 1667.0\n","positive FP: 76.0\n","positive FN: 93.0\n","\n","\n","Epoch: 14     val index of 50 minibatch: 1      time used: 11.214257955551147\n","minibatch AVG loss: 0.1542808233597316\n","\n","Epoch: 14  val \n","Loss: 0.1433  Acc: 93.8053\n","negative precision: 96.6746  recall: 93.5632\n","negative sensitivity: 93.5632  specificity: 94.2387\n","negative FPR: 5.7613  NPV: 89.1051\n","negative TP: 407.0\n","negative TN: 229.0\n","negative FP: 14.0\n","negative FN: 28.0\n","positive precision: 89.1051  recall: 94.2387\n","positive sensitivity: 94.2387  specificity: 93.5632\n","positive FPR: 6.4368  NPV: 96.6746\n","positive TP: 229.0\n","positive TN: 407.0\n","positive FP: 28.0\n","positive FN: 14.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 50 minibatch: 1      time used: 20.393357515335083\n","minibatch AVG loss: 0.13857557298615575\n","Epoch: 15     train index of 50 minibatch: 2      time used: 19.609941959381104\n","minibatch AVG loss: 0.14494919383898378\n","Epoch: 15     train index of 50 minibatch: 3      time used: 19.441813230514526\n","minibatch AVG loss: 0.1976517004147172\n","Epoch: 15     train index of 50 minibatch: 4      time used: 19.66936469078064\n","minibatch AVG loss: 0.15571291220374406\n","Epoch: 15     train index of 50 minibatch: 5      time used: 19.465831756591797\n","minibatch AVG loss: 0.1149467728100717\n","Epoch: 15     train index of 50 minibatch: 6      time used: 19.986506700515747\n","minibatch AVG loss: 0.18503615945577623\n","\n","Epoch: 15  train \n","Loss: 0.1635  Acc: 93.8858\n","negative precision: 95.0314  recall: 95.4676\n","negative sensitivity: 95.4676  specificity: 91.0494\n","negative FPR: 8.9506  NPV: 91.8050\n","negative TP: 1664.0\n","negative TN: 885.0\n","negative FP: 87.0\n","negative FN: 79.0\n","positive precision: 91.8050  recall: 91.0494\n","positive sensitivity: 91.0494  specificity: 95.4676\n","positive FPR: 4.5324  NPV: 95.0314\n","positive TP: 885.0\n","positive TN: 1664.0\n","positive FP: 79.0\n","positive FN: 87.0\n","\n","\n","Epoch: 15     val index of 50 minibatch: 1      time used: 11.203680992126465\n","minibatch AVG loss: 0.15603939278516918\n","\n","Epoch: 15  val \n","Loss: 0.1996  Acc: 91.5929\n","negative precision: 92.9545  recall: 94.0230\n","negative sensitivity: 94.0230  specificity: 87.2428\n","negative FPR: 12.7572  NPV: 89.0756\n","negative TP: 409.0\n","negative TN: 212.0\n","negative FP: 31.0\n","negative FN: 26.0\n","positive precision: 89.0756  recall: 87.2428\n","positive sensitivity: 87.2428  specificity: 94.0230\n","positive FPR: 5.9770  NPV: 92.9545\n","positive TP: 212.0\n","positive TN: 409.0\n","positive FP: 26.0\n","positive FN: 31.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 50 minibatch: 1      time used: 20.265504360198975\n","minibatch AVG loss: 0.15874052621424198\n","Epoch: 16     train index of 50 minibatch: 2      time used: 19.54192543029785\n","minibatch AVG loss: 0.15135945875197648\n","Epoch: 16     train index of 50 minibatch: 3      time used: 19.47987174987793\n","minibatch AVG loss: 0.1337596780899912\n","Epoch: 16     train index of 50 minibatch: 4      time used: 19.911534070968628\n","minibatch AVG loss: 0.16435212900862098\n","Epoch: 16     train index of 50 minibatch: 5      time used: 19.691375494003296\n","minibatch AVG loss: 0.1769560729339719\n","Epoch: 16     train index of 50 minibatch: 6      time used: 19.918912410736084\n","minibatch AVG loss: 0.15823769576847554\n","\n","Epoch: 16  train \n","Loss: 0.1543  Acc: 94.0331\n","negative precision: 94.8893  recall: 95.8692\n","negative sensitivity: 95.8692  specificity: 90.7407\n","negative FPR: 9.2593  NPV: 92.4528\n","negative TP: 1671.0\n","negative TN: 882.0\n","negative FP: 90.0\n","negative FN: 72.0\n","positive precision: 92.4528  recall: 90.7407\n","positive sensitivity: 90.7407  specificity: 95.8692\n","positive FPR: 4.1308  NPV: 94.8893\n","positive TP: 882.0\n","positive TN: 1671.0\n","positive FP: 72.0\n","positive FN: 90.0\n","\n","\n","Epoch: 16     val index of 50 minibatch: 1      time used: 11.271739721298218\n","minibatch AVG loss: 0.1389253947706311\n","\n","Epoch: 16  val \n","Loss: 0.1568  Acc: 93.3628\n","negative precision: 95.7746  recall: 93.7931\n","negative sensitivity: 93.7931  specificity: 92.5926\n","negative FPR: 7.4074  NPV: 89.2857\n","negative TP: 408.0\n","negative TN: 225.0\n","negative FP: 18.0\n","negative FN: 27.0\n","positive precision: 89.2857  recall: 92.5926\n","positive sensitivity: 92.5926  specificity: 93.7931\n","positive FPR: 6.2069  NPV: 95.7746\n","positive TP: 225.0\n","positive TN: 408.0\n","positive FP: 27.0\n","positive FN: 18.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 50 minibatch: 1      time used: 20.443354845046997\n","minibatch AVG loss: 0.16799781151115895\n","Epoch: 17     train index of 50 minibatch: 2      time used: 19.55061936378479\n","minibatch AVG loss: 0.13895850646309554\n","Epoch: 17     train index of 50 minibatch: 3      time used: 19.697964191436768\n","minibatch AVG loss: 0.1203319196868688\n","Epoch: 17     train index of 50 minibatch: 4      time used: 19.729283809661865\n","minibatch AVG loss: 0.10570344909792766\n","Epoch: 17     train index of 50 minibatch: 5      time used: 19.328091859817505\n","minibatch AVG loss: 0.14150659184902906\n","Epoch: 17     train index of 50 minibatch: 6      time used: 19.315200805664062\n","minibatch AVG loss: 0.15081711911596357\n","\n","Epoch: 17  train \n","Loss: 0.1412  Acc: 94.5120\n","negative precision: 95.6472  recall: 95.8118\n","negative sensitivity: 95.8118  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 92.4665\n","negative TP: 1670.0\n","negative TN: 896.0\n","negative FP: 76.0\n","negative FN: 73.0\n","positive precision: 92.4665  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 95.8118\n","positive FPR: 4.1882  NPV: 95.6472\n","positive TP: 896.0\n","positive TN: 1670.0\n","positive FP: 73.0\n","positive FN: 76.0\n","\n","\n","Epoch: 17     val index of 50 minibatch: 1      time used: 11.184284687042236\n","minibatch AVG loss: 0.052108392202935644\n","\n","Epoch: 17  val \n","Loss: 0.1994  Acc: 91.8879\n","negative precision: 90.4255  recall: 97.7011\n","negative sensitivity: 97.7011  specificity: 81.4815\n","negative FPR: 18.5185  NPV: 95.1923\n","negative TP: 425.0\n","negative TN: 198.0\n","negative FP: 45.0\n","negative FN: 10.0\n","positive precision: 95.1923  recall: 81.4815\n","positive sensitivity: 81.4815  specificity: 97.7011\n","positive FPR: 2.2989  NPV: 90.4255\n","positive TP: 198.0\n","positive TN: 425.0\n","positive FP: 10.0\n","positive FN: 45.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 50 minibatch: 1      time used: 19.90885066986084\n","minibatch AVG loss: 0.12352210132405161\n","Epoch: 18     train index of 50 minibatch: 2      time used: 19.595125913619995\n","minibatch AVG loss: 0.16901832355186344\n","Epoch: 18     train index of 50 minibatch: 3      time used: 19.60171866416931\n","minibatch AVG loss: 0.13679651618003846\n","Epoch: 18     train index of 50 minibatch: 4      time used: 19.877179622650146\n","minibatch AVG loss: 0.15546069318428635\n","Epoch: 18     train index of 50 minibatch: 5      time used: 19.5499165058136\n","minibatch AVG loss: 0.16939037201926113\n","Epoch: 18     train index of 50 minibatch: 6      time used: 19.51381206512451\n","minibatch AVG loss: 0.14651441829279066\n","\n","Epoch: 18  train \n","Loss: 0.1502  Acc: 94.4383\n","negative precision: 95.6422  recall: 95.6971\n","negative sensitivity: 95.6971  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 92.2760\n","negative TP: 1668.0\n","negative TN: 896.0\n","negative FP: 76.0\n","negative FN: 75.0\n","positive precision: 92.2760  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 95.6971\n","positive FPR: 4.3029  NPV: 95.6422\n","positive TP: 896.0\n","positive TN: 1668.0\n","positive FP: 75.0\n","positive FN: 76.0\n","\n","\n","Epoch: 18     val index of 50 minibatch: 1      time used: 11.190938949584961\n","minibatch AVG loss: 0.1208941082234378\n","\n","Epoch: 18  val \n","Loss: 0.1817  Acc: 92.0354\n","negative precision: 93.7931  recall: 93.7931\n","negative sensitivity: 93.7931  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 88.8889\n","negative TP: 408.0\n","negative TN: 216.0\n","negative FP: 27.0\n","negative FN: 27.0\n","positive precision: 88.8889  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 93.7931\n","positive FPR: 6.2069  NPV: 93.7931\n","positive TP: 216.0\n","positive TN: 408.0\n","positive FP: 27.0\n","positive FN: 27.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 50 minibatch: 1      time used: 19.99333119392395\n","minibatch AVG loss: 0.13019573681056498\n","Epoch: 19     train index of 50 minibatch: 2      time used: 19.603517293930054\n","minibatch AVG loss: 0.1421453916048631\n","Epoch: 19     train index of 50 minibatch: 3      time used: 19.659665822982788\n","minibatch AVG loss: 0.10116185568273067\n","Epoch: 19     train index of 50 minibatch: 4      time used: 19.5439612865448\n","minibatch AVG loss: 0.10467557210009545\n","Epoch: 19     train index of 50 minibatch: 5      time used: 19.4599871635437\n","minibatch AVG loss: 0.12679167868569494\n","Epoch: 19     train index of 50 minibatch: 6      time used: 19.72164750099182\n","minibatch AVG loss: 0.12364824929274619\n","\n","Epoch: 19  train \n","Loss: 0.1234  Acc: 94.9908\n","negative precision: 96.0987  recall: 96.0987\n","negative sensitivity: 96.0987  specificity: 93.0041\n","negative FPR: 6.9959  NPV: 93.0041\n","negative TP: 1675.0\n","negative TN: 904.0\n","negative FP: 68.0\n","negative FN: 68.0\n","positive precision: 93.0041  recall: 93.0041\n","positive sensitivity: 93.0041  specificity: 96.0987\n","positive FPR: 3.9013  NPV: 96.0987\n","positive TP: 904.0\n","positive TN: 1675.0\n","positive FP: 68.0\n","positive FN: 68.0\n","\n","\n","Epoch: 19     val index of 50 minibatch: 1      time used: 11.150678396224976\n","minibatch AVG loss: 0.25813013168401083\n","\n","Epoch: 19  val \n","Loss: 0.2260  Acc: 92.1829\n","negative precision: 96.3592  recall: 91.2644\n","negative sensitivity: 91.2644  specificity: 93.8272\n","negative FPR: 6.1728  NPV: 85.7143\n","negative TP: 397.0\n","negative TN: 228.0\n","negative FP: 15.0\n","negative FN: 38.0\n","positive precision: 85.7143  recall: 93.8272\n","positive sensitivity: 93.8272  specificity: 91.2644\n","positive FPR: 8.7356  NPV: 96.3592\n","positive TP: 228.0\n","positive TN: 397.0\n","positive FP: 38.0\n","positive FN: 15.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 50 minibatch: 1      time used: 20.34378409385681\n","minibatch AVG loss: 0.10539990267716348\n","Epoch: 20     train index of 50 minibatch: 2      time used: 19.519920349121094\n","minibatch AVG loss: 0.1622315145470202\n","Epoch: 20     train index of 50 minibatch: 3      time used: 19.851897716522217\n","minibatch AVG loss: 0.13029594991356133\n","Epoch: 20     train index of 50 minibatch: 4      time used: 19.445627689361572\n","minibatch AVG loss: 0.1384382660035044\n","Epoch: 20     train index of 50 minibatch: 5      time used: 19.550284385681152\n","minibatch AVG loss: 0.11530789009295404\n","Epoch: 20     train index of 50 minibatch: 6      time used: 19.651638507843018\n","minibatch AVG loss: 0.15623132585547864\n","\n","Epoch: 20  train \n","Loss: 0.1281  Acc: 94.9540\n","negative precision: 95.6769  recall: 96.5003\n","negative sensitivity: 96.5003  specificity: 92.1811\n","negative FPR: 7.8189  NPV: 93.6259\n","negative TP: 1682.0\n","negative TN: 896.0\n","negative FP: 76.0\n","negative FN: 61.0\n","positive precision: 93.6259  recall: 92.1811\n","positive sensitivity: 92.1811  specificity: 96.5003\n","positive FPR: 3.4997  NPV: 95.6769\n","positive TP: 896.0\n","positive TN: 1682.0\n","positive FP: 61.0\n","positive FN: 76.0\n","\n","\n","Epoch: 20     val index of 50 minibatch: 1      time used: 11.123228549957275\n","minibatch AVG loss: 0.14286483530202532\n","\n","Epoch: 20  val \n","Loss: 0.1740  Acc: 93.0678\n","negative precision: 94.7005  recall: 94.4828\n","negative sensitivity: 94.4828  specificity: 90.5350\n","negative FPR: 9.4650  NPV: 90.1639\n","negative TP: 411.0\n","negative TN: 220.0\n","negative FP: 23.0\n","negative FN: 24.0\n","positive precision: 90.1639  recall: 90.5350\n","positive sensitivity: 90.5350  specificity: 94.4828\n","positive FPR: 5.5172  NPV: 94.7005\n","positive TP: 220.0\n","positive TN: 411.0\n","positive FP: 24.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 50 minibatch: 1      time used: 20.45340371131897\n","minibatch AVG loss: 0.10157949462067335\n","Epoch: 21     train index of 50 minibatch: 2      time used: 19.621673107147217\n","minibatch AVG loss: 0.1179800963588059\n","Epoch: 21     train index of 50 minibatch: 3      time used: 19.341778993606567\n","minibatch AVG loss: 0.13994068816304206\n","Epoch: 21     train index of 50 minibatch: 4      time used: 19.571222066879272\n","minibatch AVG loss: 0.10232133345678449\n","Epoch: 21     train index of 50 minibatch: 5      time used: 19.596659660339355\n","minibatch AVG loss: 0.1088438588893041\n","Epoch: 21     train index of 50 minibatch: 6      time used: 19.823930263519287\n","minibatch AVG loss: 0.12488403100520372\n","\n","Epoch: 21  train \n","Loss: 0.1197  Acc: 95.0276\n","negative precision: 96.2601  recall: 95.9839\n","negative sensitivity: 95.9839  specificity: 93.3128\n","negative FPR: 6.6872  NPV: 92.8352\n","negative TP: 1673.0\n","negative TN: 907.0\n","negative FP: 65.0\n","negative FN: 70.0\n","positive precision: 92.8352  recall: 93.3128\n","positive sensitivity: 93.3128  specificity: 95.9839\n","positive FPR: 4.0161  NPV: 96.2601\n","positive TP: 907.0\n","positive TN: 1673.0\n","positive FP: 70.0\n","positive FN: 65.0\n","\n","\n","Epoch: 21     val index of 50 minibatch: 1      time used: 11.131707668304443\n","minibatch AVG loss: 0.12215186882007402\n","\n","Epoch: 21  val \n","Loss: 0.1666  Acc: 93.5103\n","negative precision: 94.5330  recall: 95.4023\n","negative sensitivity: 95.4023  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 91.6318\n","negative TP: 415.0\n","negative TN: 219.0\n","negative FP: 24.0\n","negative FN: 20.0\n","positive precision: 91.6318  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 95.4023\n","positive FPR: 4.5977  NPV: 94.5330\n","positive TP: 219.0\n","positive TN: 415.0\n","positive FP: 20.0\n","positive FN: 24.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 50 minibatch: 1      time used: 20.232776641845703\n","minibatch AVG loss: 0.13400021551176905\n","Epoch: 22     train index of 50 minibatch: 2      time used: 19.35541796684265\n","minibatch AVG loss: 0.08949716197093949\n","Epoch: 22     train index of 50 minibatch: 3      time used: 19.791505575180054\n","minibatch AVG loss: 0.10292809061706067\n","Epoch: 22     train index of 50 minibatch: 4      time used: 19.512855052947998\n","minibatch AVG loss: 0.10268490470945835\n","Epoch: 22     train index of 50 minibatch: 5      time used: 19.811155557632446\n","minibatch AVG loss: 0.11315925878472627\n","Epoch: 22     train index of 50 minibatch: 6      time used: 19.67885732650757\n","minibatch AVG loss: 0.12738699146546423\n","\n","Epoch: 22  train \n","Loss: 0.1179  Acc: 95.5433\n","negative precision: 96.2372  recall: 96.8445\n","negative sensitivity: 96.8445  specificity: 93.2099\n","negative FPR: 6.7901  NPV: 94.2768\n","negative TP: 1688.0\n","negative TN: 906.0\n","negative FP: 66.0\n","negative FN: 55.0\n","positive precision: 94.2768  recall: 93.2099\n","positive sensitivity: 93.2099  specificity: 96.8445\n","positive FPR: 3.1555  NPV: 96.2372\n","positive TP: 906.0\n","positive TN: 1688.0\n","positive FP: 55.0\n","positive FN: 66.0\n","\n","\n","Epoch: 22     val index of 50 minibatch: 1      time used: 11.218804597854614\n","minibatch AVG loss: 0.12799735267544748\n","\n","Epoch: 22  val \n","Loss: 0.1589  Acc: 93.6578\n","negative precision: 95.1613  recall: 94.9425\n","negative sensitivity: 94.9425  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 90.9836\n","negative TP: 413.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 22.0\n","positive precision: 90.9836  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 94.9425\n","positive FPR: 5.0575  NPV: 95.1613\n","positive TP: 222.0\n","positive TN: 413.0\n","positive FP: 22.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 50 minibatch: 1      time used: 20.602421045303345\n","minibatch AVG loss: 0.11912816941738129\n","Epoch: 23     train index of 50 minibatch: 2      time used: 19.765663623809814\n","minibatch AVG loss: 0.09891231421846897\n","Epoch: 23     train index of 50 minibatch: 3      time used: 19.83463168144226\n","minibatch AVG loss: 0.0799152194103226\n","Epoch: 23     train index of 50 minibatch: 4      time used: 19.32949686050415\n","minibatch AVG loss: 0.12103266621939839\n","Epoch: 23     train index of 50 minibatch: 5      time used: 19.268261194229126\n","minibatch AVG loss: 0.10447210757993161\n","Epoch: 23     train index of 50 minibatch: 6      time used: 19.488036632537842\n","minibatch AVG loss: 0.1435089407209307\n","\n","Epoch: 23  train \n","Loss: 0.1107  Acc: 95.7643\n","negative precision: 97.2706  recall: 96.0987\n","negative sensitivity: 96.0987  specificity: 95.1646\n","negative FPR: 4.8354  NPV: 93.1521\n","negative TP: 1675.0\n","negative TN: 925.0\n","negative FP: 47.0\n","negative FN: 68.0\n","positive precision: 93.1521  recall: 95.1646\n","positive sensitivity: 95.1646  specificity: 96.0987\n","positive FPR: 3.9013  NPV: 97.2706\n","positive TP: 925.0\n","positive TN: 1675.0\n","positive FP: 68.0\n","positive FN: 47.0\n","\n","\n","Epoch: 23     val index of 50 minibatch: 1      time used: 11.041801691055298\n","minibatch AVG loss: 0.1585797880537575\n","\n","Epoch: 23  val \n","Loss: 0.1680  Acc: 93.9528\n","negative precision: 96.4623  recall: 94.0230\n","negative sensitivity: 94.0230  specificity: 93.8272\n","negative FPR: 6.1728  NPV: 89.7638\n","negative TP: 409.0\n","negative TN: 228.0\n","negative FP: 15.0\n","negative FN: 26.0\n","positive precision: 89.7638  recall: 93.8272\n","positive sensitivity: 93.8272  specificity: 94.0230\n","positive FPR: 5.9770  NPV: 96.4623\n","positive TP: 228.0\n","positive TN: 409.0\n","positive FP: 26.0\n","positive FN: 15.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 50 minibatch: 1      time used: 20.028064012527466\n","minibatch AVG loss: 0.08538130721542984\n","Epoch: 24     train index of 50 minibatch: 2      time used: 19.809966802597046\n","minibatch AVG loss: 0.061688984730280935\n","Epoch: 24     train index of 50 minibatch: 3      time used: 19.336443185806274\n","minibatch AVG loss: 0.13228436798788606\n","Epoch: 24     train index of 50 minibatch: 4      time used: 19.43780517578125\n","minibatch AVG loss: 0.12942472649272532\n","Epoch: 24     train index of 50 minibatch: 5      time used: 19.414735078811646\n","minibatch AVG loss: 0.09673356613144278\n","Epoch: 24     train index of 50 minibatch: 6      time used: 19.251309871673584\n","minibatch AVG loss: 0.05854084630031139\n","\n","Epoch: 24  train \n","Loss: 0.0945  Acc: 96.2431\n","negative precision: 96.9125  recall: 97.2461\n","negative sensitivity: 97.2461  specificity: 94.4444\n","negative FPR: 5.5556  NPV: 95.0311\n","negative TP: 1695.0\n","negative TN: 918.0\n","negative FP: 54.0\n","negative FN: 48.0\n","positive precision: 95.0311  recall: 94.4444\n","positive sensitivity: 94.4444  specificity: 97.2461\n","positive FPR: 2.7539  NPV: 96.9125\n","positive TP: 918.0\n","positive TN: 1695.0\n","positive FP: 48.0\n","positive FN: 54.0\n","\n","\n","Epoch: 24     val index of 50 minibatch: 1      time used: 11.05855917930603\n","minibatch AVG loss: 0.12051066344582068\n","\n","Epoch: 24  val \n","Loss: 0.2024  Acc: 93.0678\n","negative precision: 93.6937  recall: 95.6322\n","negative sensitivity: 95.6322  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 91.8803\n","negative TP: 416.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 19.0\n","positive precision: 91.8803  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 95.6322\n","positive FPR: 4.3678  NPV: 93.6937\n","positive TP: 215.0\n","positive TN: 416.0\n","positive FP: 19.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 50 minibatch: 1      time used: 19.766711711883545\n","minibatch AVG loss: 0.081128214658238\n","Epoch: 25     train index of 50 minibatch: 2      time used: 19.754212141036987\n","minibatch AVG loss: 0.136503884550184\n","Epoch: 25     train index of 50 minibatch: 3      time used: 19.189737796783447\n","minibatch AVG loss: 0.13666772843338548\n","Epoch: 25     train index of 50 minibatch: 4      time used: 19.67137360572815\n","minibatch AVG loss: 0.09088833751156926\n","Epoch: 25     train index of 50 minibatch: 5      time used: 18.96015191078186\n","minibatch AVG loss: 0.10212042268365622\n","Epoch: 25     train index of 50 minibatch: 6      time used: 19.855963945388794\n","minibatch AVG loss: 0.089471528371796\n","\n","Epoch: 25  train \n","Loss: 0.1058  Acc: 96.3168\n","negative precision: 97.0774  recall: 97.1888\n","negative sensitivity: 97.1888  specificity: 94.7531\n","negative FPR: 5.2469  NPV: 94.9485\n","negative TP: 1694.0\n","negative TN: 921.0\n","negative FP: 51.0\n","negative FN: 49.0\n","positive precision: 94.9485  recall: 94.7531\n","positive sensitivity: 94.7531  specificity: 97.1888\n","positive FPR: 2.8112  NPV: 97.0774\n","positive TP: 921.0\n","positive TN: 1694.0\n","positive FP: 49.0\n","positive FN: 51.0\n","\n","\n","Epoch: 25     val index of 50 minibatch: 1      time used: 11.076533079147339\n","minibatch AVG loss: 0.195756700373895\n","\n","Epoch: 25  val \n","Loss: 0.2080  Acc: 93.6578\n","negative precision: 96.0094  recall: 94.0230\n","negative sensitivity: 94.0230  specificity: 93.0041\n","negative FPR: 6.9959  NPV: 89.6825\n","negative TP: 409.0\n","negative TN: 226.0\n","negative FP: 17.0\n","negative FN: 26.0\n","positive precision: 89.6825  recall: 93.0041\n","positive sensitivity: 93.0041  specificity: 94.0230\n","positive FPR: 5.9770  NPV: 96.0094\n","positive TP: 226.0\n","positive TN: 409.0\n","positive FP: 26.0\n","positive FN: 17.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 50 minibatch: 1      time used: 19.643083810806274\n","minibatch AVG loss: 0.1058005024632439\n","Epoch: 26     train index of 50 minibatch: 2      time used: 19.61963438987732\n","minibatch AVG loss: 0.10417804181575775\n","Epoch: 26     train index of 50 minibatch: 3      time used: 19.26739501953125\n","minibatch AVG loss: 0.10886314213275909\n","Epoch: 26     train index of 50 minibatch: 4      time used: 19.60571789741516\n","minibatch AVG loss: 0.10978449411224574\n","Epoch: 26     train index of 50 minibatch: 5      time used: 18.9778311252594\n","minibatch AVG loss: 0.08440720331855119\n","Epoch: 26     train index of 50 minibatch: 6      time used: 19.177913188934326\n","minibatch AVG loss: 0.06488988502416759\n","\n","Epoch: 26  train \n","Loss: 0.0931  Acc: 96.6114\n","negative precision: 97.3066  recall: 97.4182\n","negative sensitivity: 97.4182  specificity: 95.1646\n","negative FPR: 4.8354  NPV: 95.3608\n","negative TP: 1698.0\n","negative TN: 925.0\n","negative FP: 47.0\n","negative FN: 45.0\n","positive precision: 95.3608  recall: 95.1646\n","positive sensitivity: 95.1646  specificity: 97.4182\n","positive FPR: 2.5818  NPV: 97.3066\n","positive TP: 925.0\n","positive TN: 1698.0\n","positive FP: 45.0\n","positive FN: 47.0\n","\n","\n","Epoch: 26     val index of 50 minibatch: 1      time used: 11.086173295974731\n","minibatch AVG loss: 0.16650867297270452\n","\n","Epoch: 26  val \n","Loss: 0.1928  Acc: 93.5103\n","negative precision: 95.7845  recall: 94.0230\n","negative sensitivity: 94.0230  specificity: 92.5926\n","negative FPR: 7.4074  NPV: 89.6414\n","negative TP: 409.0\n","negative TN: 225.0\n","negative FP: 18.0\n","negative FN: 26.0\n","positive precision: 89.6414  recall: 92.5926\n","positive sensitivity: 92.5926  specificity: 94.0230\n","positive FPR: 5.9770  NPV: 95.7845\n","positive TP: 225.0\n","positive TN: 409.0\n","positive FP: 26.0\n","positive FN: 18.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 50 minibatch: 1      time used: 19.986919403076172\n","minibatch AVG loss: 0.10769100756850093\n","Epoch: 27     train index of 50 minibatch: 2      time used: 19.73820400238037\n","minibatch AVG loss: 0.06390747862868011\n","Epoch: 27     train index of 50 minibatch: 3      time used: 19.698288679122925\n","minibatch AVG loss: 0.0925833602109924\n","Epoch: 27     train index of 50 minibatch: 4      time used: 19.09181571006775\n","minibatch AVG loss: 0.10454547134693712\n","Epoch: 27     train index of 50 minibatch: 5      time used: 19.45191264152527\n","minibatch AVG loss: 0.11599858480505645\n","Epoch: 27     train index of 50 minibatch: 6      time used: 19.28500747680664\n","minibatch AVG loss: 0.08310838836245239\n","\n","Epoch: 27  train \n","Loss: 0.0940  Acc: 96.4273\n","negative precision: 97.2445  recall: 97.1888\n","negative sensitivity: 97.1888  specificity: 95.0617\n","negative FPR: 4.9383  NPV: 94.9640\n","negative TP: 1694.0\n","negative TN: 924.0\n","negative FP: 48.0\n","negative FN: 49.0\n","positive precision: 94.9640  recall: 95.0617\n","positive sensitivity: 95.0617  specificity: 97.1888\n","positive FPR: 2.8112  NPV: 97.2445\n","positive TP: 924.0\n","positive TN: 1694.0\n","positive FP: 49.0\n","positive FN: 48.0\n","\n","\n","Epoch: 27     val index of 50 minibatch: 1      time used: 11.030264616012573\n","minibatch AVG loss: 0.22591909414331895\n","\n","Epoch: 27  val \n","Loss: 0.2049  Acc: 92.9204\n","negative precision: 96.1814  recall: 92.6437\n","negative sensitivity: 92.6437  specificity: 93.4156\n","negative FPR: 6.5844  NPV: 87.6448\n","negative TP: 403.0\n","negative TN: 227.0\n","negative FP: 16.0\n","negative FN: 32.0\n","positive precision: 87.6448  recall: 93.4156\n","positive sensitivity: 93.4156  specificity: 92.6437\n","positive FPR: 7.3563  NPV: 96.1814\n","positive TP: 227.0\n","positive TN: 403.0\n","positive FP: 32.0\n","positive FN: 16.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 50 minibatch: 1      time used: 20.24678349494934\n","minibatch AVG loss: 0.11232727304100991\n","Epoch: 28     train index of 50 minibatch: 2      time used: 19.141273021697998\n","minibatch AVG loss: 0.11150054484372958\n","Epoch: 28     train index of 50 minibatch: 3      time used: 19.563045740127563\n","minibatch AVG loss: 0.08020708889700473\n","Epoch: 28     train index of 50 minibatch: 4      time used: 18.988548040390015\n","minibatch AVG loss: 0.14736427765805274\n","Epoch: 28     train index of 50 minibatch: 5      time used: 19.5948703289032\n","minibatch AVG loss: 0.06079089615494013\n","Epoch: 28     train index of 50 minibatch: 6      time used: 19.540748596191406\n","minibatch AVG loss: 0.10372348012868315\n","\n","Epoch: 28  train \n","Loss: 0.1057  Acc: 96.1326\n","negative precision: 97.1231  recall: 96.8445\n","negative sensitivity: 96.8445  specificity: 94.8560\n","negative FPR: 5.1440  NPV: 94.3705\n","negative TP: 1688.0\n","negative TN: 922.0\n","negative FP: 50.0\n","negative FN: 55.0\n","positive precision: 94.3705  recall: 94.8560\n","positive sensitivity: 94.8560  specificity: 96.8445\n","positive FPR: 3.1555  NPV: 97.1231\n","positive TP: 922.0\n","positive TN: 1688.0\n","positive FP: 55.0\n","positive FN: 50.0\n","\n","\n","Epoch: 28     val index of 50 minibatch: 1      time used: 11.018014192581177\n","minibatch AVG loss: 0.0890313734242227\n","\n","Epoch: 28  val \n","Loss: 0.2142  Acc: 91.1504\n","negative precision: 90.3226  recall: 96.5517\n","negative sensitivity: 96.5517  specificity: 81.4815\n","negative FPR: 18.5185  NPV: 92.9577\n","negative TP: 420.0\n","negative TN: 198.0\n","negative FP: 45.0\n","negative FN: 15.0\n","positive precision: 92.9577  recall: 81.4815\n","positive sensitivity: 81.4815  specificity: 96.5517\n","positive FPR: 3.4483  NPV: 90.3226\n","positive TP: 198.0\n","positive TN: 420.0\n","positive FP: 15.0\n","positive FN: 45.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 50 minibatch: 1      time used: 20.053240060806274\n","minibatch AVG loss: 0.0862440916430205\n","Epoch: 29     train index of 50 minibatch: 2      time used: 19.423100233078003\n","minibatch AVG loss: 0.04590147274080664\n","Epoch: 29     train index of 50 minibatch: 3      time used: 19.4664146900177\n","minibatch AVG loss: 0.11480966358445585\n","Epoch: 29     train index of 50 minibatch: 4      time used: 19.264841079711914\n","minibatch AVG loss: 0.05466011723037809\n","Epoch: 29     train index of 50 minibatch: 5      time used: 19.739099740982056\n","minibatch AVG loss: 0.0929888673638925\n","Epoch: 29     train index of 50 minibatch: 6      time used: 19.319977521896362\n","minibatch AVG loss: 0.08227023872546851\n","\n","Epoch: 29  train \n","Loss: 0.0810  Acc: 97.2007\n","negative precision: 97.7104  recall: 97.9346\n","negative sensitivity: 97.9346  specificity: 95.8848\n","negative FPR: 4.1152  NPV: 96.2810\n","negative TP: 1707.0\n","negative TN: 932.0\n","negative FP: 40.0\n","negative FN: 36.0\n","positive precision: 96.2810  recall: 95.8848\n","positive sensitivity: 95.8848  specificity: 97.9346\n","positive FPR: 2.0654  NPV: 97.7104\n","positive TP: 932.0\n","positive TN: 1707.0\n","positive FP: 36.0\n","positive FN: 40.0\n","\n","\n","Epoch: 29     val index of 50 minibatch: 1      time used: 11.031302452087402\n","minibatch AVG loss: 0.22887305625103183\n","\n","Epoch: 29  val \n","Loss: 0.2441  Acc: 91.7404\n","negative precision: 94.5882  recall: 92.4138\n","negative sensitivity: 92.4138  specificity: 90.5350\n","negative FPR: 9.4650  NPV: 86.9565\n","negative TP: 402.0\n","negative TN: 220.0\n","negative FP: 23.0\n","negative FN: 33.0\n","positive precision: 86.9565  recall: 90.5350\n","positive sensitivity: 90.5350  specificity: 92.4138\n","positive FPR: 7.5862  NPV: 94.5882\n","positive TP: 220.0\n","positive TN: 402.0\n","positive FP: 33.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 50 minibatch: 1      time used: 20.036529302597046\n","minibatch AVG loss: 0.0705517267715186\n","Epoch: 30     train index of 50 minibatch: 2      time used: 19.343116521835327\n","minibatch AVG loss: 0.069583822239656\n","Epoch: 30     train index of 50 minibatch: 3      time used: 19.338746786117554\n","minibatch AVG loss: 0.053084583850577474\n","Epoch: 30     train index of 50 minibatch: 4      time used: 19.360058069229126\n","minibatch AVG loss: 0.0818647366669029\n","Epoch: 30     train index of 50 minibatch: 5      time used: 19.274287462234497\n","minibatch AVG loss: 0.06942107818555086\n","Epoch: 30     train index of 50 minibatch: 6      time used: 19.811732053756714\n","minibatch AVG loss: 0.06552848367020488\n","\n","Epoch: 30  train \n","Loss: 0.0730  Acc: 97.0166\n","negative precision: 97.5945  recall: 97.7625\n","negative sensitivity: 97.7625  specificity: 95.6790\n","negative FPR: 4.3210  NPV: 95.9752\n","negative TP: 1704.0\n","negative TN: 930.0\n","negative FP: 42.0\n","negative FN: 39.0\n","positive precision: 95.9752  recall: 95.6790\n","positive sensitivity: 95.6790  specificity: 97.7625\n","positive FPR: 2.2375  NPV: 97.5945\n","positive TP: 930.0\n","positive TN: 1704.0\n","positive FP: 39.0\n","positive FN: 42.0\n","\n","\n","Epoch: 30     val index of 50 minibatch: 1      time used: 11.007827281951904\n","minibatch AVG loss: 0.1699825108134246\n","\n","Epoch: 30  val \n","Loss: 0.1967  Acc: 92.4779\n","negative precision: 94.2396  recall: 94.0230\n","negative sensitivity: 94.0230  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 89.3443\n","negative TP: 409.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 26.0\n","positive precision: 89.3443  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 94.0230\n","positive FPR: 5.9770  NPV: 94.2396\n","positive TP: 218.0\n","positive TN: 409.0\n","positive FP: 26.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 50 minibatch: 1      time used: 19.802226066589355\n","minibatch AVG loss: 0.07769364280626177\n","Epoch: 31     train index of 50 minibatch: 2      time used: 19.39589834213257\n","minibatch AVG loss: 0.1051271104812622\n","Epoch: 31     train index of 50 minibatch: 3      time used: 19.425880908966064\n","minibatch AVG loss: 0.06600719629786908\n","Epoch: 31     train index of 50 minibatch: 4      time used: 19.34358549118042\n","minibatch AVG loss: 0.04957421244122088\n","Epoch: 31     train index of 50 minibatch: 5      time used: 19.400277614593506\n","minibatch AVG loss: 0.1183527332590893\n","Epoch: 31     train index of 50 minibatch: 6      time used: 19.203336477279663\n","minibatch AVG loss: 0.057801852505654096\n","\n","Epoch: 31  train \n","Loss: 0.0795  Acc: 96.9797\n","negative precision: 97.6477  recall: 97.6477\n","negative sensitivity: 97.6477  specificity: 95.7819\n","negative FPR: 4.2181  NPV: 95.7819\n","negative TP: 1702.0\n","negative TN: 931.0\n","negative FP: 41.0\n","negative FN: 41.0\n","positive precision: 95.7819  recall: 95.7819\n","positive sensitivity: 95.7819  specificity: 97.6477\n","positive FPR: 2.3523  NPV: 97.6477\n","positive TP: 931.0\n","positive TN: 1702.0\n","positive FP: 41.0\n","positive FN: 41.0\n","\n","\n","Epoch: 31     val index of 50 minibatch: 1      time used: 11.03255581855774\n","minibatch AVG loss: 0.18913513759704073\n","\n","Epoch: 31  val \n","Loss: 0.1960  Acc: 92.6254\n","negative precision: 95.0820  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 88.4462\n","negative TP: 406.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 29.0\n","positive precision: 88.4462  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 95.0820\n","positive TP: 222.0\n","positive TN: 406.0\n","positive FP: 29.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 50 minibatch: 1      time used: 19.82636785507202\n","minibatch AVG loss: 0.08775343298446386\n","Epoch: 32     train index of 50 minibatch: 2      time used: 19.53404974937439\n","minibatch AVG loss: 0.059211521259276194\n","Epoch: 32     train index of 50 minibatch: 3      time used: 19.477198839187622\n","minibatch AVG loss: 0.06707381688291207\n","Epoch: 32     train index of 50 minibatch: 4      time used: 19.366392612457275\n","minibatch AVG loss: 0.09953909738222137\n","Epoch: 32     train index of 50 minibatch: 5      time used: 19.49651288986206\n","minibatch AVG loss: 0.06448295328300446\n","Epoch: 32     train index of 50 minibatch: 6      time used: 19.07791566848755\n","minibatch AVG loss: 0.07376462137093767\n","\n","Epoch: 32  train \n","Loss: 0.0751  Acc: 97.0902\n","negative precision: 97.8161  recall: 97.6477\n","negative sensitivity: 97.6477  specificity: 96.0905\n","negative FPR: 3.9095  NPV: 95.7949\n","negative TP: 1702.0\n","negative TN: 934.0\n","negative FP: 38.0\n","negative FN: 41.0\n","positive precision: 95.7949  recall: 96.0905\n","positive sensitivity: 96.0905  specificity: 97.6477\n","positive FPR: 2.3523  NPV: 97.8161\n","positive TP: 934.0\n","positive TN: 1702.0\n","positive FP: 41.0\n","positive FN: 38.0\n","\n","\n","Epoch: 32     val index of 50 minibatch: 1      time used: 11.108332395553589\n","minibatch AVG loss: 0.07869668406710843\n","\n","Epoch: 32  val \n","Loss: 0.2282  Acc: 92.6254\n","negative precision: 91.7570  recall: 97.2414\n","negative sensitivity: 97.2414  specificity: 84.3621\n","negative FPR: 15.6379  NPV: 94.4700\n","negative TP: 423.0\n","negative TN: 205.0\n","negative FP: 38.0\n","negative FN: 12.0\n","positive precision: 94.4700  recall: 84.3621\n","positive sensitivity: 84.3621  specificity: 97.2414\n","positive FPR: 2.7586  NPV: 91.7570\n","positive TP: 205.0\n","positive TN: 423.0\n","positive FP: 12.0\n","positive FN: 38.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 50 minibatch: 1      time used: 19.95322060585022\n","minibatch AVG loss: 0.07332302103983239\n","Epoch: 33     train index of 50 minibatch: 2      time used: 19.384759664535522\n","minibatch AVG loss: 0.07134006700944155\n","Epoch: 33     train index of 50 minibatch: 3      time used: 19.201889753341675\n","minibatch AVG loss: 0.0791147615853697\n","Epoch: 33     train index of 50 minibatch: 4      time used: 19.69846796989441\n","minibatch AVG loss: 0.05813867948250845\n","Epoch: 33     train index of 50 minibatch: 5      time used: 19.454179048538208\n","minibatch AVG loss: 0.06989820976275951\n","Epoch: 33     train index of 50 minibatch: 6      time used: 19.20536518096924\n","minibatch AVG loss: 0.08158916308544577\n","\n","Epoch: 33  train \n","Loss: 0.0711  Acc: 97.4954\n","negative precision: 98.0493  recall: 98.0493\n","negative sensitivity: 98.0493  specificity: 96.5021\n","negative FPR: 3.4979  NPV: 96.5021\n","negative TP: 1709.0\n","negative TN: 938.0\n","negative FP: 34.0\n","negative FN: 34.0\n","positive precision: 96.5021  recall: 96.5021\n","positive sensitivity: 96.5021  specificity: 98.0493\n","positive FPR: 1.9507  NPV: 98.0493\n","positive TP: 938.0\n","positive TN: 1709.0\n","positive FP: 34.0\n","positive FN: 34.0\n","\n","\n","Epoch: 33     val index of 50 minibatch: 1      time used: 11.01084589958191\n","minibatch AVG loss: 0.2353580618479464\n","\n","Epoch: 33  val \n","Loss: 0.2188  Acc: 91.8879\n","negative precision: 95.0237  recall: 92.1839\n","negative sensitivity: 92.1839  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 86.7188\n","negative TP: 401.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 34.0\n","positive precision: 86.7188  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 92.1839\n","positive FPR: 7.8161  NPV: 95.0237\n","positive TP: 222.0\n","positive TN: 401.0\n","positive FP: 34.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 50 minibatch: 1      time used: 20.259159326553345\n","minibatch AVG loss: 0.08120364828500896\n","Epoch: 34     train index of 50 minibatch: 2      time used: 19.142544984817505\n","minibatch AVG loss: 0.08613653164822609\n","Epoch: 34     train index of 50 minibatch: 3      time used: 19.261711359024048\n","minibatch AVG loss: 0.07657512299949304\n","Epoch: 34     train index of 50 minibatch: 4      time used: 19.278114557266235\n","minibatch AVG loss: 0.05088376572355628\n","Epoch: 34     train index of 50 minibatch: 5      time used: 19.460866928100586\n","minibatch AVG loss: 0.035760278173256665\n","Epoch: 34     train index of 50 minibatch: 6      time used: 19.379582166671753\n","minibatch AVG loss: 0.038586227308842355\n","\n","Epoch: 34  train \n","Loss: 0.0683  Acc: 97.6059\n","negative precision: 98.0527  recall: 98.2215\n","negative sensitivity: 98.2215  specificity: 96.5021\n","negative FPR: 3.4979  NPV: 96.8008\n","negative TP: 1712.0\n","negative TN: 938.0\n","negative FP: 34.0\n","negative FN: 31.0\n","positive precision: 96.8008  recall: 96.5021\n","positive sensitivity: 96.5021  specificity: 98.2215\n","positive FPR: 1.7785  NPV: 98.0527\n","positive TP: 938.0\n","positive TN: 1712.0\n","positive FP: 31.0\n","positive FN: 34.0\n","\n","\n","Epoch: 34     val index of 50 minibatch: 1      time used: 11.059852361679077\n","minibatch AVG loss: 0.1402524708592682\n","\n","Epoch: 34  val \n","Loss: 0.2190  Acc: 93.2153\n","negative precision: 93.9052  recall: 95.6322\n","negative sensitivity: 95.6322  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 91.9149\n","negative TP: 416.0\n","negative TN: 216.0\n","negative FP: 27.0\n","negative FN: 19.0\n","positive precision: 91.9149  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 95.6322\n","positive FPR: 4.3678  NPV: 93.9052\n","positive TP: 216.0\n","positive TN: 416.0\n","positive FP: 19.0\n","positive FN: 27.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 50 minibatch: 1      time used: 20.24508237838745\n","minibatch AVG loss: 0.06137505759019404\n","Epoch: 35     train index of 50 minibatch: 2      time used: 19.296868085861206\n","minibatch AVG loss: 0.036377901826053854\n","Epoch: 35     train index of 50 minibatch: 3      time used: 19.71609377861023\n","minibatch AVG loss: 0.08690687444759533\n","Epoch: 35     train index of 50 minibatch: 4      time used: 19.058430194854736\n","minibatch AVG loss: 0.055135301793925465\n","Epoch: 35     train index of 50 minibatch: 5      time used: 19.560876607894897\n","minibatch AVG loss: 0.08208709983387961\n","Epoch: 35     train index of 50 minibatch: 6      time used: 19.454964876174927\n","minibatch AVG loss: 0.05573321176227182\n","\n","Epoch: 35  train \n","Loss: 0.0616  Acc: 97.7164\n","negative precision: 98.1662  recall: 98.2788\n","negative sensitivity: 98.2788  specificity: 96.7078\n","negative FPR: 3.2922  NPV: 96.9072\n","negative TP: 1713.0\n","negative TN: 940.0\n","negative FP: 32.0\n","negative FN: 30.0\n","positive precision: 96.9072  recall: 96.7078\n","positive sensitivity: 96.7078  specificity: 98.2788\n","positive FPR: 1.7212  NPV: 98.1662\n","positive TP: 940.0\n","positive TN: 1713.0\n","positive FP: 30.0\n","positive FN: 32.0\n","\n","\n","Epoch: 35     val index of 50 minibatch: 1      time used: 10.987062931060791\n","minibatch AVG loss: 0.18705172349902568\n","\n","Epoch: 35  val \n","Loss: 0.2272  Acc: 92.6254\n","negative precision: 93.8497  recall: 94.7126\n","negative sensitivity: 94.7126  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 90.3766\n","negative TP: 412.0\n","negative TN: 216.0\n","negative FP: 27.0\n","negative FN: 23.0\n","positive precision: 90.3766  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 94.7126\n","positive FPR: 5.2874  NPV: 93.8497\n","positive TP: 216.0\n","positive TN: 412.0\n","positive FP: 23.0\n","positive FN: 27.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 50 minibatch: 1      time used: 20.0150887966156\n","minibatch AVG loss: 0.07524236241355538\n","Epoch: 36     train index of 50 minibatch: 2      time used: 19.56918716430664\n","minibatch AVG loss: 0.04254108356311917\n","Epoch: 36     train index of 50 minibatch: 3      time used: 19.58477210998535\n","minibatch AVG loss: 0.03744824392488226\n","Epoch: 36     train index of 50 minibatch: 4      time used: 19.626458644866943\n","minibatch AVG loss: 0.04345273427548818\n","Epoch: 36     train index of 50 minibatch: 5      time used: 19.23737359046936\n","minibatch AVG loss: 0.05938558284076862\n","Epoch: 36     train index of 50 minibatch: 6      time used: 19.352526664733887\n","minibatch AVG loss: 0.07255718080559745\n","\n","Epoch: 36  train \n","Loss: 0.0531  Acc: 97.9374\n","negative precision: 98.4492  recall: 98.3362\n","negative sensitivity: 98.3362  specificity: 97.2222\n","negative FPR: 2.7778  NPV: 97.0226\n","negative TP: 1714.0\n","negative TN: 945.0\n","negative FP: 27.0\n","negative FN: 29.0\n","positive precision: 97.0226  recall: 97.2222\n","positive sensitivity: 97.2222  specificity: 98.3362\n","positive FPR: 1.6638  NPV: 98.4492\n","positive TP: 945.0\n","positive TN: 1714.0\n","positive FP: 29.0\n","positive FN: 27.0\n","\n","\n","Epoch: 36     val index of 50 minibatch: 1      time used: 11.081556797027588\n","minibatch AVG loss: 0.15602302288942155\n","\n","Epoch: 36  val \n","Loss: 0.2241  Acc: 92.4779\n","negative precision: 93.2432  recall: 95.1724\n","negative sensitivity: 95.1724  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 91.0256\n","negative TP: 414.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 21.0\n","positive precision: 91.0256  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 95.1724\n","positive FPR: 4.8276  NPV: 93.2432\n","positive TP: 213.0\n","positive TN: 414.0\n","positive FP: 21.0\n","positive FN: 30.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 50 minibatch: 1      time used: 20.097838163375854\n","minibatch AVG loss: 0.06251185755478218\n","Epoch: 37     train index of 50 minibatch: 2      time used: 19.253204107284546\n","minibatch AVG loss: 0.045687093996675684\n","Epoch: 37     train index of 50 minibatch: 3      time used: 19.42020845413208\n","minibatch AVG loss: 0.046271745557896794\n","Epoch: 37     train index of 50 minibatch: 4      time used: 19.545069456100464\n","minibatch AVG loss: 0.06850848725647665\n","Epoch: 37     train index of 50 minibatch: 5      time used: 19.122395515441895\n","minibatch AVG loss: 0.06861310643842444\n","Epoch: 37     train index of 50 minibatch: 6      time used: 19.51252317428589\n","minibatch AVG loss: 0.08324422115925699\n","\n","Epoch: 37  train \n","Loss: 0.0612  Acc: 97.6427\n","negative precision: 98.1641  recall: 98.1641\n","negative sensitivity: 98.1641  specificity: 96.7078\n","negative FPR: 3.2922  NPV: 96.7078\n","negative TP: 1711.0\n","negative TN: 940.0\n","negative FP: 32.0\n","negative FN: 32.0\n","positive precision: 96.7078  recall: 96.7078\n","positive sensitivity: 96.7078  specificity: 98.1641\n","positive FPR: 1.8359  NPV: 98.1641\n","positive TP: 940.0\n","positive TN: 1711.0\n","positive FP: 32.0\n","positive FN: 32.0\n","\n","\n","Epoch: 37     val index of 50 minibatch: 1      time used: 11.043281316757202\n","minibatch AVG loss: 0.09761711725528585\n","\n","Epoch: 37  val \n","Loss: 0.2265  Acc: 92.7729\n","negative precision: 92.5110  recall: 96.5517\n","negative sensitivity: 96.5517  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 93.3036\n","negative TP: 420.0\n","negative TN: 209.0\n","negative FP: 34.0\n","negative FN: 15.0\n","positive precision: 93.3036  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 96.5517\n","positive FPR: 3.4483  NPV: 92.5110\n","positive TP: 209.0\n","positive TN: 420.0\n","positive FP: 15.0\n","positive FN: 34.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 50 minibatch: 1      time used: 19.8857319355011\n","minibatch AVG loss: 0.04473746631643735\n","Epoch: 38     train index of 50 minibatch: 2      time used: 19.467097997665405\n","minibatch AVG loss: 0.025702356601832434\n","Epoch: 38     train index of 50 minibatch: 3      time used: 19.577733755111694\n","minibatch AVG loss: 0.04001161384221632\n","Epoch: 38     train index of 50 minibatch: 4      time used: 19.329452514648438\n","minibatch AVG loss: 0.04253631834522821\n","Epoch: 38     train index of 50 minibatch: 5      time used: 19.546306133270264\n","minibatch AVG loss: 0.07112183061661198\n","Epoch: 38     train index of 50 minibatch: 6      time used: 19.363803386688232\n","minibatch AVG loss: 0.0683574690693058\n","\n","Epoch: 38  train \n","Loss: 0.0529  Acc: 98.0847\n","negative precision: 98.3973  recall: 98.6231\n","negative sensitivity: 98.6231  specificity: 97.1193\n","negative FPR: 2.8807  NPV: 97.5207\n","negative TP: 1719.0\n","negative TN: 944.0\n","negative FP: 28.0\n","negative FN: 24.0\n","positive precision: 97.5207  recall: 97.1193\n","positive sensitivity: 97.1193  specificity: 98.6231\n","positive FPR: 1.3769  NPV: 98.3973\n","positive TP: 944.0\n","positive TN: 1719.0\n","positive FP: 24.0\n","positive FN: 28.0\n","\n","\n","Epoch: 38     val index of 50 minibatch: 1      time used: 11.122987985610962\n","minibatch AVG loss: 0.1623381260698079\n","\n","Epoch: 38  val \n","Loss: 0.2277  Acc: 92.4779\n","negative precision: 93.6364  recall: 94.7126\n","negative sensitivity: 94.7126  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 90.3361\n","negative TP: 412.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 23.0\n","positive precision: 90.3361  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 94.7126\n","positive FPR: 5.2874  NPV: 93.6364\n","positive TP: 215.0\n","positive TN: 412.0\n","positive FP: 23.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 50 minibatch: 1      time used: 20.18241000175476\n","minibatch AVG loss: 0.06325755801633931\n","Epoch: 39     train index of 50 minibatch: 2      time used: 19.013076782226562\n","minibatch AVG loss: 0.0469087162008509\n","Epoch: 39     train index of 50 minibatch: 3      time used: 19.43797254562378\n","minibatch AVG loss: 0.05125683371210471\n","Epoch: 39     train index of 50 minibatch: 4      time used: 19.42306423187256\n","minibatch AVG loss: 0.03572647371562198\n","Epoch: 39     train index of 50 minibatch: 5      time used: 19.491935968399048\n","minibatch AVG loss: 0.03368773051886819\n","Epoch: 39     train index of 50 minibatch: 6      time used: 19.41919183731079\n","minibatch AVG loss: 0.05272757848259062\n","\n","Epoch: 39  train \n","Loss: 0.0484  Acc: 98.4162\n","negative precision: 98.6827  recall: 98.8526\n","negative sensitivity: 98.8526  specificity: 97.6337\n","negative FPR: 2.3663  NPV: 97.9360\n","negative TP: 1723.0\n","negative TN: 949.0\n","negative FP: 23.0\n","negative FN: 20.0\n","positive precision: 97.9360  recall: 97.6337\n","positive sensitivity: 97.6337  specificity: 98.8526\n","positive FPR: 1.1474  NPV: 98.6827\n","positive TP: 949.0\n","positive TN: 1723.0\n","positive FP: 20.0\n","positive FN: 23.0\n","\n","\n","Epoch: 39     val index of 50 minibatch: 1      time used: 11.118789434432983\n","minibatch AVG loss: 0.18528805783455027\n","\n","Epoch: 39  val \n","Loss: 0.1964  Acc: 93.6578\n","negative precision: 95.3704  recall: 94.7126\n","negative sensitivity: 94.7126  specificity: 91.7695\n","negative FPR: 8.2305  NPV: 90.6504\n","negative TP: 412.0\n","negative TN: 223.0\n","negative FP: 20.0\n","negative FN: 23.0\n","positive precision: 90.6504  recall: 91.7695\n","positive sensitivity: 91.7695  specificity: 94.7126\n","positive FPR: 5.2874  NPV: 95.3704\n","positive TP: 223.0\n","positive TN: 412.0\n","positive FP: 23.0\n","positive FN: 20.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 50 minibatch: 1      time used: 19.965054512023926\n","minibatch AVG loss: 0.0328844549076166\n","Epoch: 40     train index of 50 minibatch: 2      time used: 19.687398195266724\n","minibatch AVG loss: 0.08196097356500104\n","Epoch: 40     train index of 50 minibatch: 3      time used: 18.99416995048523\n","minibatch AVG loss: 0.047800426642643286\n","Epoch: 40     train index of 50 minibatch: 4      time used: 19.481425762176514\n","minibatch AVG loss: 0.05448651153128594\n","Epoch: 40     train index of 50 minibatch: 5      time used: 19.3066303730011\n","minibatch AVG loss: 0.05099583835573867\n","Epoch: 40     train index of 50 minibatch: 6      time used: 19.21515154838562\n","minibatch AVG loss: 0.0557247876515612\n","\n","Epoch: 40  train \n","Loss: 0.0526  Acc: 98.0847\n","negative precision: 98.4527  recall: 98.5657\n","negative sensitivity: 98.5657  specificity: 97.2222\n","negative FPR: 2.7778  NPV: 97.4227\n","negative TP: 1718.0\n","negative TN: 945.0\n","negative FP: 27.0\n","negative FN: 25.0\n","positive precision: 97.4227  recall: 97.2222\n","positive sensitivity: 97.2222  specificity: 98.5657\n","positive FPR: 1.4343  NPV: 98.4527\n","positive TP: 945.0\n","positive TN: 1718.0\n","positive FP: 25.0\n","positive FN: 27.0\n","\n","\n","Epoch: 40     val index of 50 minibatch: 1      time used: 11.096771240234375\n","minibatch AVG loss: 0.14776126946118892\n","\n","Epoch: 40  val \n","Loss: 0.2129  Acc: 92.9204\n","negative precision: 94.0774  recall: 94.9425\n","negative sensitivity: 94.9425  specificity: 89.3004\n","negative FPR: 10.6996  NPV: 90.7950\n","negative TP: 413.0\n","negative TN: 217.0\n","negative FP: 26.0\n","negative FN: 22.0\n","positive precision: 90.7950  recall: 89.3004\n","positive sensitivity: 89.3004  specificity: 94.9425\n","positive FPR: 5.0575  NPV: 94.0774\n","positive TP: 217.0\n","positive TN: 413.0\n","positive FP: 22.0\n","positive FN: 26.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 50 minibatch: 1      time used: 20.04806137084961\n","minibatch AVG loss: 0.06304420744534582\n","Epoch: 41     train index of 50 minibatch: 2      time used: 19.012343406677246\n","minibatch AVG loss: 0.04704873110400513\n","Epoch: 41     train index of 50 minibatch: 3      time used: 19.40568709373474\n","minibatch AVG loss: 0.027754013348603623\n","Epoch: 41     train index of 50 minibatch: 4      time used: 19.39410376548767\n","minibatch AVG loss: 0.03249538416741416\n","Epoch: 41     train index of 50 minibatch: 5      time used: 19.257925033569336\n","minibatch AVG loss: 0.05002731853513978\n","Epoch: 41     train index of 50 minibatch: 6      time used: 19.24252700805664\n","minibatch AVG loss: 0.037538874293677506\n","\n","Epoch: 41  train \n","Loss: 0.0419  Acc: 98.6004\n","negative precision: 98.8539  recall: 98.9673\n","negative sensitivity: 98.9673  specificity: 97.9424\n","negative FPR: 2.0576  NPV: 98.1443\n","negative TP: 1725.0\n","negative TN: 952.0\n","negative FP: 20.0\n","negative FN: 18.0\n","positive precision: 98.1443  recall: 97.9424\n","positive sensitivity: 97.9424  specificity: 98.9673\n","positive FPR: 1.0327  NPV: 98.8539\n","positive TP: 952.0\n","positive TN: 1725.0\n","positive FP: 18.0\n","positive FN: 20.0\n","\n","\n","Epoch: 41     val index of 50 minibatch: 1      time used: 11.08388352394104\n","minibatch AVG loss: 0.11531368139607366\n","\n","Epoch: 41  val \n","Loss: 0.2316  Acc: 92.7729\n","negative precision: 92.6991  recall: 96.3218\n","negative sensitivity: 96.3218  specificity: 86.4198\n","negative FPR: 13.5802  NPV: 92.9204\n","negative TP: 419.0\n","negative TN: 210.0\n","negative FP: 33.0\n","negative FN: 16.0\n","positive precision: 92.9204  recall: 86.4198\n","positive sensitivity: 86.4198  specificity: 96.3218\n","positive FPR: 3.6782  NPV: 92.6991\n","positive TP: 210.0\n","positive TN: 419.0\n","positive FP: 16.0\n","positive FN: 33.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 50 minibatch: 1      time used: 19.99185299873352\n","minibatch AVG loss: 0.02276899733580649\n","Epoch: 42     train index of 50 minibatch: 2      time used: 19.00842261314392\n","minibatch AVG loss: 0.023387975816149265\n","Epoch: 42     train index of 50 minibatch: 3      time used: 19.224976539611816\n","minibatch AVG loss: 0.04213204241299536\n","Epoch: 42     train index of 50 minibatch: 4      time used: 19.747181177139282\n","minibatch AVG loss: 0.02958948349347338\n","Epoch: 42     train index of 50 minibatch: 5      time used: 19.185168027877808\n","minibatch AVG loss: 0.0287919656210579\n","Epoch: 42     train index of 50 minibatch: 6      time used: 19.061177253723145\n","minibatch AVG loss: 0.04940724362269975\n","\n","Epoch: 42  train \n","Loss: 0.0334  Acc: 98.6740\n","negative precision: 98.7993  recall: 99.1394\n","negative sensitivity: 99.1394  specificity: 97.8395\n","negative FPR: 2.1605  NPV: 98.4472\n","negative TP: 1728.0\n","negative TN: 951.0\n","negative FP: 21.0\n","negative FN: 15.0\n","positive precision: 98.4472  recall: 97.8395\n","positive sensitivity: 97.8395  specificity: 99.1394\n","positive FPR: 0.8606  NPV: 98.7993\n","positive TP: 951.0\n","positive TN: 1728.0\n","positive FP: 15.0\n","positive FN: 21.0\n","\n","\n","Epoch: 42     val index of 50 minibatch: 1      time used: 11.00162386894226\n","minibatch AVG loss: 0.23039040478754033\n","\n","Epoch: 42  val \n","Loss: 0.2504  Acc: 92.6254\n","negative precision: 93.8497  recall: 94.7126\n","negative sensitivity: 94.7126  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 90.3766\n","negative TP: 412.0\n","negative TN: 216.0\n","negative FP: 27.0\n","negative FN: 23.0\n","positive precision: 90.3766  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 94.7126\n","positive FPR: 5.2874  NPV: 93.8497\n","positive TP: 216.0\n","positive TN: 412.0\n","positive FP: 23.0\n","positive FN: 27.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 50 minibatch: 1      time used: 20.316813468933105\n","minibatch AVG loss: 0.026439714113948867\n","Epoch: 43     train index of 50 minibatch: 2      time used: 19.40859055519104\n","minibatch AVG loss: 0.04226053709804546\n","Epoch: 43     train index of 50 minibatch: 3      time used: 19.072001457214355\n","minibatch AVG loss: 0.0512746540887747\n","Epoch: 43     train index of 50 minibatch: 4      time used: 19.505140781402588\n","minibatch AVG loss: 0.04225622248603031\n","Epoch: 43     train index of 50 minibatch: 5      time used: 19.29038691520691\n","minibatch AVG loss: 0.03370479985838756\n","Epoch: 43     train index of 50 minibatch: 6      time used: 19.634846448898315\n","minibatch AVG loss: 0.041114635086851196\n","\n","Epoch: 43  train \n","Loss: 0.0395  Acc: 98.7109\n","negative precision: 98.9679  recall: 99.0247\n","negative sensitivity: 99.0247  specificity: 98.1481\n","negative FPR: 1.8519  NPV: 98.2492\n","negative TP: 1726.0\n","negative TN: 954.0\n","negative FP: 18.0\n","negative FN: 17.0\n","positive precision: 98.2492  recall: 98.1481\n","positive sensitivity: 98.1481  specificity: 99.0247\n","positive FPR: 0.9753  NPV: 98.9679\n","positive TP: 954.0\n","positive TN: 1726.0\n","positive FP: 17.0\n","positive FN: 18.0\n","\n","\n","Epoch: 43     val index of 50 minibatch: 1      time used: 11.053427934646606\n","minibatch AVG loss: 0.07967711642821086\n","\n","Epoch: 43  val \n","Loss: 0.2132  Acc: 93.0678\n","negative precision: 92.5439  recall: 97.0115\n","negative sensitivity: 97.0115  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 94.1441\n","negative TP: 422.0\n","negative TN: 209.0\n","negative FP: 34.0\n","negative FN: 13.0\n","positive precision: 94.1441  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 97.0115\n","positive FPR: 2.9885  NPV: 92.5439\n","positive TP: 209.0\n","positive TN: 422.0\n","positive FP: 13.0\n","positive FN: 34.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 50 minibatch: 1      time used: 20.066745042800903\n","minibatch AVG loss: 0.08990066691301762\n","Epoch: 44     train index of 50 minibatch: 2      time used: 19.68345594406128\n","minibatch AVG loss: 0.05771848640521057\n","Epoch: 44     train index of 50 minibatch: 3      time used: 19.429441690444946\n","minibatch AVG loss: 0.03608217371162027\n","Epoch: 44     train index of 50 minibatch: 4      time used: 19.11403489112854\n","minibatch AVG loss: 0.027841469740960748\n","Epoch: 44     train index of 50 minibatch: 5      time used: 19.512217044830322\n","minibatch AVG loss: 0.04411313088494353\n","Epoch: 44     train index of 50 minibatch: 6      time used: 19.439324855804443\n","minibatch AVG loss: 0.039298887939658016\n","\n","Epoch: 44  train \n","Loss: 0.0485  Acc: 98.3057\n","negative precision: 98.7924  recall: 98.5657\n","negative sensitivity: 98.5657  specificity: 97.8395\n","negative FPR: 2.1605  NPV: 97.4385\n","negative TP: 1718.0\n","negative TN: 951.0\n","negative FP: 21.0\n","negative FN: 25.0\n","positive precision: 97.4385  recall: 97.8395\n","positive sensitivity: 97.8395  specificity: 98.5657\n","positive FPR: 1.4343  NPV: 98.7924\n","positive TP: 951.0\n","positive TN: 1718.0\n","positive FP: 25.0\n","positive FN: 21.0\n","\n","\n","Epoch: 44     val index of 50 minibatch: 1      time used: 11.012536764144897\n","minibatch AVG loss: 0.0896885276507237\n","\n","Epoch: 44  val \n","Loss: 0.2313  Acc: 93.5103\n","negative precision: 92.7790  recall: 97.4713\n","negative sensitivity: 97.4713  specificity: 86.4198\n","negative FPR: 13.5802  NPV: 95.0226\n","negative TP: 424.0\n","negative TN: 210.0\n","negative FP: 33.0\n","negative FN: 11.0\n","positive precision: 95.0226  recall: 86.4198\n","positive sensitivity: 86.4198  specificity: 97.4713\n","positive FPR: 2.5287  NPV: 92.7790\n","positive TP: 210.0\n","positive TN: 424.0\n","positive FP: 11.0\n","positive FN: 33.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 50 minibatch: 1      time used: 19.998103380203247\n","minibatch AVG loss: 0.040547687452635726\n","Epoch: 45     train index of 50 minibatch: 2      time used: 19.53791308403015\n","minibatch AVG loss: 0.015880178653169423\n","Epoch: 45     train index of 50 minibatch: 3      time used: 19.296902179718018\n","minibatch AVG loss: 0.03265322990017012\n","Epoch: 45     train index of 50 minibatch: 4      time used: 19.4713351726532\n","minibatch AVG loss: 0.029455420717131347\n","Epoch: 45     train index of 50 minibatch: 5      time used: 19.815818548202515\n","minibatch AVG loss: 0.04325012975546997\n","Epoch: 45     train index of 50 minibatch: 6      time used: 19.73953151702881\n","minibatch AVG loss: 0.051203465533908456\n","\n","Epoch: 45  train \n","Loss: 0.0393  Acc: 98.6740\n","negative precision: 98.9673  recall: 98.9673\n","negative sensitivity: 98.9673  specificity: 98.1481\n","negative FPR: 1.8519  NPV: 98.1481\n","negative TP: 1725.0\n","negative TN: 954.0\n","negative FP: 18.0\n","negative FN: 18.0\n","positive precision: 98.1481  recall: 98.1481\n","positive sensitivity: 98.1481  specificity: 98.9673\n","positive FPR: 1.0327  NPV: 98.9673\n","positive TP: 954.0\n","positive TN: 1725.0\n","positive FP: 18.0\n","positive FN: 18.0\n","\n","\n","Epoch: 45     val index of 50 minibatch: 1      time used: 11.126725435256958\n","minibatch AVG loss: 0.1625265868837596\n","\n","Epoch: 45  val \n","Loss: 0.2078  Acc: 93.6578\n","negative precision: 94.9541  recall: 95.1724\n","negative sensitivity: 95.1724  specificity: 90.9465\n","negative FPR: 9.0535  NPV: 91.3223\n","negative TP: 414.0\n","negative TN: 221.0\n","negative FP: 22.0\n","negative FN: 21.0\n","positive precision: 91.3223  recall: 90.9465\n","positive sensitivity: 90.9465  specificity: 95.1724\n","positive FPR: 4.8276  NPV: 94.9541\n","positive TP: 221.0\n","positive TN: 414.0\n","positive FP: 21.0\n","positive FN: 22.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 50 minibatch: 1      time used: 19.984702825546265\n","minibatch AVG loss: 0.04231546296505258\n","Epoch: 46     train index of 50 minibatch: 2      time used: 19.527477264404297\n","minibatch AVG loss: 0.04543295402196236\n","Epoch: 46     train index of 50 minibatch: 3      time used: 19.25354242324829\n","minibatch AVG loss: 0.03666031706728973\n","Epoch: 46     train index of 50 minibatch: 4      time used: 19.249094247817993\n","minibatch AVG loss: 0.027748014422832055\n","Epoch: 46     train index of 50 minibatch: 5      time used: 19.474380493164062\n","minibatch AVG loss: 0.03071638548746705\n","Epoch: 46     train index of 50 minibatch: 6      time used: 19.32765769958496\n","minibatch AVG loss: 0.031380357497837394\n","\n","Epoch: 46  train \n","Loss: 0.0346  Acc: 98.8950\n","negative precision: 99.1959  recall: 99.0820\n","negative sensitivity: 99.0820  specificity: 98.5597\n","negative FPR: 1.4403  NPV: 98.3573\n","negative TP: 1727.0\n","negative TN: 958.0\n","negative FP: 14.0\n","negative FN: 16.0\n","positive precision: 98.3573  recall: 98.5597\n","positive sensitivity: 98.5597  specificity: 99.0820\n","positive FPR: 0.9180  NPV: 99.1959\n","positive TP: 958.0\n","positive TN: 1727.0\n","positive FP: 16.0\n","positive FN: 14.0\n","\n","\n","Epoch: 46     val index of 50 minibatch: 1      time used: 10.987670421600342\n","minibatch AVG loss: 0.10931763728280203\n","\n","Epoch: 46  val \n","Loss: 0.2126  Acc: 94.3953\n","negative precision: 94.2094  recall: 97.2414\n","negative sensitivity: 97.2414  specificity: 89.3004\n","negative FPR: 10.6996  NPV: 94.7598\n","negative TP: 423.0\n","negative TN: 217.0\n","negative FP: 26.0\n","negative FN: 12.0\n","positive precision: 94.7598  recall: 89.3004\n","positive sensitivity: 89.3004  specificity: 97.2414\n","positive FPR: 2.7586  NPV: 94.2094\n","positive TP: 217.0\n","positive TN: 423.0\n","positive FP: 12.0\n","positive FN: 26.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 50 minibatch: 1      time used: 20.076836109161377\n","minibatch AVG loss: 0.03433047728700331\n","Epoch: 47     train index of 50 minibatch: 2      time used: 19.671252012252808\n","minibatch AVG loss: 0.07582949974923395\n","Epoch: 47     train index of 50 minibatch: 3      time used: 19.435444593429565\n","minibatch AVG loss: 0.03964859622064978\n","Epoch: 47     train index of 50 minibatch: 4      time used: 19.320690393447876\n","minibatch AVG loss: 0.02985471243970096\n","Epoch: 47     train index of 50 minibatch: 5      time used: 19.929595947265625\n","minibatch AVG loss: 0.051506110400659964\n","Epoch: 47     train index of 50 minibatch: 6      time used: 19.642579793930054\n","minibatch AVG loss: 0.04132514661643654\n","\n","Epoch: 47  train \n","Loss: 0.0448  Acc: 98.3425\n","negative precision: 98.7931  recall: 98.6231\n","negative sensitivity: 98.6231  specificity: 97.8395\n","negative FPR: 2.1605  NPV: 97.5385\n","negative TP: 1719.0\n","negative TN: 951.0\n","negative FP: 21.0\n","negative FN: 24.0\n","positive precision: 97.5385  recall: 97.8395\n","positive sensitivity: 97.8395  specificity: 98.6231\n","positive FPR: 1.3769  NPV: 98.7931\n","positive TP: 951.0\n","positive TN: 1719.0\n","positive FP: 24.0\n","positive FN: 21.0\n","\n","\n","Epoch: 47     val index of 50 minibatch: 1      time used: 11.092040777206421\n","minibatch AVG loss: 0.14072500456226408\n","\n","Epoch: 47  val \n","Loss: 0.2078  Acc: 93.2153\n","negative precision: 94.1043  recall: 95.4023\n","negative sensitivity: 95.4023  specificity: 89.3004\n","negative FPR: 10.6996  NPV: 91.5612\n","negative TP: 415.0\n","negative TN: 217.0\n","negative FP: 26.0\n","negative FN: 20.0\n","positive precision: 91.5612  recall: 89.3004\n","positive sensitivity: 89.3004  specificity: 95.4023\n","positive FPR: 4.5977  NPV: 94.1043\n","positive TP: 217.0\n","positive TN: 415.0\n","positive FP: 20.0\n","positive FN: 26.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 50 minibatch: 1      time used: 20.50409960746765\n","minibatch AVG loss: 0.02382262550177984\n","Epoch: 48     train index of 50 minibatch: 2      time used: 19.3595449924469\n","minibatch AVG loss: 0.0324558732972946\n","Epoch: 48     train index of 50 minibatch: 3      time used: 19.34329628944397\n","minibatch AVG loss: 0.03420134775107726\n","Epoch: 48     train index of 50 minibatch: 4      time used: 19.48148465156555\n","minibatch AVG loss: 0.02603296412155032\n","Epoch: 48     train index of 50 minibatch: 5      time used: 19.28391456604004\n","minibatch AVG loss: 0.03779993775882758\n","Epoch: 48     train index of 50 minibatch: 6      time used: 19.492489337921143\n","minibatch AVG loss: 0.012985955172916874\n","\n","Epoch: 48  train \n","Loss: 0.0309  Acc: 99.0055\n","negative precision: 99.3103  recall: 99.1394\n","negative sensitivity: 99.1394  specificity: 98.7654\n","negative FPR: 1.2346  NPV: 98.4615\n","negative TP: 1728.0\n","negative TN: 960.0\n","negative FP: 12.0\n","negative FN: 15.0\n","positive precision: 98.4615  recall: 98.7654\n","positive sensitivity: 98.7654  specificity: 99.1394\n","positive FPR: 0.8606  NPV: 99.3103\n","positive TP: 960.0\n","positive TN: 1728.0\n","positive FP: 15.0\n","positive FN: 12.0\n","\n","\n","Epoch: 48     val index of 50 minibatch: 1      time used: 11.08265495300293\n","minibatch AVG loss: 0.15749401064633275\n","\n","Epoch: 48  val \n","Loss: 0.2525  Acc: 93.0678\n","negative precision: 93.4978  recall: 95.8621\n","negative sensitivity: 95.8621  specificity: 88.0658\n","negative FPR: 11.9342  NPV: 92.2414\n","negative TP: 417.0\n","negative TN: 214.0\n","negative FP: 29.0\n","negative FN: 18.0\n","positive precision: 92.2414  recall: 88.0658\n","positive sensitivity: 88.0658  specificity: 95.8621\n","positive FPR: 4.1379  NPV: 93.4978\n","positive TP: 214.0\n","positive TN: 417.0\n","positive FP: 18.0\n","positive FN: 29.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 50 minibatch: 1      time used: 20.251092195510864\n","minibatch AVG loss: 0.032325215952005236\n","Epoch: 49     train index of 50 minibatch: 2      time used: 20.1506667137146\n","minibatch AVG loss: 0.020237118806689977\n","Epoch: 49     train index of 50 minibatch: 3      time used: 19.972031354904175\n","minibatch AVG loss: 0.03810504918103106\n","Epoch: 49     train index of 50 minibatch: 4      time used: 19.561352014541626\n","minibatch AVG loss: 0.031800777898170055\n","Epoch: 49     train index of 50 minibatch: 5      time used: 20.03231167793274\n","minibatch AVG loss: 0.030701784844277425\n","Epoch: 49     train index of 50 minibatch: 6      time used: 19.244616508483887\n","minibatch AVG loss: 0.03807204112526961\n","\n","Epoch: 49  train \n","Loss: 0.0328  Acc: 98.9319\n","negative precision: 99.1963  recall: 99.1394\n","negative sensitivity: 99.1394  specificity: 98.5597\n","negative FPR: 1.4403  NPV: 98.4584\n","negative TP: 1728.0\n","negative TN: 958.0\n","negative FP: 14.0\n","negative FN: 15.0\n","positive precision: 98.4584  recall: 98.5597\n","positive sensitivity: 98.5597  specificity: 99.1394\n","positive FPR: 0.8606  NPV: 99.1963\n","positive TP: 958.0\n","positive TN: 1728.0\n","positive FP: 15.0\n","positive FN: 14.0\n","\n","\n","Epoch: 49     val index of 50 minibatch: 1      time used: 11.096786260604858\n","minibatch AVG loss: 0.17373327983092168\n","\n","Epoch: 49  val \n","Loss: 0.1939  Acc: 93.9528\n","negative precision: 95.8140  recall: 94.7126\n","negative sensitivity: 94.7126  specificity: 92.5926\n","negative FPR: 7.4074  NPV: 90.7258\n","negative TP: 412.0\n","negative TN: 225.0\n","negative FP: 18.0\n","negative FN: 23.0\n","positive precision: 90.7258  recall: 92.5926\n","positive sensitivity: 92.5926  specificity: 94.7126\n","positive FPR: 5.2874  NPV: 95.8140\n","positive TP: 225.0\n","positive TN: 412.0\n","positive FP: 23.0\n","positive FN: 18.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 50 minibatch: 1      time used: 19.817981481552124\n","minibatch AVG loss: 0.024553356253891254\n","Epoch: 50     train index of 50 minibatch: 2      time used: 19.381219387054443\n","minibatch AVG loss: 0.0473055543191731\n","Epoch: 50     train index of 50 minibatch: 3      time used: 19.398573875427246\n","minibatch AVG loss: 0.029792387510533445\n","Epoch: 50     train index of 50 minibatch: 4      time used: 19.15576148033142\n","minibatch AVG loss: 0.017112761068274265\n","Epoch: 50     train index of 50 minibatch: 5      time used: 19.412962675094604\n","minibatch AVG loss: 0.061441653546644374\n","Epoch: 50     train index of 50 minibatch: 6      time used: 19.158770322799683\n","minibatch AVG loss: 0.0341993655601982\n","\n","Epoch: 50  train \n","Loss: 0.0385  Acc: 98.8214\n","negative precision: 99.1384  recall: 99.0247\n","negative sensitivity: 99.0247  specificity: 98.4568\n","negative FPR: 1.5432  NPV: 98.2546\n","negative TP: 1726.0\n","negative TN: 957.0\n","negative FP: 15.0\n","negative FN: 17.0\n","positive precision: 98.2546  recall: 98.4568\n","positive sensitivity: 98.4568  specificity: 99.0247\n","positive FPR: 0.9753  NPV: 99.1384\n","positive TP: 957.0\n","positive TN: 1726.0\n","positive FP: 17.0\n","positive FN: 15.0\n","\n","\n","Epoch: 50     val index of 50 minibatch: 1      time used: 11.05112361907959\n","minibatch AVG loss: 0.19670301024139916\n","\n","Epoch: 50  val \n","Loss: 0.2188  Acc: 92.7729\n","negative precision: 94.4700  recall: 94.2529\n","negative sensitivity: 94.2529  specificity: 90.1235\n","negative FPR: 9.8765  NPV: 89.7541\n","negative TP: 410.0\n","negative TN: 219.0\n","negative FP: 24.0\n","negative FN: 25.0\n","positive precision: 89.7541  recall: 90.1235\n","positive sensitivity: 90.1235  specificity: 94.2529\n","positive FPR: 5.7471  NPV: 94.4700\n","positive TP: 219.0\n","positive TN: 410.0\n","positive FP: 25.0\n","positive FN: 24.0\n","\n","\n","\n","Training complete in 126m 31s\n","Best epoch idx:  46\n","Best epoch train Acc: 98.895028\n","Best epoch val Acc: 94.395280\n","negative precision: 94.2094  recall: 97.2414\n","negative sensitivity: 97.2414  specificity: 89.3004\n","negative FPR: 10.6996  NPV: 94.7598\n","positive precision: 94.7598  recall: 89.3004\n","positive sensitivity: 89.3004  specificity: 97.2414\n","positive FPR: 2.7586  NPV: 94.2094\n","model trained by GPU (idx:0) has been saved at  /home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_401_PT_lf25_b8_k4.pth\n","finished\n","\n","============================================================\n","Processing finished !\n","start time: 2021_10_28  14:27:11\n","end time: 2021_10_28  16:33:49\n","source: e3c8fe55b95c\n","\n","Preparing the email with auto log file :\n"," Train__2021_10_28-14_27_11_log \n","as  .rtf\n","processing log catched\n","server log catched\n","发送log邮件成功，title:  [e3c8fe55b95c  LOG] Train__2021_10_28-14_27_11_log\n","如果没有，看看垃圾箱:)\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"e1WMm89oWBO-","outputId":"8e57c553-4de8-452b-d32e-6425c9cd19dd"},"source":["!python Test.py --model_idx Hybrid2_384_401_PT_lf25_b8_k4 --enable_attention_check --dataroot /data/pancreatic-cancer-project/dataset --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/runs"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[0.1320, 0.0722]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : Hybrid2_384_401_PT_lf25_b8_k4\n","*********************************setting*************************************\n","Namespace(att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=None, cls_token_off=False, dataroot='/data/pancreatic-cancer-project/dataset', draw_root='/home/pancreatic-cancer-project/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='Hybrid2_384_401_PT_lf25_b8_k4', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 80 minibatch: 1      time used: 2.703792095184326\n","minibatch AVG loss: 0.08708093302016096\n","Epoch: test     test index of 80 minibatch: 2      time used: 2.4501149654388428\n","minibatch AVG loss: 0.19357508910193247\n","Epoch: test     test index of 80 minibatch: 3      time used: 2.4732160568237305\n","minibatch AVG loss: 0.11508381818191538\n","Epoch: test     test index of 80 minibatch: 4      time used: 2.4538769721984863\n","minibatch AVG loss: 0.02016331316647211\n","Epoch: test     test index of 80 minibatch: 5      time used: 2.498647928237915\n","minibatch AVG loss: 0.000527132938577779\n","Epoch: test     test index of 80 minibatch: 6      time used: 2.5203981399536133\n","minibatch AVG loss: 0.04457902932244906\n","Epoch: test     test index of 80 minibatch: 7      time used: 2.5103869438171387\n","minibatch AVG loss: 0.057843198958426004\n","Epoch: test     test index of 80 minibatch: 8      time used: 2.475436210632324\n","minibatch AVG loss: 0.2526578048918964\n","Epoch: test     test index of 80 minibatch: 9      time used: 2.4765737056732178\n","minibatch AVG loss: 0.026256721939807902\n","Epoch: test     test index of 80 minibatch: 10      time used: 2.4709389209747314\n","minibatch AVG loss: 0.43834634251679744\n","\n","Epoch:  test \n","Loss: 0.1575  Acc: 95.8678\n","negative precision: 96.1887  recall: 97.4265\n","negative sensitivity: 97.4265  specificity: 93.0693\n","negative FPR: 6.9307  NPV: 95.2703\n","negative TP: 530.0\n","negative TN: 282.0\n","negative FP: 21.0\n","negative FN: 14.0\n","positive precision: 95.2703  recall: 93.0693\n","positive sensitivity: 93.0693  specificity: 97.4265\n","positive FPR: 2.5735  NPV: 96.1887\n","positive TP: 282.0\n","positive TN: 530.0\n","positive FP: 14.0\n","positive FN: 21.0\n","\n","\n","Testing complete in 2m 32s\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"hQJaqjscRWbC","outputId":"459c7a1f-6924-4869-e632-c81cbc06eae7"},"source":["!python Train.py --model_idx Hybrid2_384_401_PT_lf25_b8_k5 --lr 0.00001 --lrf 0.25 --enable_notify --enable_tensorboard --Pre_Trained_model_path /home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_PreTrain_000.pth --dataroot /data/pancreatic-cancer-project/dataset/fold_5 --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/runs"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Notify is waiting for reboost\n","*****************LOG_Cache_2021_10_28_16_36*****************\n","notify started\n","notify_frontend reboosted!\n","log_root_path log\n","mail_user tum9598@163.com\n","default_reciving_list ['tum9598@163.com']\n","start monitoring:)\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path='/home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_PreTrain_000.pth', att_module='SimAM', attn_drop_rate=0.0, backbone_PT_off=False, batch_size=8, check_minibatch=None, cls_token_off=False, dataroot='/data/pancreatic-cancer-project/dataset/fold_5', draw_root='/home/pancreatic-cancer-project/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=True, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=-1, intake_epochs=0, lr=1e-05, lrf=0.25, model_idx='Hybrid2_384_401_PT_lf25_b8_k5', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, pos_embedding_off=False)\n","we dont have more GPU idx here, try to use gpu_idx=0\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[ 2.1666e-01, -4.7421e-01,  1.8033e-01,  3.0284e-01, -4.8657e-01,\n","         -6.5892e-01,  6.7286e-01, -9.4735e-01,  1.8332e-03,  1.1280e+00,\n","          6.0691e-01,  4.4678e-01,  1.0305e+00,  2.6081e-01, -8.9324e-01,\n","          9.0739e-01,  3.3736e-01, -8.4321e-01, -5.3484e-01, -2.6153e-01,\n","          1.1813e-01,  5.8210e-01, -9.1074e-02,  5.5711e-02, -5.0008e-01,\n","          5.0046e-01,  2.2023e-01,  3.8575e-01, -3.6419e-01,  1.8775e-01,\n","         -1.0013e+00,  9.7029e-01, -8.9606e-01,  5.8526e-01, -6.0324e-02,\n","          2.8680e-01, -1.7486e-01, -5.7358e-02, -2.3304e-02, -8.9619e-02,\n","         -5.2647e-01,  7.6940e-01,  4.0491e-01, -1.8638e-01,  1.2026e+00,\n","         -2.9995e-01, -3.0298e-01, -5.5280e-01, -3.2249e-01,  5.9502e-01,\n","         -4.3468e-01,  1.0191e+00,  1.4346e-01,  1.5864e-01,  7.4061e-01,\n","         -3.8455e-01, -1.1300e+00,  4.2022e-01, -7.5100e-01, -4.4431e-01,\n","         -3.2544e-01,  4.3934e-01,  2.9867e-01,  1.0853e-01,  4.0149e-01,\n","          4.8915e-01,  6.2100e-02, -7.2858e-01, -8.0314e-02,  6.3522e-02,\n","          9.2666e-01, -4.2381e-01, -3.6368e-01,  1.6887e-02, -5.2490e-01,\n","         -5.2767e-01, -2.1943e-01,  5.2008e-01,  4.3857e-01, -6.1164e-01,\n","         -4.1595e-01,  2.7936e-01,  7.3350e-01,  7.9244e-01, -1.7026e-01,\n","          1.6747e-01, -6.8064e-02, -7.3537e-02, -1.0140e+00,  8.4919e-02,\n","         -4.0062e-01,  1.6448e+00, -9.2639e-01,  2.0900e-01, -1.8306e-01,\n","          5.8141e-01,  3.8690e-01, -6.2016e-01,  4.9578e-01,  1.0685e+00,\n","          8.6109e-02,  1.3977e-01,  6.8784e-01, -8.0958e-01,  2.0807e-01,\n","         -4.6999e-01, -1.7971e-01, -8.4584e-02,  6.8367e-01,  8.3208e-01,\n","          5.2042e-01, -4.3107e-01, -4.5932e-01, -4.8616e-01, -4.6352e-01,\n","         -3.3450e-01,  4.8264e-01, -2.5343e-01,  4.8577e-02, -2.6356e-01,\n","          1.0537e+00, -1.1945e-01, -1.7415e+00, -5.0386e-01, -2.2265e-01,\n","          3.1367e-01, -1.4120e+00, -3.5089e-01, -1.9413e-01,  5.0706e-02,\n","          1.0555e+00,  1.0856e-01,  4.9621e-01, -3.9441e-01,  3.0980e-01,\n","          1.5954e-01, -2.2117e-01,  4.4933e-01, -1.4019e-01,  3.3464e-01,\n","         -8.0265e-01,  7.6930e-01,  3.9676e-01, -2.3813e-01,  5.8820e-01,\n","         -2.5222e-01, -2.2237e-01, -5.7166e-01, -6.9520e-01, -8.6945e-01,\n","         -1.9836e-01, -5.2389e-01, -6.6921e-01, -9.6664e-01, -2.1290e-01,\n","          3.6217e-02,  5.8212e-01,  7.6754e-01,  6.3949e-01, -7.3677e-01,\n","          1.2266e+00, -1.0001e-01, -2.8125e-01, -8.0921e-01,  1.1078e+00,\n","          1.0405e+00, -3.8854e-01,  5.2377e-01,  4.7812e-01, -6.1291e-02,\n","         -6.7650e-01, -9.9664e-01, -7.8526e-01, -2.5582e-01,  8.0009e-01,\n","          1.6076e-01,  1.3886e-01,  5.7681e-01,  3.2688e-01, -1.0707e+00,\n","         -7.5648e-01,  3.7256e-01,  7.4912e-01,  1.5014e-01,  5.6243e-01,\n","          6.6609e-01,  3.8102e-01,  4.9880e-01,  2.9567e-01,  1.2317e+00,\n","          2.2053e-01,  1.0838e-01, -3.2360e-01, -4.1344e-01,  2.6800e-01,\n","          1.6090e-01,  9.9983e-01,  7.1696e-01,  3.0113e-01,  1.4047e-01,\n","         -2.8635e-01, -2.6977e-02,  1.0585e+00, -4.0660e-01, -4.8512e-01,\n","         -5.6495e-01,  4.2269e-01, -4.4172e-01, -2.9341e-01,  8.9416e-02,\n","          5.7455e-01, -1.5858e-01,  1.9142e-01, -8.2919e-01, -1.1784e-01,\n","         -3.8307e-01, -8.3623e-01, -1.1778e+00,  1.0831e+00,  2.3893e-01,\n","          5.4679e-01,  2.3990e-01, -9.2425e-02,  5.3054e-01, -3.4389e-01,\n","         -1.4973e+00, -3.8203e-01, -4.5449e-01, -2.0671e-01, -1.8606e-02,\n","          6.9127e-01,  1.2140e-01, -7.5049e-01,  2.3656e-01, -9.5200e-02,\n","         -4.1982e-01,  4.5942e-01,  3.1451e-01, -4.4832e-01,  3.2117e-01,\n","          1.5423e-03,  2.6317e-01,  8.3795e-01,  6.1409e-01,  4.5812e-01,\n","         -4.3683e-01, -2.7957e-01,  1.1908e-01,  1.0032e-01,  2.6231e-02,\n","          4.7835e-03,  3.9014e-01,  2.5367e-02, -9.4333e-01,  2.7289e-01,\n","          1.3458e+00, -7.0671e-01, -4.3741e-01,  6.2262e-01, -4.7800e-01,\n","          4.2114e-02, -5.2731e-01,  1.4530e-01,  3.4526e-01, -4.0380e-01,\n","          8.0879e-01,  2.0872e-01, -3.1978e-01, -4.1021e-01,  3.0624e-02,\n","         -9.4838e-01,  1.8232e-01,  8.7393e-01, -2.8509e-01,  2.8806e-01,\n","         -1.0527e-01, -5.5985e-01, -2.3851e-01, -6.7235e-01, -6.8656e-01,\n","          6.0549e-01, -4.0970e-03,  8.3409e-01,  1.6456e-01,  1.7790e-02,\n","         -6.0855e-01, -3.1545e-02, -2.7620e-01,  4.7811e-01,  1.0174e+00,\n","          6.7161e-01,  5.8914e-01, -2.6104e-02,  1.1465e+00,  4.7396e-01,\n","          1.7520e-01, -5.3694e-01, -1.0094e+00,  6.0517e-01, -6.2272e-01,\n","         -1.5679e-01, -8.0598e-01, -8.0097e-02,  1.4145e+00, -1.2229e+00,\n","         -8.1610e-03, -4.1985e-01, -8.1593e-01,  6.1630e-01, -6.2003e-01,\n","         -5.1867e-01, -1.3416e-01,  1.1829e-01, -6.4824e-01,  8.1688e-01,\n","          3.5813e-01, -8.2212e-01, -5.4484e-01,  1.0119e-01, -2.3940e-01,\n","          1.0492e+00, -3.2231e-01,  8.8072e-01, -2.0386e-01,  3.4266e-01,\n","         -2.1809e-04, -4.3811e-01, -1.4643e-01, -1.4370e-01,  2.2846e-01,\n","         -4.9339e-01, -3.7553e-02,  8.9154e-01,  1.3907e-01,  9.4544e-02,\n","          2.1967e-01,  1.0154e+00,  4.4208e-01, -4.6395e-01, -9.0063e-01,\n","         -6.6472e-01,  3.4370e-01, -1.0131e+00, -1.3204e+00, -1.0094e+00,\n","         -5.9364e-01, -4.8717e-01,  4.4058e-01,  5.4193e-01,  1.6144e-01,\n","         -7.4380e-01,  1.9032e-01,  2.3118e-02,  2.8254e-01, -3.4857e-01,\n","          1.1796e-01,  4.1222e-01, -1.8240e-01, -2.9825e-01,  1.6421e-01,\n","         -8.3378e-02,  1.9388e-01,  6.3008e-01, -6.3716e-01,  1.5108e+00,\n","          9.1688e-01,  5.8826e-01, -3.2557e-01,  3.7183e-01, -1.6559e+00,\n","         -1.1680e-01, -8.7413e-01, -3.1305e-01,  3.6092e-01,  6.5580e-01,\n","         -8.9679e-01, -5.7921e-01,  1.0326e-01,  1.0422e+00, -5.1449e-01,\n","          9.4280e-01,  4.0336e-01,  2.6656e-01, -3.8148e-01,  1.4276e-01,\n","          1.5177e-02, -9.5266e-01, -5.7478e-01, -7.0650e-01, -6.0620e-01,\n","          1.6522e-01,  7.8339e-01,  2.7598e-02,  6.0522e-01,  6.7714e-02,\n","         -2.0373e-01,  5.2184e-01, -2.0795e-01, -1.4365e-01,  6.2235e-01,\n","         -2.1461e-01,  9.8679e-02,  4.0264e-01,  9.4615e-01, -7.1391e-01,\n","         -5.0820e-02, -5.5782e-01,  8.4015e-01, -2.4695e-01,  2.0569e-01,\n","         -1.0167e+00, -4.0228e-01,  1.1637e+00, -2.4513e-01,  9.5664e-02,\n","          2.8576e-01,  1.1327e+00,  1.8957e-01, -7.1850e-01,  4.4865e-01,\n","          3.5293e-01,  4.0419e-01,  1.1109e+00,  1.3175e+00,  2.4401e-02,\n","          3.7667e-01, -2.5981e-01, -2.6797e-01,  1.5575e+00,  4.9660e-02,\n","          1.1472e-01, -1.1175e-02,  3.6860e-01,  6.4207e-01, -1.0836e-04,\n","         -6.2095e-01,  2.5976e-01,  3.8648e-01,  1.0039e+00,  5.3080e-01,\n","         -9.1269e-01,  1.0460e+00, -3.9773e-01,  4.7867e-01,  3.3357e-01,\n","          1.6247e-01, -8.7713e-03,  7.6417e-01, -1.5434e+00,  3.6742e-01,\n","         -1.7368e-01, -1.3163e+00,  1.3577e+00, -1.0784e-01, -1.1486e-01,\n","          1.2644e+00, -3.4705e-01,  2.6563e-01,  2.8580e-01, -2.3911e-01,\n","         -5.8467e-01, -4.9897e-01,  2.1585e-01,  1.4748e+00, -4.4899e-01,\n","          8.8774e-01, -1.6235e-01, -2.7376e-01, -7.1224e-01, -1.3764e-01,\n","          3.6147e-01,  6.7793e-01,  6.9520e-01,  2.7143e-01,  5.9280e-01,\n","          5.4819e-01,  4.9856e-01,  1.2604e+00,  2.9709e-01,  2.6040e-01,\n","         -5.8097e-01,  1.5439e-01,  8.0847e-01, -3.0217e-01,  6.4507e-01,\n","          2.2922e-02,  2.3991e-01,  1.2384e+00, -2.2171e-01, -7.0928e-03,\n","          1.9838e-01,  8.3678e-01, -8.5981e-01, -2.8568e-01,  1.9095e-01,\n","         -5.9930e-01,  3.4530e-01,  1.7907e-01, -5.8533e-01, -3.9108e-01,\n","          1.3534e-01, -3.9534e-01,  2.9089e-01,  1.1026e-01,  2.2106e-01,\n","         -8.9309e-02, -3.6811e-01, -2.6436e-01, -4.2888e-01, -1.5628e-01,\n","          3.5117e-01,  5.9574e-01,  1.6612e-01, -3.4786e-01, -2.6749e-01,\n","         -8.0357e-02,  9.3936e-01, -1.1385e+00,  6.2440e-01,  9.5759e-01,\n","         -4.1871e-01, -3.5787e-01, -3.8892e-01,  4.0981e-01, -3.9806e-01,\n","         -1.7236e-01,  2.1272e-01,  3.7206e-01,  7.2732e-01, -4.1594e-01,\n","          4.6727e-01, -8.8528e-01, -9.8807e-01, -1.5185e-01,  4.2987e-01,\n","         -1.7785e-01, -5.0763e-01, -8.4378e-01,  6.2516e-01,  4.7258e-01,\n","          7.2423e-01,  8.7806e-01,  4.1242e-01, -1.4148e-01, -5.0299e-01,\n","          7.8564e-01,  7.9717e-02, -6.8691e-02, -2.9585e-01, -3.4100e-01,\n","          5.4962e-01,  6.2462e-02, -1.0496e+00,  3.7820e-01,  9.5406e-01,\n","         -8.6697e-01,  3.3542e-01,  1.3459e-01,  1.1273e-01, -6.4730e-01,\n","         -3.3621e-01,  2.6752e-01,  2.4378e-01, -2.2441e-01,  2.6785e-01,\n","         -5.9391e-01, -4.1546e-01, -7.9487e-01, -2.9756e-01,  5.7530e-01,\n","          7.3612e-01, -1.3985e+00,  1.2317e+00,  7.2213e-01, -5.8227e-01,\n","         -1.0673e-01,  5.7164e-01,  1.5425e-01,  1.0895e+00,  1.2320e+00,\n","         -2.9984e-01, -8.0997e-01, -8.0534e-01,  2.7615e-01, -1.0259e-01,\n","         -2.0853e-01,  7.6011e-01, -2.0839e-01, -1.7049e-01, -8.2152e-02,\n","         -7.6952e-01,  5.5893e-01, -4.5167e-02,  2.1071e-01, -1.6695e-01,\n","         -9.4379e-01,  7.0505e-01, -1.0129e+00, -1.4160e+00, -9.1469e-01,\n","          6.5794e-02,  5.9263e-02,  4.3184e-01,  7.7075e-01,  1.1557e+00,\n","         -1.5775e-01, -6.4064e-01, -6.5827e-01, -8.9281e-01,  1.2247e+00,\n","         -7.1033e-02,  1.5717e-01,  2.5382e-01, -5.3365e-01, -4.3624e-01,\n","          8.6912e-02, -2.6298e-01,  1.1626e-01,  8.7539e-01, -1.9012e-01,\n","         -6.6729e-01, -2.3464e-01,  8.6478e-01,  7.2786e-01,  3.3397e-01,\n","         -1.6017e-01, -5.0254e-01, -7.3996e-02, -3.7829e-01, -1.4741e+00,\n","         -8.3302e-01,  3.7283e-01,  2.1826e-01,  2.5692e-02, -6.5851e-01,\n","         -2.9597e-01, -3.3820e-01,  1.3639e+00, -7.7488e-01,  5.1539e-01,\n","         -5.7388e-01, -7.8878e-02,  1.4294e-02, -1.1069e+00, -3.7966e-01,\n","         -8.9033e-01, -1.2349e+00,  8.7038e-01, -9.4274e-01,  7.7459e-01,\n","          2.9489e-03, -5.5035e-01, -4.9410e-01,  1.6765e-01, -8.5204e-01,\n","         -4.2691e-01, -1.8325e-01,  1.5029e+00,  5.1469e-01,  5.7784e-01,\n","         -6.3793e-01, -6.1114e-01, -4.0964e-02, -8.2097e-02, -1.5212e-01,\n","         -1.9229e-01,  3.4257e-01,  3.9545e-02, -9.6416e-02, -1.1933e-02,\n","         -9.0584e-01,  8.6432e-01, -3.7954e-01, -1.8582e-01,  5.3733e-01,\n","         -1.2165e-01,  2.3117e-01,  4.4549e-01,  9.0628e-02, -3.9202e-01,\n","          5.9542e-01, -6.2026e-01,  1.7630e-01, -2.6233e-01, -3.4569e-01,\n","          4.4749e-01, -1.3701e-01,  5.9270e-02, -8.8871e-01, -7.8990e-01,\n","         -8.5382e-01, -2.1154e-01, -1.2771e+00, -9.5926e-03,  8.8370e-01,\n","          7.4744e-01,  6.9917e-01,  1.4780e-01, -2.1493e-01,  3.7231e-01,\n","          9.2370e-02,  1.0832e+00,  3.9699e-01,  1.0125e-01,  7.1224e-01,\n","          6.8133e-01, -8.9262e-01, -1.1712e+00,  2.6976e-01,  5.7062e-01,\n","          4.7347e-01, -9.0269e-01, -7.5984e-02,  1.9798e-02,  4.9426e-01,\n","         -6.8980e-01,  6.2834e-01,  3.1884e-01,  2.1181e-01,  2.9812e-02,\n","         -1.4362e-01,  6.0778e-01,  9.0836e-01,  2.4475e-01,  2.1145e-01,\n","         -3.1287e-01, -1.2203e+00, -2.6419e-01, -4.4693e-01, -4.4690e-02,\n","          6.8615e-01,  4.1714e-01,  5.6715e-01,  1.3130e-02,  4.7644e-01,\n","         -1.9041e-01, -2.4661e-01,  3.8793e-01, -1.3892e-01, -5.6922e-01,\n","         -3.8136e-01,  7.2892e-01, -6.4470e-01, -5.5313e-01,  6.1247e-01,\n","         -1.0014e-01,  4.0849e-01, -1.9521e-01, -5.9512e-01, -6.4988e-02,\n","         -2.7915e-01,  5.3021e-01, -1.6933e-01, -4.2548e-01,  2.4398e-01,\n","         -2.7639e-01,  5.9434e-01,  1.4690e+00,  4.8321e-01,  1.6484e-01,\n","          6.0448e-02, -3.8277e-02,  1.6056e-01,  7.0794e-01, -2.1264e-01,\n","          2.2819e-01,  6.3278e-01,  1.9960e-02, -1.7677e-01,  1.8472e-01,\n","         -3.5790e-01, -2.3733e-01,  1.1483e-02, -9.6668e-01, -5.1292e-01,\n","          1.6635e-01,  1.5496e-01,  1.5968e-01, -6.0187e-01,  7.4434e-01,\n","          2.1636e-01, -1.9631e-02, -1.2121e+00, -1.9568e-01,  4.4568e-01,\n","         -5.8059e-01,  5.7306e-01, -3.5325e-01,  1.2262e+00,  8.5117e-01,\n","         -1.2517e+00,  1.5711e-01, -4.8338e-01, -8.9890e-01, -5.7489e-01,\n","          6.4357e-01, -7.7923e-01,  3.3649e-01,  1.3424e-01, -1.1829e-01,\n","         -2.0373e-01, -2.7749e-01, -1.3068e+00, -5.0447e-01, -4.9479e-01,\n","         -6.8277e-01,  5.1541e-01,  9.5475e-01, -1.2515e-01,  3.1012e-01,\n","         -2.8129e-01,  1.7821e+00,  8.9728e-01, -3.3743e-01,  2.3577e-01,\n","         -1.7557e-01, -1.1398e+00,  9.9451e-01, -9.4415e-01, -6.0988e-01,\n","          1.3445e-01, -3.4160e-01,  5.0410e-01, -3.7131e-01, -1.6956e-01,\n","          3.4758e-01, -4.7118e-01, -4.7098e-01, -2.7183e-01,  8.8055e-01,\n","          1.4070e-01,  2.8334e-01, -2.1244e-01, -8.2920e-02,  6.8698e-01,\n","         -1.3666e+00, -8.1465e-01,  3.3053e-01,  2.8022e-02,  1.4109e-01,\n","         -7.3691e-01,  3.9807e-01,  9.1929e-02, -5.7754e-01, -3.9033e-02,\n","          8.0497e-02, -1.2178e-01, -2.4387e-01,  4.7647e-01, -1.0630e-01,\n","         -1.0826e-01, -2.1110e-03,  3.7709e-01, -1.4875e-01, -1.1374e+00,\n","         -7.6128e-01, -3.7458e-02, -1.8034e-01, -3.6584e-01,  2.2185e-01,\n","         -4.3772e-01, -7.1709e-01,  5.8107e-01,  1.8911e-02,  2.8151e-01,\n","         -5.4206e-01,  8.0032e-01,  9.6944e-01, -2.8757e-01, -1.7112e-01,\n","         -6.1564e-01,  6.8253e-01,  1.6584e-01,  7.0866e-01, -6.5146e-01,\n","         -8.7727e-01,  1.8078e-01,  5.9838e-01,  7.1257e-01,  4.9618e-01,\n","          3.7922e-01,  9.9859e-01,  6.3601e-02,  1.6859e-01,  3.9038e-01,\n","          3.1408e-01, -5.3799e-01,  5.2695e-01, -7.0191e-01, -2.1992e-01,\n","         -1.0359e+00, -6.0567e-01,  2.2677e-01,  1.7703e-01, -1.1606e+00,\n","          2.3550e-01,  5.5554e-01,  1.9281e+00,  1.9194e-01, -8.5557e-01,\n","          4.5519e-02,  4.3140e-01, -1.1850e+00,  2.7465e-01, -3.5207e-01,\n","         -9.3445e-01, -2.0982e-01,  9.0532e-01, -1.1775e+00,  9.8909e-01,\n","         -7.2240e-01,  5.4872e-03,  6.5173e-01,  9.2605e-01,  3.5818e-01,\n","         -7.0264e-02, -5.3810e-01,  6.0329e-01,  7.2034e-02,  4.8261e-01,\n","         -7.4249e-02, -3.4379e-01, -8.3596e-01, -6.9483e-01, -1.6042e-01,\n","         -3.2902e-01, -2.7382e-01, -1.1209e+00, -3.7440e-01, -1.3012e+00,\n","         -1.0944e-02,  6.2558e-01, -2.1302e-01, -1.5804e-01,  1.0750e+00,\n","          1.9843e-01,  1.1140e+00, -1.3254e-01, -2.3597e-01,  6.4282e-01,\n","         -1.4200e-01,  6.1646e-01,  6.9602e-01,  1.4218e-01, -6.0943e-01,\n","         -2.3569e-01,  2.2932e-01,  2.0487e-01, -1.4491e+00, -1.1249e-01,\n","         -8.1519e-01,  2.7957e-01,  2.0120e-01,  8.3839e-01, -9.2751e-01,\n","          4.0007e-01,  1.0488e-02, -5.1090e-01, -4.0092e-02,  4.4054e-02,\n","         -8.8771e-03,  4.2877e-01, -6.0787e-02, -3.7034e-01, -4.1881e-01,\n","          6.2871e-01, -1.8778e-01, -4.2418e-01,  1.6102e-01, -9.5770e-02,\n","         -2.3623e-01,  4.4124e-01, -5.5353e-01, -2.9374e-01, -1.1476e-01,\n","         -2.6253e-01, -4.5752e-01,  9.6869e-01, -4.6147e-04, -5.1060e-01,\n","         -9.5821e-01,  1.0444e+00,  1.0781e+00,  8.4808e-01, -3.7346e-01,\n","          2.9457e-01,  4.7508e-02,  4.4786e-01,  1.0769e+00, -1.7285e-02,\n","         -4.1817e-01,  1.7504e-01, -5.0107e-01, -4.1750e-01, -7.8469e-02,\n","         -6.2529e-02,  7.1313e-01,  3.7026e-01, -5.6427e-01,  9.2629e-03]],\n","       grad_fn=<AddmmBackward>)\n","model is ready now!\n","pretrain model loaded\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 192, 192]           9,408\n","       BatchNorm2d-2         [-1, 64, 192, 192]             128\n","              ReLU-3         [-1, 64, 192, 192]               0\n","         MaxPool2d-4           [-1, 64, 96, 96]               0\n","            Conv2d-5           [-1, 64, 96, 96]           4,096\n","       BatchNorm2d-6           [-1, 64, 96, 96]             128\n","              ReLU-7           [-1, 64, 96, 96]               0\n","            Conv2d-8           [-1, 64, 96, 96]          36,864\n","       BatchNorm2d-9           [-1, 64, 96, 96]             128\n","             ReLU-10           [-1, 64, 96, 96]               0\n","           Conv2d-11          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-12          [-1, 256, 96, 96]             512\n","             ReLU-13          [-1, 256, 96, 96]               0\n","           Conv2d-14          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-15          [-1, 256, 96, 96]             512\n","             ReLU-16          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-17          [-1, 256, 96, 96]               0\n","           Conv2d-18           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-19           [-1, 64, 96, 96]             128\n","             ReLU-20           [-1, 64, 96, 96]               0\n","           Conv2d-21           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-22           [-1, 64, 96, 96]             128\n","             ReLU-23           [-1, 64, 96, 96]               0\n","           Conv2d-24          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-25          [-1, 256, 96, 96]             512\n","             ReLU-26          [-1, 256, 96, 96]               0\n","             ReLU-27          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-28          [-1, 256, 96, 96]               0\n","           Conv2d-29           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-30           [-1, 64, 96, 96]             128\n","             ReLU-31           [-1, 64, 96, 96]               0\n","           Conv2d-32           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-33           [-1, 64, 96, 96]             128\n","             ReLU-34           [-1, 64, 96, 96]               0\n","           Conv2d-35          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-36          [-1, 256, 96, 96]             512\n","             ReLU-37          [-1, 256, 96, 96]               0\n","             ReLU-38          [-1, 256, 96, 96]               0\n","Bottleneck_block_constructor-39          [-1, 256, 96, 96]               0\n","           Conv2d-40          [-1, 128, 48, 48]          32,768\n","      BatchNorm2d-41          [-1, 128, 48, 48]             256\n","             ReLU-42          [-1, 128, 48, 48]               0\n","           Conv2d-43          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-44          [-1, 128, 48, 48]             256\n","             ReLU-45          [-1, 128, 48, 48]               0\n","           Conv2d-46          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-47          [-1, 512, 48, 48]           1,024\n","             ReLU-48          [-1, 512, 48, 48]               0\n","           Conv2d-49          [-1, 512, 48, 48]         131,072\n","      BatchNorm2d-50          [-1, 512, 48, 48]           1,024\n","             ReLU-51          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-52          [-1, 512, 48, 48]               0\n","           Conv2d-53          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-54          [-1, 128, 48, 48]             256\n","             ReLU-55          [-1, 128, 48, 48]               0\n","           Conv2d-56          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-57          [-1, 128, 48, 48]             256\n","             ReLU-58          [-1, 128, 48, 48]               0\n","           Conv2d-59          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-60          [-1, 512, 48, 48]           1,024\n","             ReLU-61          [-1, 512, 48, 48]               0\n","             ReLU-62          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-63          [-1, 512, 48, 48]               0\n","           Conv2d-64          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-65          [-1, 128, 48, 48]             256\n","             ReLU-66          [-1, 128, 48, 48]               0\n","           Conv2d-67          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-68          [-1, 128, 48, 48]             256\n","             ReLU-69          [-1, 128, 48, 48]               0\n","           Conv2d-70          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-71          [-1, 512, 48, 48]           1,024\n","             ReLU-72          [-1, 512, 48, 48]               0\n","             ReLU-73          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-74          [-1, 512, 48, 48]               0\n","           Conv2d-75          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-76          [-1, 128, 48, 48]             256\n","             ReLU-77          [-1, 128, 48, 48]               0\n","           Conv2d-78          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-79          [-1, 128, 48, 48]             256\n","             ReLU-80          [-1, 128, 48, 48]               0\n","           Conv2d-81          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-82          [-1, 512, 48, 48]           1,024\n","             ReLU-83          [-1, 512, 48, 48]               0\n","             ReLU-84          [-1, 512, 48, 48]               0\n","Bottleneck_block_constructor-85          [-1, 512, 48, 48]               0\n","           Conv2d-86          [-1, 256, 24, 24]         131,072\n","      BatchNorm2d-87          [-1, 256, 24, 24]             512\n","             ReLU-88          [-1, 256, 24, 24]               0\n","           Conv2d-89          [-1, 256, 24, 24]         589,824\n","      BatchNorm2d-90          [-1, 256, 24, 24]             512\n","             ReLU-91          [-1, 256, 24, 24]               0\n","           Conv2d-92         [-1, 1024, 24, 24]         262,144\n","      BatchNorm2d-93         [-1, 1024, 24, 24]           2,048\n","             ReLU-94         [-1, 1024, 24, 24]               0\n","           Conv2d-95         [-1, 1024, 24, 24]         524,288\n","      BatchNorm2d-96         [-1, 1024, 24, 24]           2,048\n","             ReLU-97         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-98         [-1, 1024, 24, 24]               0\n","           Conv2d-99          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-100          [-1, 256, 24, 24]             512\n","            ReLU-101          [-1, 256, 24, 24]               0\n","          Conv2d-102          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-103          [-1, 256, 24, 24]             512\n","            ReLU-104          [-1, 256, 24, 24]               0\n","          Conv2d-105         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-106         [-1, 1024, 24, 24]           2,048\n","            ReLU-107         [-1, 1024, 24, 24]               0\n","            ReLU-108         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-109         [-1, 1024, 24, 24]               0\n","          Conv2d-110          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-111          [-1, 256, 24, 24]             512\n","            ReLU-112          [-1, 256, 24, 24]               0\n","          Conv2d-113          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-114          [-1, 256, 24, 24]             512\n","            ReLU-115          [-1, 256, 24, 24]               0\n","          Conv2d-116         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-117         [-1, 1024, 24, 24]           2,048\n","            ReLU-118         [-1, 1024, 24, 24]               0\n","            ReLU-119         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-120         [-1, 1024, 24, 24]               0\n","          Conv2d-121          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-122          [-1, 256, 24, 24]             512\n","            ReLU-123          [-1, 256, 24, 24]               0\n","          Conv2d-124          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-125          [-1, 256, 24, 24]             512\n","            ReLU-126          [-1, 256, 24, 24]               0\n","          Conv2d-127         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-128         [-1, 1024, 24, 24]           2,048\n","            ReLU-129         [-1, 1024, 24, 24]               0\n","            ReLU-130         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-131         [-1, 1024, 24, 24]               0\n","          Conv2d-132          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-133          [-1, 256, 24, 24]             512\n","            ReLU-134          [-1, 256, 24, 24]               0\n","          Conv2d-135          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-136          [-1, 256, 24, 24]             512\n","            ReLU-137          [-1, 256, 24, 24]               0\n","          Conv2d-138         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-139         [-1, 1024, 24, 24]           2,048\n","            ReLU-140         [-1, 1024, 24, 24]               0\n","            ReLU-141         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-142         [-1, 1024, 24, 24]               0\n","          Conv2d-143          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-144          [-1, 256, 24, 24]             512\n","            ReLU-145          [-1, 256, 24, 24]               0\n","          Conv2d-146          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-147          [-1, 256, 24, 24]             512\n","            ReLU-148          [-1, 256, 24, 24]               0\n","          Conv2d-149         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-150         [-1, 1024, 24, 24]           2,048\n","            ReLU-151         [-1, 1024, 24, 24]               0\n","            ReLU-152         [-1, 1024, 24, 24]               0\n","Bottleneck_block_constructor-153         [-1, 1024, 24, 24]               0\n","          Conv2d-154          [-1, 512, 12, 12]         524,288\n","     BatchNorm2d-155          [-1, 512, 12, 12]           1,024\n","            ReLU-156          [-1, 512, 12, 12]               0\n","          Conv2d-157          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-158          [-1, 512, 12, 12]           1,024\n","            ReLU-159          [-1, 512, 12, 12]               0\n","          Conv2d-160         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-161         [-1, 2048, 12, 12]           4,096\n","            ReLU-162         [-1, 2048, 12, 12]               0\n","          Conv2d-163         [-1, 2048, 12, 12]       2,097,152\n","     BatchNorm2d-164         [-1, 2048, 12, 12]           4,096\n","            ReLU-165         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-166         [-1, 2048, 12, 12]               0\n","          Conv2d-167          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-168          [-1, 512, 12, 12]           1,024\n","            ReLU-169          [-1, 512, 12, 12]               0\n","          Conv2d-170          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-171          [-1, 512, 12, 12]           1,024\n","            ReLU-172          [-1, 512, 12, 12]               0\n","          Conv2d-173         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-174         [-1, 2048, 12, 12]           4,096\n","            ReLU-175         [-1, 2048, 12, 12]               0\n","            ReLU-176         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-177         [-1, 2048, 12, 12]               0\n","          Conv2d-178          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-179          [-1, 512, 12, 12]           1,024\n","            ReLU-180          [-1, 512, 12, 12]               0\n","          Conv2d-181          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-182          [-1, 512, 12, 12]           1,024\n","            ReLU-183          [-1, 512, 12, 12]               0\n","          Conv2d-184         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-185         [-1, 2048, 12, 12]           4,096\n","            ReLU-186         [-1, 2048, 12, 12]               0\n","            ReLU-187         [-1, 2048, 12, 12]               0\n","Bottleneck_block_constructor-188         [-1, 2048, 12, 12]               0\n","Hybrid_backbone_4-189  [[-1, 256, 96, 96], [-1, 512, 48, 48], [-1, 1024, 24, 24], [-1, 2048, 12, 12]]               0\n","         Sigmoid-190         [-1, 2048, 12, 12]               0\n","    simam_module-191         [-1, 2048, 12, 12]               0\n","          Conv2d-192          [-1, 768, 12, 12]       1,573,632\n","Last_feature_map_Embed-193             [-1, 144, 768]               0\n","         Sigmoid-194          [-1, 256, 96, 96]               0\n","    simam_module-195          [-1, 256, 96, 96]               0\n","       MaxPool2d-196          [-1, 256, 12, 12]               0\n","          Conv2d-197          [-1, 768, 12, 12]         197,376\n","       LayerNorm-198             [-1, 144, 768]           1,536\n","       AvgPool2d-199          [-1, 256, 12, 12]               0\n","          Conv2d-200          [-1, 768, 12, 12]         197,376\n","       LayerNorm-201             [-1, 144, 768]           1,536\n","     Focus_Embed-202  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-203          [-1, 512, 48, 48]               0\n","    simam_module-204          [-1, 512, 48, 48]               0\n","       MaxPool2d-205          [-1, 512, 12, 12]               0\n","          Conv2d-206          [-1, 768, 12, 12]         393,984\n","       LayerNorm-207             [-1, 144, 768]           1,536\n","       AvgPool2d-208          [-1, 512, 12, 12]               0\n","          Conv2d-209          [-1, 768, 12, 12]         393,984\n","       LayerNorm-210             [-1, 144, 768]           1,536\n","     Focus_Embed-211  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-212         [-1, 1024, 24, 24]               0\n","    simam_module-213         [-1, 1024, 24, 24]               0\n","       MaxPool2d-214         [-1, 1024, 12, 12]               0\n","          Conv2d-215          [-1, 768, 12, 12]         787,200\n","       LayerNorm-216             [-1, 144, 768]           1,536\n","       AvgPool2d-217         [-1, 1024, 12, 12]               0\n","          Conv2d-218          [-1, 768, 12, 12]         787,200\n","       LayerNorm-219             [-1, 144, 768]           1,536\n","     Focus_Embed-220  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Sigmoid-221         [-1, 2048, 12, 12]               0\n","    simam_module-222         [-1, 2048, 12, 12]               0\n","       MaxPool2d-223         [-1, 2048, 12, 12]               0\n","          Conv2d-224          [-1, 768, 12, 12]       1,573,632\n","       LayerNorm-225             [-1, 144, 768]           1,536\n","       AvgPool2d-226         [-1, 2048, 12, 12]               0\n","          Conv2d-227          [-1, 768, 12, 12]       1,573,632\n","       LayerNorm-228             [-1, 144, 768]           1,536\n","     Focus_Embed-229  [[-1, 144, 768], [-1, 144, 768]]               0\n","         Dropout-230             [-1, 145, 768]               0\n","         Dropout-231             [-1, 145, 768]               0\n","         Dropout-232             [-1, 145, 768]               0\n","         Dropout-233             [-1, 145, 768]               0\n","         Dropout-234             [-1, 145, 768]               0\n","         Dropout-235             [-1, 145, 768]               0\n","         Dropout-236             [-1, 145, 768]               0\n","         Dropout-237             [-1, 145, 768]               0\n","         Dropout-238             [-1, 145, 768]               0\n","       LayerNorm-239             [-1, 145, 768]           1,536\n","          Linear-240            [-1, 145, 2304]       1,771,776\n","         Dropout-241          [-1, 8, 145, 145]               0\n","          Linear-242             [-1, 145, 768]         590,592\n","         Dropout-243             [-1, 145, 768]               0\n","       Attention-244             [-1, 145, 768]               0\n","        Identity-245             [-1, 145, 768]               0\n","       LayerNorm-246             [-1, 145, 768]           1,536\n","          Linear-247            [-1, 145, 3072]       2,362,368\n","            GELU-248            [-1, 145, 3072]               0\n","         Dropout-249            [-1, 145, 3072]               0\n","          Linear-250             [-1, 145, 768]       2,360,064\n","         Dropout-251             [-1, 145, 768]               0\n","             FFN-252             [-1, 145, 768]               0\n","        Identity-253             [-1, 145, 768]               0\n","       LayerNorm-254             [-1, 145, 768]           1,536\n","          Linear-255             [-1, 145, 768]         590,592\n","          Linear-256             [-1, 145, 768]         590,592\n","          Linear-257             [-1, 145, 768]         590,592\n","         Dropout-258          [-1, 8, 145, 145]               0\n","          Linear-259             [-1, 145, 768]         590,592\n","         Dropout-260             [-1, 145, 768]               0\n","Guided_Attention-261             [-1, 145, 768]               0\n","        Identity-262             [-1, 145, 768]               0\n","       LayerNorm-263             [-1, 145, 768]           1,536\n","          Linear-264            [-1, 145, 3072]       2,362,368\n","            GELU-265            [-1, 145, 3072]               0\n","         Dropout-266            [-1, 145, 3072]               0\n","          Linear-267             [-1, 145, 768]       2,360,064\n","         Dropout-268             [-1, 145, 768]               0\n","             FFN-269             [-1, 145, 768]               0\n","        Identity-270             [-1, 145, 768]               0\n","   Decoder_Block-271             [-1, 145, 768]               0\n","       LayerNorm-272             [-1, 145, 768]           1,536\n","          Linear-273            [-1, 145, 2304]       1,771,776\n","         Dropout-274          [-1, 8, 145, 145]               0\n","          Linear-275             [-1, 145, 768]         590,592\n","         Dropout-276             [-1, 145, 768]               0\n","       Attention-277             [-1, 145, 768]               0\n","        Identity-278             [-1, 145, 768]               0\n","       LayerNorm-279             [-1, 145, 768]           1,536\n","          Linear-280            [-1, 145, 3072]       2,362,368\n","            GELU-281            [-1, 145, 3072]               0\n","         Dropout-282            [-1, 145, 3072]               0\n","          Linear-283             [-1, 145, 768]       2,360,064\n","         Dropout-284             [-1, 145, 768]               0\n","             FFN-285             [-1, 145, 768]               0\n","        Identity-286             [-1, 145, 768]               0\n","       LayerNorm-287             [-1, 145, 768]           1,536\n","          Linear-288             [-1, 145, 768]         590,592\n","          Linear-289             [-1, 145, 768]         590,592\n","          Linear-290             [-1, 145, 768]         590,592\n","         Dropout-291          [-1, 8, 145, 145]               0\n","          Linear-292             [-1, 145, 768]         590,592\n","         Dropout-293             [-1, 145, 768]               0\n","Guided_Attention-294             [-1, 145, 768]               0\n","        Identity-295             [-1, 145, 768]               0\n","       LayerNorm-296             [-1, 145, 768]           1,536\n","          Linear-297            [-1, 145, 3072]       2,362,368\n","            GELU-298            [-1, 145, 3072]               0\n","         Dropout-299            [-1, 145, 3072]               0\n","          Linear-300             [-1, 145, 768]       2,360,064\n","         Dropout-301             [-1, 145, 768]               0\n","             FFN-302             [-1, 145, 768]               0\n","        Identity-303             [-1, 145, 768]               0\n","   Decoder_Block-304             [-1, 145, 768]               0\n","       LayerNorm-305             [-1, 145, 768]           1,536\n","          Linear-306            [-1, 145, 2304]       1,771,776\n","         Dropout-307          [-1, 8, 145, 145]               0\n","          Linear-308             [-1, 145, 768]         590,592\n","         Dropout-309             [-1, 145, 768]               0\n","       Attention-310             [-1, 145, 768]               0\n","        Identity-311             [-1, 145, 768]               0\n","       LayerNorm-312             [-1, 145, 768]           1,536\n","          Linear-313            [-1, 145, 3072]       2,362,368\n","            GELU-314            [-1, 145, 3072]               0\n","         Dropout-315            [-1, 145, 3072]               0\n","          Linear-316             [-1, 145, 768]       2,360,064\n","         Dropout-317             [-1, 145, 768]               0\n","             FFN-318             [-1, 145, 768]               0\n","        Identity-319             [-1, 145, 768]               0\n","       LayerNorm-320             [-1, 145, 768]           1,536\n","          Linear-321             [-1, 145, 768]         590,592\n","          Linear-322             [-1, 145, 768]         590,592\n","          Linear-323             [-1, 145, 768]         590,592\n","         Dropout-324          [-1, 8, 145, 145]               0\n","          Linear-325             [-1, 145, 768]         590,592\n","         Dropout-326             [-1, 145, 768]               0\n","Guided_Attention-327             [-1, 145, 768]               0\n","        Identity-328             [-1, 145, 768]               0\n","       LayerNorm-329             [-1, 145, 768]           1,536\n","          Linear-330            [-1, 145, 3072]       2,362,368\n","            GELU-331            [-1, 145, 3072]               0\n","         Dropout-332            [-1, 145, 3072]               0\n","          Linear-333             [-1, 145, 768]       2,360,064\n","         Dropout-334             [-1, 145, 768]               0\n","             FFN-335             [-1, 145, 768]               0\n","        Identity-336             [-1, 145, 768]               0\n","   Decoder_Block-337             [-1, 145, 768]               0\n","       LayerNorm-338             [-1, 145, 768]           1,536\n","          Linear-339            [-1, 145, 2304]       1,771,776\n","         Dropout-340          [-1, 8, 145, 145]               0\n","          Linear-341             [-1, 145, 768]         590,592\n","         Dropout-342             [-1, 145, 768]               0\n","       Attention-343             [-1, 145, 768]               0\n","        Identity-344             [-1, 145, 768]               0\n","       LayerNorm-345             [-1, 145, 768]           1,536\n","          Linear-346            [-1, 145, 3072]       2,362,368\n","            GELU-347            [-1, 145, 3072]               0\n","         Dropout-348            [-1, 145, 3072]               0\n","          Linear-349             [-1, 145, 768]       2,360,064\n","         Dropout-350             [-1, 145, 768]               0\n","             FFN-351             [-1, 145, 768]               0\n","        Identity-352             [-1, 145, 768]               0\n","       LayerNorm-353             [-1, 145, 768]           1,536\n","          Linear-354             [-1, 145, 768]         590,592\n","          Linear-355             [-1, 145, 768]         590,592\n","          Linear-356             [-1, 145, 768]         590,592\n","         Dropout-357          [-1, 8, 145, 145]               0\n","          Linear-358             [-1, 145, 768]         590,592\n","         Dropout-359             [-1, 145, 768]               0\n","Guided_Attention-360             [-1, 145, 768]               0\n","        Identity-361             [-1, 145, 768]               0\n","       LayerNorm-362             [-1, 145, 768]           1,536\n","          Linear-363            [-1, 145, 3072]       2,362,368\n","            GELU-364            [-1, 145, 3072]               0\n","         Dropout-365            [-1, 145, 3072]               0\n","          Linear-366             [-1, 145, 768]       2,360,064\n","         Dropout-367             [-1, 145, 768]               0\n","             FFN-368             [-1, 145, 768]               0\n","        Identity-369             [-1, 145, 768]               0\n","   Decoder_Block-370             [-1, 145, 768]               0\n","       LayerNorm-371             [-1, 145, 768]           1,536\n","        Identity-372                  [-1, 768]               0\n","          Linear-373                    [-1, 2]           1,538\n","================================================================\n","Total params: 87,704,386\n","Trainable params: 87,704,386\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 372029.91\n","Params size (MB): 334.57\n","Estimated Total Size (MB): 372366.16\n","----------------------------------------------------------------\n","model : Hybrid2_384_401_PT_lf25_b8_k5\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 50 minibatch: 1      time used: 20.721304893493652\n","minibatch AVG loss: 0.6798357850313187\n","Epoch: 1     train index of 50 minibatch: 2      time used: 20.062009811401367\n","minibatch AVG loss: 0.5101999643445015\n","Epoch: 1     train index of 50 minibatch: 3      time used: 19.7853946685791\n","minibatch AVG loss: 0.4592346215248108\n","Epoch: 1     train index of 50 minibatch: 4      time used: 19.754279375076294\n","minibatch AVG loss: 0.43836796909570697\n","Epoch: 1     train index of 50 minibatch: 5      time used: 19.588932991027832\n","minibatch AVG loss: 0.42810078904032706\n","Epoch: 1     train index of 50 minibatch: 6      time used: 19.92945647239685\n","minibatch AVG loss: 0.3291989371180534\n","\n","Epoch: 1  train \n","Loss: 0.4607  Acc: 79.5580\n","negative precision: 81.4619  recall: 88.2387\n","negative sensitivity: 88.2387  specificity: 63.9918\n","negative FPR: 36.0082  NPV: 75.2116\n","negative TP: 1538.0\n","negative TN: 622.0\n","negative FP: 350.0\n","negative FN: 205.0\n","positive precision: 75.2116  recall: 63.9918\n","positive sensitivity: 63.9918  specificity: 88.2387\n","positive FPR: 11.7613  NPV: 81.4619\n","positive TP: 622.0\n","positive TN: 1538.0\n","positive FP: 205.0\n","positive FN: 350.0\n","\n","\n","Epoch: 1     val index of 50 minibatch: 1      time used: 11.177090167999268\n","minibatch AVG loss: 0.1339991472288966\n","\n","Epoch: 1  val \n","Loss: 0.2984  Acc: 87.7581\n","negative precision: 85.3414  recall: 97.7011\n","negative sensitivity: 97.7011  specificity: 69.9588\n","negative FPR: 30.0412  NPV: 94.4444\n","negative TP: 425.0\n","negative TN: 170.0\n","negative FP: 73.0\n","negative FN: 10.0\n","positive precision: 94.4444  recall: 69.9588\n","positive sensitivity: 69.9588  specificity: 97.7011\n","positive FPR: 2.2989  NPV: 85.3414\n","positive TP: 170.0\n","positive TN: 425.0\n","positive FP: 10.0\n","positive FN: 73.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 50 minibatch: 1      time used: 19.854998350143433\n","minibatch AVG loss: 0.3836514124274254\n","Epoch: 2     train index of 50 minibatch: 2      time used: 19.682896852493286\n","minibatch AVG loss: 0.33247117675840854\n","Epoch: 2     train index of 50 minibatch: 3      time used: 19.61592936515808\n","minibatch AVG loss: 0.3395503547787666\n","Epoch: 2     train index of 50 minibatch: 4      time used: 19.664721250534058\n","minibatch AVG loss: 0.3728383630514145\n","Epoch: 2     train index of 50 minibatch: 5      time used: 19.26412034034729\n","minibatch AVG loss: 0.2945706007629633\n","Epoch: 2     train index of 50 minibatch: 6      time used: 19.296499729156494\n","minibatch AVG loss: 0.359189688116312\n","\n","Epoch: 2  train \n","Loss: 0.3447  Acc: 84.6777\n","negative precision: 86.9638  recall: 89.5582\n","negative sensitivity: 89.5582  specificity: 75.9259\n","negative FPR: 24.0741  NPV: 80.2174\n","negative TP: 1561.0\n","negative TN: 738.0\n","negative FP: 234.0\n","negative FN: 182.0\n","positive precision: 80.2174  recall: 75.9259\n","positive sensitivity: 75.9259  specificity: 89.5582\n","positive FPR: 10.4418  NPV: 86.9638\n","positive TP: 738.0\n","positive TN: 1561.0\n","positive FP: 182.0\n","positive FN: 234.0\n","\n","\n","Epoch: 2     val index of 50 minibatch: 1      time used: 11.070191144943237\n","minibatch AVG loss: 0.14447583084926008\n","\n","Epoch: 2  val \n","Loss: 0.2340  Acc: 89.9705\n","negative precision: 91.2360  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 83.9506\n","negative FPR: 16.0494  NPV: 87.5536\n","negative TP: 406.0\n","negative TN: 204.0\n","negative FP: 39.0\n","negative FN: 29.0\n","positive precision: 87.5536  recall: 83.9506\n","positive sensitivity: 83.9506  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 91.2360\n","positive TP: 204.0\n","positive TN: 406.0\n","positive FP: 29.0\n","positive FN: 39.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 50 minibatch: 1      time used: 20.266706705093384\n","minibatch AVG loss: 0.23687181897461415\n","Epoch: 3     train index of 50 minibatch: 2      time used: 19.325642108917236\n","minibatch AVG loss: 0.2901143468916416\n","Epoch: 3     train index of 50 minibatch: 3      time used: 19.125818490982056\n","minibatch AVG loss: 0.3719125272333622\n","Epoch: 3     train index of 50 minibatch: 4      time used: 19.424078464508057\n","minibatch AVG loss: 0.3187884700298309\n","Epoch: 3     train index of 50 minibatch: 5      time used: 19.43004608154297\n","minibatch AVG loss: 0.26108574025332926\n","Epoch: 3     train index of 50 minibatch: 6      time used: 19.68675971031189\n","minibatch AVG loss: 0.28584707275032994\n","\n","Epoch: 3  train \n","Loss: 0.2967  Acc: 87.8085\n","negative precision: 90.0227  recall: 91.1073\n","negative sensitivity: 91.1073  specificity: 81.8930\n","negative FPR: 18.1070  NPV: 83.7014\n","negative TP: 1588.0\n","negative TN: 796.0\n","negative FP: 176.0\n","negative FN: 155.0\n","positive precision: 83.7014  recall: 81.8930\n","positive sensitivity: 81.8930  specificity: 91.1073\n","positive FPR: 8.8927  NPV: 90.0227\n","positive TP: 796.0\n","positive TN: 1588.0\n","positive FP: 155.0\n","positive FN: 176.0\n","\n","\n","Epoch: 3     val index of 50 minibatch: 1      time used: 11.08449912071228\n","minibatch AVG loss: 0.07175520306453109\n","\n","Epoch: 3  val \n","Loss: 0.2820  Acc: 88.9381\n","negative precision: 87.0370  recall: 97.2414\n","negative sensitivity: 97.2414  specificity: 74.0741\n","negative FPR: 25.9259  NPV: 93.7500\n","negative TP: 423.0\n","negative TN: 180.0\n","negative FP: 63.0\n","negative FN: 12.0\n","positive precision: 93.7500  recall: 74.0741\n","positive sensitivity: 74.0741  specificity: 97.2414\n","positive FPR: 2.7586  NPV: 87.0370\n","positive TP: 180.0\n","positive TN: 423.0\n","positive FP: 12.0\n","positive FN: 63.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 50 minibatch: 1      time used: 20.22090458869934\n","minibatch AVG loss: 0.287482581846416\n","Epoch: 4     train index of 50 minibatch: 2      time used: 19.30807876586914\n","minibatch AVG loss: 0.27296557046473024\n","Epoch: 4     train index of 50 minibatch: 3      time used: 19.620224237442017\n","minibatch AVG loss: 0.2728773880004883\n","Epoch: 4     train index of 50 minibatch: 4      time used: 19.67731809616089\n","minibatch AVG loss: 0.2908636997640133\n","Epoch: 4     train index of 50 minibatch: 5      time used: 19.474670886993408\n","minibatch AVG loss: 0.2907631368935108\n","Epoch: 4     train index of 50 minibatch: 6      time used: 19.49822235107422\n","minibatch AVG loss: 0.2810352872312069\n","\n","Epoch: 4  train \n","Loss: 0.2759  Acc: 89.0608\n","negative precision: 90.4362  recall: 92.7711\n","negative sensitivity: 92.7711  specificity: 82.4074\n","negative FPR: 17.5926  NPV: 86.4078\n","negative TP: 1617.0\n","negative TN: 801.0\n","negative FP: 171.0\n","negative FN: 126.0\n","positive precision: 86.4078  recall: 82.4074\n","positive sensitivity: 82.4074  specificity: 92.7711\n","positive FPR: 7.2289  NPV: 90.4362\n","positive TP: 801.0\n","positive TN: 1617.0\n","positive FP: 126.0\n","positive FN: 171.0\n","\n","\n","Epoch: 4     val index of 50 minibatch: 1      time used: 11.097436428070068\n","minibatch AVG loss: 0.10405883671715856\n","\n","Epoch: 4  val \n","Loss: 0.2353  Acc: 91.8879\n","negative precision: 91.1255  recall: 96.7816\n","negative sensitivity: 96.7816  specificity: 83.1276\n","negative FPR: 16.8724  NPV: 93.5185\n","negative TP: 421.0\n","negative TN: 202.0\n","negative FP: 41.0\n","negative FN: 14.0\n","positive precision: 93.5185  recall: 83.1276\n","positive sensitivity: 83.1276  specificity: 96.7816\n","positive FPR: 3.2184  NPV: 91.1255\n","positive TP: 202.0\n","positive TN: 421.0\n","positive FP: 14.0\n","positive FN: 41.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 50 minibatch: 1      time used: 20.00505304336548\n","minibatch AVG loss: 0.3173372130095959\n","Epoch: 5     train index of 50 minibatch: 2      time used: 19.590083360671997\n","minibatch AVG loss: 0.3221011774241924\n","Epoch: 5     train index of 50 minibatch: 3      time used: 19.35948395729065\n","minibatch AVG loss: 0.249793446585536\n","Epoch: 5     train index of 50 minibatch: 4      time used: 19.44727110862732\n","minibatch AVG loss: 0.2761919528245926\n","Epoch: 5     train index of 50 minibatch: 5      time used: 19.514899730682373\n","minibatch AVG loss: 0.2596232282742858\n","Epoch: 5     train index of 50 minibatch: 6      time used: 19.55767822265625\n","minibatch AVG loss: 0.19762702472507954\n","\n","Epoch: 5  train \n","Loss: 0.2675  Acc: 89.2081\n","negative precision: 90.6390  recall: 92.7711\n","negative sensitivity: 92.7711  specificity: 82.8189\n","negative FPR: 17.1811  NPV: 86.4662\n","negative TP: 1617.0\n","negative TN: 805.0\n","negative FP: 167.0\n","negative FN: 126.0\n","positive precision: 86.4662  recall: 82.8189\n","positive sensitivity: 82.8189  specificity: 92.7711\n","positive FPR: 7.2289  NPV: 90.6390\n","positive TP: 805.0\n","positive TN: 1617.0\n","positive FP: 126.0\n","positive FN: 167.0\n","\n","\n","Epoch: 5     val index of 50 minibatch: 1      time used: 11.097053050994873\n","minibatch AVG loss: 0.08236105668358505\n","\n","Epoch: 5  val \n","Loss: 0.2517  Acc: 90.5605\n","negative precision: 89.2178  recall: 97.0115\n","negative sensitivity: 97.0115  specificity: 79.0123\n","negative FPR: 20.9877  NPV: 93.6585\n","negative TP: 422.0\n","negative TN: 192.0\n","negative FP: 51.0\n","negative FN: 13.0\n","positive precision: 93.6585  recall: 79.0123\n","positive sensitivity: 79.0123  specificity: 97.0115\n","positive FPR: 2.9885  NPV: 89.2178\n","positive TP: 192.0\n","positive TN: 422.0\n","positive FP: 13.0\n","positive FN: 51.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 50 minibatch: 1      time used: 20.276453256607056\n","minibatch AVG loss: 0.248863769993186\n","Epoch: 6     train index of 50 minibatch: 2      time used: 19.527518033981323\n","minibatch AVG loss: 0.2515693722292781\n","Epoch: 6     train index of 50 minibatch: 3      time used: 19.49795913696289\n","minibatch AVG loss: 0.2663603027909994\n","Epoch: 6     train index of 50 minibatch: 4      time used: 19.492098808288574\n","minibatch AVG loss: 0.2332278062775731\n","Epoch: 6     train index of 50 minibatch: 5      time used: 19.567533493041992\n","minibatch AVG loss: 0.24349370531737805\n","Epoch: 6     train index of 50 minibatch: 6      time used: 19.45392632484436\n","minibatch AVG loss: 0.22976278126239777\n","\n","Epoch: 6  train \n","Loss: 0.2503  Acc: 89.7606\n","negative precision: 90.9905  recall: 93.2874\n","negative sensitivity: 93.2874  specificity: 83.4362\n","negative FPR: 16.5638  NPV: 87.3922\n","negative TP: 1626.0\n","negative TN: 811.0\n","negative FP: 161.0\n","negative FN: 117.0\n","positive precision: 87.3922  recall: 83.4362\n","positive sensitivity: 83.4362  specificity: 93.2874\n","positive FPR: 6.7126  NPV: 90.9905\n","positive TP: 811.0\n","positive TN: 1626.0\n","positive FP: 117.0\n","positive FN: 161.0\n","\n","\n","Epoch: 6     val index of 50 minibatch: 1      time used: 11.12395715713501\n","minibatch AVG loss: 0.04582034607883543\n","\n","Epoch: 6  val \n","Loss: 0.2810  Acc: 87.9056\n","negative precision: 84.9505  recall: 98.6207\n","negative sensitivity: 98.6207  specificity: 68.7243\n","negative FPR: 31.2757  NPV: 96.5318\n","negative TP: 429.0\n","negative TN: 167.0\n","negative FP: 76.0\n","negative FN: 6.0\n","positive precision: 96.5318  recall: 68.7243\n","positive sensitivity: 68.7243  specificity: 98.6207\n","positive FPR: 1.3793  NPV: 84.9505\n","positive TP: 167.0\n","positive TN: 429.0\n","positive FP: 6.0\n","positive FN: 76.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 50 minibatch: 1      time used: 20.07491707801819\n","minibatch AVG loss: 0.21937374426051975\n","Epoch: 7     train index of 50 minibatch: 2      time used: 19.10783076286316\n","minibatch AVG loss: 0.21990409351885318\n","Epoch: 7     train index of 50 minibatch: 3      time used: 19.887275218963623\n","minibatch AVG loss: 0.21941368471831083\n","Epoch: 7     train index of 50 minibatch: 4      time used: 19.291996955871582\n","minibatch AVG loss: 0.24016326233744623\n","Epoch: 7     train index of 50 minibatch: 5      time used: 19.508031368255615\n","minibatch AVG loss: 0.24811223447322844\n","Epoch: 7     train index of 50 minibatch: 6      time used: 19.28764843940735\n","minibatch AVG loss: 0.2103782495483756\n","\n","Epoch: 7  train \n","Loss: 0.2322  Acc: 90.4972\n","negative precision: 92.2595  recall: 93.0006\n","negative sensitivity: 93.0006  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 87.2651\n","negative TP: 1621.0\n","negative TN: 836.0\n","negative FP: 136.0\n","negative FN: 122.0\n","positive precision: 87.2651  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 93.0006\n","positive FPR: 6.9994  NPV: 92.2595\n","positive TP: 836.0\n","positive TN: 1621.0\n","positive FP: 122.0\n","positive FN: 136.0\n","\n","\n","Epoch: 7     val index of 50 minibatch: 1      time used: 11.18826675415039\n","minibatch AVG loss: 0.07878739083651454\n","\n","Epoch: 7  val \n","Loss: 0.2154  Acc: 91.7404\n","negative precision: 91.2854  recall: 96.3218\n","negative sensitivity: 96.3218  specificity: 83.5391\n","negative FPR: 16.4609  NPV: 92.6941\n","negative TP: 419.0\n","negative TN: 203.0\n","negative FP: 40.0\n","negative FN: 16.0\n","positive precision: 92.6941  recall: 83.5391\n","positive sensitivity: 83.5391  specificity: 96.3218\n","positive FPR: 3.6782  NPV: 91.2854\n","positive TP: 203.0\n","positive TN: 419.0\n","positive FP: 16.0\n","positive FN: 40.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 50 minibatch: 1      time used: 20.30095362663269\n","minibatch AVG loss: 0.2402885729819536\n","Epoch: 8     train index of 50 minibatch: 2      time used: 19.40429139137268\n","minibatch AVG loss: 0.23211269054561853\n","Epoch: 8     train index of 50 minibatch: 3      time used: 19.49703288078308\n","minibatch AVG loss: 0.2315321819856763\n","Epoch: 8     train index of 50 minibatch: 4      time used: 19.46091055870056\n","minibatch AVG loss: 0.26390435472130774\n","Epoch: 8     train index of 50 minibatch: 5      time used: 19.705722332000732\n","minibatch AVG loss: 0.2094418041035533\n","Epoch: 8     train index of 50 minibatch: 6      time used: 19.356082677841187\n","minibatch AVG loss: 0.21529477003961803\n","\n","Epoch: 8  train \n","Loss: 0.2298  Acc: 91.0129\n","negative precision: 92.7553  recall: 93.2874\n","negative sensitivity: 93.2874  specificity: 86.9342\n","negative FPR: 13.0658  NPV: 87.8378\n","negative TP: 1626.0\n","negative TN: 845.0\n","negative FP: 127.0\n","negative FN: 117.0\n","positive precision: 87.8378  recall: 86.9342\n","positive sensitivity: 86.9342  specificity: 93.2874\n","positive FPR: 6.7126  NPV: 92.7553\n","positive TP: 845.0\n","positive TN: 1626.0\n","positive FP: 117.0\n","positive FN: 127.0\n","\n","\n","Epoch: 8     val index of 50 minibatch: 1      time used: 11.160013198852539\n","minibatch AVG loss: 0.09984873202658491\n","\n","Epoch: 8  val \n","Loss: 0.2071  Acc: 91.8879\n","negative precision: 92.7928  recall: 94.7126\n","negative sensitivity: 94.7126  specificity: 86.8313\n","negative FPR: 13.1687  NPV: 90.1709\n","negative TP: 412.0\n","negative TN: 211.0\n","negative FP: 32.0\n","negative FN: 23.0\n","positive precision: 90.1709  recall: 86.8313\n","positive sensitivity: 86.8313  specificity: 94.7126\n","positive FPR: 5.2874  NPV: 92.7928\n","positive TP: 211.0\n","positive TN: 412.0\n","positive FP: 23.0\n","positive FN: 32.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 50 minibatch: 1      time used: 20.129337787628174\n","minibatch AVG loss: 0.24717121761292218\n","Epoch: 9     train index of 50 minibatch: 2      time used: 19.361003160476685\n","minibatch AVG loss: 0.170941351801157\n","Epoch: 9     train index of 50 minibatch: 3      time used: 19.604706048965454\n","minibatch AVG loss: 0.23872235795482993\n","Epoch: 9     train index of 50 minibatch: 4      time used: 19.3875949382782\n","minibatch AVG loss: 0.1911160521954298\n","Epoch: 9     train index of 50 minibatch: 5      time used: 19.488052368164062\n","minibatch AVG loss: 0.19006803702563047\n","Epoch: 9     train index of 50 minibatch: 6      time used: 19.399879932403564\n","minibatch AVG loss: 0.20855750735849143\n","\n","Epoch: 9  train \n","Loss: 0.2110  Acc: 91.6759\n","negative precision: 93.2194  recall: 93.8612\n","negative sensitivity: 93.8612  specificity: 87.7572\n","negative FPR: 12.2428  NPV: 88.8542\n","negative TP: 1636.0\n","negative TN: 853.0\n","negative FP: 119.0\n","negative FN: 107.0\n","positive precision: 88.8542  recall: 87.7572\n","positive sensitivity: 87.7572  specificity: 93.8612\n","positive FPR: 6.1388  NPV: 93.2194\n","positive TP: 853.0\n","positive TN: 1636.0\n","positive FP: 107.0\n","positive FN: 119.0\n","\n","\n","Epoch: 9     val index of 50 minibatch: 1      time used: 11.152711153030396\n","minibatch AVG loss: 0.1026472517545335\n","\n","Epoch: 9  val \n","Loss: 0.1763  Acc: 92.7729\n","negative precision: 92.5110  recall: 96.5517\n","negative sensitivity: 96.5517  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 93.3036\n","negative TP: 420.0\n","negative TN: 209.0\n","negative FP: 34.0\n","negative FN: 15.0\n","positive precision: 93.3036  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 96.5517\n","positive FPR: 3.4483  NPV: 92.5110\n","positive TP: 209.0\n","positive TN: 420.0\n","positive FP: 15.0\n","positive FN: 34.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 50 minibatch: 1      time used: 20.100388288497925\n","minibatch AVG loss: 0.20231286961585282\n","Epoch: 10     train index of 50 minibatch: 2      time used: 19.714945793151855\n","minibatch AVG loss: 0.1442207261733711\n","Epoch: 10     train index of 50 minibatch: 3      time used: 19.354693174362183\n","minibatch AVG loss: 0.20087700033560396\n","Epoch: 10     train index of 50 minibatch: 4      time used: 19.363013982772827\n","minibatch AVG loss: 0.196099340505898\n","Epoch: 10     train index of 50 minibatch: 5      time used: 19.98142695426941\n","minibatch AVG loss: 0.1457695645093918\n","Epoch: 10     train index of 50 minibatch: 6      time used: 19.128028392791748\n","minibatch AVG loss: 0.2352659124135971\n","\n","Epoch: 10  train \n","Loss: 0.1864  Acc: 92.1915\n","negative precision: 93.8180  recall: 94.0333\n","negative sensitivity: 94.0333  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 89.2562\n","negative TP: 1639.0\n","negative TN: 864.0\n","negative FP: 108.0\n","negative FN: 104.0\n","positive precision: 89.2562  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 94.0333\n","positive FPR: 5.9667  NPV: 93.8180\n","positive TP: 864.0\n","positive TN: 1639.0\n","positive FP: 104.0\n","positive FN: 108.0\n","\n","\n","Epoch: 10     val index of 50 minibatch: 1      time used: 11.263002872467041\n","minibatch AVG loss: 0.11860115569841582\n","\n","Epoch: 10  val \n","Loss: 0.1943  Acc: 93.3628\n","negative precision: 93.9189  recall: 95.8621\n","negative sensitivity: 95.8621  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 92.3077\n","negative TP: 417.0\n","negative TN: 216.0\n","negative FP: 27.0\n","negative FN: 18.0\n","positive precision: 92.3077  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 95.8621\n","positive FPR: 4.1379  NPV: 93.9189\n","positive TP: 216.0\n","positive TN: 417.0\n","positive FP: 18.0\n","positive FN: 27.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 50 minibatch: 1      time used: 20.2248854637146\n","minibatch AVG loss: 0.2474982619844377\n","Epoch: 11     train index of 50 minibatch: 2      time used: 19.450775861740112\n","minibatch AVG loss: 0.20838303342461587\n","Epoch: 11     train index of 50 minibatch: 3      time used: 19.666215181350708\n","minibatch AVG loss: 0.19999188594520093\n","Epoch: 11     train index of 50 minibatch: 4      time used: 19.303967475891113\n","minibatch AVG loss: 0.19681193467229605\n","Epoch: 11     train index of 50 minibatch: 5      time used: 19.689817428588867\n","minibatch AVG loss: 0.13863332115113736\n","Epoch: 11     train index of 50 minibatch: 6      time used: 19.496124267578125\n","minibatch AVG loss: 0.1944153532758355\n","\n","Epoch: 11  train \n","Loss: 0.1955  Acc: 91.8600\n","negative precision: 93.3865  recall: 93.9759\n","negative sensitivity: 93.9759  specificity: 88.0658\n","negative FPR: 11.9342  NPV: 89.0739\n","negative TP: 1638.0\n","negative TN: 856.0\n","negative FP: 116.0\n","negative FN: 105.0\n","positive precision: 89.0739  recall: 88.0658\n","positive sensitivity: 88.0658  specificity: 93.9759\n","positive FPR: 6.0241  NPV: 93.3865\n","positive TP: 856.0\n","positive TN: 1638.0\n","positive FP: 105.0\n","positive FN: 116.0\n","\n","\n","Epoch: 11     val index of 50 minibatch: 1      time used: 11.15677523612976\n","minibatch AVG loss: 0.06672969161096262\n","\n","Epoch: 11  val \n","Loss: 0.1794  Acc: 92.7729\n","negative precision: 91.9565  recall: 97.2414\n","negative sensitivity: 97.2414  specificity: 84.7737\n","negative FPR: 15.2263  NPV: 94.4954\n","negative TP: 423.0\n","negative TN: 206.0\n","negative FP: 37.0\n","negative FN: 12.0\n","positive precision: 94.4954  recall: 84.7737\n","positive sensitivity: 84.7737  specificity: 97.2414\n","positive FPR: 2.7586  NPV: 91.9565\n","positive TP: 206.0\n","positive TN: 423.0\n","positive FP: 12.0\n","positive FN: 37.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 50 minibatch: 1      time used: 20.120832920074463\n","minibatch AVG loss: 0.18208853915333748\n","Epoch: 12     train index of 50 minibatch: 2      time used: 19.68199896812439\n","minibatch AVG loss: 0.1558040777593851\n","Epoch: 12     train index of 50 minibatch: 3      time used: 19.550180673599243\n","minibatch AVG loss: 0.20702200770378112\n","Epoch: 12     train index of 50 minibatch: 4      time used: 19.432186365127563\n","minibatch AVG loss: 0.16875358110293745\n","Epoch: 12     train index of 50 minibatch: 5      time used: 19.58824872970581\n","minibatch AVG loss: 0.2022221885062754\n","Epoch: 12     train index of 50 minibatch: 6      time used: 19.43143606185913\n","minibatch AVG loss: 0.17027724280953407\n","\n","Epoch: 12  train \n","Loss: 0.1838  Acc: 92.6703\n","negative precision: 94.1648  recall: 94.4349\n","negative sensitivity: 94.4349  specificity: 89.5062\n","negative FPR: 10.4938  NPV: 89.9690\n","negative TP: 1646.0\n","negative TN: 870.0\n","negative FP: 102.0\n","negative FN: 97.0\n","positive precision: 89.9690  recall: 89.5062\n","positive sensitivity: 89.5062  specificity: 94.4349\n","positive FPR: 5.5651  NPV: 94.1648\n","positive TP: 870.0\n","positive TN: 1646.0\n","positive FP: 97.0\n","positive FN: 102.0\n","\n","\n","Epoch: 12     val index of 50 minibatch: 1      time used: 11.206831216812134\n","minibatch AVG loss: 0.10963101290879422\n","\n","Epoch: 12  val \n","Loss: 0.1678  Acc: 94.1003\n","negative precision: 95.1945  recall: 95.6322\n","negative sensitivity: 95.6322  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 92.1162\n","negative TP: 416.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 19.0\n","positive precision: 92.1162  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 95.6322\n","positive FPR: 4.3678  NPV: 95.1945\n","positive TP: 222.0\n","positive TN: 416.0\n","positive FP: 19.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 50 minibatch: 1      time used: 20.125690698623657\n","minibatch AVG loss: 0.15302516150288284\n","Epoch: 13     train index of 50 minibatch: 2      time used: 19.88562774658203\n","minibatch AVG loss: 0.14018234715797007\n","Epoch: 13     train index of 50 minibatch: 3      time used: 19.215545415878296\n","minibatch AVG loss: 0.16271118614822627\n","Epoch: 13     train index of 50 minibatch: 4      time used: 19.868708848953247\n","minibatch AVG loss: 0.1869497198984027\n","Epoch: 13     train index of 50 minibatch: 5      time used: 19.468337535858154\n","minibatch AVG loss: 0.16062915559858085\n","Epoch: 13     train index of 50 minibatch: 6      time used: 19.715628623962402\n","minibatch AVG loss: 0.17175124272704123\n","\n","Epoch: 13  train \n","Loss: 0.1668  Acc: 92.9282\n","negative precision: 94.2890  recall: 94.7217\n","negative sensitivity: 94.7217  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 90.4564\n","negative TP: 1651.0\n","negative TN: 872.0\n","negative FP: 100.0\n","negative FN: 92.0\n","positive precision: 90.4564  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 94.7217\n","positive FPR: 5.2783  NPV: 94.2890\n","positive TP: 872.0\n","positive TN: 1651.0\n","positive FP: 92.0\n","positive FN: 100.0\n","\n","\n","Epoch: 13     val index of 50 minibatch: 1      time used: 11.1565260887146\n","minibatch AVG loss: 0.18145730780583108\n","\n","Epoch: 13  val \n","Loss: 0.2125  Acc: 92.6254\n","negative precision: 96.8370  recall: 91.4943\n","negative sensitivity: 91.4943  specificity: 94.6502\n","negative FPR: 5.3498  NPV: 86.1423\n","negative TP: 398.0\n","negative TN: 230.0\n","negative FP: 13.0\n","negative FN: 37.0\n","positive precision: 86.1423  recall: 94.6502\n","positive sensitivity: 94.6502  specificity: 91.4943\n","positive FPR: 8.5057  NPV: 96.8370\n","positive TP: 230.0\n","positive TN: 398.0\n","positive FP: 37.0\n","positive FN: 13.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 50 minibatch: 1      time used: 20.196948051452637\n","minibatch AVG loss: 0.1557946846820414\n","Epoch: 14     train index of 50 minibatch: 2      time used: 19.361948490142822\n","minibatch AVG loss: 0.17722639786079525\n","Epoch: 14     train index of 50 minibatch: 3      time used: 19.918116092681885\n","minibatch AVG loss: 0.1535791539028287\n","Epoch: 14     train index of 50 minibatch: 4      time used: 19.217458248138428\n","minibatch AVG loss: 0.18300808735191823\n","Epoch: 14     train index of 50 minibatch: 5      time used: 19.805870532989502\n","minibatch AVG loss: 0.15591552529484035\n","Epoch: 14     train index of 50 minibatch: 6      time used: 19.500118255615234\n","minibatch AVG loss: 0.18857732508331537\n","\n","Epoch: 14  train \n","Loss: 0.1739  Acc: 93.2228\n","negative precision: 94.2144  recall: 95.2955\n","negative sensitivity: 95.2955  specificity: 89.5062\n","negative FPR: 10.4938  NPV: 91.3866\n","negative TP: 1661.0\n","negative TN: 870.0\n","negative FP: 102.0\n","negative FN: 82.0\n","positive precision: 91.3866  recall: 89.5062\n","positive sensitivity: 89.5062  specificity: 95.2955\n","positive FPR: 4.7045  NPV: 94.2144\n","positive TP: 870.0\n","positive TN: 1661.0\n","positive FP: 82.0\n","positive FN: 102.0\n","\n","\n","Epoch: 14     val index of 50 minibatch: 1      time used: 11.186702966690063\n","minibatch AVG loss: 0.12830962005769833\n","\n","Epoch: 14  val \n","Loss: 0.1873  Acc: 93.0678\n","negative precision: 95.1163  recall: 94.0230\n","negative sensitivity: 94.0230  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 89.5161\n","negative TP: 409.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 26.0\n","positive precision: 89.5161  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 94.0230\n","positive FPR: 5.9770  NPV: 95.1163\n","positive TP: 222.0\n","positive TN: 409.0\n","positive FP: 26.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 50 minibatch: 1      time used: 20.086233854293823\n","minibatch AVG loss: 0.16176927905529737\n","Epoch: 15     train index of 50 minibatch: 2      time used: 19.785247564315796\n","minibatch AVG loss: 0.13021602921187878\n","Epoch: 15     train index of 50 minibatch: 3      time used: 19.915864944458008\n","minibatch AVG loss: 0.15746260104700924\n","Epoch: 15     train index of 50 minibatch: 4      time used: 19.141298055648804\n","minibatch AVG loss: 0.12273189523257315\n","Epoch: 15     train index of 50 minibatch: 5      time used: 19.389320850372314\n","minibatch AVG loss: 0.18502647100947797\n","Epoch: 15     train index of 50 minibatch: 6      time used: 19.564502716064453\n","minibatch AVG loss: 0.11218555718660354\n","\n","Epoch: 15  train \n","Loss: 0.1505  Acc: 93.8490\n","negative precision: 94.8747  recall: 95.5823\n","negative sensitivity: 95.5823  specificity: 90.7407\n","negative FPR: 9.2593  NPV: 91.9708\n","negative TP: 1666.0\n","negative TN: 882.0\n","negative FP: 90.0\n","negative FN: 77.0\n","positive precision: 91.9708  recall: 90.7407\n","positive sensitivity: 90.7407  specificity: 95.5823\n","positive FPR: 4.4177  NPV: 94.8747\n","positive TP: 882.0\n","positive TN: 1666.0\n","positive FP: 77.0\n","positive FN: 90.0\n","\n","\n","Epoch: 15     val index of 50 minibatch: 1      time used: 11.162006139755249\n","minibatch AVG loss: 0.19715035427361727\n","\n","Epoch: 15  val \n","Loss: 0.2477  Acc: 91.1504\n","negative precision: 93.7063  recall: 92.4138\n","negative sensitivity: 92.4138  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 86.7470\n","negative TP: 402.0\n","negative TN: 216.0\n","negative FP: 27.0\n","negative FN: 33.0\n","positive precision: 86.7470  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 92.4138\n","positive FPR: 7.5862  NPV: 93.7063\n","positive TP: 216.0\n","positive TN: 402.0\n","positive FP: 33.0\n","positive FN: 27.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 50 minibatch: 1      time used: 20.441944122314453\n","minibatch AVG loss: 0.18652486072853208\n","Epoch: 16     train index of 50 minibatch: 2      time used: 19.589306116104126\n","minibatch AVG loss: 0.19093640131875872\n","Epoch: 16     train index of 50 minibatch: 3      time used: 19.42547059059143\n","minibatch AVG loss: 0.13674512648023665\n","Epoch: 16     train index of 50 minibatch: 4      time used: 19.702486515045166\n","minibatch AVG loss: 0.14136786767281592\n","Epoch: 16     train index of 50 minibatch: 5      time used: 19.64318299293518\n","minibatch AVG loss: 0.1650703616067767\n","Epoch: 16     train index of 50 minibatch: 6      time used: 19.50157117843628\n","minibatch AVG loss: 0.1414473303500563\n","\n","Epoch: 16  train \n","Loss: 0.1560  Acc: 93.4438\n","negative precision: 94.8939  recall: 94.8939\n","negative sensitivity: 94.8939  specificity: 90.8436\n","negative FPR: 9.1564  NPV: 90.8436\n","negative TP: 1654.0\n","negative TN: 883.0\n","negative FP: 89.0\n","negative FN: 89.0\n","positive precision: 90.8436  recall: 90.8436\n","positive sensitivity: 90.8436  specificity: 94.8939\n","positive FPR: 5.1061  NPV: 94.8939\n","positive TP: 883.0\n","positive TN: 1654.0\n","positive FP: 89.0\n","positive FN: 89.0\n","\n","\n","Epoch: 16     val index of 50 minibatch: 1      time used: 11.306073904037476\n","minibatch AVG loss: 0.12833455309199052\n","\n","Epoch: 16  val \n","Loss: 0.2307  Acc: 93.3628\n","negative precision: 94.3182  recall: 95.4023\n","negative sensitivity: 95.4023  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 91.5966\n","negative TP: 415.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 20.0\n","positive precision: 91.5966  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 95.4023\n","positive FPR: 4.5977  NPV: 94.3182\n","positive TP: 218.0\n","positive TN: 415.0\n","positive FP: 20.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 50 minibatch: 1      time used: 20.479984760284424\n","minibatch AVG loss: 0.1530397042259574\n","Epoch: 17     train index of 50 minibatch: 2      time used: 19.27445125579834\n","minibatch AVG loss: 0.11552248280495406\n","Epoch: 17     train index of 50 minibatch: 3      time used: 19.619722366333008\n","minibatch AVG loss: 0.14453707421198486\n","Epoch: 17     train index of 50 minibatch: 4      time used: 19.673400163650513\n","minibatch AVG loss: 0.21745518105104567\n","Epoch: 17     train index of 50 minibatch: 5      time used: 19.661710262298584\n","minibatch AVG loss: 0.10062891547568142\n","Epoch: 17     train index of 50 minibatch: 6      time used: 19.724820613861084\n","minibatch AVG loss: 0.1385113338334486\n","\n","Epoch: 17  train \n","Loss: 0.1437  Acc: 94.3278\n","negative precision: 95.2191  recall: 95.9839\n","negative sensitivity: 95.9839  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 92.6931\n","negative TP: 1673.0\n","negative TN: 888.0\n","negative FP: 84.0\n","negative FN: 70.0\n","positive precision: 92.6931  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 95.9839\n","positive FPR: 4.0161  NPV: 95.2191\n","positive TP: 888.0\n","positive TN: 1673.0\n","positive FP: 70.0\n","positive FN: 84.0\n","\n","\n","Epoch: 17     val index of 50 minibatch: 1      time used: 11.236077070236206\n","minibatch AVG loss: 0.1013361826714754\n","\n","Epoch: 17  val \n","Loss: 0.2100  Acc: 93.0678\n","negative precision: 94.2922  recall: 94.9425\n","negative sensitivity: 94.9425  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 90.8333\n","negative TP: 413.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 22.0\n","positive precision: 90.8333  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 94.9425\n","positive FPR: 5.0575  NPV: 94.2922\n","positive TP: 218.0\n","positive TN: 413.0\n","positive FP: 22.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 50 minibatch: 1      time used: 20.179337978363037\n","minibatch AVG loss: 0.08579979657894\n","Epoch: 18     train index of 50 minibatch: 2      time used: 19.76518726348877\n","minibatch AVG loss: 0.16188800094649194\n","Epoch: 18     train index of 50 minibatch: 3      time used: 19.543400526046753\n","minibatch AVG loss: 0.17523398734629153\n","Epoch: 18     train index of 50 minibatch: 4      time used: 19.588114738464355\n","minibatch AVG loss: 0.14188144711777567\n","Epoch: 18     train index of 50 minibatch: 5      time used: 19.514973878860474\n","minibatch AVG loss: 0.16466346731409431\n","Epoch: 18     train index of 50 minibatch: 6      time used: 19.703798532485962\n","minibatch AVG loss: 0.15193839204497636\n","\n","Epoch: 18  train \n","Loss: 0.1455  Acc: 94.3278\n","negative precision: 95.4780  recall: 95.6971\n","negative sensitivity: 95.6971  specificity: 91.8724\n","negative FPR: 8.1276  NPV: 92.2521\n","negative TP: 1668.0\n","negative TN: 893.0\n","negative FP: 79.0\n","negative FN: 75.0\n","positive precision: 92.2521  recall: 91.8724\n","positive sensitivity: 91.8724  specificity: 95.6971\n","positive FPR: 4.3029  NPV: 95.4780\n","positive TP: 893.0\n","positive TN: 1668.0\n","positive FP: 75.0\n","positive FN: 79.0\n","\n","\n","Epoch: 18     val index of 50 minibatch: 1      time used: 11.207206964492798\n","minibatch AVG loss: 0.12172802996821702\n","\n","Epoch: 18  val \n","Loss: 0.2015  Acc: 92.4779\n","negative precision: 93.8356  recall: 94.4828\n","negative sensitivity: 94.4828  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 90.0000\n","negative TP: 411.0\n","negative TN: 216.0\n","negative FP: 27.0\n","negative FN: 24.0\n","positive precision: 90.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 94.4828\n","positive FPR: 5.5172  NPV: 93.8356\n","positive TP: 216.0\n","positive TN: 411.0\n","positive FP: 24.0\n","positive FN: 27.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 50 minibatch: 1      time used: 20.56549882888794\n","minibatch AVG loss: 0.16368937261402608\n","Epoch: 19     train index of 50 minibatch: 2      time used: 19.445029973983765\n","minibatch AVG loss: 0.09596225740388035\n","Epoch: 19     train index of 50 minibatch: 3      time used: 19.931352138519287\n","minibatch AVG loss: 0.08090185446897522\n","Epoch: 19     train index of 50 minibatch: 4      time used: 19.443588972091675\n","minibatch AVG loss: 0.12427019382128492\n","Epoch: 19     train index of 50 minibatch: 5      time used: 20.048064947128296\n","minibatch AVG loss: 0.13077336110174656\n","Epoch: 19     train index of 50 minibatch: 6      time used: 19.313660383224487\n","minibatch AVG loss: 0.15489326895214617\n","\n","Epoch: 19  train \n","Loss: 0.1263  Acc: 94.7698\n","negative precision: 95.9793  recall: 95.8692\n","negative sensitivity: 95.8692  specificity: 92.7984\n","negative FPR: 7.2016  NPV: 92.6078\n","negative TP: 1671.0\n","negative TN: 902.0\n","negative FP: 70.0\n","negative FN: 72.0\n","positive precision: 92.6078  recall: 92.7984\n","positive sensitivity: 92.7984  specificity: 95.8692\n","positive FPR: 4.1308  NPV: 95.9793\n","positive TP: 902.0\n","positive TN: 1671.0\n","positive FP: 72.0\n","positive FN: 70.0\n","\n","\n","Epoch: 19     val index of 50 minibatch: 1      time used: 11.142709255218506\n","minibatch AVG loss: 0.11202352955471724\n","\n","Epoch: 19  val \n","Loss: 0.1875  Acc: 93.2153\n","negative precision: 94.3052  recall: 95.1724\n","negative sensitivity: 95.1724  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 91.2134\n","negative TP: 414.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 21.0\n","positive precision: 91.2134  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 95.1724\n","positive FPR: 4.8276  NPV: 94.3052\n","positive TP: 218.0\n","positive TN: 414.0\n","positive FP: 21.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 50 minibatch: 1      time used: 20.356863021850586\n","minibatch AVG loss: 0.07471299652941525\n","Epoch: 20     train index of 50 minibatch: 2      time used: 19.35935950279236\n","minibatch AVG loss: 0.12335420366609469\n","Epoch: 20     train index of 50 minibatch: 3      time used: 19.25968599319458\n","minibatch AVG loss: 0.10814729209523648\n","Epoch: 20     train index of 50 minibatch: 4      time used: 19.389761447906494\n","minibatch AVG loss: 0.15130544509738683\n","Epoch: 20     train index of 50 minibatch: 5      time used: 19.399563550949097\n","minibatch AVG loss: 0.14361027541570365\n","Epoch: 20     train index of 50 minibatch: 6      time used: 19.60576033592224\n","minibatch AVG loss: 0.1370578037854284\n","\n","Epoch: 20  train \n","Loss: 0.1212  Acc: 95.1013\n","negative precision: 96.2113  recall: 96.1561\n","negative sensitivity: 96.1561  specificity: 93.2099\n","negative FPR: 6.7901  NPV: 93.1141\n","negative TP: 1676.0\n","negative TN: 906.0\n","negative FP: 66.0\n","negative FN: 67.0\n","positive precision: 93.1141  recall: 93.2099\n","positive sensitivity: 93.2099  specificity: 96.1561\n","positive FPR: 3.8439  NPV: 96.2113\n","positive TP: 906.0\n","positive TN: 1676.0\n","positive FP: 67.0\n","positive FN: 66.0\n","\n","\n","Epoch: 20     val index of 50 minibatch: 1      time used: 11.270208358764648\n","minibatch AVG loss: 0.05542093655269127\n","\n","Epoch: 20  val \n","Loss: 0.2048  Acc: 94.2478\n","negative precision: 93.8053  recall: 97.4713\n","negative sensitivity: 97.4713  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 95.1327\n","negative TP: 424.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 11.0\n","positive precision: 95.1327  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 97.4713\n","positive FPR: 2.5287  NPV: 93.8053\n","positive TP: 215.0\n","positive TN: 424.0\n","positive FP: 11.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 50 minibatch: 1      time used: 20.565174341201782\n","minibatch AVG loss: 0.10158012724481523\n","Epoch: 21     train index of 50 minibatch: 2      time used: 19.82121992111206\n","minibatch AVG loss: 0.11526502730324864\n","Epoch: 21     train index of 50 minibatch: 3      time used: 19.83213472366333\n","minibatch AVG loss: 0.14207973090931772\n","Epoch: 21     train index of 50 minibatch: 4      time used: 19.982296466827393\n","minibatch AVG loss: 0.11378357021138072\n","Epoch: 21     train index of 50 minibatch: 5      time used: 19.81265878677368\n","minibatch AVG loss: 0.13138407387770712\n","Epoch: 21     train index of 50 minibatch: 6      time used: 20.128333806991577\n","minibatch AVG loss: 0.1123124890960753\n","\n","Epoch: 21  train \n","Loss: 0.1225  Acc: 94.7698\n","negative precision: 95.7690  recall: 96.0987\n","negative sensitivity: 96.0987  specificity: 92.3868\n","negative FPR: 7.6132  NPV: 92.9607\n","negative TP: 1675.0\n","negative TN: 898.0\n","negative FP: 74.0\n","negative FN: 68.0\n","positive precision: 92.9607  recall: 92.3868\n","positive sensitivity: 92.3868  specificity: 96.0987\n","positive FPR: 3.9013  NPV: 95.7690\n","positive TP: 898.0\n","positive TN: 1675.0\n","positive FP: 68.0\n","positive FN: 74.0\n","\n","\n","Epoch: 21     val index of 50 minibatch: 1      time used: 11.326269388198853\n","minibatch AVG loss: 0.21593036358215614\n","\n","Epoch: 21  val \n","Loss: 0.2588  Acc: 92.6254\n","negative precision: 96.1631  recall: 92.1839\n","negative sensitivity: 92.1839  specificity: 93.4156\n","negative FPR: 6.5844  NPV: 86.9732\n","negative TP: 401.0\n","negative TN: 227.0\n","negative FP: 16.0\n","negative FN: 34.0\n","positive precision: 86.9732  recall: 93.4156\n","positive sensitivity: 93.4156  specificity: 92.1839\n","positive FPR: 7.8161  NPV: 96.1631\n","positive TP: 227.0\n","positive TN: 401.0\n","positive FP: 34.0\n","positive FN: 16.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 50 minibatch: 1      time used: 20.648030757904053\n","minibatch AVG loss: 0.1062940871436149\n","Epoch: 22     train index of 50 minibatch: 2      time used: 19.79407787322998\n","minibatch AVG loss: 0.15135096945799886\n","Epoch: 22     train index of 50 minibatch: 3      time used: 20.199310541152954\n","minibatch AVG loss: 0.08440481175668538\n","Epoch: 22     train index of 50 minibatch: 4      time used: 19.5844988822937\n","minibatch AVG loss: 0.09255503136664629\n","Epoch: 22     train index of 50 minibatch: 5      time used: 19.95032048225403\n","minibatch AVG loss: 0.07240520278573967\n","Epoch: 22     train index of 50 minibatch: 6      time used: 19.973016500473022\n","minibatch AVG loss: 0.09017274644924328\n","\n","Epoch: 22  train \n","Loss: 0.1082  Acc: 95.9484\n","negative precision: 96.8445  recall: 96.8445\n","negative sensitivity: 96.8445  specificity: 94.3416\n","negative FPR: 5.6584  NPV: 94.3416\n","negative TP: 1688.0\n","negative TN: 917.0\n","negative FP: 55.0\n","negative FN: 55.0\n","positive precision: 94.3416  recall: 94.3416\n","positive sensitivity: 94.3416  specificity: 96.8445\n","positive FPR: 3.1555  NPV: 96.8445\n","positive TP: 917.0\n","positive TN: 1688.0\n","positive FP: 55.0\n","positive FN: 55.0\n","\n","\n","Epoch: 22     val index of 50 minibatch: 1      time used: 11.329022884368896\n","minibatch AVG loss: 0.13533509510045405\n","\n","Epoch: 22  val \n","Loss: 0.1984  Acc: 93.8053\n","negative precision: 96.0187  recall: 94.2529\n","negative sensitivity: 94.2529  specificity: 93.0041\n","negative FPR: 6.9959  NPV: 90.0398\n","negative TP: 410.0\n","negative TN: 226.0\n","negative FP: 17.0\n","negative FN: 25.0\n","positive precision: 90.0398  recall: 93.0041\n","positive sensitivity: 93.0041  specificity: 94.2529\n","positive FPR: 5.7471  NPV: 96.0187\n","positive TP: 226.0\n","positive TN: 410.0\n","positive FP: 25.0\n","positive FN: 17.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 50 minibatch: 1      time used: 20.493847608566284\n","minibatch AVG loss: 0.117753025139682\n","Epoch: 23     train index of 50 minibatch: 2      time used: 19.997527360916138\n","minibatch AVG loss: 0.09399113398976625\n","Epoch: 23     train index of 50 minibatch: 3      time used: 20.173312425613403\n","minibatch AVG loss: 0.11811421493068337\n","Epoch: 23     train index of 50 minibatch: 4      time used: 19.58000135421753\n","minibatch AVG loss: 0.06819540919736028\n","Epoch: 23     train index of 50 minibatch: 5      time used: 19.917144536972046\n","minibatch AVG loss: 0.08952223769621924\n","Epoch: 23     train index of 50 minibatch: 6      time used: 20.005170822143555\n","minibatch AVG loss: 0.11273350750561803\n","\n","Epoch: 23  train \n","Loss: 0.1020  Acc: 95.7274\n","negative precision: 96.6724  recall: 96.6724\n","negative sensitivity: 96.6724  specificity: 94.0329\n","negative FPR: 5.9671  NPV: 94.0329\n","negative TP: 1685.0\n","negative TN: 914.0\n","negative FP: 58.0\n","negative FN: 58.0\n","positive precision: 94.0329  recall: 94.0329\n","positive sensitivity: 94.0329  specificity: 96.6724\n","positive FPR: 3.3276  NPV: 96.6724\n","positive TP: 914.0\n","positive TN: 1685.0\n","positive FP: 58.0\n","positive FN: 58.0\n","\n","\n","Epoch: 23     val index of 50 minibatch: 1      time used: 11.362220048904419\n","minibatch AVG loss: 0.07705280326335924\n","\n","Epoch: 23  val \n","Loss: 0.2190  Acc: 92.0354\n","negative precision: 91.8681  recall: 96.0920\n","negative sensitivity: 96.0920  specificity: 84.7737\n","negative FPR: 15.2263  NPV: 92.3767\n","negative TP: 418.0\n","negative TN: 206.0\n","negative FP: 37.0\n","negative FN: 17.0\n","positive precision: 92.3767  recall: 84.7737\n","positive sensitivity: 84.7737  specificity: 96.0920\n","positive FPR: 3.9080  NPV: 91.8681\n","positive TP: 206.0\n","positive TN: 418.0\n","positive FP: 17.0\n","positive FN: 37.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 50 minibatch: 1      time used: 20.587107181549072\n","minibatch AVG loss: 0.09219547621440143\n","Epoch: 24     train index of 50 minibatch: 2      time used: 19.91089940071106\n","minibatch AVG loss: 0.09833643772173672\n","Epoch: 24     train index of 50 minibatch: 3      time used: 19.835880756378174\n","minibatch AVG loss: 0.1379983827052638\n","Epoch: 24     train index of 50 minibatch: 4      time used: 20.289897918701172\n","minibatch AVG loss: 0.10278599453158677\n","Epoch: 24     train index of 50 minibatch: 5      time used: 19.611302852630615\n","minibatch AVG loss: 0.11664702924899757\n","Epoch: 24     train index of 50 minibatch: 6      time used: 20.13426160812378\n","minibatch AVG loss: 0.10735337786376477\n","\n","Epoch: 24  train \n","Loss: 0.1072  Acc: 95.6538\n","negative precision: 96.6150  recall: 96.6150\n","negative sensitivity: 96.6150  specificity: 93.9300\n","negative FPR: 6.0700  NPV: 93.9300\n","negative TP: 1684.0\n","negative TN: 913.0\n","negative FP: 59.0\n","negative FN: 59.0\n","positive precision: 93.9300  recall: 93.9300\n","positive sensitivity: 93.9300  specificity: 96.6150\n","positive FPR: 3.3850  NPV: 96.6150\n","positive TP: 913.0\n","positive TN: 1684.0\n","positive FP: 59.0\n","positive FN: 59.0\n","\n","\n","Epoch: 24     val index of 50 minibatch: 1      time used: 11.326409816741943\n","minibatch AVG loss: 0.10656418239464983\n","\n","Epoch: 24  val \n","Loss: 0.2238  Acc: 92.9204\n","negative precision: 93.4831  recall: 95.6322\n","negative sensitivity: 95.6322  specificity: 88.0658\n","negative FPR: 11.9342  NPV: 91.8455\n","negative TP: 416.0\n","negative TN: 214.0\n","negative FP: 29.0\n","negative FN: 19.0\n","positive precision: 91.8455  recall: 88.0658\n","positive sensitivity: 88.0658  specificity: 95.6322\n","positive FPR: 4.3678  NPV: 93.4831\n","positive TP: 214.0\n","positive TN: 416.0\n","positive FP: 19.0\n","positive FN: 29.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 50 minibatch: 1      time used: 20.486449241638184\n","minibatch AVG loss: 0.06635161325335502\n","Epoch: 25     train index of 50 minibatch: 2      time used: 19.857344388961792\n","minibatch AVG loss: 0.11134094803128392\n","Epoch: 25     train index of 50 minibatch: 3      time used: 20.03339147567749\n","minibatch AVG loss: 0.08149227852001786\n","Epoch: 25     train index of 50 minibatch: 4      time used: 19.435311794281006\n","minibatch AVG loss: 0.08961851488333196\n","Epoch: 25     train index of 50 minibatch: 5      time used: 19.811858415603638\n","minibatch AVG loss: 0.09673773607239128\n","Epoch: 25     train index of 50 minibatch: 6      time used: 19.987812757492065\n","minibatch AVG loss: 0.11217237935401499\n","\n","Epoch: 25  train \n","Loss: 0.0922  Acc: 96.0589\n","negative precision: 96.9575  recall: 96.9019\n","negative sensitivity: 96.9019  specificity: 94.5473\n","negative FPR: 5.4527  NPV: 94.4502\n","negative TP: 1689.0\n","negative TN: 919.0\n","negative FP: 53.0\n","negative FN: 54.0\n","positive precision: 94.4502  recall: 94.5473\n","positive sensitivity: 94.5473  specificity: 96.9019\n","positive FPR: 3.0981  NPV: 96.9575\n","positive TP: 919.0\n","positive TN: 1689.0\n","positive FP: 54.0\n","positive FN: 53.0\n","\n","\n","Epoch: 25     val index of 50 minibatch: 1      time used: 11.44881296157837\n","minibatch AVG loss: 0.10854920164278155\n","\n","Epoch: 25  val \n","Loss: 0.2275  Acc: 93.2153\n","negative precision: 94.3052  recall: 95.1724\n","negative sensitivity: 95.1724  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 91.2134\n","negative TP: 414.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 21.0\n","positive precision: 91.2134  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 95.1724\n","positive FPR: 4.8276  NPV: 94.3052\n","positive TP: 218.0\n","positive TN: 414.0\n","positive FP: 21.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 50 minibatch: 1      time used: 20.276018381118774\n","minibatch AVG loss: 0.07593529916368424\n","Epoch: 26     train index of 50 minibatch: 2      time used: 19.95112633705139\n","minibatch AVG loss: 0.11311398829333484\n","Epoch: 26     train index of 50 minibatch: 3      time used: 19.47858953475952\n","minibatch AVG loss: 0.13164750690106303\n","Epoch: 26     train index of 50 minibatch: 4      time used: 19.95613670349121\n","minibatch AVG loss: 0.12090681718429551\n","Epoch: 26     train index of 50 minibatch: 5      time used: 19.86821937561035\n","minibatch AVG loss: 0.08008234480861574\n","Epoch: 26     train index of 50 minibatch: 6      time used: 19.589247226715088\n","minibatch AVG loss: 0.09891198456753045\n","\n","Epoch: 26  train \n","Loss: 0.1087  Acc: 96.0221\n","negative precision: 96.9558  recall: 96.8445\n","negative sensitivity: 96.8445  specificity: 94.5473\n","negative FPR: 5.4527  NPV: 94.3532\n","negative TP: 1688.0\n","negative TN: 919.0\n","negative FP: 53.0\n","negative FN: 55.0\n","positive precision: 94.3532  recall: 94.5473\n","positive sensitivity: 94.5473  specificity: 96.8445\n","positive FPR: 3.1555  NPV: 96.9558\n","positive TP: 919.0\n","positive TN: 1688.0\n","positive FP: 55.0\n","positive FN: 53.0\n","\n","\n","Epoch: 26     val index of 50 minibatch: 1      time used: 11.446051359176636\n","minibatch AVG loss: 0.09404836645000614\n","\n","Epoch: 26  val \n","Loss: 0.2071  Acc: 91.7404\n","negative precision: 91.6484  recall: 95.8621\n","negative sensitivity: 95.8621  specificity: 84.3621\n","negative FPR: 15.6379  NPV: 91.9283\n","negative TP: 417.0\n","negative TN: 205.0\n","negative FP: 38.0\n","negative FN: 18.0\n","positive precision: 91.9283  recall: 84.3621\n","positive sensitivity: 84.3621  specificity: 95.8621\n","positive FPR: 4.1379  NPV: 91.6484\n","positive TP: 205.0\n","positive TN: 417.0\n","positive FP: 18.0\n","positive FN: 38.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 50 minibatch: 1      time used: 20.466027975082397\n","minibatch AVG loss: 0.05834198022261262\n","Epoch: 27     train index of 50 minibatch: 2      time used: 19.93939781188965\n","minibatch AVG loss: 0.07959450556430965\n","Epoch: 27     train index of 50 minibatch: 3      time used: 19.571539640426636\n","minibatch AVG loss: 0.041920098912669346\n","Epoch: 27     train index of 50 minibatch: 4      time used: 19.83858323097229\n","minibatch AVG loss: 0.06464972379850224\n","Epoch: 27     train index of 50 minibatch: 5      time used: 20.00126075744629\n","minibatch AVG loss: 0.1191482832795009\n","Epoch: 27     train index of 50 minibatch: 6      time used: 19.679535150527954\n","minibatch AVG loss: 0.11793394852429628\n","\n","Epoch: 27  train \n","Loss: 0.0776  Acc: 96.8324\n","negative precision: 97.6423  recall: 97.4182\n","negative sensitivity: 97.4182  specificity: 95.7819\n","negative FPR: 4.2181  NPV: 95.3893\n","negative TP: 1698.0\n","negative TN: 931.0\n","negative FP: 41.0\n","negative FN: 45.0\n","positive precision: 95.3893  recall: 95.7819\n","positive sensitivity: 95.7819  specificity: 97.4182\n","positive FPR: 2.5818  NPV: 97.6423\n","positive TP: 931.0\n","positive TN: 1698.0\n","positive FP: 45.0\n","positive FN: 41.0\n","\n","\n","Epoch: 27     val index of 50 minibatch: 1      time used: 11.459067583084106\n","minibatch AVG loss: 0.12017254822727409\n","\n","Epoch: 27  val \n","Loss: 0.2551  Acc: 92.9204\n","negative precision: 93.4831  recall: 95.6322\n","negative sensitivity: 95.6322  specificity: 88.0658\n","negative FPR: 11.9342  NPV: 91.8455\n","negative TP: 416.0\n","negative TN: 214.0\n","negative FP: 29.0\n","negative FN: 19.0\n","positive precision: 91.8455  recall: 88.0658\n","positive sensitivity: 88.0658  specificity: 95.6322\n","positive FPR: 4.3678  NPV: 93.4831\n","positive TP: 214.0\n","positive TN: 416.0\n","positive FP: 19.0\n","positive FN: 29.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 50 minibatch: 1      time used: 20.733946561813354\n","minibatch AVG loss: 0.07250617715064436\n","Epoch: 28     train index of 50 minibatch: 2      time used: 19.911284923553467\n","minibatch AVG loss: 0.0802273316681385\n","Epoch: 28     train index of 50 minibatch: 3      time used: 19.74876117706299\n","minibatch AVG loss: 0.10534643382765353\n","Epoch: 28     train index of 50 minibatch: 4      time used: 19.96993136405945\n","minibatch AVG loss: 0.11728034892119467\n","Epoch: 28     train index of 50 minibatch: 5      time used: 20.12494921684265\n","minibatch AVG loss: 0.09730986351380125\n","Epoch: 28     train index of 50 minibatch: 6      time used: 19.917363166809082\n","minibatch AVG loss: 0.08161601511295885\n","\n","Epoch: 28  train \n","Loss: 0.0923  Acc: 96.5009\n","negative precision: 97.1396  recall: 97.4182\n","negative sensitivity: 97.4182  specificity: 94.8560\n","negative FPR: 5.1440  NPV: 95.3464\n","negative TP: 1698.0\n","negative TN: 922.0\n","negative FP: 50.0\n","negative FN: 45.0\n","positive precision: 95.3464  recall: 94.8560\n","positive sensitivity: 94.8560  specificity: 97.4182\n","positive FPR: 2.5818  NPV: 97.1396\n","positive TP: 922.0\n","positive TN: 1698.0\n","positive FP: 45.0\n","positive FN: 50.0\n","\n","\n","Epoch: 28     val index of 50 minibatch: 1      time used: 11.503658771514893\n","minibatch AVG loss: 0.0828311814184417\n","\n","Epoch: 28  val \n","Loss: 0.2355  Acc: 92.1829\n","negative precision: 91.3420  recall: 97.0115\n","negative sensitivity: 97.0115  specificity: 83.5391\n","negative FPR: 16.4609  NPV: 93.9815\n","negative TP: 422.0\n","negative TN: 203.0\n","negative FP: 40.0\n","negative FN: 13.0\n","positive precision: 93.9815  recall: 83.5391\n","positive sensitivity: 83.5391  specificity: 97.0115\n","positive FPR: 2.9885  NPV: 91.3420\n","positive TP: 203.0\n","positive TN: 422.0\n","positive FP: 13.0\n","positive FN: 40.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 50 minibatch: 1      time used: 20.580763578414917\n","minibatch AVG loss: 0.05971749745309353\n","Epoch: 29     train index of 50 minibatch: 2      time used: 20.148617029190063\n","minibatch AVG loss: 0.12561016455758364\n","Epoch: 29     train index of 50 minibatch: 3      time used: 19.853236436843872\n","minibatch AVG loss: 0.07944318269379437\n","Epoch: 29     train index of 50 minibatch: 4      time used: 19.730053186416626\n","minibatch AVG loss: 0.09538534226361663\n","Epoch: 29     train index of 50 minibatch: 5      time used: 19.957699298858643\n","minibatch AVG loss: 0.1323322404967621\n","Epoch: 29     train index of 50 minibatch: 6      time used: 19.98138427734375\n","minibatch AVG loss: 0.07380613709334284\n","\n","Epoch: 29  train \n","Loss: 0.0922  Acc: 96.7219\n","negative precision: 97.3112  recall: 97.5904\n","negative sensitivity: 97.5904  specificity: 95.1646\n","negative FPR: 4.8354  NPV: 95.6567\n","negative TP: 1701.0\n","negative TN: 925.0\n","negative FP: 47.0\n","negative FN: 42.0\n","positive precision: 95.6567  recall: 95.1646\n","positive sensitivity: 95.1646  specificity: 97.5904\n","positive FPR: 2.4096  NPV: 97.3112\n","positive TP: 925.0\n","positive TN: 1701.0\n","positive FP: 42.0\n","positive FN: 47.0\n","\n","\n","Epoch: 29     val index of 50 minibatch: 1      time used: 11.404944896697998\n","minibatch AVG loss: 0.1361371150954801\n","\n","Epoch: 29  val \n","Loss: 0.2410  Acc: 93.3628\n","negative precision: 93.7220  recall: 96.0920\n","negative sensitivity: 96.0920  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 92.6724\n","negative TP: 418.0\n","negative TN: 215.0\n","negative FP: 28.0\n","negative FN: 17.0\n","positive precision: 92.6724  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 96.0920\n","positive FPR: 3.9080  NPV: 93.7220\n","positive TP: 215.0\n","positive TN: 418.0\n","positive FP: 17.0\n","positive FN: 28.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 50 minibatch: 1      time used: 20.33922839164734\n","minibatch AVG loss: 0.07249627394136042\n","Epoch: 30     train index of 50 minibatch: 2      time used: 20.021356344223022\n","minibatch AVG loss: 0.07090978092513979\n","Epoch: 30     train index of 50 minibatch: 3      time used: 19.577718019485474\n","minibatch AVG loss: 0.06031880079302937\n","Epoch: 30     train index of 50 minibatch: 4      time used: 20.16053318977356\n","minibatch AVG loss: 0.0694843353657052\n","Epoch: 30     train index of 50 minibatch: 5      time used: 19.641963005065918\n","minibatch AVG loss: 0.05053656050353311\n","Epoch: 30     train index of 50 minibatch: 6      time used: 19.723329782485962\n","minibatch AVG loss: 0.09802931395824999\n","\n","Epoch: 30  train \n","Loss: 0.0700  Acc: 97.4217\n","negative precision: 97.9370  recall: 98.0493\n","negative sensitivity: 98.0493  specificity: 96.2963\n","negative FPR: 3.7037  NPV: 96.4948\n","negative TP: 1709.0\n","negative TN: 936.0\n","negative FP: 36.0\n","negative FN: 34.0\n","positive precision: 96.4948  recall: 96.2963\n","positive sensitivity: 96.2963  specificity: 98.0493\n","positive FPR: 1.9507  NPV: 97.9370\n","positive TP: 936.0\n","positive TN: 1709.0\n","positive FP: 34.0\n","positive FN: 36.0\n","\n","\n","Epoch: 30     val index of 50 minibatch: 1      time used: 11.388253927230835\n","minibatch AVG loss: 0.1318512595237553\n","\n","Epoch: 30  val \n","Loss: 0.2455  Acc: 92.0354\n","negative precision: 93.0023  recall: 94.7126\n","negative sensitivity: 94.7126  specificity: 87.2428\n","negative FPR: 12.7572  NPV: 90.2128\n","negative TP: 412.0\n","negative TN: 212.0\n","negative FP: 31.0\n","negative FN: 23.0\n","positive precision: 90.2128  recall: 87.2428\n","positive sensitivity: 87.2428  specificity: 94.7126\n","positive FPR: 5.2874  NPV: 93.0023\n","positive TP: 212.0\n","positive TN: 412.0\n","positive FP: 23.0\n","positive FN: 31.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 50 minibatch: 1      time used: 20.40817928314209\n","minibatch AVG loss: 0.0810279159876518\n","Epoch: 31     train index of 50 minibatch: 2      time used: 19.788272380828857\n","minibatch AVG loss: 0.0673300731787458\n","Epoch: 31     train index of 50 minibatch: 3      time used: 20.163511753082275\n","minibatch AVG loss: 0.0749150156788528\n","Epoch: 31     train index of 50 minibatch: 4      time used: 19.97074794769287\n","minibatch AVG loss: 0.08080618783133105\n","Epoch: 31     train index of 50 minibatch: 5      time used: 19.999608278274536\n","minibatch AVG loss: 0.08555757304653526\n","Epoch: 31     train index of 50 minibatch: 6      time used: 20.11754560470581\n","minibatch AVG loss: 0.07085600253660232\n","\n","Epoch: 31  train \n","Loss: 0.0777  Acc: 97.0166\n","negative precision: 97.8687  recall: 97.4756\n","negative sensitivity: 97.4756  specificity: 96.1934\n","negative FPR: 3.8066  NPV: 95.5056\n","negative TP: 1699.0\n","negative TN: 935.0\n","negative FP: 37.0\n","negative FN: 44.0\n","positive precision: 95.5056  recall: 96.1934\n","positive sensitivity: 96.1934  specificity: 97.4756\n","positive FPR: 2.5244  NPV: 97.8687\n","positive TP: 935.0\n","positive TN: 1699.0\n","positive FP: 44.0\n","positive FN: 37.0\n","\n","\n","Epoch: 31     val index of 50 minibatch: 1      time used: 11.382867574691772\n","minibatch AVG loss: 0.1850456337200012\n","\n","Epoch: 31  val \n","Loss: 0.2142  Acc: 92.9204\n","negative precision: 95.1049  recall: 93.7931\n","negative sensitivity: 93.7931  specificity: 91.3580\n","negative FPR: 8.6420  NPV: 89.1566\n","negative TP: 408.0\n","negative TN: 222.0\n","negative FP: 21.0\n","negative FN: 27.0\n","positive precision: 89.1566  recall: 91.3580\n","positive sensitivity: 91.3580  specificity: 93.7931\n","positive FPR: 6.2069  NPV: 95.1049\n","positive TP: 222.0\n","positive TN: 408.0\n","positive FP: 27.0\n","positive FN: 21.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 50 minibatch: 1      time used: 20.624181270599365\n","minibatch AVG loss: 0.05035979251610115\n","Epoch: 32     train index of 50 minibatch: 2      time used: 19.758240222930908\n","minibatch AVG loss: 0.06626104557071813\n","Epoch: 32     train index of 50 minibatch: 3      time used: 19.678519010543823\n","minibatch AVG loss: 0.059567106724716726\n","Epoch: 32     train index of 50 minibatch: 4      time used: 19.51071858406067\n","minibatch AVG loss: 0.052550006048986686\n","Epoch: 32     train index of 50 minibatch: 5      time used: 19.937787532806396\n","minibatch AVG loss: 0.08701328688766807\n","Epoch: 32     train index of 50 minibatch: 6      time used: 19.916489124298096\n","minibatch AVG loss: 0.039600865084212275\n","\n","Epoch: 32  train \n","Loss: 0.0586  Acc: 97.5322\n","negative precision: 98.2163  recall: 97.9346\n","negative sensitivity: 97.9346  specificity: 96.8107\n","negative FPR: 3.1893  NPV: 96.3153\n","negative TP: 1707.0\n","negative TN: 941.0\n","negative FP: 31.0\n","negative FN: 36.0\n","positive precision: 96.3153  recall: 96.8107\n","positive sensitivity: 96.8107  specificity: 97.9346\n","positive FPR: 2.0654  NPV: 98.2163\n","positive TP: 941.0\n","positive TN: 1707.0\n","positive FP: 36.0\n","positive FN: 31.0\n","\n","\n","Epoch: 32     val index of 50 minibatch: 1      time used: 11.388079404830933\n","minibatch AVG loss: 0.11769383773498703\n","\n","Epoch: 32  val \n","Loss: 0.3187  Acc: 91.8879\n","negative precision: 91.1255  recall: 96.7816\n","negative sensitivity: 96.7816  specificity: 83.1276\n","negative FPR: 16.8724  NPV: 93.5185\n","negative TP: 421.0\n","negative TN: 202.0\n","negative FP: 41.0\n","negative FN: 14.0\n","positive precision: 93.5185  recall: 83.1276\n","positive sensitivity: 83.1276  specificity: 96.7816\n","positive FPR: 3.2184  NPV: 91.1255\n","positive TP: 202.0\n","positive TN: 421.0\n","positive FP: 14.0\n","positive FN: 41.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 50 minibatch: 1      time used: 20.645665884017944\n","minibatch AVG loss: 0.03248402437428013\n","Epoch: 33     train index of 50 minibatch: 2      time used: 19.796473503112793\n","minibatch AVG loss: 0.06310684814932756\n","Epoch: 33     train index of 50 minibatch: 3      time used: 19.75613760948181\n","minibatch AVG loss: 0.07144711744738742\n","Epoch: 33     train index of 50 minibatch: 4      time used: 20.388822317123413\n","minibatch AVG loss: 0.07616077836137265\n","Epoch: 33     train index of 50 minibatch: 5      time used: 20.769859552383423\n","minibatch AVG loss: 0.06311568857636303\n","Epoch: 33     train index of 50 minibatch: 6      time used: 20.211750507354736\n","minibatch AVG loss: 0.09341848208336159\n","\n","Epoch: 33  train \n","Loss: 0.0656  Acc: 97.5691\n","negative precision: 98.2729  recall: 97.9346\n","negative sensitivity: 97.9346  specificity: 96.9136\n","negative FPR: 3.0864  NPV: 96.3190\n","negative TP: 1707.0\n","negative TN: 942.0\n","negative FP: 30.0\n","negative FN: 36.0\n","positive precision: 96.3190  recall: 96.9136\n","positive sensitivity: 96.9136  specificity: 97.9346\n","positive FPR: 2.0654  NPV: 98.2729\n","positive TP: 942.0\n","positive TN: 1707.0\n","positive FP: 36.0\n","positive FN: 30.0\n","\n","\n","Epoch: 33     val index of 50 minibatch: 1      time used: 11.648541450500488\n","minibatch AVG loss: 0.11186507835780503\n","\n","Epoch: 33  val \n","Loss: 0.2328  Acc: 92.7729\n","negative precision: 92.6991  recall: 96.3218\n","negative sensitivity: 96.3218  specificity: 86.4198\n","negative FPR: 13.5802  NPV: 92.9204\n","negative TP: 419.0\n","negative TN: 210.0\n","negative FP: 33.0\n","negative FN: 16.0\n","positive precision: 92.9204  recall: 86.4198\n","positive sensitivity: 86.4198  specificity: 96.3218\n","positive FPR: 3.6782  NPV: 92.6991\n","positive TP: 210.0\n","positive TN: 419.0\n","positive FP: 16.0\n","positive FN: 33.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 50 minibatch: 1      time used: 20.500275373458862\n","minibatch AVG loss: 0.05696474646916613\n","Epoch: 34     train index of 50 minibatch: 2      time used: 20.14368724822998\n","minibatch AVG loss: 0.04770588210551068\n","Epoch: 34     train index of 50 minibatch: 3      time used: 19.650182962417603\n","minibatch AVG loss: 0.042766328663565216\n","Epoch: 34     train index of 50 minibatch: 4      time used: 19.998173475265503\n","minibatch AVG loss: 0.05447536877705716\n","Epoch: 34     train index of 50 minibatch: 5      time used: 19.61167860031128\n","minibatch AVG loss: 0.041894908037502315\n","Epoch: 34     train index of 50 minibatch: 6      time used: 19.82162046432495\n","minibatch AVG loss: 0.028236411786638202\n","\n","Epoch: 34  train \n","Loss: 0.0497  Acc: 98.1215\n","negative precision: 98.6766  recall: 98.3936\n","negative sensitivity: 98.3936  specificity: 97.6337\n","negative FPR: 2.3663  NPV: 97.1341\n","negative TP: 1715.0\n","negative TN: 949.0\n","negative FP: 23.0\n","negative FN: 28.0\n","positive precision: 97.1341  recall: 97.6337\n","positive sensitivity: 97.6337  specificity: 98.3936\n","positive FPR: 1.6064  NPV: 98.6766\n","positive TP: 949.0\n","positive TN: 1715.0\n","positive FP: 28.0\n","positive FN: 23.0\n","\n","\n","Epoch: 34     val index of 50 minibatch: 1      time used: 11.370094060897827\n","minibatch AVG loss: 0.074240665376783\n","\n","Epoch: 34  val \n","Loss: 0.3117  Acc: 91.4454\n","negative precision: 90.1919  recall: 97.2414\n","negative sensitivity: 97.2414  specificity: 81.0700\n","negative FPR: 18.9300  NPV: 94.2584\n","negative TP: 423.0\n","negative TN: 197.0\n","negative FP: 46.0\n","negative FN: 12.0\n","positive precision: 94.2584  recall: 81.0700\n","positive sensitivity: 81.0700  specificity: 97.2414\n","positive FPR: 2.7586  NPV: 90.1919\n","positive TP: 197.0\n","positive TN: 423.0\n","positive FP: 12.0\n","positive FN: 46.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 50 minibatch: 1      time used: 20.405900478363037\n","minibatch AVG loss: 0.05597815323853865\n","Epoch: 35     train index of 50 minibatch: 2      time used: 20.01801562309265\n","minibatch AVG loss: 0.056200574340764434\n","Epoch: 35     train index of 50 minibatch: 3      time used: 20.28756833076477\n","minibatch AVG loss: 0.05344261104939505\n","Epoch: 35     train index of 50 minibatch: 4      time used: 19.75318455696106\n","minibatch AVG loss: 0.03816176738240756\n","Epoch: 35     train index of 50 minibatch: 5      time used: 19.907146453857422\n","minibatch AVG loss: 0.02858423721860163\n","Epoch: 35     train index of 50 minibatch: 6      time used: 19.806251049041748\n","minibatch AVG loss: 0.07032846651272848\n","\n","Epoch: 35  train \n","Loss: 0.0540  Acc: 97.9006\n","negative precision: 98.2818  recall: 98.4509\n","negative sensitivity: 98.4509  specificity: 96.9136\n","negative FPR: 3.0864  NPV: 97.2136\n","negative TP: 1716.0\n","negative TN: 942.0\n","negative FP: 30.0\n","negative FN: 27.0\n","positive precision: 97.2136  recall: 96.9136\n","positive sensitivity: 96.9136  specificity: 98.4509\n","positive FPR: 1.5491  NPV: 98.2818\n","positive TP: 942.0\n","positive TN: 1716.0\n","positive FP: 27.0\n","positive FN: 30.0\n","\n","\n","Epoch: 35     val index of 50 minibatch: 1      time used: 11.412914752960205\n","minibatch AVG loss: 0.10251617847905437\n","\n","Epoch: 35  val \n","Loss: 0.2402  Acc: 93.8053\n","negative precision: 94.3567  recall: 96.0920\n","negative sensitivity: 96.0920  specificity: 89.7119\n","negative FPR: 10.2881  NPV: 92.7660\n","negative TP: 418.0\n","negative TN: 218.0\n","negative FP: 25.0\n","negative FN: 17.0\n","positive precision: 92.7660  recall: 89.7119\n","positive sensitivity: 89.7119  specificity: 96.0920\n","positive FPR: 3.9080  NPV: 94.3567\n","positive TP: 218.0\n","positive TN: 418.0\n","positive FP: 17.0\n","positive FN: 25.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 50 minibatch: 1      time used: 20.48863935470581\n","minibatch AVG loss: 0.055667160525918004\n","Epoch: 36     train index of 50 minibatch: 2      time used: 19.852736234664917\n","minibatch AVG loss: 0.05209625087562017\n","Epoch: 36     train index of 50 minibatch: 3      time used: 19.984167098999023\n","minibatch AVG loss: 0.05812484094174579\n","Epoch: 36     train index of 50 minibatch: 4      time used: 19.741863250732422\n","minibatch AVG loss: 0.038988670118851584\n","Epoch: 36     train index of 50 minibatch: 5      time used: 19.89381456375122\n","minibatch AVG loss: 0.06606872555566952\n","Epoch: 36     train index of 50 minibatch: 6      time used: 20.041624307632446\n","minibatch AVG loss: 0.0637319887150079\n","\n","Epoch: 36  train \n","Loss: 0.0546  Acc: 98.0110\n","negative precision: 98.6183  recall: 98.2788\n","negative sensitivity: 98.2788  specificity: 97.5309\n","negative FPR: 2.4691  NPV: 96.9325\n","negative TP: 1713.0\n","negative TN: 948.0\n","negative FP: 24.0\n","negative FN: 30.0\n","positive precision: 96.9325  recall: 97.5309\n","positive sensitivity: 97.5309  specificity: 98.2788\n","positive FPR: 1.7212  NPV: 98.6183\n","positive TP: 948.0\n","positive TN: 1713.0\n","positive FP: 30.0\n","positive FN: 24.0\n","\n","\n","Epoch: 36     val index of 50 minibatch: 1      time used: 11.437281370162964\n","minibatch AVG loss: 0.09313293283379608\n","\n","Epoch: 36  val \n","Loss: 0.3136  Acc: 92.4779\n","negative precision: 91.7391  recall: 97.0115\n","negative sensitivity: 97.0115  specificity: 84.3621\n","negative FPR: 15.6379  NPV: 94.0367\n","negative TP: 422.0\n","negative TN: 205.0\n","negative FP: 38.0\n","negative FN: 13.0\n","positive precision: 94.0367  recall: 84.3621\n","positive sensitivity: 84.3621  specificity: 97.0115\n","positive FPR: 2.9885  NPV: 91.7391\n","positive TP: 205.0\n","positive TN: 422.0\n","positive FP: 13.0\n","positive FN: 38.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 50 minibatch: 1      time used: 20.48393440246582\n","minibatch AVG loss: 0.034075738340616224\n","Epoch: 37     train index of 50 minibatch: 2      time used: 19.678367137908936\n","minibatch AVG loss: 0.04333293807634618\n","Epoch: 37     train index of 50 minibatch: 3      time used: 19.620360851287842\n","minibatch AVG loss: 0.05471383281517774\n","Epoch: 37     train index of 50 minibatch: 4      time used: 19.798990726470947\n","minibatch AVG loss: 0.06552262530196458\n","Epoch: 37     train index of 50 minibatch: 5      time used: 19.5170841217041\n","minibatch AVG loss: 0.053341395223978905\n","Epoch: 37     train index of 50 minibatch: 6      time used: 19.346136569976807\n","minibatch AVG loss: 0.08009179107379168\n","\n","Epoch: 37  train \n","Loss: 0.0541  Acc: 97.8637\n","negative precision: 98.3917  recall: 98.2788\n","negative sensitivity: 98.2788  specificity: 97.1193\n","negative FPR: 2.8807  NPV: 96.9199\n","negative TP: 1713.0\n","negative TN: 944.0\n","negative FP: 28.0\n","negative FN: 30.0\n","positive precision: 96.9199  recall: 97.1193\n","positive sensitivity: 97.1193  specificity: 98.2788\n","positive FPR: 1.7212  NPV: 98.3917\n","positive TP: 944.0\n","positive TN: 1713.0\n","positive FP: 30.0\n","positive FN: 28.0\n","\n","\n","Epoch: 37     val index of 50 minibatch: 1      time used: 11.18728518486023\n","minibatch AVG loss: 0.07330462229441764\n","\n","Epoch: 37  val \n","Loss: 0.2676  Acc: 93.2153\n","negative precision: 92.1909  recall: 97.7011\n","negative sensitivity: 97.7011  specificity: 85.1852\n","negative FPR: 14.8148  NPV: 95.3917\n","negative TP: 425.0\n","negative TN: 207.0\n","negative FP: 36.0\n","negative FN: 10.0\n","positive precision: 95.3917  recall: 85.1852\n","positive sensitivity: 85.1852  specificity: 97.7011\n","positive FPR: 2.2989  NPV: 92.1909\n","positive TP: 207.0\n","positive TN: 425.0\n","positive FP: 10.0\n","positive FN: 36.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 50 minibatch: 1      time used: 20.235329627990723\n","minibatch AVG loss: 0.042232591517968106\n","Epoch: 38     train index of 50 minibatch: 2      time used: 19.34541130065918\n","minibatch AVG loss: 0.07459187984699384\n","Epoch: 38     train index of 50 minibatch: 3      time used: 19.844425439834595\n","minibatch AVG loss: 0.0683817410474876\n","Epoch: 38     train index of 50 minibatch: 4      time used: 19.533502340316772\n","minibatch AVG loss: 0.057541811482515186\n","Epoch: 38     train index of 50 minibatch: 5      time used: 19.92966365814209\n","minibatch AVG loss: 0.05897845281288028\n","Epoch: 38     train index of 50 minibatch: 6      time used: 19.757293224334717\n","minibatch AVG loss: 0.03457608365919441\n","\n","Epoch: 38  train \n","Loss: 0.0574  Acc: 97.9742\n","negative precision: 98.5057  recall: 98.3362\n","negative sensitivity: 98.3362  specificity: 97.3251\n","negative FPR: 2.6749  NPV: 97.0256\n","negative TP: 1714.0\n","negative TN: 946.0\n","negative FP: 26.0\n","negative FN: 29.0\n","positive precision: 97.0256  recall: 97.3251\n","positive sensitivity: 97.3251  specificity: 98.3362\n","positive FPR: 1.6638  NPV: 98.5057\n","positive TP: 946.0\n","positive TN: 1714.0\n","positive FP: 29.0\n","positive FN: 26.0\n","\n","\n","Epoch: 38     val index of 50 minibatch: 1      time used: 11.506154775619507\n","minibatch AVG loss: 0.13004779538456204\n","\n","Epoch: 38  val \n","Loss: 0.2637  Acc: 92.1829\n","negative precision: 92.4444  recall: 95.6322\n","negative sensitivity: 95.6322  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 91.6667\n","negative TP: 416.0\n","negative TN: 209.0\n","negative FP: 34.0\n","negative FN: 19.0\n","positive precision: 91.6667  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 95.6322\n","positive FPR: 4.3678  NPV: 92.4444\n","positive TP: 209.0\n","positive TN: 416.0\n","positive FP: 19.0\n","positive FN: 34.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 50 minibatch: 1      time used: 20.615177392959595\n","minibatch AVG loss: 0.06386632743757219\n","Epoch: 39     train index of 50 minibatch: 2      time used: 19.959911108016968\n","minibatch AVG loss: 0.07370521196746267\n","Epoch: 39     train index of 50 minibatch: 3      time used: 19.95086908340454\n","minibatch AVG loss: 0.08047235451173038\n","Epoch: 39     train index of 50 minibatch: 4      time used: 19.754459857940674\n","minibatch AVG loss: 0.05832974887918681\n","Epoch: 39     train index of 50 minibatch: 5      time used: 19.7062771320343\n","minibatch AVG loss: 0.07835568077862262\n","Epoch: 39     train index of 50 minibatch: 6      time used: 19.302594900131226\n","minibatch AVG loss: 0.06137574948370457\n","\n","Epoch: 39  train \n","Loss: 0.0653  Acc: 97.6427\n","negative precision: 98.2194  recall: 98.1067\n","negative sensitivity: 98.1067  specificity: 96.8107\n","negative FPR: 3.1893  NPV: 96.6119\n","negative TP: 1710.0\n","negative TN: 941.0\n","negative FP: 31.0\n","negative FN: 33.0\n","positive precision: 96.6119  recall: 96.8107\n","positive sensitivity: 96.8107  specificity: 98.1067\n","positive FPR: 1.8933  NPV: 98.2194\n","positive TP: 941.0\n","positive TN: 1710.0\n","positive FP: 33.0\n","positive FN: 31.0\n","\n","\n","Epoch: 39     val index of 50 minibatch: 1      time used: 11.42479920387268\n","minibatch AVG loss: 0.06272597671195398\n","\n","Epoch: 39  val \n","Loss: 0.2934  Acc: 92.1829\n","negative precision: 91.1638  recall: 97.2414\n","negative sensitivity: 97.2414  specificity: 83.1276\n","negative FPR: 16.8724  NPV: 94.3925\n","negative TP: 423.0\n","negative TN: 202.0\n","negative FP: 41.0\n","negative FN: 12.0\n","positive precision: 94.3925  recall: 83.1276\n","positive sensitivity: 83.1276  specificity: 97.2414\n","positive FPR: 2.7586  NPV: 91.1638\n","positive TP: 202.0\n","positive TN: 423.0\n","positive FP: 12.0\n","positive FN: 41.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 50 minibatch: 1      time used: 20.45846152305603\n","minibatch AVG loss: 0.05085211290745065\n","Epoch: 40     train index of 50 minibatch: 2      time used: 20.219073057174683\n","minibatch AVG loss: 0.04186540029011667\n","Epoch: 40     train index of 50 minibatch: 3      time used: 19.731993913650513\n","minibatch AVG loss: 0.057905341997975486\n","Epoch: 40     train index of 50 minibatch: 4      time used: 19.86482071876526\n","minibatch AVG loss: 0.022660686642630025\n","Epoch: 40     train index of 50 minibatch: 5      time used: 19.94232678413391\n","minibatch AVG loss: 0.04149060600379016\n","Epoch: 40     train index of 50 minibatch: 6      time used: 19.740522146224976\n","minibatch AVG loss: 0.052250757539877665\n","\n","Epoch: 40  train \n","Loss: 0.0461  Acc: 98.2320\n","negative precision: 98.5673  recall: 98.6804\n","negative sensitivity: 98.6804  specificity: 97.4280\n","negative FPR: 2.5720  NPV: 97.6289\n","negative TP: 1720.0\n","negative TN: 947.0\n","negative FP: 25.0\n","negative FN: 23.0\n","positive precision: 97.6289  recall: 97.4280\n","positive sensitivity: 97.4280  specificity: 98.6804\n","positive FPR: 1.3196  NPV: 98.5673\n","positive TP: 947.0\n","positive TN: 1720.0\n","positive FP: 23.0\n","positive FN: 25.0\n","\n","\n","Epoch: 40     val index of 50 minibatch: 1      time used: 11.445498943328857\n","minibatch AVG loss: 0.05748674591875897\n","\n","Epoch: 40  val \n","Loss: 0.2977  Acc: 91.8879\n","negative precision: 90.0844  recall: 98.1609\n","negative sensitivity: 98.1609  specificity: 80.6584\n","negative FPR: 19.3416  NPV: 96.0784\n","negative TP: 427.0\n","negative TN: 196.0\n","negative FP: 47.0\n","negative FN: 8.0\n","positive precision: 96.0784  recall: 80.6584\n","positive sensitivity: 80.6584  specificity: 98.1609\n","positive FPR: 1.8391  NPV: 90.0844\n","positive TP: 196.0\n","positive TN: 427.0\n","positive FP: 8.0\n","positive FN: 47.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 50 minibatch: 1      time used: 20.76284408569336\n","minibatch AVG loss: 0.026578584894305094\n","Epoch: 41     train index of 50 minibatch: 2      time used: 19.930786609649658\n","minibatch AVG loss: 0.06183613676694222\n","Epoch: 41     train index of 50 minibatch: 3      time used: 19.725885152816772\n","minibatch AVG loss: 0.04210324637242593\n","Epoch: 41     train index of 50 minibatch: 4      time used: 19.98667049407959\n","minibatch AVG loss: 0.03836637303698808\n","Epoch: 41     train index of 50 minibatch: 5      time used: 19.845715284347534\n","minibatch AVG loss: 0.025484809554181993\n","Epoch: 41     train index of 50 minibatch: 6      time used: 19.436325788497925\n","minibatch AVG loss: 0.050473846578970555\n","\n","Epoch: 41  train \n","Loss: 0.0432  Acc: 98.4530\n","negative precision: 98.9074  recall: 98.6804\n","negative sensitivity: 98.6804  specificity: 98.0453\n","negative FPR: 1.9547  NPV: 97.6434\n","negative TP: 1720.0\n","negative TN: 953.0\n","negative FP: 19.0\n","negative FN: 23.0\n","positive precision: 97.6434  recall: 98.0453\n","positive sensitivity: 98.0453  specificity: 98.6804\n","positive FPR: 1.3196  NPV: 98.9074\n","positive TP: 953.0\n","positive TN: 1720.0\n","positive FP: 23.0\n","positive FN: 19.0\n","\n","\n","Epoch: 41     val index of 50 minibatch: 1      time used: 11.451032400131226\n","minibatch AVG loss: 0.07585431353363674\n","\n","Epoch: 41  val \n","Loss: 0.2792  Acc: 92.0354\n","negative precision: 90.6183  recall: 97.7011\n","negative sensitivity: 97.7011  specificity: 81.8930\n","negative FPR: 18.1070  NPV: 95.2153\n","negative TP: 425.0\n","negative TN: 199.0\n","negative FP: 44.0\n","negative FN: 10.0\n","positive precision: 95.2153  recall: 81.8930\n","positive sensitivity: 81.8930  specificity: 97.7011\n","positive FPR: 2.2989  NPV: 90.6183\n","positive TP: 199.0\n","positive TN: 425.0\n","positive FP: 10.0\n","positive FN: 44.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 50 minibatch: 1      time used: 20.642081022262573\n","minibatch AVG loss: 0.08799114588648081\n","Epoch: 42     train index of 50 minibatch: 2      time used: 19.408788204193115\n","minibatch AVG loss: 0.026164146115770563\n","Epoch: 42     train index of 50 minibatch: 3      time used: 19.401448726654053\n","minibatch AVG loss: 0.046304189674556254\n","Epoch: 42     train index of 50 minibatch: 4      time used: 19.51042103767395\n","minibatch AVG loss: 0.030069945667637512\n","Epoch: 42     train index of 50 minibatch: 5      time used: 19.672796487808228\n","minibatch AVG loss: 0.05392713897919748\n","Epoch: 42     train index of 50 minibatch: 6      time used: 19.62810468673706\n","minibatch AVG loss: 0.0415839781309478\n","\n","Epoch: 42  train \n","Loss: 0.0454  Acc: 98.0479\n","negative precision: 98.6751  recall: 98.2788\n","negative sensitivity: 98.2788  specificity: 97.6337\n","negative FPR: 2.3663  NPV: 96.9356\n","negative TP: 1713.0\n","negative TN: 949.0\n","negative FP: 23.0\n","negative FN: 30.0\n","positive precision: 96.9356  recall: 97.6337\n","positive sensitivity: 97.6337  specificity: 98.2788\n","positive FPR: 1.7212  NPV: 98.6751\n","positive TP: 949.0\n","positive TN: 1713.0\n","positive FP: 30.0\n","positive FN: 23.0\n","\n","\n","Epoch: 42     val index of 50 minibatch: 1      time used: 11.179739236831665\n","minibatch AVG loss: 0.15756163926016598\n","\n","Epoch: 42  val \n","Loss: 0.3393  Acc: 92.1829\n","negative precision: 92.6339  recall: 95.4023\n","negative sensitivity: 95.4023  specificity: 86.4198\n","negative FPR: 13.5802  NPV: 91.3043\n","negative TP: 415.0\n","negative TN: 210.0\n","negative FP: 33.0\n","negative FN: 20.0\n","positive precision: 91.3043  recall: 86.4198\n","positive sensitivity: 86.4198  specificity: 95.4023\n","positive FPR: 4.5977  NPV: 92.6339\n","positive TP: 210.0\n","positive TN: 415.0\n","positive FP: 20.0\n","positive FN: 33.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 50 minibatch: 1      time used: 20.168135166168213\n","minibatch AVG loss: 0.046030346258776264\n","Epoch: 43     train index of 50 minibatch: 2      time used: 19.531091928482056\n","minibatch AVG loss: 0.052307442681631074\n","Epoch: 43     train index of 50 minibatch: 3      time used: 19.711749792099\n","minibatch AVG loss: 0.054624581951647995\n","Epoch: 43     train index of 50 minibatch: 4      time used: 19.33129906654358\n","minibatch AVG loss: 0.06577442688867449\n","Epoch: 43     train index of 50 minibatch: 5      time used: 19.475398540496826\n","minibatch AVG loss: 0.03159098129719496\n","Epoch: 43     train index of 50 minibatch: 6      time used: 19.783090353012085\n","minibatch AVG loss: 0.056157332579605285\n","\n","Epoch: 43  train \n","Loss: 0.0503  Acc: 98.2689\n","negative precision: 98.4018  recall: 98.9099\n","negative sensitivity: 98.9099  specificity: 97.1193\n","negative FPR: 2.8807  NPV: 98.0270\n","negative TP: 1724.0\n","negative TN: 944.0\n","negative FP: 28.0\n","negative FN: 19.0\n","positive precision: 98.0270  recall: 97.1193\n","positive sensitivity: 97.1193  specificity: 98.9099\n","positive FPR: 1.0901  NPV: 98.4018\n","positive TP: 944.0\n","positive TN: 1724.0\n","positive FP: 19.0\n","positive FN: 28.0\n","\n","\n","Epoch: 43     val index of 50 minibatch: 1      time used: 11.161697149276733\n","minibatch AVG loss: 0.08104455722655984\n","\n","Epoch: 43  val \n","Loss: 0.3167  Acc: 92.3304\n","negative precision: 91.1828  recall: 97.4713\n","negative sensitivity: 97.4713  specificity: 83.1276\n","negative FPR: 16.8724  NPV: 94.8357\n","negative TP: 424.0\n","negative TN: 202.0\n","negative FP: 41.0\n","negative FN: 11.0\n","positive precision: 94.8357  recall: 83.1276\n","positive sensitivity: 83.1276  specificity: 97.4713\n","positive FPR: 2.5287  NPV: 91.1828\n","positive TP: 202.0\n","positive TN: 424.0\n","positive FP: 11.0\n","positive FN: 41.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 50 minibatch: 1      time used: 20.23399257659912\n","minibatch AVG loss: 0.03386322744889185\n","Epoch: 44     train index of 50 minibatch: 2      time used: 19.753751516342163\n","minibatch AVG loss: 0.045015722450334576\n","Epoch: 44     train index of 50 minibatch: 3      time used: 19.675085067749023\n","minibatch AVG loss: 0.045536981542827565\n","Epoch: 44     train index of 50 minibatch: 4      time used: 19.795554876327515\n","minibatch AVG loss: 0.02975122021511197\n","Epoch: 44     train index of 50 minibatch: 5      time used: 19.303853273391724\n","minibatch AVG loss: 0.036340285160113124\n","Epoch: 44     train index of 50 minibatch: 6      time used: 19.453272819519043\n","minibatch AVG loss: 0.026025985451997257\n","\n","Epoch: 44  train \n","Loss: 0.0373  Acc: 98.6372\n","negative precision: 98.7986  recall: 99.0820\n","negative sensitivity: 99.0820  specificity: 97.8395\n","negative FPR: 2.1605  NPV: 98.3454\n","negative TP: 1727.0\n","negative TN: 951.0\n","negative FP: 21.0\n","negative FN: 16.0\n","positive precision: 98.3454  recall: 97.8395\n","positive sensitivity: 97.8395  specificity: 99.0820\n","positive FPR: 0.9180  NPV: 98.7986\n","positive TP: 951.0\n","positive TN: 1727.0\n","positive FP: 16.0\n","positive FN: 21.0\n","\n","\n","Epoch: 44     val index of 50 minibatch: 1      time used: 11.15901231765747\n","minibatch AVG loss: 0.06585632486938266\n","\n","Epoch: 44  val \n","Loss: 0.3324  Acc: 92.1829\n","negative precision: 91.1638  recall: 97.2414\n","negative sensitivity: 97.2414  specificity: 83.1276\n","negative FPR: 16.8724  NPV: 94.3925\n","negative TP: 423.0\n","negative TN: 202.0\n","negative FP: 41.0\n","negative FN: 12.0\n","positive precision: 94.3925  recall: 83.1276\n","positive sensitivity: 83.1276  specificity: 97.2414\n","positive FPR: 2.7586  NPV: 91.1638\n","positive TP: 202.0\n","positive TN: 423.0\n","positive FP: 12.0\n","positive FN: 41.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 50 minibatch: 1      time used: 20.616796016693115\n","minibatch AVG loss: 0.02983491814462468\n","Epoch: 45     train index of 50 minibatch: 2      time used: 19.82915425300598\n","minibatch AVG loss: 0.032353855518158524\n","Epoch: 45     train index of 50 minibatch: 3      time used: 19.735553741455078\n","minibatch AVG loss: 0.02703495626919903\n","Epoch: 45     train index of 50 minibatch: 4      time used: 20.045467853546143\n","minibatch AVG loss: 0.020437926373560913\n","Epoch: 45     train index of 50 minibatch: 5      time used: 19.43688726425171\n","minibatch AVG loss: 0.04236561220779549\n","Epoch: 45     train index of 50 minibatch: 6      time used: 19.69622564315796\n","minibatch AVG loss: 0.06041141456225887\n","\n","Epoch: 45  train \n","Loss: 0.0367  Acc: 98.6372\n","negative precision: 99.0794  recall: 98.7952\n","negative sensitivity: 98.7952  specificity: 98.3539\n","negative FPR: 1.6461  NPV: 97.8506\n","negative TP: 1722.0\n","negative TN: 956.0\n","negative FP: 16.0\n","negative FN: 21.0\n","positive precision: 97.8506  recall: 98.3539\n","positive sensitivity: 98.3539  specificity: 98.7952\n","positive FPR: 1.2048  NPV: 99.0794\n","positive TP: 956.0\n","positive TN: 1722.0\n","positive FP: 21.0\n","positive FN: 16.0\n","\n","\n","Epoch: 45     val index of 50 minibatch: 1      time used: 11.15450143814087\n","minibatch AVG loss: 0.07577237377459824\n","\n","Epoch: 45  val \n","Loss: 0.3240  Acc: 91.8879\n","negative precision: 90.9483  recall: 97.0115\n","negative sensitivity: 97.0115  specificity: 82.7160\n","negative FPR: 17.2840  NPV: 93.9252\n","negative TP: 422.0\n","negative TN: 201.0\n","negative FP: 42.0\n","negative FN: 13.0\n","positive precision: 93.9252  recall: 82.7160\n","positive sensitivity: 82.7160  specificity: 97.0115\n","positive FPR: 2.9885  NPV: 90.9483\n","positive TP: 201.0\n","positive TN: 422.0\n","positive FP: 13.0\n","positive FN: 42.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 50 minibatch: 1      time used: 20.228248596191406\n","minibatch AVG loss: 0.031260250385385005\n","Epoch: 46     train index of 50 minibatch: 2      time used: 19.649542808532715\n","minibatch AVG loss: 0.04524526525987312\n","Epoch: 46     train index of 50 minibatch: 3      time used: 19.83007550239563\n","minibatch AVG loss: 0.026013531100470572\n","Epoch: 46     train index of 50 minibatch: 4      time used: 19.72510290145874\n","minibatch AVG loss: 0.04875617479847279\n","Epoch: 46     train index of 50 minibatch: 5      time used: 19.935741186141968\n","minibatch AVG loss: 0.02763800583896227\n","Epoch: 46     train index of 50 minibatch: 6      time used: 19.51306700706482\n","minibatch AVG loss: 0.01806429718970321\n","\n","Epoch: 46  train \n","Loss: 0.0354  Acc: 98.8214\n","negative precision: 99.0820  recall: 99.0820\n","negative sensitivity: 99.0820  specificity: 98.3539\n","negative FPR: 1.6461  NPV: 98.3539\n","negative TP: 1727.0\n","negative TN: 956.0\n","negative FP: 16.0\n","negative FN: 16.0\n","positive precision: 98.3539  recall: 98.3539\n","positive sensitivity: 98.3539  specificity: 99.0820\n","positive FPR: 0.9180  NPV: 99.0820\n","positive TP: 956.0\n","positive TN: 1727.0\n","positive FP: 16.0\n","positive FN: 16.0\n","\n","\n","Epoch: 46     val index of 50 minibatch: 1      time used: 11.32174038887024\n","minibatch AVG loss: 0.11893939172296086\n","\n","Epoch: 46  val \n","Loss: 0.2917  Acc: 93.0678\n","negative precision: 92.9204  recall: 96.5517\n","negative sensitivity: 96.5517  specificity: 86.8313\n","negative FPR: 13.1687  NPV: 93.3628\n","negative TP: 420.0\n","negative TN: 211.0\n","negative FP: 32.0\n","negative FN: 15.0\n","positive precision: 93.3628  recall: 86.8313\n","positive sensitivity: 86.8313  specificity: 96.5517\n","positive FPR: 3.4483  NPV: 92.9204\n","positive TP: 211.0\n","positive TN: 420.0\n","positive FP: 15.0\n","positive FN: 32.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 50 minibatch: 1      time used: 20.76073408126831\n","minibatch AVG loss: 0.03402162286045495\n","Epoch: 47     train index of 50 minibatch: 2      time used: 19.71276044845581\n","minibatch AVG loss: 0.04652309406432323\n","Epoch: 47     train index of 50 minibatch: 3      time used: 19.818965196609497\n","minibatch AVG loss: 0.04154313686536625\n","Epoch: 47     train index of 50 minibatch: 4      time used: 20.300393104553223\n","minibatch AVG loss: 0.021840809929417445\n","Epoch: 47     train index of 50 minibatch: 5      time used: 19.596177577972412\n","minibatch AVG loss: 0.01727568434784189\n","Epoch: 47     train index of 50 minibatch: 6      time used: 20.080309629440308\n","minibatch AVG loss: 0.021872904726769775\n","\n","Epoch: 47  train \n","Loss: 0.0314  Acc: 99.0424\n","negative precision: 99.2542  recall: 99.2542\n","negative sensitivity: 99.2542  specificity: 98.6626\n","negative FPR: 1.3374  NPV: 98.6626\n","negative TP: 1730.0\n","negative TN: 959.0\n","negative FP: 13.0\n","negative FN: 13.0\n","positive precision: 98.6626  recall: 98.6626\n","positive sensitivity: 98.6626  specificity: 99.2542\n","positive FPR: 0.7458  NPV: 99.2542\n","positive TP: 959.0\n","positive TN: 1730.0\n","positive FP: 13.0\n","positive FN: 13.0\n","\n","\n","Epoch: 47     val index of 50 minibatch: 1      time used: 11.65924072265625\n","minibatch AVG loss: 0.1035456370445172\n","\n","Epoch: 47  val \n","Loss: 0.3254  Acc: 92.0354\n","negative precision: 91.3232  recall: 96.7816\n","negative sensitivity: 96.7816  specificity: 83.5391\n","negative FPR: 16.4609  NPV: 93.5484\n","negative TP: 421.0\n","negative TN: 203.0\n","negative FP: 40.0\n","negative FN: 14.0\n","positive precision: 93.5484  recall: 83.5391\n","positive sensitivity: 83.5391  specificity: 96.7816\n","positive FPR: 3.2184  NPV: 91.3232\n","positive TP: 203.0\n","positive TN: 421.0\n","positive FP: 14.0\n","positive FN: 40.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 50 minibatch: 1      time used: 20.643320322036743\n","minibatch AVG loss: 0.032238167207688094\n","Epoch: 48     train index of 50 minibatch: 2      time used: 20.246365070343018\n","minibatch AVG loss: 0.03604623931227252\n","Epoch: 48     train index of 50 minibatch: 3      time used: 20.24320363998413\n","minibatch AVG loss: 0.05238251190516166\n","Epoch: 48     train index of 50 minibatch: 4      time used: 20.230626583099365\n","minibatch AVG loss: 0.02844551655347459\n","Epoch: 48     train index of 50 minibatch: 5      time used: 20.373034954071045\n","minibatch AVG loss: 0.022154949617106467\n","Epoch: 48     train index of 50 minibatch: 6      time used: 20.122379779815674\n","minibatch AVG loss: 0.025594251863658428\n","\n","Epoch: 48  train \n","Loss: 0.0349  Acc: 98.7845\n","negative precision: 98.9130  recall: 99.1968\n","negative sensitivity: 99.1968  specificity: 98.0453\n","negative FPR: 1.9547  NPV: 98.5522\n","negative TP: 1729.0\n","negative TN: 953.0\n","negative FP: 19.0\n","negative FN: 14.0\n","positive precision: 98.5522  recall: 98.0453\n","positive sensitivity: 98.0453  specificity: 99.1968\n","positive FPR: 0.8032  NPV: 98.9130\n","positive TP: 953.0\n","positive TN: 1729.0\n","positive FP: 14.0\n","positive FN: 19.0\n","\n","\n","Epoch: 48     val index of 50 minibatch: 1      time used: 11.577683925628662\n","minibatch AVG loss: 0.1339729948488093\n","\n","Epoch: 48  val \n","Loss: 0.2718  Acc: 92.6254\n","negative precision: 93.2584  recall: 95.4023\n","negative sensitivity: 95.4023  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 91.4163\n","negative TP: 415.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 20.0\n","positive precision: 91.4163  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 95.4023\n","positive FPR: 4.5977  NPV: 93.2584\n","positive TP: 213.0\n","positive TN: 415.0\n","positive FP: 20.0\n","positive FN: 30.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 50 minibatch: 1      time used: 20.708568811416626\n","minibatch AVG loss: 0.02878522521699779\n","Epoch: 49     train index of 50 minibatch: 2      time used: 20.537582874298096\n","minibatch AVG loss: 0.020448892917484043\n","Epoch: 49     train index of 50 minibatch: 3      time used: 21.035622596740723\n","minibatch AVG loss: 0.031086075875209646\n","Epoch: 49     train index of 50 minibatch: 4      time used: 20.082245111465454\n","minibatch AVG loss: 0.059501065613003445\n","Epoch: 49     train index of 50 minibatch: 5      time used: 19.718993425369263\n","minibatch AVG loss: 0.04715776393655688\n","Epoch: 49     train index of 50 minibatch: 6      time used: 20.098531007766724\n","minibatch AVG loss: 0.03301421412150376\n","\n","Epoch: 49  train \n","Loss: 0.0369  Acc: 98.4162\n","negative precision: 98.8506  recall: 98.6804\n","negative sensitivity: 98.6804  specificity: 97.9424\n","negative FPR: 2.0576  NPV: 97.6410\n","negative TP: 1720.0\n","negative TN: 952.0\n","negative FP: 20.0\n","negative FN: 23.0\n","positive precision: 97.6410  recall: 97.9424\n","positive sensitivity: 97.9424  specificity: 98.6804\n","positive FPR: 1.3196  NPV: 98.8506\n","positive TP: 952.0\n","positive TN: 1720.0\n","positive FP: 23.0\n","positive FN: 20.0\n","\n","\n","Epoch: 49     val index of 50 minibatch: 1      time used: 11.544521570205688\n","minibatch AVG loss: 0.1423172994892957\n","\n","Epoch: 49  val \n","Loss: 0.2750  Acc: 92.6254\n","negative precision: 93.2584  recall: 95.4023\n","negative sensitivity: 95.4023  specificity: 87.6543\n","negative FPR: 12.3457  NPV: 91.4163\n","negative TP: 415.0\n","negative TN: 213.0\n","negative FP: 30.0\n","negative FN: 20.0\n","positive precision: 91.4163  recall: 87.6543\n","positive sensitivity: 87.6543  specificity: 95.4023\n","positive FPR: 4.5977  NPV: 93.2584\n","positive TP: 213.0\n","positive TN: 415.0\n","positive FP: 20.0\n","positive FN: 30.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 50 minibatch: 1      time used: 20.559444665908813\n","minibatch AVG loss: 0.010691048607695848\n","Epoch: 50     train index of 50 minibatch: 2      time used: 19.96185040473938\n","minibatch AVG loss: 0.05465330129605718\n","Epoch: 50     train index of 50 minibatch: 3      time used: 20.043975353240967\n","minibatch AVG loss: 0.024880866502644493\n","Epoch: 50     train index of 50 minibatch: 4      time used: 19.513944149017334\n","minibatch AVG loss: 0.018966114254435524\n","Epoch: 50     train index of 50 minibatch: 5      time used: 19.4414644241333\n","minibatch AVG loss: 0.03785247868276201\n","Epoch: 50     train index of 50 minibatch: 6      time used: 19.503333806991577\n","minibatch AVG loss: 0.031301785208052026\n","\n","Epoch: 50  train \n","Loss: 0.0307  Acc: 98.8582\n","negative precision: 99.1389  recall: 99.0820\n","negative sensitivity: 99.0820  specificity: 98.4568\n","negative FPR: 1.5432  NPV: 98.3556\n","negative TP: 1727.0\n","negative TN: 957.0\n","negative FP: 15.0\n","negative FN: 16.0\n","positive precision: 98.3556  recall: 98.4568\n","positive sensitivity: 98.4568  specificity: 99.0820\n","positive FPR: 0.9180  NPV: 99.1389\n","positive TP: 957.0\n","positive TN: 1727.0\n","positive FP: 16.0\n","positive FN: 15.0\n","\n","\n","Epoch: 50     val index of 50 minibatch: 1      time used: 11.30541205406189\n","minibatch AVG loss: 0.12433962216120563\n","\n","Epoch: 50  val \n","Loss: 0.3007  Acc: 92.7729\n","negative precision: 92.5110  recall: 96.5517\n","negative sensitivity: 96.5517  specificity: 86.0082\n","negative FPR: 13.9918  NPV: 93.3036\n","negative TP: 420.0\n","negative TN: 209.0\n","negative FP: 34.0\n","negative FN: 15.0\n","positive precision: 93.3036  recall: 86.0082\n","positive sensitivity: 86.0082  specificity: 96.5517\n","positive FPR: 3.4483  NPV: 92.5110\n","positive TP: 209.0\n","positive TN: 420.0\n","positive FP: 15.0\n","positive FN: 34.0\n","\n","\n","\n","Training complete in 128m 3s\n","Best epoch idx:  20\n","Best epoch train Acc: 95.101289\n","Best epoch val Acc: 94.247788\n","negative precision: 93.8053  recall: 97.4713\n","negative sensitivity: 97.4713  specificity: 88.4774\n","negative FPR: 11.5226  NPV: 95.1327\n","positive precision: 95.1327  recall: 88.4774\n","positive sensitivity: 88.4774  specificity: 97.4713\n","positive FPR: 2.5287  NPV: 93.8053\n","model trained by GPU (idx:0) has been saved at  /home/pancreatic-cancer-project/saved_models/PC_Hybrid2_384_401_PT_lf25_b8_k5.pth\n","finished\n","\n","============================================================\n","Processing finished !\n","start time: 2021_10_28  16:36:37\n","end time: 2021_10_28  18:44:50\n","source: e3c8fe55b95c\n","\n","Preparing the email with auto log file :\n"," Train__2021_10_28-16_36_37_log \n","as  .rtf\n","processing log catched\n","server log catched\n","发送log邮件成功，title:  [e3c8fe55b95c  LOG] Train__2021_10_28-16_36_37_log\n","如果没有，看看垃圾箱:)\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"0-z2QmkukjJ_","outputId":"61474511-cf49-43c0-f98f-f266114af65f"},"source":["!python Test.py --model_idx Hybrid2_384_401_PT_lf25_b8_k5 --enable_attention_check --dataroot /data/pancreatic-cancer-project/dataset --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/runs"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[-0.7753,  0.3782]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : Hybrid2_384_401_PT_lf25_b8_k5\n","*********************************setting*************************************\n","Namespace(att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=None, cls_token_off=False, dataroot='/data/pancreatic-cancer-project/dataset', draw_root='/home/pancreatic-cancer-project/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='Hybrid2_384_401_PT_lf25_b8_k5', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 80 minibatch: 1      time used: 2.6770434379577637\n","minibatch AVG loss: 0.10160557246942972\n","Epoch: test     test index of 80 minibatch: 2      time used: 2.5114758014678955\n","minibatch AVG loss: 0.19185702577005942\n","Epoch: test     test index of 80 minibatch: 3      time used: 2.629035711288452\n","minibatch AVG loss: 0.09097784415296246\n","Epoch: test     test index of 80 minibatch: 4      time used: 2.562105178833008\n","minibatch AVG loss: 0.024674487742322525\n","Epoch: test     test index of 80 minibatch: 5      time used: 2.5461530685424805\n","minibatch AVG loss: 0.0026015845027814065\n","Epoch: test     test index of 80 minibatch: 6      time used: 2.58190655708313\n","minibatch AVG loss: 0.06225360244484364\n","Epoch: test     test index of 80 minibatch: 7      time used: 2.640320062637329\n","minibatch AVG loss: 0.09627051655343166\n","Epoch: test     test index of 80 minibatch: 8      time used: 2.6092915534973145\n","minibatch AVG loss: 0.23451480458461446\n","Epoch: test     test index of 80 minibatch: 9      time used: 2.6215925216674805\n","minibatch AVG loss: 0.15150791857740842\n","Epoch: test     test index of 80 minibatch: 10      time used: 2.6500606536865234\n","minibatch AVG loss: 0.16519331074232468\n","\n","Epoch:  test \n","Loss: 0.1280  Acc: 95.0413\n","negative precision: 95.9707  recall: 96.3235\n","negative sensitivity: 96.3235  specificity: 92.7393\n","negative FPR: 7.2607  NPV: 93.3555\n","negative TP: 524.0\n","negative TN: 281.0\n","negative FP: 22.0\n","negative FN: 20.0\n","positive precision: 93.3555  recall: 92.7393\n","positive sensitivity: 92.7393  specificity: 96.3235\n","positive FPR: 3.6765  NPV: 95.9707\n","positive TP: 281.0\n","positive TN: 524.0\n","positive FP: 20.0\n","positive FN: 22.0\n","\n","\n","Testing complete in 2m 39s\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"NKz9yyaScOvN","outputId":"322b468c-f5c3-41f9-9788-7f02688acb03"},"source":["!python 5fold_test.py --enable_attention_check --model_idx_groups Hybrid2_384_401_PT_lf25_b8 --check_minibatch 10 --dataroot /data/pancreatic-cancer-project/dataset --model_path /home/pancreatic-cancer-project/saved_models --draw_root /home/pancreatic-cancer-project/imaging_results"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["*********************************setting*************************************\n","Namespace(attn_drop_rate=0.0, batch_size=1, check_minibatch=10, dataroot='/data/pancreatic-cancer-project/dataset', draw_root='/home/pancreatic-cancer-project/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx_groups='Hybrid2_384_401_PT_lf25_b8', model_path='/home/pancreatic-cancer-project/saved_models', num_classes=2, paint=True)\n","\n","target models groups:\n"," ['Hybrid2_384_401_PT_lf25_b8']\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[-0.1602,  1.0787]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : Hybrid2_384_401_PT_lf25_b8_k1\n","Epoch: Test\n","----------\n","5fold_test.py:106: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return self.soft_max(x)\n","Epoch: test     test index of 10 minibatch: 1      time used: 0.485929012298584\n","minibatch AVG loss: 0.0018296249676495791\n","Epoch: test     test index of 10 minibatch: 2      time used: 0.32277512550354004\n","minibatch AVG loss: 0.3805073211871786\n","Epoch: test     test index of 10 minibatch: 3      time used: 0.29816532135009766\n","minibatch AVG loss: 0.0966029183131468\n","Epoch: test     test index of 10 minibatch: 4      time used: 0.3078343868255615\n","minibatch AVG loss: 0.7250663455364702\n","Epoch: test     test index of 10 minibatch: 5      time used: 0.30120301246643066\n","minibatch AVG loss: 0.0002703320275031729\n","Epoch: test     test index of 10 minibatch: 6      time used: 0.2982051372528076\n","minibatch AVG loss: 0.05222179296470131\n","Epoch: test     test index of 10 minibatch: 7      time used: 0.29210758209228516\n","minibatch AVG loss: 0.0010908414398727473\n","Epoch: test     test index of 10 minibatch: 8      time used: 0.3041219711303711\n","minibatch AVG loss: 0.009661643530125729\n","Epoch: test     test index of 10 minibatch: 9      time used: 0.29784083366394043\n","minibatch AVG loss: 0.21560054447436414\n","Epoch: test     test index of 10 minibatch: 10      time used: 0.2889101505279541\n","minibatch AVG loss: 0.1314210434691631\n","Epoch: test     test index of 10 minibatch: 11      time used: 0.3013935089111328\n","minibatch AVG loss: 0.3038708826636139\n","Epoch: test     test index of 10 minibatch: 12      time used: 0.29065775871276855\n","minibatch AVG loss: 0.18271395624615253\n","Epoch: test     test index of 10 minibatch: 13      time used: 0.2975893020629883\n","minibatch AVG loss: 0.7886173692473676\n","Epoch: test     test index of 10 minibatch: 14      time used: 0.3037745952606201\n","minibatch AVG loss: 0.2983909452421358\n","Epoch: test     test index of 10 minibatch: 15      time used: 0.29640650749206543\n","minibatch AVG loss: 0.4702537047101941\n","Epoch: test     test index of 10 minibatch: 16      time used: 0.303605318069458\n","minibatch AVG loss: 1.671316243140609\n","Epoch: test     test index of 10 minibatch: 17      time used: 0.3050873279571533\n","minibatch AVG loss: 0.0006770910582417855\n","Epoch: test     test index of 10 minibatch: 18      time used: 0.3034524917602539\n","minibatch AVG loss: 0.002691338229124085\n","Epoch: test     test index of 10 minibatch: 19      time used: 0.3165905475616455\n","minibatch AVG loss: 0.0029854009950213366\n","Epoch: test     test index of 10 minibatch: 20      time used: 0.30681800842285156\n","minibatch AVG loss: 4.5274588410393334e-05\n","Epoch: test     test index of 10 minibatch: 21      time used: 0.30544352531433105\n","minibatch AVG loss: 0.7907755816120698\n","Epoch: test     test index of 10 minibatch: 22      time used: 0.3088409900665283\n","minibatch AVG loss: 1.2008882145659299\n","Epoch: test     test index of 10 minibatch: 23      time used: 0.3004782199859619\n","minibatch AVG loss: 0.32073833089416437\n","Epoch: test     test index of 10 minibatch: 24      time used: 0.3089725971221924\n","minibatch AVG loss: 0.00012786293336830568\n","Epoch: test     test index of 10 minibatch: 25      time used: 0.3036036491394043\n","minibatch AVG loss: 0.456432299970038\n","Epoch: test     test index of 10 minibatch: 26      time used: 0.3052372932434082\n","minibatch AVG loss: 0.0003458762843365548\n","Epoch: test     test index of 10 minibatch: 27      time used: 0.30401134490966797\n","minibatch AVG loss: 0.0001242513291799696\n","Epoch: test     test index of 10 minibatch: 28      time used: 0.3051924705505371\n","minibatch AVG loss: 0.00024444235787086656\n","Epoch: test     test index of 10 minibatch: 29      time used: 0.3078901767730713\n","minibatch AVG loss: 0.3902842221508763\n","Epoch: test     test index of 10 minibatch: 30      time used: 0.3063781261444092\n","minibatch AVG loss: 0.003158806240207923\n","Epoch: test     test index of 10 minibatch: 31      time used: 0.304302453994751\n","minibatch AVG loss: 0.026807967885179095\n","Epoch: test     test index of 10 minibatch: 32      time used: 0.3090393543243408\n","minibatch AVG loss: 0.0034607805750056287\n","Epoch: test     test index of 10 minibatch: 33      time used: 0.3200397491455078\n","minibatch AVG loss: 0.0007419681083774776\n","Epoch: test     test index of 10 minibatch: 34      time used: 0.30670952796936035\n","minibatch AVG loss: 0.014097455328737851\n","Epoch: test     test index of 10 minibatch: 35      time used: 0.31375861167907715\n","minibatch AVG loss: 0.014830661494124797\n","Epoch: test     test index of 10 minibatch: 36      time used: 0.3064308166503906\n","minibatch AVG loss: 0.000364882530811883\n","Epoch: test     test index of 10 minibatch: 37      time used: 0.29897642135620117\n","minibatch AVG loss: 0.02090750936713448\n","Epoch: test     test index of 10 minibatch: 38      time used: 0.30866384506225586\n","minibatch AVG loss: 0.020688032835460037\n","Epoch: test     test index of 10 minibatch: 39      time used: 0.3020036220550537\n","minibatch AVG loss: 0.00010843711097550113\n","Epoch: test     test index of 10 minibatch: 40      time used: 0.3111698627471924\n","minibatch AVG loss: 0.0006418787648726721\n","Epoch: test     test index of 10 minibatch: 41      time used: 0.2952091693878174\n","minibatch AVG loss: 0.00016608908135822275\n","Epoch: test     test index of 10 minibatch: 42      time used: 0.31018614768981934\n","minibatch AVG loss: 0.0007079096338202362\n","Epoch: test     test index of 10 minibatch: 43      time used: 0.3094491958618164\n","minibatch AVG loss: 0.016941816648068198\n","Epoch: test     test index of 10 minibatch: 44      time used: 0.2983841896057129\n","minibatch AVG loss: 0.0003438031468249392\n","Epoch: test     test index of 10 minibatch: 45      time used: 0.30026817321777344\n","minibatch AVG loss: 0.001541089540842222\n","Epoch: test     test index of 10 minibatch: 46      time used: 0.30281662940979004\n","minibatch AVG loss: 0.45885133981864784\n","Epoch: test     test index of 10 minibatch: 47      time used: 0.28472042083740234\n","minibatch AVG loss: 0.0005173976585865602\n","Epoch: test     test index of 10 minibatch: 48      time used: 0.29479265213012695\n","minibatch AVG loss: 0.20969266854808666\n","Epoch: test     test index of 10 minibatch: 49      time used: 0.30593347549438477\n","minibatch AVG loss: 0.008196536986724822\n","Epoch: test     test index of 10 minibatch: 50      time used: 0.3042330741882324\n","minibatch AVG loss: 0.0006113351955718827\n","Epoch: test     test index of 10 minibatch: 51      time used: 0.3042597770690918\n","minibatch AVG loss: 0.0004152543915552087\n","Epoch: test     test index of 10 minibatch: 52      time used: 0.30012941360473633\n","minibatch AVG loss: 0.0004699529774370603\n","Epoch: test     test index of 10 minibatch: 53      time used: 0.2975928783416748\n","minibatch AVG loss: 0.003495602232942474\n","Epoch: test     test index of 10 minibatch: 54      time used: 0.29146671295166016\n","minibatch AVG loss: 0.04464550965494709\n","Epoch: test     test index of 10 minibatch: 55      time used: 0.3101317882537842\n","minibatch AVG loss: 0.3212358568882337\n","Epoch: test     test index of 10 minibatch: 56      time used: 0.29775309562683105\n","minibatch AVG loss: 0.08871324699721299\n","Epoch: test     test index of 10 minibatch: 57      time used: 0.30219316482543945\n","minibatch AVG loss: 0.0010059910120617133\n","Epoch: test     test index of 10 minibatch: 58      time used: 0.31108736991882324\n","minibatch AVG loss: 0.002256995836069109\n","Epoch: test     test index of 10 minibatch: 59      time used: 0.2998697757720947\n","minibatch AVG loss: 0.002949401892692549\n","Epoch: test     test index of 10 minibatch: 60      time used: 0.298553466796875\n","minibatch AVG loss: 0.9015556738042505\n","Epoch: test     test index of 10 minibatch: 61      time used: 0.2972068786621094\n","minibatch AVG loss: 0.008898711122310488\n","Epoch: test     test index of 10 minibatch: 62      time used: 0.3002941608428955\n","minibatch AVG loss: 0.003883953897457104\n","Epoch: test     test index of 10 minibatch: 63      time used: 0.2998974323272705\n","minibatch AVG loss: 0.0010586116593913175\n","Epoch: test     test index of 10 minibatch: 64      time used: 0.29847192764282227\n","minibatch AVG loss: 0.4590187799134583\n","Epoch: test     test index of 10 minibatch: 65      time used: 0.2935647964477539\n","minibatch AVG loss: 0.003308285140519729\n","Epoch: test     test index of 10 minibatch: 66      time used: 0.300875186920166\n","minibatch AVG loss: 0.0007713986669841688\n","Epoch: test     test index of 10 minibatch: 67      time used: 0.30874085426330566\n","minibatch AVG loss: 0.13201828446763103\n","Epoch: test     test index of 10 minibatch: 68      time used: 0.3229367733001709\n","minibatch AVG loss: 0.050126867046492406\n","Epoch: test     test index of 10 minibatch: 69      time used: 0.3037071228027344\n","minibatch AVG loss: 0.0035665969568071886\n","Epoch: test     test index of 10 minibatch: 70      time used: 0.2980337142944336\n","minibatch AVG loss: 0.4810934881374124\n","Epoch: test     test index of 10 minibatch: 71      time used: 0.2985241413116455\n","minibatch AVG loss: 0.007186860562069341\n","Epoch: test     test index of 10 minibatch: 72      time used: 0.30445098876953125\n","minibatch AVG loss: 0.0024263240818982014\n","Epoch: test     test index of 10 minibatch: 73      time used: 0.30138158798217773\n","minibatch AVG loss: 0.013720288564218207\n","Epoch: test     test index of 10 minibatch: 74      time used: 0.2970588207244873\n","minibatch AVG loss: 0.018936647044029087\n","Epoch: test     test index of 10 minibatch: 75      time used: 0.30397653579711914\n","minibatch AVG loss: 0.0013914864422986284\n","Epoch: test     test index of 10 minibatch: 76      time used: 0.29706549644470215\n","minibatch AVG loss: 0.01507361267140368\n","Epoch: test     test index of 10 minibatch: 77      time used: 0.29930853843688965\n","minibatch AVG loss: 0.004655157162051182\n","Epoch: test     test index of 10 minibatch: 78      time used: 0.3137228488922119\n","minibatch AVG loss: 0.03357064723386429\n","Epoch: test     test index of 10 minibatch: 79      time used: 0.29959702491760254\n","minibatch AVG loss: 0.4140318536556151\n","Epoch: test     test index of 10 minibatch: 80      time used: 0.2950866222381592\n","minibatch AVG loss: 0.42080347002047347\n","Epoch: test     test index of 10 minibatch: 81      time used: 0.29613804817199707\n","minibatch AVG loss: 0.1876999149346375\n","Epoch: test     test index of 10 minibatch: 82      time used: 0.30741333961486816\n","minibatch AVG loss: 0.19910516859890776\n","Epoch: test     test index of 10 minibatch: 83      time used: 0.2887442111968994\n","minibatch AVG loss: 0.002180208941717865\n","Epoch: test     test index of 10 minibatch: 84      time used: 0.3105316162109375\n","minibatch AVG loss: 0.6312203527384554\n","\n","Epoch:  test \n","Loss: 0.1721  Acc: 94.5691\n","negative precision: 97.1591  recall: 94.3015\n","negative sensitivity: 94.3015  specificity: 95.0495\n","negative FPR: 4.9505  NPV: 90.2821\n","negative TP: 513.0\n","negative TN: 288.0\n","negative FP: 15.0\n","negative FN: 31.0\n","AUC:0.9887\n","AUC:0.9887\n","positive precision: 90.2821  recall: 95.0495\n","positive sensitivity: 95.0495  specificity: 94.3015\n","positive FPR: 5.6985  NPV: 97.1591\n","positive TP: 288.0\n","positive TN: 513.0\n","positive FP: 31.0\n","positive FN: 15.0\n","AUC:0.9887\n","AUC:0.9887\n","\n","\n","Testing complete in 18m 17s\n","test model output： tensor([[ 0.5911, -0.2149]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : Hybrid2_384_401_PT_lf25_b8_k2\n","Epoch: Test\n","----------\n","5fold_test.py:106: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return self.soft_max(x)\n","Epoch: test     test index of 10 minibatch: 1      time used: 0.42030763626098633\n","minibatch AVG loss: 0.006964064788917312\n","Epoch: test     test index of 10 minibatch: 2      time used: 0.2947988510131836\n","minibatch AVG loss: 0.4600478971740813\n","Epoch: test     test index of 10 minibatch: 3      time used: 0.3007326126098633\n","minibatch AVG loss: 0.019250623076732153\n","Epoch: test     test index of 10 minibatch: 4      time used: 0.3028228282928467\n","minibatch AVG loss: 0.007523179217241704\n","Epoch: test     test index of 10 minibatch: 5      time used: 0.29044175148010254\n","minibatch AVG loss: 0.00212581005107495\n","Epoch: test     test index of 10 minibatch: 6      time used: 0.28566980361938477\n","minibatch AVG loss: 0.00988406728283735\n","Epoch: test     test index of 10 minibatch: 7      time used: 0.28787899017333984\n","minibatch AVG loss: 0.011824740414886037\n","Epoch: test     test index of 10 minibatch: 8      time used: 0.2973201274871826\n","minibatch AVG loss: 0.24434174282068852\n","Epoch: test     test index of 10 minibatch: 9      time used: 0.2877495288848877\n","minibatch AVG loss: 0.05474662087799516\n","Epoch: test     test index of 10 minibatch: 10      time used: 0.28754734992980957\n","minibatch AVG loss: 0.03583108909879229\n","Epoch: test     test index of 10 minibatch: 11      time used: 0.2943415641784668\n","minibatch AVG loss: 0.052318170193757396\n","Epoch: test     test index of 10 minibatch: 12      time used: 0.285428524017334\n","minibatch AVG loss: 0.03038102768477984\n","Epoch: test     test index of 10 minibatch: 13      time used: 0.2962768077850342\n","minibatch AVG loss: 0.006347402710525784\n","Epoch: test     test index of 10 minibatch: 14      time used: 0.29637742042541504\n","minibatch AVG loss: 0.03650141062535113\n","Epoch: test     test index of 10 minibatch: 15      time used: 0.3015127182006836\n","minibatch AVG loss: 0.02747485179352225\n","Epoch: test     test index of 10 minibatch: 16      time used: 0.3023686408996582\n","minibatch AVG loss: 0.34020791051152627\n","Epoch: test     test index of 10 minibatch: 17      time used: 0.30979204177856445\n","minibatch AVG loss: 0.0022094338448368942\n","Epoch: test     test index of 10 minibatch: 18      time used: 0.2968478202819824\n","minibatch AVG loss: 0.00282731737170252\n","Epoch: test     test index of 10 minibatch: 19      time used: 0.3149409294128418\n","minibatch AVG loss: 0.04745113261924416\n","Epoch: test     test index of 10 minibatch: 20      time used: 0.3069000244140625\n","minibatch AVG loss: 0.0005399598954682006\n","Epoch: test     test index of 10 minibatch: 21      time used: 0.306873083114624\n","minibatch AVG loss: 0.0568230346090786\n","Epoch: test     test index of 10 minibatch: 22      time used: 0.2950751781463623\n","minibatch AVG loss: 0.10332536381247337\n","Epoch: test     test index of 10 minibatch: 23      time used: 0.30222606658935547\n","minibatch AVG loss: 0.09108697215597203\n","Epoch: test     test index of 10 minibatch: 24      time used: 0.3071892261505127\n","minibatch AVG loss: 0.0008673663867739378\n","Epoch: test     test index of 10 minibatch: 25      time used: 0.30545926094055176\n","minibatch AVG loss: 0.03927659235050669\n","Epoch: test     test index of 10 minibatch: 26      time used: 0.2939329147338867\n","minibatch AVG loss: 0.00027239477894909215\n","Epoch: test     test index of 10 minibatch: 27      time used: 0.3135249614715576\n","minibatch AVG loss: 0.0002602671460408601\n","Epoch: test     test index of 10 minibatch: 28      time used: 0.3104665279388428\n","minibatch AVG loss: 0.0009122915136686061\n","Epoch: test     test index of 10 minibatch: 29      time used: 0.29099154472351074\n","minibatch AVG loss: 0.0010271514242049307\n","Epoch: test     test index of 10 minibatch: 30      time used: 0.30107641220092773\n","minibatch AVG loss: 0.0006865894134534756\n","Epoch: test     test index of 10 minibatch: 31      time used: 0.29480671882629395\n","minibatch AVG loss: 0.043162058769667055\n","Epoch: test     test index of 10 minibatch: 32      time used: 0.3055446147918701\n","minibatch AVG loss: 0.0015972001288901082\n","Epoch: test     test index of 10 minibatch: 33      time used: 0.30141496658325195\n","minibatch AVG loss: 0.0002999976379214786\n","Epoch: test     test index of 10 minibatch: 34      time used: 0.30744051933288574\n","minibatch AVG loss: 0.0011688483944453764\n","Epoch: test     test index of 10 minibatch: 35      time used: 0.2976107597351074\n","minibatch AVG loss: 0.00044935859223187434\n","Epoch: test     test index of 10 minibatch: 36      time used: 0.300919771194458\n","minibatch AVG loss: 0.00038227670811465944\n","Epoch: test     test index of 10 minibatch: 37      time used: 0.3117854595184326\n","minibatch AVG loss: 0.0005966508673736825\n","Epoch: test     test index of 10 minibatch: 38      time used: 0.2944357395172119\n","minibatch AVG loss: 0.0008084497356321662\n","Epoch: test     test index of 10 minibatch: 39      time used: 0.30518341064453125\n","minibatch AVG loss: 0.0002095167692459654\n","Epoch: test     test index of 10 minibatch: 40      time used: 0.31668806076049805\n","minibatch AVG loss: 0.0005107162447529845\n","Epoch: test     test index of 10 minibatch: 41      time used: 0.3082897663116455\n","minibatch AVG loss: 0.0001571175867866259\n","Epoch: test     test index of 10 minibatch: 42      time used: 0.3069038391113281\n","minibatch AVG loss: 0.001834963116561994\n","Epoch: test     test index of 10 minibatch: 43      time used: 0.3029944896697998\n","minibatch AVG loss: 0.002128622501550126\n","Epoch: test     test index of 10 minibatch: 44      time used: 0.30241823196411133\n","minibatch AVG loss: 0.0010124610511411448\n","Epoch: test     test index of 10 minibatch: 45      time used: 0.3038311004638672\n","minibatch AVG loss: 0.000968869226926472\n","Epoch: test     test index of 10 minibatch: 46      time used: 0.30416393280029297\n","minibatch AVG loss: 0.0028375500165566335\n","Epoch: test     test index of 10 minibatch: 47      time used: 0.2964348793029785\n","minibatch AVG loss: 0.001559149651802727\n","Epoch: test     test index of 10 minibatch: 48      time used: 0.29815030097961426\n","minibatch AVG loss: 0.13813222125390895\n","Epoch: test     test index of 10 minibatch: 49      time used: 0.300692081451416\n","minibatch AVG loss: 0.0008541700677596964\n","Epoch: test     test index of 10 minibatch: 50      time used: 0.3182649612426758\n","minibatch AVG loss: 0.006247416629776126\n","Epoch: test     test index of 10 minibatch: 51      time used: 0.3005671501159668\n","minibatch AVG loss: 0.000678371854883153\n","Epoch: test     test index of 10 minibatch: 52      time used: 0.301464319229126\n","minibatch AVG loss: 0.00034780305359163324\n","Epoch: test     test index of 10 minibatch: 53      time used: 0.3101806640625\n","minibatch AVG loss: 0.004375621897997917\n","Epoch: test     test index of 10 minibatch: 54      time used: 0.29144287109375\n","minibatch AVG loss: 0.005782155953056645\n","Epoch: test     test index of 10 minibatch: 55      time used: 0.3029439449310303\n","minibatch AVG loss: 0.8246571482828585\n","Epoch: test     test index of 10 minibatch: 56      time used: 0.3125648498535156\n","minibatch AVG loss: 0.011803271956159734\n","Epoch: test     test index of 10 minibatch: 57      time used: 0.2948784828186035\n","minibatch AVG loss: 0.007724877903820015\n","Epoch: test     test index of 10 minibatch: 58      time used: 0.31012916564941406\n","minibatch AVG loss: 0.6585722162766615\n","Epoch: test     test index of 10 minibatch: 59      time used: 0.2949395179748535\n","minibatch AVG loss: 0.04223914990143385\n","Epoch: test     test index of 10 minibatch: 60      time used: 0.31180572509765625\n","minibatch AVG loss: 0.8407353494956624\n","Epoch: test     test index of 10 minibatch: 61      time used: 0.303570032119751\n","minibatch AVG loss: 0.0504137175885262\n","Epoch: test     test index of 10 minibatch: 62      time used: 0.31824231147766113\n","minibatch AVG loss: 0.0041651889012428\n","Epoch: test     test index of 10 minibatch: 63      time used: 0.2939271926879883\n","minibatch AVG loss: 0.023842256018542684\n","Epoch: test     test index of 10 minibatch: 64      time used: 0.29577064514160156\n","minibatch AVG loss: 0.08533138877537567\n","Epoch: test     test index of 10 minibatch: 65      time used: 0.2945058345794678\n","minibatch AVG loss: 0.00459295641630888\n","Epoch: test     test index of 10 minibatch: 66      time used: 0.3036975860595703\n","minibatch AVG loss: 0.0010978291247738525\n","Epoch: test     test index of 10 minibatch: 67      time used: 0.29755306243896484\n","minibatch AVG loss: 0.095115479035303\n","Epoch: test     test index of 10 minibatch: 68      time used: 0.3020930290222168\n","minibatch AVG loss: 0.01596226364490576\n","Epoch: test     test index of 10 minibatch: 69      time used: 0.3030893802642822\n","minibatch AVG loss: 0.0400454712624196\n","Epoch: test     test index of 10 minibatch: 70      time used: 0.3193540573120117\n","minibatch AVG loss: 0.17259203105350024\n","Epoch: test     test index of 10 minibatch: 71      time used: 0.30873990058898926\n","minibatch AVG loss: 0.028957599122077227\n","Epoch: test     test index of 10 minibatch: 72      time used: 0.3130218982696533\n","minibatch AVG loss: 0.008574734546709806\n","Epoch: test     test index of 10 minibatch: 73      time used: 0.30393099784851074\n","minibatch AVG loss: 0.047213584373821504\n","Epoch: test     test index of 10 minibatch: 74      time used: 0.3062865734100342\n","minibatch AVG loss: 0.008112476707901805\n","Epoch: test     test index of 10 minibatch: 75      time used: 0.2996518611907959\n","minibatch AVG loss: 0.013896517176181077\n","Epoch: test     test index of 10 minibatch: 76      time used: 0.30565762519836426\n","minibatch AVG loss: 0.14228794844821097\n","Epoch: test     test index of 10 minibatch: 77      time used: 0.3267502784729004\n","minibatch AVG loss: 0.031227538303937763\n","Epoch: test     test index of 10 minibatch: 78      time used: 0.30924415588378906\n","minibatch AVG loss: 0.3548395418707514\n","Epoch: test     test index of 10 minibatch: 79      time used: 0.30696797370910645\n","minibatch AVG loss: 0.7768395248160231\n","Epoch: test     test index of 10 minibatch: 80      time used: 0.30045127868652344\n","minibatch AVG loss: 0.8627260234614369\n","Epoch: test     test index of 10 minibatch: 81      time used: 0.29122376441955566\n","minibatch AVG loss: 0.9379515985463514\n","Epoch: test     test index of 10 minibatch: 82      time used: 0.29244565963745117\n","minibatch AVG loss: 1.1678988887346349\n","Epoch: test     test index of 10 minibatch: 83      time used: 0.30585312843322754\n","minibatch AVG loss: 0.025157278997357934\n","Epoch: test     test index of 10 minibatch: 84      time used: 0.2972137928009033\n","minibatch AVG loss: 0.4866662059095688\n","\n","Epoch:  test \n","Loss: 0.1189  Acc: 96.5762\n","negative precision: 96.2298  recall: 98.5294\n","negative sensitivity: 98.5294  specificity: 93.0693\n","negative FPR: 6.9307  NPV: 97.2414\n","negative TP: 536.0\n","negative TN: 282.0\n","negative FP: 21.0\n","negative FN: 8.0\n","AUC:0.9917\n","AUC:0.9917\n","positive precision: 97.2414  recall: 93.0693\n","positive sensitivity: 93.0693  specificity: 98.5294\n","positive FPR: 1.4706  NPV: 96.2298\n","positive TP: 282.0\n","positive TN: 536.0\n","positive FP: 8.0\n","positive FN: 21.0\n","AUC:0.9917\n","AUC:0.9917\n","\n","\n","Testing complete in 18m 15s\n","test model output： tensor([[-0.6953, -0.4569]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : Hybrid2_384_401_PT_lf25_b8_k3\n","Epoch: Test\n","----------\n","5fold_test.py:106: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return self.soft_max(x)\n","Epoch: test     test index of 10 minibatch: 1      time used: 0.4279601573944092\n","minibatch AVG loss: 0.022770581662189215\n","Epoch: test     test index of 10 minibatch: 2      time used: 0.2966771125793457\n","minibatch AVG loss: 0.6243235480040312\n","Epoch: test     test index of 10 minibatch: 3      time used: 0.29970884323120117\n","minibatch AVG loss: 0.0369716510802391\n","Epoch: test     test index of 10 minibatch: 4      time used: 0.30984950065612793\n","minibatch AVG loss: 0.0386176671810972\n","Epoch: test     test index of 10 minibatch: 5      time used: 0.29673051834106445\n","minibatch AVG loss: 0.0004027064496767707\n","Epoch: test     test index of 10 minibatch: 6      time used: 0.293903112411499\n","minibatch AVG loss: 0.0014557456233887933\n","Epoch: test     test index of 10 minibatch: 7      time used: 0.30854320526123047\n","minibatch AVG loss: 0.002523641980224056\n","Epoch: test     test index of 10 minibatch: 8      time used: 0.3130073547363281\n","minibatch AVG loss: 0.004924986581318081\n","Epoch: test     test index of 10 minibatch: 9      time used: 0.29341793060302734\n","minibatch AVG loss: 0.003719077534333337\n","Epoch: test     test index of 10 minibatch: 10      time used: 0.2946510314941406\n","minibatch AVG loss: 0.1062966501354822\n","Epoch: test     test index of 10 minibatch: 11      time used: 0.29814696311950684\n","minibatch AVG loss: 0.055619075438880825\n","Epoch: test     test index of 10 minibatch: 12      time used: 0.2911109924316406\n","minibatch AVG loss: 0.327883638239291\n","Epoch: test     test index of 10 minibatch: 13      time used: 0.30658864974975586\n","minibatch AVG loss: 0.011080365949601401\n","Epoch: test     test index of 10 minibatch: 14      time used: 0.2957594394683838\n","minibatch AVG loss: 0.011239970318274572\n","Epoch: test     test index of 10 minibatch: 15      time used: 0.3031961917877197\n","minibatch AVG loss: 0.011709147386136464\n","Epoch: test     test index of 10 minibatch: 16      time used: 0.30597686767578125\n","minibatch AVG loss: 0.25318470488564343\n","Epoch: test     test index of 10 minibatch: 17      time used: 0.31285548210144043\n","minibatch AVG loss: 0.0009902827077894472\n","Epoch: test     test index of 10 minibatch: 18      time used: 0.3030118942260742\n","minibatch AVG loss: 0.004772057018635678\n","Epoch: test     test index of 10 minibatch: 19      time used: 0.2984132766723633\n","minibatch AVG loss: 0.022947905821638415\n","Epoch: test     test index of 10 minibatch: 20      time used: 0.3094494342803955\n","minibatch AVG loss: 0.00017277930455747992\n","Epoch: test     test index of 10 minibatch: 21      time used: 0.29802727699279785\n","minibatch AVG loss: 0.06254491964791668\n","Epoch: test     test index of 10 minibatch: 22      time used: 0.31926465034484863\n","minibatch AVG loss: 0.042619840416591614\n","Epoch: test     test index of 10 minibatch: 23      time used: 0.30466675758361816\n","minibatch AVG loss: 0.13787795448442922\n","Epoch: test     test index of 10 minibatch: 24      time used: 0.3296382427215576\n","minibatch AVG loss: 0.058088509851222624\n","Epoch: test     test index of 10 minibatch: 25      time used: 0.2965371608734131\n","minibatch AVG loss: 0.0029752315429504963\n","Epoch: test     test index of 10 minibatch: 26      time used: 0.3007633686065674\n","minibatch AVG loss: 8.599256616435014e-05\n","Epoch: test     test index of 10 minibatch: 27      time used: 0.2957925796508789\n","minibatch AVG loss: 0.0001229189078003401\n","Epoch: test     test index of 10 minibatch: 28      time used: 0.30068469047546387\n","minibatch AVG loss: 0.0013767992859357037\n","Epoch: test     test index of 10 minibatch: 29      time used: 0.2911567687988281\n","minibatch AVG loss: 0.016152189986314625\n","Epoch: test     test index of 10 minibatch: 30      time used: 0.30203819274902344\n","minibatch AVG loss: 0.15503921173294657\n","Epoch: test     test index of 10 minibatch: 31      time used: 0.30311036109924316\n","minibatch AVG loss: 0.0009360104959341697\n","Epoch: test     test index of 10 minibatch: 32      time used: 0.3032708168029785\n","minibatch AVG loss: 0.15591993311682018\n","Epoch: test     test index of 10 minibatch: 33      time used: 0.3038482666015625\n","minibatch AVG loss: 0.0007732731966825668\n","Epoch: test     test index of 10 minibatch: 34      time used: 0.2930123805999756\n","minibatch AVG loss: 0.00397830747133412\n","Epoch: test     test index of 10 minibatch: 35      time used: 0.29801106452941895\n","minibatch AVG loss: 0.0004283238340576645\n","Epoch: test     test index of 10 minibatch: 36      time used: 0.3037686347961426\n","minibatch AVG loss: 0.00037624581818818115\n","Epoch: test     test index of 10 minibatch: 37      time used: 0.2970552444458008\n","minibatch AVG loss: 0.0011595169329666533\n","Epoch: test     test index of 10 minibatch: 38      time used: 0.30440831184387207\n","minibatch AVG loss: 0.0025577226755558514\n","Epoch: test     test index of 10 minibatch: 39      time used: 0.31551051139831543\n","minibatch AVG loss: 0.0001415961545717437\n","Epoch: test     test index of 10 minibatch: 40      time used: 0.30893754959106445\n","minibatch AVG loss: 0.0005005800583603559\n","Epoch: test     test index of 10 minibatch: 41      time used: 0.317333459854126\n","minibatch AVG loss: 0.00016954263737716245\n","Epoch: test     test index of 10 minibatch: 42      time used: 0.30751872062683105\n","minibatch AVG loss: 0.005168602218327578\n","Epoch: test     test index of 10 minibatch: 43      time used: 0.30896782875061035\n","minibatch AVG loss: 0.02996995059220353\n","Epoch: test     test index of 10 minibatch: 44      time used: 0.31372809410095215\n","minibatch AVG loss: 0.0002526869866414927\n","Epoch: test     test index of 10 minibatch: 45      time used: 0.3007490634918213\n","minibatch AVG loss: 0.0011848176472994965\n","Epoch: test     test index of 10 minibatch: 46      time used: 0.297196626663208\n","minibatch AVG loss: 0.1543178546762647\n","Epoch: test     test index of 10 minibatch: 47      time used: 0.2889108657836914\n","minibatch AVG loss: 0.004678571211115923\n","Epoch: test     test index of 10 minibatch: 48      time used: 0.3035721778869629\n","minibatch AVG loss: 0.03116587214753963\n","Epoch: test     test index of 10 minibatch: 49      time used: 0.32300233840942383\n","minibatch AVG loss: 0.4110687707499892\n","Epoch: test     test index of 10 minibatch: 50      time used: 0.3025016784667969\n","minibatch AVG loss: 0.0008026873307244387\n","Epoch: test     test index of 10 minibatch: 51      time used: 0.30936646461486816\n","minibatch AVG loss: 0.006399653854532517\n","Epoch: test     test index of 10 minibatch: 52      time used: 0.29290294647216797\n","minibatch AVG loss: 0.0007997992244781927\n","Epoch: test     test index of 10 minibatch: 53      time used: 0.28821587562561035\n","minibatch AVG loss: 0.0022248674802540338\n","Epoch: test     test index of 10 minibatch: 54      time used: 0.289534330368042\n","minibatch AVG loss: 0.04618613447237294\n","Epoch: test     test index of 10 minibatch: 55      time used: 0.3020622730255127\n","minibatch AVG loss: 0.40307664520732944\n","Epoch: test     test index of 10 minibatch: 56      time used: 0.3093557357788086\n","minibatch AVG loss: 0.00557927718036808\n","Epoch: test     test index of 10 minibatch: 57      time used: 0.3045918941497803\n","minibatch AVG loss: 0.002723671258718241\n","Epoch: test     test index of 10 minibatch: 58      time used: 0.306640625\n","minibatch AVG loss: 0.013933088893827517\n","Epoch: test     test index of 10 minibatch: 59      time used: 0.2984910011291504\n","minibatch AVG loss: 0.02993997445992136\n","Epoch: test     test index of 10 minibatch: 60      time used: 0.3014984130859375\n","minibatch AVG loss: 0.6275128474575468\n","Epoch: test     test index of 10 minibatch: 61      time used: 0.29265880584716797\n","minibatch AVG loss: 0.2834164138315828\n","Epoch: test     test index of 10 minibatch: 62      time used: 0.29988861083984375\n","minibatch AVG loss: 0.001301235357823316\n","Epoch: test     test index of 10 minibatch: 63      time used: 0.30132555961608887\n","minibatch AVG loss: 0.110500691026391\n","Epoch: test     test index of 10 minibatch: 64      time used: 0.301440954208374\n","minibatch AVG loss: 0.0175195578194689\n","Epoch: test     test index of 10 minibatch: 65      time used: 0.31154489517211914\n","minibatch AVG loss: 0.004843358516518492\n","Epoch: test     test index of 10 minibatch: 66      time used: 0.2923867702484131\n","minibatch AVG loss: 0.00019065183296333997\n","Epoch: test     test index of 10 minibatch: 67      time used: 0.2956721782684326\n","minibatch AVG loss: 0.03147719756816514\n","Epoch: test     test index of 10 minibatch: 68      time used: 0.3044314384460449\n","minibatch AVG loss: 0.012998876444180496\n","Epoch: test     test index of 10 minibatch: 69      time used: 0.30347728729248047\n","minibatch AVG loss: 0.2790218435933639\n","Epoch: test     test index of 10 minibatch: 70      time used: 0.29625415802001953\n","minibatch AVG loss: 0.2928492840801482\n","Epoch: test     test index of 10 minibatch: 71      time used: 0.29894495010375977\n","minibatch AVG loss: 0.010439598363882396\n","Epoch: test     test index of 10 minibatch: 72      time used: 0.2932600975036621\n","minibatch AVG loss: 0.007452298462158069\n","Epoch: test     test index of 10 minibatch: 73      time used: 0.2996492385864258\n","minibatch AVG loss: 0.01895804425003007\n","Epoch: test     test index of 10 minibatch: 74      time used: 0.29587292671203613\n","minibatch AVG loss: 0.27192741926701275\n","Epoch: test     test index of 10 minibatch: 75      time used: 0.3124685287475586\n","minibatch AVG loss: 0.009822817592066713\n","Epoch: test     test index of 10 minibatch: 76      time used: 0.2936697006225586\n","minibatch AVG loss: 0.013102663468453101\n","Epoch: test     test index of 10 minibatch: 77      time used: 0.29668569564819336\n","minibatch AVG loss: 0.10196971077821218\n","Epoch: test     test index of 10 minibatch: 78      time used: 0.31380510330200195\n","minibatch AVG loss: 0.021636148425750436\n","Epoch: test     test index of 10 minibatch: 79      time used: 0.300098180770874\n","minibatch AVG loss: 0.7494695021479856\n","Epoch: test     test index of 10 minibatch: 80      time used: 0.3039393424987793\n","minibatch AVG loss: 0.45170555873191914\n","Epoch: test     test index of 10 minibatch: 81      time used: 0.29744768142700195\n","minibatch AVG loss: 1.146934875959414\n","Epoch: test     test index of 10 minibatch: 82      time used: 0.29750967025756836\n","minibatch AVG loss: 1.7719060490133416\n","Epoch: test     test index of 10 minibatch: 83      time used: 0.2964909076690674\n","minibatch AVG loss: 0.009584696516321855\n","Epoch: test     test index of 10 minibatch: 84      time used: 0.29732608795166016\n","minibatch AVG loss: 0.8520380303642014\n","\n","Epoch:  test \n","Loss: 0.1332  Acc: 96.3400\n","negative precision: 96.2162  recall: 98.1618\n","negative sensitivity: 98.1618  specificity: 93.0693\n","negative FPR: 6.9307  NPV: 96.5753\n","negative TP: 534.0\n","negative TN: 282.0\n","negative FP: 21.0\n","negative FN: 10.0\n","AUC:0.9905\n","AUC:0.9905\n","positive precision: 96.5753  recall: 93.0693\n","positive sensitivity: 93.0693  specificity: 98.1618\n","positive FPR: 1.8382  NPV: 96.2162\n","positive TP: 282.0\n","positive TN: 534.0\n","positive FP: 10.0\n","positive FN: 21.0\n","AUC:0.9905\n","AUC:0.9905\n","\n","\n","Testing complete in 18m 8s\n","test model output： tensor([[ 0.9295, -0.1416]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : Hybrid2_384_401_PT_lf25_b8_k4\n","Epoch: Test\n","----------\n","5fold_test.py:106: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return self.soft_max(x)\n","Epoch: test     test index of 10 minibatch: 1      time used: 0.4196586608886719\n","minibatch AVG loss: 0.14482682091947935\n","Epoch: test     test index of 10 minibatch: 2      time used: 0.3104102611541748\n","minibatch AVG loss: 0.20993406757224875\n","Epoch: test     test index of 10 minibatch: 3      time used: 0.3001711368560791\n","minibatch AVG loss: 0.017060647568723653\n","Epoch: test     test index of 10 minibatch: 4      time used: 0.2980997562408447\n","minibatch AVG loss: 0.07867404588869249\n","Epoch: test     test index of 10 minibatch: 5      time used: 0.3099496364593506\n","minibatch AVG loss: 0.0003403015922231134\n","Epoch: test     test index of 10 minibatch: 6      time used: 0.29522252082824707\n","minibatch AVG loss: 0.24197993966154172\n","Epoch: test     test index of 10 minibatch: 7      time used: 0.2951192855834961\n","minibatch AVG loss: 0.00024721321678953243\n","Epoch: test     test index of 10 minibatch: 8      time used: 0.2993311882019043\n","minibatch AVG loss: 0.003584427741589025\n","Epoch: test     test index of 10 minibatch: 9      time used: 0.29691362380981445\n","minibatch AVG loss: 0.0044913683890626995\n","Epoch: test     test index of 10 minibatch: 10      time used: 0.2942814826965332\n","minibatch AVG loss: 0.06630307927698595\n","Epoch: test     test index of 10 minibatch: 11      time used: 0.30724096298217773\n","minibatch AVG loss: 0.051517232255719136\n","Epoch: test     test index of 10 minibatch: 12      time used: 0.29526281356811523\n","minibatch AVG loss: 0.3137176425654616\n","Epoch: test     test index of 10 minibatch: 13      time used: 0.2977008819580078\n","minibatch AVG loss: 0.009061422990635037\n","Epoch: test     test index of 10 minibatch: 14      time used: 0.30379652976989746\n","minibatch AVG loss: 0.010868333567486843\n","Epoch: test     test index of 10 minibatch: 15      time used: 0.3015007972717285\n","minibatch AVG loss: 0.0009935568778018933\n","Epoch: test     test index of 10 minibatch: 16      time used: 0.31460094451904297\n","minibatch AVG loss: 1.0916480768923065\n","Epoch: test     test index of 10 minibatch: 17      time used: 0.3014662265777588\n","minibatch AVG loss: 0.0001646932814765023\n","Epoch: test     test index of 10 minibatch: 18      time used: 0.3036208152770996\n","minibatch AVG loss: 0.000663684604660375\n","Epoch: test     test index of 10 minibatch: 19      time used: 0.31096601486206055\n","minibatch AVG loss: 0.004299408703809604\n","Epoch: test     test index of 10 minibatch: 20      time used: 0.31365323066711426\n","minibatch AVG loss: 3.4021714600385164e-05\n","Epoch: test     test index of 10 minibatch: 21      time used: 0.30765748023986816\n","minibatch AVG loss: 0.23175569073155203\n","Epoch: test     test index of 10 minibatch: 22      time used: 0.33379030227661133\n","minibatch AVG loss: 0.4833030150475679\n","Epoch: test     test index of 10 minibatch: 23      time used: 0.30342936515808105\n","minibatch AVG loss: 0.20018556389513834\n","Epoch: test     test index of 10 minibatch: 24      time used: 0.30506253242492676\n","minibatch AVG loss: 0.0002644674765178934\n","Epoch: test     test index of 10 minibatch: 25      time used: 0.30663204193115234\n","minibatch AVG loss: 0.00171652264543809\n","Epoch: test     test index of 10 minibatch: 26      time used: 0.3043360710144043\n","minibatch AVG loss: 0.00012907263735542073\n","Epoch: test     test index of 10 minibatch: 27      time used: 0.2979438304901123\n","minibatch AVG loss: 0.0001112848720367765\n","Epoch: test     test index of 10 minibatch: 28      time used: 0.2973647117614746\n","minibatch AVG loss: 0.0023016822575300465\n","Epoch: test     test index of 10 minibatch: 29      time used: 0.31005001068115234\n","minibatch AVG loss: 0.020718978523655097\n","Epoch: test     test index of 10 minibatch: 30      time used: 0.3043026924133301\n","minibatch AVG loss: 0.000158009533151926\n","Epoch: test     test index of 10 minibatch: 31      time used: 0.31442713737487793\n","minibatch AVG loss: 0.13579298462864245\n","Epoch: test     test index of 10 minibatch: 32      time used: 0.31763720512390137\n","minibatch AVG loss: 0.0003779702339670621\n","Epoch: test     test index of 10 minibatch: 33      time used: 0.30490565299987793\n","minibatch AVG loss: 0.0003448180686973501\n","Epoch: test     test index of 10 minibatch: 34      time used: 0.31629014015197754\n","minibatch AVG loss: 0.000432377056858968\n","Epoch: test     test index of 10 minibatch: 35      time used: 0.31467294692993164\n","minibatch AVG loss: 0.00021597911400021984\n","Epoch: test     test index of 10 minibatch: 36      time used: 0.31685471534729004\n","minibatch AVG loss: 0.0002073940275295172\n","Epoch: test     test index of 10 minibatch: 37      time used: 0.3110346794128418\n","minibatch AVG loss: 0.0003270437016908545\n","Epoch: test     test index of 10 minibatch: 38      time used: 0.3160548210144043\n","minibatch AVG loss: 0.0023414019982737956\n","Epoch: test     test index of 10 minibatch: 39      time used: 0.3228111267089844\n","minibatch AVG loss: 0.00016989128416753375\n","Epoch: test     test index of 10 minibatch: 40      time used: 0.3010718822479248\n","minibatch AVG loss: 0.00017815825740399304\n","Epoch: test     test index of 10 minibatch: 41      time used: 0.3126087188720703\n","minibatch AVG loss: 0.00018056724875350482\n","Epoch: test     test index of 10 minibatch: 42      time used: 0.30408716201782227\n","minibatch AVG loss: 0.004546445505184238\n","Epoch: test     test index of 10 minibatch: 43      time used: 0.31520962715148926\n","minibatch AVG loss: 0.0020450007057661425\n","Epoch: test     test index of 10 minibatch: 44      time used: 0.31066107749938965\n","minibatch AVG loss: 0.0001135271304519847\n","Epoch: test     test index of 10 minibatch: 45      time used: 0.30454063415527344\n","minibatch AVG loss: 0.0015587023550324374\n","Epoch: test     test index of 10 minibatch: 46      time used: 0.2949025630950928\n","minibatch AVG loss: 0.3398758477305819\n","Epoch: test     test index of 10 minibatch: 47      time used: 0.2925448417663574\n","minibatch AVG loss: 0.0002711392102355603\n","Epoch: test     test index of 10 minibatch: 48      time used: 0.30053067207336426\n","minibatch AVG loss: 0.008041004693586729\n","Epoch: test     test index of 10 minibatch: 49      time used: 0.3066427707672119\n","minibatch AVG loss: 0.001738564651168417\n","Epoch: test     test index of 10 minibatch: 50      time used: 0.30856895446777344\n","minibatch AVG loss: 0.0025812354702793527\n","Epoch: test     test index of 10 minibatch: 51      time used: 0.30284667015075684\n","minibatch AVG loss: 0.0003594897731090896\n","Epoch: test     test index of 10 minibatch: 52      time used: 0.31365060806274414\n","minibatch AVG loss: 0.0006008486281643855\n","Epoch: test     test index of 10 minibatch: 53      time used: 0.2851395606994629\n","minibatch AVG loss: 0.00036171226965961976\n","Epoch: test     test index of 10 minibatch: 54      time used: 0.29416346549987793\n","minibatch AVG loss: 0.008182105204468826\n","Epoch: test     test index of 10 minibatch: 55      time used: 0.2931482791900635\n","minibatch AVG loss: 0.4472355201134633\n","Epoch: test     test index of 10 minibatch: 56      time used: 0.29935574531555176\n","minibatch AVG loss: 0.0016861155570950359\n","Epoch: test     test index of 10 minibatch: 57      time used: 0.30368757247924805\n","minibatch AVG loss: 0.004418663278920576\n","Epoch: test     test index of 10 minibatch: 58      time used: 0.3096935749053955\n","minibatch AVG loss: 0.25477398782095406\n","Epoch: test     test index of 10 minibatch: 59      time used: 0.2981083393096924\n","minibatch AVG loss: 0.024035392327641604\n","Epoch: test     test index of 10 minibatch: 60      time used: 0.30624842643737793\n","minibatch AVG loss: 1.1293389346144977\n","Epoch: test     test index of 10 minibatch: 61      time used: 0.30001282691955566\n","minibatch AVG loss: 0.10732806989108212\n","Epoch: test     test index of 10 minibatch: 62      time used: 0.3270692825317383\n","minibatch AVG loss: 0.0016556525559280999\n","Epoch: test     test index of 10 minibatch: 63      time used: 0.2933368682861328\n","minibatch AVG loss: 0.4593538221794006\n","Epoch: test     test index of 10 minibatch: 64      time used: 0.2970919609069824\n","minibatch AVG loss: 0.040357916466746246\n","Epoch: test     test index of 10 minibatch: 65      time used: 0.29410672187805176\n","minibatch AVG loss: 0.006781939731445164\n","Epoch: test     test index of 10 minibatch: 66      time used: 0.30702900886535645\n","minibatch AVG loss: 0.0009644523554015905\n","Epoch: test     test index of 10 minibatch: 67      time used: 0.3058621883392334\n","minibatch AVG loss: 0.03271749741688836\n","Epoch: test     test index of 10 minibatch: 68      time used: 0.30017566680908203\n","minibatch AVG loss: 0.05055879594729049\n","Epoch: test     test index of 10 minibatch: 69      time used: 0.29773569107055664\n","minibatch AVG loss: 0.04610273946964298\n","Epoch: test     test index of 10 minibatch: 70      time used: 0.30829882621765137\n","minibatch AVG loss: 0.05362370587972691\n","Epoch: test     test index of 10 minibatch: 71      time used: 0.3033444881439209\n","minibatch AVG loss: 0.005234518100041896\n","Epoch: test     test index of 10 minibatch: 72      time used: 0.29947376251220703\n","minibatch AVG loss: 0.014070126618025824\n","Epoch: test     test index of 10 minibatch: 73      time used: 0.3169515132904053\n","minibatch AVG loss: 0.03503495833574562\n","Epoch: test     test index of 10 minibatch: 74      time used: 0.29628872871398926\n","minibatch AVG loss: 0.18487941434723326\n","Epoch: test     test index of 10 minibatch: 75      time used: 0.30635786056518555\n","minibatch AVG loss: 0.006632549078494776\n","Epoch: test     test index of 10 minibatch: 76      time used: 0.31060099601745605\n","minibatch AVG loss: 0.7598516241501784\n","Epoch: test     test index of 10 minibatch: 77      time used: 0.3065941333770752\n","minibatch AVG loss: 0.0005850597910466604\n","Epoch: test     test index of 10 minibatch: 78      time used: 0.3102083206176758\n","minibatch AVG loss: 0.4631757692543033\n","Epoch: test     test index of 10 minibatch: 79      time used: 0.3156280517578125\n","minibatch AVG loss: 1.5302596592635382\n","Epoch: test     test index of 10 minibatch: 80      time used: 0.309171199798584\n","minibatch AVG loss: 0.5263517059138394\n","Epoch: test     test index of 10 minibatch: 81      time used: 0.30409979820251465\n","minibatch AVG loss: 0.9998943404840247\n","Epoch: test     test index of 10 minibatch: 82      time used: 0.2963743209838867\n","minibatch AVG loss: 0.5354275195662922\n","Epoch: test     test index of 10 minibatch: 83      time used: 0.30193257331848145\n","minibatch AVG loss: 0.2021647902976838\n","Epoch: test     test index of 10 minibatch: 84      time used: 0.3052396774291992\n","minibatch AVG loss: 1.0066575725097209\n","\n","Epoch:  test \n","Loss: 0.1575  Acc: 95.8678\n","negative precision: 96.1887  recall: 97.4265\n","negative sensitivity: 97.4265  specificity: 93.0693\n","negative FPR: 6.9307  NPV: 95.2703\n","negative TP: 530.0\n","negative TN: 282.0\n","negative FP: 21.0\n","negative FN: 14.0\n","AUC:0.9897\n","AUC:0.9897\n","positive precision: 95.2703  recall: 93.0693\n","positive sensitivity: 93.0693  specificity: 97.4265\n","positive FPR: 2.5735  NPV: 96.1887\n","positive TP: 282.0\n","positive TN: 530.0\n","positive FP: 14.0\n","positive FN: 21.0\n","AUC:0.9897\n","AUC:0.9897\n","\n","\n","Testing complete in 18m 20s\n","test model output： tensor([[-0.0558,  0.3941]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : Hybrid2_384_401_PT_lf25_b8_k5\n","Epoch: Test\n","----------\n","5fold_test.py:106: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return self.soft_max(x)\n","Epoch: test     test index of 10 minibatch: 1      time used: 0.42765259742736816\n","minibatch AVG loss: 0.015003412470105105\n","Epoch: test     test index of 10 minibatch: 2      time used: 0.3011465072631836\n","minibatch AVG loss: 0.4270459620805923\n","Epoch: test     test index of 10 minibatch: 3      time used: 0.2959251403808594\n","minibatch AVG loss: 0.03957580511923879\n","Epoch: test     test index of 10 minibatch: 4      time used: 0.297473669052124\n","minibatch AVG loss: 0.289105104344344\n","Epoch: test     test index of 10 minibatch: 5      time used: 0.29776740074157715\n","minibatch AVG loss: 0.001371277555517736\n","Epoch: test     test index of 10 minibatch: 6      time used: 0.30356812477111816\n","minibatch AVG loss: 0.01734352772236889\n","Epoch: test     test index of 10 minibatch: 7      time used: 0.31229114532470703\n","minibatch AVG loss: 0.015415526247306844\n","Epoch: test     test index of 10 minibatch: 8      time used: 0.30611491203308105\n","minibatch AVG loss: 0.00798396421596408\n","Epoch: test     test index of 10 minibatch: 9      time used: 0.2893211841583252\n","minibatch AVG loss: 0.3017982645294978\n","Epoch: test     test index of 10 minibatch: 10      time used: 0.28645992279052734\n","minibatch AVG loss: 0.2852289287897293\n","Epoch: test     test index of 10 minibatch: 11      time used: 0.2942807674407959\n","minibatch AVG loss: 0.20849546776444186\n","Epoch: test     test index of 10 minibatch: 12      time used: 0.2888338565826416\n","minibatch AVG loss: 0.14912256969255394\n","Epoch: test     test index of 10 minibatch: 13      time used: 0.28987693786621094\n","minibatch AVG loss: 0.1387697782367468\n","Epoch: test     test index of 10 minibatch: 14      time used: 0.3208639621734619\n","minibatch AVG loss: 0.17906721405452117\n","Epoch: test     test index of 10 minibatch: 15      time used: 0.29963088035583496\n","minibatch AVG loss: 0.19070407655162852\n","Epoch: test     test index of 10 minibatch: 16      time used: 0.3024556636810303\n","minibatch AVG loss: 0.08166990654135589\n","Epoch: test     test index of 10 minibatch: 17      time used: 0.3288614749908447\n","minibatch AVG loss: 0.004047918738797307\n","Epoch: test     test index of 10 minibatch: 18      time used: 0.3046865463256836\n","minibatch AVG loss: 0.023371645495353734\n","Epoch: test     test index of 10 minibatch: 19      time used: 0.3407433032989502\n","minibatch AVG loss: 0.013702129367629823\n","Epoch: test     test index of 10 minibatch: 20      time used: 0.3358006477355957\n","minibatch AVG loss: 0.00039459120143874314\n","Epoch: test     test index of 10 minibatch: 21      time used: 0.3104102611541748\n","minibatch AVG loss: 0.21687594612722022\n","Epoch: test     test index of 10 minibatch: 22      time used: 0.29910922050476074\n","minibatch AVG loss: 0.36540362396044657\n","Epoch: test     test index of 10 minibatch: 23      time used: 0.3086225986480713\n","minibatch AVG loss: 0.09995025609023286\n","Epoch: test     test index of 10 minibatch: 24      time used: 0.2926483154296875\n","minibatch AVG loss: 0.004076642242580419\n","Epoch: test     test index of 10 minibatch: 25      time used: 0.2994527816772461\n","minibatch AVG loss: 0.15113716396735982\n","Epoch: test     test index of 10 minibatch: 26      time used: 0.3046865463256836\n","minibatch AVG loss: 0.0006885995979246217\n","Epoch: test     test index of 10 minibatch: 27      time used: 0.2995448112487793\n","minibatch AVG loss: 0.0002442350294586504\n","Epoch: test     test index of 10 minibatch: 28      time used: 0.299562931060791\n","minibatch AVG loss: 0.002249208440480288\n","Epoch: test     test index of 10 minibatch: 29      time used: 0.29019784927368164\n","minibatch AVG loss: 0.002628475182427792\n","Epoch: test     test index of 10 minibatch: 30      time used: 0.31280946731567383\n","minibatch AVG loss: 0.0018989748026797316\n","Epoch: test     test index of 10 minibatch: 31      time used: 0.30038976669311523\n","minibatch AVG loss: 0.037385834957967747\n","Epoch: test     test index of 10 minibatch: 32      time used: 0.3040652275085449\n","minibatch AVG loss: 0.0011634099602815696\n","Epoch: test     test index of 10 minibatch: 33      time used: 0.30692124366760254\n","minibatch AVG loss: 0.001493070189462742\n","Epoch: test     test index of 10 minibatch: 34      time used: 0.30376434326171875\n","minibatch AVG loss: 0.002360019465777441\n","Epoch: test     test index of 10 minibatch: 35      time used: 0.2998344898223877\n","minibatch AVG loss: 0.0022497098601888866\n","Epoch: test     test index of 10 minibatch: 36      time used: 0.3153958320617676\n","minibatch AVG loss: 0.006634711992228403\n","Epoch: test     test index of 10 minibatch: 37      time used: 0.3192918300628662\n","minibatch AVG loss: 0.000827973012928851\n","Epoch: test     test index of 10 minibatch: 38      time used: 0.30543088912963867\n","minibatch AVG loss: 0.005475577086326666\n","Epoch: test     test index of 10 minibatch: 39      time used: 0.3095831871032715\n","minibatch AVG loss: 0.0007884997234214097\n","Epoch: test     test index of 10 minibatch: 40      time used: 0.3108787536621094\n","minibatch AVG loss: 0.0009831146919168532\n","Epoch: test     test index of 10 minibatch: 41      time used: 0.31064510345458984\n","minibatch AVG loss: 0.00040171442306018433\n","Epoch: test     test index of 10 minibatch: 42      time used: 0.3190150260925293\n","minibatch AVG loss: 0.0015628024884790648\n","Epoch: test     test index of 10 minibatch: 43      time used: 0.3221719264984131\n","minibatch AVG loss: 0.0374688679297833\n","Epoch: test     test index of 10 minibatch: 44      time used: 0.30548620223999023\n","minibatch AVG loss: 0.0021575127124378924\n","Epoch: test     test index of 10 minibatch: 45      time used: 0.30478453636169434\n","minibatch AVG loss: 0.002462442358955741\n","Epoch: test     test index of 10 minibatch: 46      time used: 0.3028564453125\n","minibatch AVG loss: 0.1288357048702892\n","Epoch: test     test index of 10 minibatch: 47      time used: 0.2982470989227295\n","minibatch AVG loss: 0.0010547388301347382\n","Epoch: test     test index of 10 minibatch: 48      time used: 0.31438326835632324\n","minibatch AVG loss: 0.324085035945609\n","Epoch: test     test index of 10 minibatch: 49      time used: 0.3110952377319336\n","minibatch AVG loss: 0.0028993411498959175\n","Epoch: test     test index of 10 minibatch: 50      time used: 0.3249857425689697\n","minibatch AVG loss: 0.04651185486654867\n","Epoch: test     test index of 10 minibatch: 51      time used: 0.3177170753479004\n","minibatch AVG loss: 0.0009861310856649653\n","Epoch: test     test index of 10 minibatch: 52      time used: 0.30503201484680176\n","minibatch AVG loss: 0.0038407534404541364\n","Epoch: test     test index of 10 minibatch: 53      time used: 0.3003363609313965\n","minibatch AVG loss: 0.028034656343515964\n","Epoch: test     test index of 10 minibatch: 54      time used: 0.2984592914581299\n","minibatch AVG loss: 0.1480967061012052\n","Epoch: test     test index of 10 minibatch: 55      time used: 0.3077547550201416\n","minibatch AVG loss: 0.5070106048020534\n","Epoch: test     test index of 10 minibatch: 56      time used: 0.3008394241333008\n","minibatch AVG loss: 0.03278408463811502\n","Epoch: test     test index of 10 minibatch: 57      time used: 0.3280298709869385\n","minibatch AVG loss: 0.14572120678494685\n","Epoch: test     test index of 10 minibatch: 58      time used: 0.33258914947509766\n","minibatch AVG loss: 0.5435494964942336\n","Epoch: test     test index of 10 minibatch: 59      time used: 0.30817604064941406\n","minibatch AVG loss: 0.010256211319938303\n","Epoch: test     test index of 10 minibatch: 60      time used: 0.30829668045043945\n","minibatch AVG loss: 0.9410985975060612\n","Epoch: test     test index of 10 minibatch: 61      time used: 0.32333922386169434\n","minibatch AVG loss: 0.02812026212341152\n","Epoch: test     test index of 10 minibatch: 62      time used: 0.30652546882629395\n","minibatch AVG loss: 0.03111663254676387\n","Epoch: test     test index of 10 minibatch: 63      time used: 0.3018472194671631\n","minibatch AVG loss: 0.14440092992736026\n","Epoch: test     test index of 10 minibatch: 64      time used: 0.31366491317749023\n","minibatch AVG loss: 0.03185509997420013\n","Epoch: test     test index of 10 minibatch: 65      time used: 0.2987558841705322\n","minibatch AVG loss: 0.011404833383858204\n","Epoch: test     test index of 10 minibatch: 66      time used: 0.30667543411254883\n","minibatch AVG loss: 0.012684727704618126\n","Epoch: test     test index of 10 minibatch: 67      time used: 0.3027224540710449\n","minibatch AVG loss: 0.462640734994784\n","Epoch: test     test index of 10 minibatch: 68      time used: 0.30559253692626953\n","minibatch AVG loss: 0.030225070519372822\n","Epoch: test     test index of 10 minibatch: 69      time used: 0.3183016777038574\n","minibatch AVG loss: 0.17804707712493836\n","Epoch: test     test index of 10 minibatch: 70      time used: 0.30224156379699707\n","minibatch AVG loss: 0.3954662100994028\n","Epoch: test     test index of 10 minibatch: 71      time used: 0.30194783210754395\n","minibatch AVG loss: 0.05694160433486104\n","Epoch: test     test index of 10 minibatch: 72      time used: 0.301501989364624\n","minibatch AVG loss: 0.06465309045743198\n","Epoch: test     test index of 10 minibatch: 73      time used: 0.29981207847595215\n","minibatch AVG loss: 0.0297217552899383\n","Epoch: test     test index of 10 minibatch: 74      time used: 0.3011455535888672\n","minibatch AVG loss: 0.07081840937025845\n","Epoch: test     test index of 10 minibatch: 75      time used: 0.3043098449707031\n","minibatch AVG loss: 0.01425417624413967\n","Epoch: test     test index of 10 minibatch: 76      time used: 0.3153531551361084\n","minibatch AVG loss: 0.18491353862918913\n","Epoch: test     test index of 10 minibatch: 77      time used: 0.29569053649902344\n","minibatch AVG loss: 0.06131143956445158\n","Epoch: test     test index of 10 minibatch: 78      time used: 0.3075695037841797\n","minibatch AVG loss: 0.07281724938657134\n","Epoch: test     test index of 10 minibatch: 79      time used: 0.3151581287384033\n","minibatch AVG loss: 0.19734372678212822\n","Epoch: test     test index of 10 minibatch: 80      time used: 0.2916562557220459\n","minibatch AVG loss: 0.6903661906719207\n","Epoch: test     test index of 10 minibatch: 81      time used: 0.29968881607055664\n","minibatch AVG loss: 0.6108803922077641\n","Epoch: test     test index of 10 minibatch: 82      time used: 0.29125094413757324\n","minibatch AVG loss: 0.6123779913410544\n","Epoch: test     test index of 10 minibatch: 83      time used: 0.3005406856536865\n","minibatch AVG loss: 0.039067944593261926\n","Epoch: test     test index of 10 minibatch: 84      time used: 0.30754852294921875\n","minibatch AVG loss: 0.1975285330787301\n","\n","Epoch:  test \n","Loss: 0.1280  Acc: 95.0413\n","negative precision: 95.9707  recall: 96.3235\n","negative sensitivity: 96.3235  specificity: 92.7393\n","negative FPR: 7.2607  NPV: 93.3555\n","negative TP: 524.0\n","negative TN: 281.0\n","negative FP: 22.0\n","negative FN: 20.0\n","AUC:0.9895\n","AUC:0.9895\n","positive precision: 93.3555  recall: 92.7393\n","positive sensitivity: 92.7393  specificity: 96.3235\n","positive FPR: 3.6765  NPV: 95.9707\n","positive TP: 281.0\n","positive TN: 524.0\n","positive FP: 20.0\n","positive FN: 22.0\n","AUC:0.9895\n","AUC:0.9895\n","\n","\n","Testing complete in 18m 27s\n","5fold_test.py:65: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n","  tprs.append(interp(mean_fpr, roc_auc_list[i][0], roc_auc_list[i][1]))\n","5fold_test.py:65: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n","  tprs.append(interp(mean_fpr, roc_auc_list[i][0], roc_auc_list[i][1]))\n","5fold_test.py:65: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n","  tprs.append(interp(mean_fpr, roc_auc_list[i][0], roc_auc_list[i][1]))\n","5fold_test.py:65: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n","  tprs.append(interp(mean_fpr, roc_auc_list[i][0], roc_auc_list[i][1]))\n","5fold_test.py:65: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n","  tprs.append(interp(mean_fpr, roc_auc_list[i][0], roc_auc_list[i][1]))\n","Mean AUC = 0.990 ± 0.001\n","findfont: Font family ['Times New Roman'] not found. Falling back to DejaVu Sans.\n"]}]},{"cell_type":"markdown","metadata":{"id":"XX6Vjy9ec2b2"},"source":["# check the Tensorboard output"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"MWtYyRI1ff0q","outputId":"48778258-2ed5-42b7-d237-4c757a6e7f61"},"source":["%load_ext tensorboard\n","%tensorboard --logdir '/home/pancreatic-cancer-project/runs'"],"execution_count":null,"outputs":[{"data":{"application/javascript":["\n","        (async () => {\n","            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n","            url.searchParams.set('tensorboardColab', 'true');\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"markdown","metadata":{"id":"XSGgbUQ3E0H5"},"source":["# After the task, save the output to google drive\n"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"_Wx0ymiiEuyS","outputId":"b66c087e-6b86-4eb9-830a-fe5117f25065"},"source":["# copy tensorboard runs\n","!/bin/cp -rf /home/pancreatic-cancer-project/runs/*  /content/drive/MyDrive/MSHT_offcial_result/runs/\n","print('runs copy completed!')\n","# copy the traind models\n","!/bin/cp -rf /home/pancreatic-cancer-project/saved_models/* /content/drive/MyDrive/MSHT_offcial_result/saved_models/\n","print('models copy completed!')\n","# copy the imaging_results\n","!/bin/cp -rf /home/pancreatic-cancer-project/imaging_results/* /content/drive/MyDrive/MSHT_offcial_result/imaging_results/\n","print('imaging_results copy completed!')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["runs copy completed!\n","models copy completed!\n","imaging_results copy completed!\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"9lzAtLIhnGe5","outputId":"d1487a64-4165-4ada-b2fc-4dd93dd87503"},"source":["!date --date='+8 hour'  # CST time zone"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Oct 29 04:21:06 UTC 2021\n"]}]}]}