{"cells":[{"cell_type":"markdown","metadata":{"id":"-1_HUut4YYm5"},"source":["# Introduction\n","\n","## This is the official counterparts evaluation script of CLS tasks\n","* Use google colab pro+ (high RAM+GPU)\n","* we use the P100 GPU for the Experiments\n","\n","## The code and Training process along with all record are public avaliable\n","* Our github page: https://github.com/sagizty/Multi-Stage-Hybrid-Transformer\n","* The ROSE dataset is not publicly aviliable.\n","* The Warwick dataset is publicly aviliable, therefore we use it for illustration.\n","\n","\n","# 说明\n","* 这是一个公开的colab脚本，意在展现深度学习做病理学图像任务的能力。\n","* 本人的github会陆续更新更多自己的开源工作，包括模型设计（backbone），训练策略设计，预训练工作，数据增强工作等。欢迎持续关注，感谢您的每一个star！任何疑问可以去github联系我。\n","* 更多详细介绍会逐步更新\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1656337173744,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"ZnbrNSoSXFm5","outputId":"cb01c424-6c60-4c66-81d2-5a401098980c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jun 27 13:39:32 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# check GPU\n","!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656337177571,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"n9GPOn5gcykA","outputId":"d8dc8908-6c71-436d-919f-8c296f82935c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jun 27 21:39:36 UTC 2022\n"]}],"source":["!date --date='+8 hour'  # CST time zone"]},{"cell_type":"markdown","metadata":{"id":"fbnpeHYUgsJz"},"source":["## Mount Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18142,"status":"ok","timestamp":1656323351029,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"3obRNrIaffjK","outputId":"ec9a2c33-b20e-4fd5-d55d-b1089e284a0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"BYevYeMFYmlx"},"source":["## create file-system enviroment\n","* mount your google drive first\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6532,"status":"ok","timestamp":1656323357554,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"ePtQFcQCEPlu","outputId":"cd445728-3880-458c-c83a-76f1bd705d06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Folder Tree Creation completed!\n","Cloning into '/home/MIL_Experiment/code'...\n","remote: Enumerating objects: 451, done.\u001b[K\n","remote: Counting objects: 100% (17/17), done.\u001b[K\n","remote: Compressing objects: 100% (16/16), done.\u001b[K\n","remote: Total 451 (delta 4), reused 0 (delta 0), pack-reused 434\u001b[K\n","Receiving objects: 100% (451/451), 116.26 MiB | 41.80 MiB/s, done.\n","Resolving deltas: 100% (201/201), done.\n","code transfer from github completed!\n","data transfer completed!\n"]}],"source":["# create file-system enviroment\n","# mount the google drive first\n","# https://drive.google.com/drive/u/1/my-drive\n","\n","# clear colab path\n","!rm -rf /data\n","!rm -rf /home/MIL_Experiment\n","\n","# create path\n","!mkdir /home/MIL_Experiment\n","!mkdir /home/MIL_Experiment/runs\n","!mkdir /home/MIL_Experiment/code\n","!mkdir /home/MIL_Experiment/saved_models\n","!mkdir /home/MIL_Experiment/imaging_results\n","\n","!mkdir /data\n","!mkdir /data/MIL_Experiment\n","!mkdir /data/MIL_Experiment/dataset\n","\n","print('Folder Tree Creation completed!')\n","\n","# get the latest code from Github MIL-SI official page\n","!git clone https://github.com/sagizty/Multi-Stage-Hybrid-Transformer.git /home/MIL_Experiment/code\n","print('code transfer from github completed!')\n","\n","# copy runs if u want to compare\n","# !cp -r /content/drive/MyDrive/MIL_Experiment/runs/* /home/MIL_Experiment/runs\n","# print('tensorboard log transfer completed!')\n","\n","# copy saved_models if u want to compare\n","# !cp -r /content/drive/MyDrive/MIL_Experiment/saved_models/* /home/MIL_Experiment/saved_models\n","# print('saved_models transfer completed!')\n","\n","# get the MIL and CLS dataset from github\n","# by its zip\n","# !cp /home/MIL_Experiment/code/sample_datasets/warwick_MIL.zip /data/MIL_Experiment/dataset/\n","!cp /home/MIL_Experiment/code/sample_datasets/warwick_CLS.zip /data/MIL_Experiment/dataset/\n","# unzip\n","# !unzip -q /data/MIL_Experiment/dataset/warwick_MIL.zip -d /data/MIL_Experiment/dataset/\n","!unzip -q /data/MIL_Experiment/dataset/warwick_CLS.zip -d /data/MIL_Experiment/dataset/\n","\n","# alter the path\n","# !rm -rf /data/MIL_Experiment/dataset/warwick_MIL.zip\n","!rm -rf /data/MIL_Experiment/dataset/warwick_CLS.zip\n","print('data transfer completed!')"]},{"cell_type":"markdown","metadata":{"id":"xLxxHGq_wwwL"},"source":["## Arrange the working enviorment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":179413,"status":"ok","timestamp":1656323536963,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"Nx9fi6CgitxF","outputId":"284d87fa-9c6c-4d24-f181-b257af104a23"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |█████████████                   | 834.1 MB 1.3 MB/s eta 0:15:09tcmalloc: large alloc 1147494400 bytes == 0x3a3d6000 @  0x7f3e8335a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████▌               | 1055.7 MB 60.5 MB/s eta 0:00:17tcmalloc: large alloc 1434370048 bytes == 0x7ea2c000 @  0x7f3e8335a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.3 MB/s eta 0:08:51tcmalloc: large alloc 1792966656 bytes == 0x385e000 @  0x7f3e8335a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 78.9 MB/s eta 0:00:05tcmalloc: large alloc 2241208320 bytes == 0x6e646000 @  0x7f3e8335a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf3fa8000 @  0x7f3e833591e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2551685120 bytes == 0x16da70000 @  0x7f3e8335a615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 2041.3 MB 7.1 kB/s \n","\u001b[K     |████████████████████████████████| 23.2 MB 169 kB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.0+cu111 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11269,"status":"ok","timestamp":1656323656802,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"K1Yb2b6TGF4r","outputId":"96e4bbaf-6586-4ae8-bbb2-cfb32d1aa637"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/MIL_Experiment/code\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu111)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: notifyemail in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ttach in /usr/local/lib/python3.7/dist-packages (0.0.3)\n"]}],"source":["# change working dir\n","import os\n","os.chdir(\"/home/MIL_Experiment/code\")\n","!pwd\n","\n","# get packages\n","!pip install tensorboardX\n","!pip install timm\n","!pip install notifyemail\n","!pip install ttach\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":476,"status":"ok","timestamp":1656323550980,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"87Owjg_pN2yD","outputId":"970a3c4c-4668-454e-b47c-f2f19f5b117e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.7.13\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1656323551377,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"GpEVUWwqK79D","outputId":"1c796c41-8808-4533-a05d-5258de3b4aca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Package                       Version\n","----------------------------- ------------------------------\n","absl-py                       1.1.0\n","alabaster                     0.7.12\n","albumentations                0.1.12\n","altair                        4.2.0\n","appdirs                       1.4.4\n","argon2-cffi                   21.3.0\n","argon2-cffi-bindings          21.2.0\n","arviz                         0.12.1\n","astor                         0.8.1\n","astropy                       4.3.1\n","astunparse                    1.6.3\n","atari-py                      0.2.9\n","atomicwrites                  1.4.0\n","attrs                         21.4.0\n","audioread                     2.1.9\n","autograd                      1.4\n","Babel                         2.10.2\n","backcall                      0.2.0\n","beautifulsoup4                4.6.3\n","bleach                        5.0.0\n","blis                          0.7.7\n","bokeh                         2.3.3\n","branca                        0.5.0\n","bs4                           0.0.1\n","CacheControl                  0.12.11\n","cached-property               1.5.2\n","cachetools                    4.2.4\n","catalogue                     2.0.7\n","certifi                       2022.6.15\n","cffi                          1.15.0\n","cftime                        1.6.0\n","chardet                       3.0.4\n","charset-normalizer            2.0.12\n","click                         7.1.2\n","cloudpickle                   1.3.0\n","cmake                         3.22.5\n","cmdstanpy                     0.9.5\n","colorcet                      3.0.0\n","colorlover                    0.3.0\n","community                     1.0.0b1\n","contextlib2                   0.5.5\n","convertdate                   2.4.0\n","coverage                      3.7.1\n","coveralls                     0.5\n","crcmod                        1.7\n","cufflinks                     0.17.3\n","cupy-cuda111                  9.4.0\n","cvxopt                        1.2.7\n","cvxpy                         1.0.31\n","cycler                        0.11.0\n","cymem                         2.0.6\n","Cython                        0.29.30\n","daft                          0.0.4\n","dask                          2.12.0\n","datascience                   0.10.6\n","debugpy                       1.0.0\n","decorator                     4.4.2\n","defusedxml                    0.7.1\n","descartes                     1.1.0\n","dill                          0.3.5.1\n","distributed                   1.25.3\n","dlib                          19.18.0+zzzcolab20220513001918\n","dm-tree                       0.1.7\n","docopt                        0.6.2\n","docutils                      0.17.1\n","dopamine-rl                   1.0.5\n","earthengine-api               0.1.315\n","easydict                      1.9\n","ecos                          2.0.10\n","editdistance                  0.5.3\n","en-core-web-sm                3.3.0\n","entrypoints                   0.4\n","ephem                         4.1.3\n","et-xmlfile                    1.1.0\n","fa2                           0.3.5\n","fastai                        2.6.3\n","fastcore                      1.4.4\n","fastdownload                  0.0.6\n","fastdtw                       0.3.4\n","fastjsonschema                2.15.3\n","fastprogress                  1.0.2\n","fastrlock                     0.8\n","fbprophet                     0.7.1\n","feather-format                0.4.1\n","filelock                      3.7.1\n","firebase-admin                4.4.0\n","fix-yahoo-finance             0.0.22\n","Flask                         1.1.4\n","flatbuffers                   2.0\n","folium                        0.8.3\n","future                        0.16.0\n","gast                          0.5.3\n","GDAL                          2.2.2\n","gdown                         4.4.0\n","gensim                        3.6.0\n","geographiclib                 1.52\n","geopy                         1.17.0\n","gin-config                    0.5.0\n","glob2                         0.7\n","google                        2.0.3\n","google-api-core               1.31.6\n","google-api-python-client      1.12.11\n","google-auth                   1.35.0\n","google-auth-httplib2          0.0.4\n","google-auth-oauthlib          0.4.6\n","google-cloud-bigquery         1.21.0\n","google-cloud-bigquery-storage 1.1.2\n","google-cloud-core             1.0.3\n","google-cloud-datastore        1.8.0\n","google-cloud-firestore        1.7.0\n","google-cloud-language         1.2.0\n","google-cloud-storage          1.18.1\n","google-cloud-translate        1.5.0\n","google-colab                  1.0.0\n","google-pasta                  0.2.0\n","google-resumable-media        0.4.1\n","googleapis-common-protos      1.56.2\n","googledrivedownloader         0.4\n","graphviz                      0.10.1\n","greenlet                      1.1.2\n","grpcio                        1.46.3\n","gspread                       3.4.2\n","gspread-dataframe             3.0.8\n","gym                           0.17.3\n","h5py                          3.1.0\n","HeapDict                      1.0.1\n","hijri-converter               2.2.4\n","holidays                      0.10.5.2\n","holoviews                     1.14.9\n","html5lib                      1.0.1\n","httpimport                    0.5.18\n","httplib2                      0.17.4\n","httplib2shim                  0.0.3\n","humanize                      0.5.1\n","hyperopt                      0.1.2\n","ideep4py                      2.0.0.post3\n","idna                          2.10\n","imageio                       2.4.1\n","imagesize                     1.3.0\n","imbalanced-learn              0.8.1\n","imblearn                      0.0\n","imgaug                        0.2.9\n","importlib-metadata            4.11.4\n","importlib-resources           5.7.1\n","imutils                       0.5.4\n","inflect                       2.1.0\n","iniconfig                     1.1.1\n","intel-openmp                  2022.1.0\n","intervaltree                  2.1.0\n","ipykernel                     4.10.1\n","ipython                       5.5.0\n","ipython-genutils              0.2.0\n","ipython-sql                   0.3.9\n","ipywidgets                    7.7.0\n","itsdangerous                  1.1.0\n","jax                           0.3.8\n","jaxlib                        0.3.7+cuda11.cudnn805\n","jedi                          0.18.1\n","jieba                         0.42.1\n","Jinja2                        2.11.3\n","joblib                        1.1.0\n","jpeg4py                       0.1.4\n","jsonschema                    4.3.3\n","jupyter                       1.0.0\n","jupyter-client                5.3.5\n","jupyter-console               5.2.0\n","jupyter-core                  4.10.0\n","jupyterlab-pygments           0.2.2\n","jupyterlab-widgets            1.1.0\n","kaggle                        1.5.12\n","kapre                         0.3.7\n","keras                         2.8.0\n","Keras-Preprocessing           1.1.2\n","keras-vis                     0.4.1\n","kiwisolver                    1.4.3\n","korean-lunar-calendar         0.2.1\n","langcodes                     3.3.0\n","libclang                      14.0.1\n","librosa                       0.8.1\n","lightgbm                      2.2.3\n","llvmlite                      0.34.0\n","lmdb                          0.99\n","LunarCalendar                 0.0.9\n","lxml                          4.2.6\n","Markdown                      3.3.7\n","MarkupSafe                    2.0.1\n","matplotlib                    3.2.2\n","matplotlib-inline             0.1.3\n","matplotlib-venn               0.11.7\n","missingno                     0.5.1\n","mistune                       0.8.4\n","mizani                        0.6.0\n","mkl                           2019.0\n","mlxtend                       0.14.0\n","more-itertools                8.13.0\n","moviepy                       0.2.3.5\n","mpmath                        1.2.1\n","msgpack                       1.0.4\n","multiprocess                  0.70.13\n","multitasking                  0.0.10\n","murmurhash                    1.0.7\n","music21                       5.5.0\n","natsort                       5.5.0\n","nbclient                      0.6.4\n","nbconvert                     5.6.1\n","nbformat                      5.4.0\n","nest-asyncio                  1.5.5\n","netCDF4                       1.5.8\n","networkx                      2.6.3\n","nibabel                       3.0.2\n","nltk                          3.7\n","notebook                      5.3.1\n","notifyemail                   1.0.2\n","numba                         0.51.2\n","numexpr                       2.8.1\n","numpy                         1.21.6\n","oauth2client                  4.1.3\n","oauthlib                      3.2.0\n","okgrade                       0.4.3\n","opencv-contrib-python         4.1.2.30\n","opencv-python                 4.1.2.30\n","openpyxl                      3.0.10\n","opt-einsum                    3.3.0\n","osqp                          0.6.2.post0\n","packaging                     21.3\n","palettable                    3.3.0\n","pandas                        1.3.5\n","pandas-datareader             0.9.0\n","pandas-gbq                    0.13.3\n","pandas-profiling              1.4.1\n","pandocfilters                 1.5.0\n","panel                         0.12.1\n","param                         1.12.1\n","parso                         0.8.3\n","pathlib                       1.0.1\n","pathy                         0.6.1\n","patsy                         0.5.2\n","pep517                        0.12.0\n","pexpect                       4.8.0\n","pickleshare                   0.7.5\n","Pillow                        7.1.2\n","pip                           21.1.3\n","pip-tools                     6.2.0\n","plotly                        5.5.0\n","plotnine                      0.6.0\n","pluggy                        0.7.1\n","pooch                         1.6.0\n","portpicker                    1.3.9\n","prefetch-generator            1.0.1\n","preshed                       3.0.6\n","prettytable                   3.3.0\n","progressbar2                  3.38.0\n","prometheus-client             0.14.1\n","promise                       2.3\n","prompt-toolkit                1.0.18\n","protobuf                      3.17.3\n","psutil                        5.4.8\n","psycopg2                      2.7.6.1\n","ptyprocess                    0.7.0\n","py                            1.11.0\n","pyarrow                       6.0.1\n","pyasn1                        0.4.8\n","pyasn1-modules                0.2.8\n","pycocotools                   2.0.4\n","pycparser                     2.21\n","pyct                          0.4.8\n","pydantic                      1.8.2\n","pydata-google-auth            1.4.0\n","pydot                         1.3.0\n","pydot-ng                      2.0.0\n","pydotplus                     2.0.2\n","PyDrive                       1.3.1\n","pyemd                         0.5.1\n","pyerfa                        2.0.0.1\n","pyglet                        1.5.0\n","Pygments                      2.6.1\n","pygobject                     3.26.1\n","pymc3                         3.11.4\n","PyMeeus                       0.5.11\n","pymongo                       4.1.1\n","pymystem3                     0.2.0\n","PyOpenGL                      3.1.6\n","pyparsing                     3.0.9\n","pyrsistent                    0.18.1\n","pysndfile                     1.3.8\n","PySocks                       1.7.1\n","pystan                        2.19.1.1\n","pytest                        3.6.4\n","python-apt                    0.0.0\n","python-chess                  0.23.11\n","python-dateutil               2.8.2\n","python-louvain                0.16\n","python-slugify                6.1.2\n","python-utils                  3.3.3\n","pytz                          2022.1\n","pyviz-comms                   2.2.0\n","PyWavelets                    1.3.0\n","PyYAML                        3.13\n","pyzmq                         23.1.0\n","qdldl                         0.1.5.post2\n","qtconsole                     5.3.1\n","QtPy                          2.1.0\n","regex                         2022.6.2\n","requests                      2.23.0\n","requests-oauthlib             1.3.1\n","resampy                       0.2.2\n","rpy2                          3.4.5\n","rsa                           4.8\n","scikit-image                  0.18.3\n","scikit-learn                  1.0.2\n","scipy                         1.4.1\n","screen-resolution-extra       0.0.0\n","scs                           3.2.0\n","seaborn                       0.11.2\n","semver                        2.13.0\n","Send2Trash                    1.8.0\n","setuptools                    57.4.0\n","setuptools-git                1.2\n","Shapely                       1.8.2\n","simplegeneric                 0.8.1\n","six                           1.15.0\n","sklearn                       0.0\n","sklearn-pandas                1.8.0\n","smart-open                    5.2.1\n","snowballstemmer               2.2.0\n","sortedcontainers              2.4.0\n","SoundFile                     0.10.3.post1\n","soupsieve                     2.3.2.post1\n","spacy                         3.3.1\n","spacy-legacy                  3.0.9\n","spacy-loggers                 1.0.2\n","Sphinx                        1.8.6\n","sphinxcontrib-serializinghtml 1.1.5\n","sphinxcontrib-websupport      1.2.4\n","SQLAlchemy                    1.4.37\n","sqlparse                      0.4.2\n","srsly                         2.4.3\n","statsmodels                   0.10.2\n","sympy                         1.7.1\n","tables                        3.7.0\n","tabulate                      0.8.9\n","tblib                         1.7.0\n","tenacity                      8.0.1\n","tensorboard                   2.8.0\n","tensorboard-data-server       0.6.1\n","tensorboard-plugin-wit        1.8.1\n","tensorboardX                  2.5.1\n","tensorflow                    2.8.2+zzzcolab20220527125636\n","tensorflow-datasets           4.0.1\n","tensorflow-estimator          2.8.0\n","tensorflow-gcs-config         2.8.0\n","tensorflow-hub                0.12.0\n","tensorflow-io-gcs-filesystem  0.26.0\n","tensorflow-metadata           1.8.0\n","tensorflow-probability        0.16.0\n","termcolor                     1.1.0\n","terminado                     0.13.3\n","testpath                      0.6.0\n","text-unidecode                1.3\n","textblob                      0.15.3\n","Theano-PyMC                   1.1.2\n","thinc                         8.0.17\n","threadpoolctl                 3.1.0\n","tifffile                      2021.11.2\n","timm                          0.5.4\n","tinycss2                      1.1.1\n","tomli                         2.0.1\n","toolz                         0.11.2\n","torch                         1.9.0+cu111\n","torchaudio                    0.11.0+cu113\n","torchsummary                  1.5.1\n","torchtext                     0.12.0\n","torchvision                   0.10.0+cu111\n","tornado                       5.1.1\n","tqdm                          4.64.0\n","traitlets                     5.1.1\n","ttach                         0.0.3\n","tweepy                        3.10.0\n","typeguard                     2.7.1\n","typer                         0.4.1\n","typing-extensions             4.1.1\n","tzlocal                       1.5.1\n","uritemplate                   3.0.1\n","urllib3                       1.24.3\n","vega-datasets                 0.9.0\n","wasabi                        0.9.1\n","wcwidth                       0.2.5\n","webencodings                  0.5.1\n","Werkzeug                      1.0.1\n","wheel                         0.37.1\n","widgetsnbextension            3.6.0\n","wordcloud                     1.5.0\n","wrapt                         1.14.1\n","xarray                        0.20.2\n","xarray-einstats               0.2.2\n","xgboost                       0.90\n","xkit                          0.0.0\n","xlrd                          1.1.0\n","xlwt                          1.3.0\n","yellowbrick                   1.4\n","zict                          2.2.0\n","zipp                          3.8.0\n"]}],"source":["!pip list"]},{"cell_type":"markdown","metadata":{"id":"h31KAx1ZZEl9"},"source":["## Start Training\n","* by command line\n","* use argparse to set down hyper-parameter\n","\n","* 5-fold experiment is used here"]},{"cell_type":"markdown","metadata":{"id":"--aldMsHOZkP"},"source":["# CLS counterparts"]},{"cell_type":"markdown","metadata":{"id":"QqeBMVh6OjTu"},"source":["* Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314814,"status":"ok","timestamp":1656323971611,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"fxJcLMKMYeDt","outputId":"4398b07a-eaac-4303-e47e-a6487b2d0773"},"outputs":[{"name":"stdout","output_type":"stream","text":["*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, att_module='SimAM', attn_drop_rate=0.0, backbone_PT_off=False, batch_size=4, check_minibatch=5, cls_token_off=False, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=False, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=-1, intake_epochs=0, lr=1e-05, lrf=0.05, model_idx='ViT_384_401_PT_lf05_b4_warwick_CLS', model_path='/home/MIL_Experiment/saved_models', num_classes=2, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, pos_embedding_off=False)\n","we dont have more GPU idx here, try to use gpu_idx=0\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_384',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_sam_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_sam_224',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[ 1.0506, -0.2006]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 768, 24, 24]         590,592\n","          Identity-2             [-1, 576, 768]               0\n","        PatchEmbed-3             [-1, 576, 768]               0\n","           Dropout-4             [-1, 577, 768]               0\n","         LayerNorm-5             [-1, 577, 768]           1,536\n","            Linear-6            [-1, 577, 2304]       1,771,776\n","           Dropout-7         [-1, 12, 577, 577]               0\n","            Linear-8             [-1, 577, 768]         590,592\n","           Dropout-9             [-1, 577, 768]               0\n","        Attention-10             [-1, 577, 768]               0\n","         Identity-11             [-1, 577, 768]               0\n","        LayerNorm-12             [-1, 577, 768]           1,536\n","           Linear-13            [-1, 577, 3072]       2,362,368\n","             GELU-14            [-1, 577, 3072]               0\n","          Dropout-15            [-1, 577, 3072]               0\n","           Linear-16             [-1, 577, 768]       2,360,064\n","          Dropout-17             [-1, 577, 768]               0\n","              Mlp-18             [-1, 577, 768]               0\n","         Identity-19             [-1, 577, 768]               0\n","            Block-20             [-1, 577, 768]               0\n","        LayerNorm-21             [-1, 577, 768]           1,536\n","           Linear-22            [-1, 577, 2304]       1,771,776\n","          Dropout-23         [-1, 12, 577, 577]               0\n","           Linear-24             [-1, 577, 768]         590,592\n","          Dropout-25             [-1, 577, 768]               0\n","        Attention-26             [-1, 577, 768]               0\n","         Identity-27             [-1, 577, 768]               0\n","        LayerNorm-28             [-1, 577, 768]           1,536\n","           Linear-29            [-1, 577, 3072]       2,362,368\n","             GELU-30            [-1, 577, 3072]               0\n","          Dropout-31            [-1, 577, 3072]               0\n","           Linear-32             [-1, 577, 768]       2,360,064\n","          Dropout-33             [-1, 577, 768]               0\n","              Mlp-34             [-1, 577, 768]               0\n","         Identity-35             [-1, 577, 768]               0\n","            Block-36             [-1, 577, 768]               0\n","        LayerNorm-37             [-1, 577, 768]           1,536\n","           Linear-38            [-1, 577, 2304]       1,771,776\n","          Dropout-39         [-1, 12, 577, 577]               0\n","           Linear-40             [-1, 577, 768]         590,592\n","          Dropout-41             [-1, 577, 768]               0\n","        Attention-42             [-1, 577, 768]               0\n","         Identity-43             [-1, 577, 768]               0\n","        LayerNorm-44             [-1, 577, 768]           1,536\n","           Linear-45            [-1, 577, 3072]       2,362,368\n","             GELU-46            [-1, 577, 3072]               0\n","          Dropout-47            [-1, 577, 3072]               0\n","           Linear-48             [-1, 577, 768]       2,360,064\n","          Dropout-49             [-1, 577, 768]               0\n","              Mlp-50             [-1, 577, 768]               0\n","         Identity-51             [-1, 577, 768]               0\n","            Block-52             [-1, 577, 768]               0\n","        LayerNorm-53             [-1, 577, 768]           1,536\n","           Linear-54            [-1, 577, 2304]       1,771,776\n","          Dropout-55         [-1, 12, 577, 577]               0\n","           Linear-56             [-1, 577, 768]         590,592\n","          Dropout-57             [-1, 577, 768]               0\n","        Attention-58             [-1, 577, 768]               0\n","         Identity-59             [-1, 577, 768]               0\n","        LayerNorm-60             [-1, 577, 768]           1,536\n","           Linear-61            [-1, 577, 3072]       2,362,368\n","             GELU-62            [-1, 577, 3072]               0\n","          Dropout-63            [-1, 577, 3072]               0\n","           Linear-64             [-1, 577, 768]       2,360,064\n","          Dropout-65             [-1, 577, 768]               0\n","              Mlp-66             [-1, 577, 768]               0\n","         Identity-67             [-1, 577, 768]               0\n","            Block-68             [-1, 577, 768]               0\n","        LayerNorm-69             [-1, 577, 768]           1,536\n","           Linear-70            [-1, 577, 2304]       1,771,776\n","          Dropout-71         [-1, 12, 577, 577]               0\n","           Linear-72             [-1, 577, 768]         590,592\n","          Dropout-73             [-1, 577, 768]               0\n","        Attention-74             [-1, 577, 768]               0\n","         Identity-75             [-1, 577, 768]               0\n","        LayerNorm-76             [-1, 577, 768]           1,536\n","           Linear-77            [-1, 577, 3072]       2,362,368\n","             GELU-78            [-1, 577, 3072]               0\n","          Dropout-79            [-1, 577, 3072]               0\n","           Linear-80             [-1, 577, 768]       2,360,064\n","          Dropout-81             [-1, 577, 768]               0\n","              Mlp-82             [-1, 577, 768]               0\n","         Identity-83             [-1, 577, 768]               0\n","            Block-84             [-1, 577, 768]               0\n","        LayerNorm-85             [-1, 577, 768]           1,536\n","           Linear-86            [-1, 577, 2304]       1,771,776\n","          Dropout-87         [-1, 12, 577, 577]               0\n","           Linear-88             [-1, 577, 768]         590,592\n","          Dropout-89             [-1, 577, 768]               0\n","        Attention-90             [-1, 577, 768]               0\n","         Identity-91             [-1, 577, 768]               0\n","        LayerNorm-92             [-1, 577, 768]           1,536\n","           Linear-93            [-1, 577, 3072]       2,362,368\n","             GELU-94            [-1, 577, 3072]               0\n","          Dropout-95            [-1, 577, 3072]               0\n","           Linear-96             [-1, 577, 768]       2,360,064\n","          Dropout-97             [-1, 577, 768]               0\n","              Mlp-98             [-1, 577, 768]               0\n","         Identity-99             [-1, 577, 768]               0\n","           Block-100             [-1, 577, 768]               0\n","       LayerNorm-101             [-1, 577, 768]           1,536\n","          Linear-102            [-1, 577, 2304]       1,771,776\n","         Dropout-103         [-1, 12, 577, 577]               0\n","          Linear-104             [-1, 577, 768]         590,592\n","         Dropout-105             [-1, 577, 768]               0\n","       Attention-106             [-1, 577, 768]               0\n","        Identity-107             [-1, 577, 768]               0\n","       LayerNorm-108             [-1, 577, 768]           1,536\n","          Linear-109            [-1, 577, 3072]       2,362,368\n","            GELU-110            [-1, 577, 3072]               0\n","         Dropout-111            [-1, 577, 3072]               0\n","          Linear-112             [-1, 577, 768]       2,360,064\n","         Dropout-113             [-1, 577, 768]               0\n","             Mlp-114             [-1, 577, 768]               0\n","        Identity-115             [-1, 577, 768]               0\n","           Block-116             [-1, 577, 768]               0\n","       LayerNorm-117             [-1, 577, 768]           1,536\n","          Linear-118            [-1, 577, 2304]       1,771,776\n","         Dropout-119         [-1, 12, 577, 577]               0\n","          Linear-120             [-1, 577, 768]         590,592\n","         Dropout-121             [-1, 577, 768]               0\n","       Attention-122             [-1, 577, 768]               0\n","        Identity-123             [-1, 577, 768]               0\n","       LayerNorm-124             [-1, 577, 768]           1,536\n","          Linear-125            [-1, 577, 3072]       2,362,368\n","            GELU-126            [-1, 577, 3072]               0\n","         Dropout-127            [-1, 577, 3072]               0\n","          Linear-128             [-1, 577, 768]       2,360,064\n","         Dropout-129             [-1, 577, 768]               0\n","             Mlp-130             [-1, 577, 768]               0\n","        Identity-131             [-1, 577, 768]               0\n","           Block-132             [-1, 577, 768]               0\n","       LayerNorm-133             [-1, 577, 768]           1,536\n","          Linear-134            [-1, 577, 2304]       1,771,776\n","         Dropout-135         [-1, 12, 577, 577]               0\n","          Linear-136             [-1, 577, 768]         590,592\n","         Dropout-137             [-1, 577, 768]               0\n","       Attention-138             [-1, 577, 768]               0\n","        Identity-139             [-1, 577, 768]               0\n","       LayerNorm-140             [-1, 577, 768]           1,536\n","          Linear-141            [-1, 577, 3072]       2,362,368\n","            GELU-142            [-1, 577, 3072]               0\n","         Dropout-143            [-1, 577, 3072]               0\n","          Linear-144             [-1, 577, 768]       2,360,064\n","         Dropout-145             [-1, 577, 768]               0\n","             Mlp-146             [-1, 577, 768]               0\n","        Identity-147             [-1, 577, 768]               0\n","           Block-148             [-1, 577, 768]               0\n","       LayerNorm-149             [-1, 577, 768]           1,536\n","          Linear-150            [-1, 577, 2304]       1,771,776\n","         Dropout-151         [-1, 12, 577, 577]               0\n","          Linear-152             [-1, 577, 768]         590,592\n","         Dropout-153             [-1, 577, 768]               0\n","       Attention-154             [-1, 577, 768]               0\n","        Identity-155             [-1, 577, 768]               0\n","       LayerNorm-156             [-1, 577, 768]           1,536\n","          Linear-157            [-1, 577, 3072]       2,362,368\n","            GELU-158            [-1, 577, 3072]               0\n","         Dropout-159            [-1, 577, 3072]               0\n","          Linear-160             [-1, 577, 768]       2,360,064\n","         Dropout-161             [-1, 577, 768]               0\n","             Mlp-162             [-1, 577, 768]               0\n","        Identity-163             [-1, 577, 768]               0\n","           Block-164             [-1, 577, 768]               0\n","       LayerNorm-165             [-1, 577, 768]           1,536\n","          Linear-166            [-1, 577, 2304]       1,771,776\n","         Dropout-167         [-1, 12, 577, 577]               0\n","          Linear-168             [-1, 577, 768]         590,592\n","         Dropout-169             [-1, 577, 768]               0\n","       Attention-170             [-1, 577, 768]               0\n","        Identity-171             [-1, 577, 768]               0\n","       LayerNorm-172             [-1, 577, 768]           1,536\n","          Linear-173            [-1, 577, 3072]       2,362,368\n","            GELU-174            [-1, 577, 3072]               0\n","         Dropout-175            [-1, 577, 3072]               0\n","          Linear-176             [-1, 577, 768]       2,360,064\n","         Dropout-177             [-1, 577, 768]               0\n","             Mlp-178             [-1, 577, 768]               0\n","        Identity-179             [-1, 577, 768]               0\n","           Block-180             [-1, 577, 768]               0\n","       LayerNorm-181             [-1, 577, 768]           1,536\n","          Linear-182            [-1, 577, 2304]       1,771,776\n","         Dropout-183         [-1, 12, 577, 577]               0\n","          Linear-184             [-1, 577, 768]         590,592\n","         Dropout-185             [-1, 577, 768]               0\n","       Attention-186             [-1, 577, 768]               0\n","        Identity-187             [-1, 577, 768]               0\n","       LayerNorm-188             [-1, 577, 768]           1,536\n","          Linear-189            [-1, 577, 3072]       2,362,368\n","            GELU-190            [-1, 577, 3072]               0\n","         Dropout-191            [-1, 577, 3072]               0\n","          Linear-192             [-1, 577, 768]       2,360,064\n","         Dropout-193             [-1, 577, 768]               0\n","             Mlp-194             [-1, 577, 768]               0\n","        Identity-195             [-1, 577, 768]               0\n","           Block-196             [-1, 577, 768]               0\n","       LayerNorm-197             [-1, 577, 768]           1,536\n","        Identity-198                  [-1, 768]               0\n","          Linear-199                    [-1, 2]           1,538\n","================================================================\n","Total params: 85,648,130\n","Trainable params: 85,648,130\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 1437.49\n","Params size (MB): 326.72\n","Estimated Total Size (MB): 1765.90\n","----------------------------------------------------------------\n","model : ViT_384_401_PT_lf05_b4_warwick_CLS\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 5 minibatch: 1      time used: 1.7598493099212646\n","minibatch AVG loss: 0.8037030458450317\n","Epoch: 1     train index of 5 minibatch: 2      time used: 1.4939453601837158\n","minibatch AVG loss: 0.16086829900741578\n","Epoch: 1     train index of 5 minibatch: 3      time used: 1.4949162006378174\n","minibatch AVG loss: 0.19306816179305314\n","\n","Epoch: 1  train \n","Loss: 0.3406  Acc: 85.5072\n","negative precision: 85.7143  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 85.3659\n","negative TP: 24.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 6.0\n","positive precision: 85.3659  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 85.7143\n","positive TP: 35.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 1  val \n","Loss: 0.1425  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 5 minibatch: 1      time used: 1.7199509143829346\n","minibatch AVG loss: 0.0679447490721941\n","Epoch: 2     train index of 5 minibatch: 2      time used: 1.496232032775879\n","minibatch AVG loss: 0.16357617562171073\n","Epoch: 2     train index of 5 minibatch: 3      time used: 1.495366096496582\n","minibatch AVG loss: 0.09292816584929824\n","\n","Epoch: 2  train \n","Loss: 0.1116  Acc: 94.2029\n","negative precision: 93.3333  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 94.8718\n","negative TP: 28.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 2.0\n","positive precision: 94.8718  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 93.3333\n","positive TP: 37.0\n","positive TN: 28.0\n","positive FP: 2.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 2  val \n","Loss: 0.1078  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 5 minibatch: 1      time used: 1.723578929901123\n","minibatch AVG loss: 0.027069391956320032\n","Epoch: 3     train index of 5 minibatch: 2      time used: 1.4942870140075684\n","minibatch AVG loss: 0.08385863077710383\n","Epoch: 3     train index of 5 minibatch: 3      time used: 1.4907290935516357\n","minibatch AVG loss: 0.000495721127208526\n","\n","Epoch: 3  train \n","Loss: 0.0325  Acc: 98.5507\n","negative precision: 96.7742  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 96.7742\n","positive TP: 38.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 3  val \n","Loss: 0.0017  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 5 minibatch: 1      time used: 1.7217187881469727\n","minibatch AVG loss: 0.006335301532271842\n","Epoch: 4     train index of 5 minibatch: 2      time used: 1.4933598041534424\n","minibatch AVG loss: 0.3210893572326313\n","Epoch: 4     train index of 5 minibatch: 3      time used: 1.4928174018859863\n","minibatch AVG loss: 0.09088391398545355\n","\n","Epoch: 4  train \n","Loss: 0.1213  Acc: 95.6522\n","negative precision: 93.5484  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 97.3684\n","negative TP: 29.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 1.0\n","positive precision: 97.3684  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 93.5484\n","positive TP: 37.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 4  val \n","Loss: 0.0031  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 5 minibatch: 1      time used: 1.7191998958587646\n","minibatch AVG loss: 0.00016552289462197224\n","Epoch: 5     train index of 5 minibatch: 2      time used: 1.4920594692230225\n","minibatch AVG loss: 0.0010604346123727737\n","Epoch: 5     train index of 5 minibatch: 3      time used: 1.4916796684265137\n","minibatch AVG loss: 0.11453463883808582\n","\n","Epoch: 5  train \n","Loss: 0.0336  Acc: 98.5507\n","negative precision: 100.0000  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 97.5000\n","negative TP: 29.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 97.5000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 5  val \n","Loss: 0.0080  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 5 minibatch: 1      time used: 1.7180063724517822\n","minibatch AVG loss: 0.015266371491816245\n","Epoch: 6     train index of 5 minibatch: 2      time used: 1.4935719966888428\n","minibatch AVG loss: 0.0012944535905262456\n","Epoch: 6     train index of 5 minibatch: 3      time used: 1.4922707080841064\n","minibatch AVG loss: 0.0006413359595171641\n","\n","Epoch: 6  train \n","Loss: 0.0050  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 6  val \n","Loss: 0.0982  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 5 minibatch: 1      time used: 1.7286789417266846\n","minibatch AVG loss: 0.00041547193031874483\n","Epoch: 7     train index of 5 minibatch: 2      time used: 1.495703935623169\n","minibatch AVG loss: 0.013965365479816683\n","Epoch: 7     train index of 5 minibatch: 3      time used: 1.494434118270874\n","minibatch AVG loss: 4.9448512800154273e-05\n","\n","Epoch: 7  train \n","Loss: 0.0042  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 7  val \n","Loss: 0.0029  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 5 minibatch: 1      time used: 1.7185425758361816\n","minibatch AVG loss: 0.0001647404205868952\n","Epoch: 8     train index of 5 minibatch: 2      time used: 1.4946117401123047\n","minibatch AVG loss: 0.02233263564048684\n","Epoch: 8     train index of 5 minibatch: 3      time used: 1.4949522018432617\n","minibatch AVG loss: 0.0005307823957991786\n","\n","Epoch: 8  train \n","Loss: 0.0169  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 8  val \n","Loss: 0.0064  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 5 minibatch: 1      time used: 1.7214131355285645\n","minibatch AVG loss: 1.2349726603133604e-05\n","Epoch: 9     train index of 5 minibatch: 2      time used: 1.4950454235076904\n","minibatch AVG loss: 6.217137415660545e-05\n","Epoch: 9     train index of 5 minibatch: 3      time used: 1.4937424659729004\n","minibatch AVG loss: 0.00019086934662482236\n","\n","Epoch: 9  train \n","Loss: 0.0002  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 9  val \n","Loss: 0.0082  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 5 minibatch: 1      time used: 1.7184357643127441\n","minibatch AVG loss: 0.0013223671789091896\n","Epoch: 10     train index of 5 minibatch: 2      time used: 1.4932737350463867\n","minibatch AVG loss: 0.00018000257214225712\n","Epoch: 10     train index of 5 minibatch: 3      time used: 1.4934167861938477\n","minibatch AVG loss: 0.0005658195731484738\n","\n","Epoch: 10  train \n","Loss: 0.0007  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 10  val \n","Loss: 0.0092  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 5 minibatch: 1      time used: 1.7276949882507324\n","minibatch AVG loss: 0.0003838837092189351\n","Epoch: 11     train index of 5 minibatch: 2      time used: 1.4942600727081299\n","minibatch AVG loss: 4.205155646559433e-05\n","Epoch: 11     train index of 5 minibatch: 3      time used: 1.493607997894287\n","minibatch AVG loss: 0.012666298595922854\n","\n","Epoch: 11  train \n","Loss: 0.0038  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 11  val \n","Loss: 0.0007  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 5 minibatch: 1      time used: 1.7194814682006836\n","minibatch AVG loss: 0.000379658932070015\n","Epoch: 12     train index of 5 minibatch: 2      time used: 1.4927632808685303\n","minibatch AVG loss: 0.005840893663480529\n","Epoch: 12     train index of 5 minibatch: 3      time used: 1.4939773082733154\n","minibatch AVG loss: 4.995038093511539e-05\n","\n","Epoch: 12  train \n","Loss: 0.0018  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 12  val \n","Loss: 0.0005  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 5 minibatch: 1      time used: 1.7296466827392578\n","minibatch AVG loss: 8.737873190511892e-06\n","Epoch: 13     train index of 5 minibatch: 2      time used: 1.492816686630249\n","minibatch AVG loss: 5.874555022273853e-05\n","Epoch: 13     train index of 5 minibatch: 3      time used: 1.4939351081848145\n","minibatch AVG loss: 5.253215340417228e-05\n","\n","Epoch: 13  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 13  val \n","Loss: 0.0003  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 5 minibatch: 1      time used: 1.7154431343078613\n","minibatch AVG loss: 4.7508225179626606e-05\n","Epoch: 14     train index of 5 minibatch: 2      time used: 1.4933030605316162\n","minibatch AVG loss: 4.3667817226378244e-05\n","Epoch: 14     train index of 5 minibatch: 3      time used: 1.4935598373413086\n","minibatch AVG loss: 3.206550745744607e-05\n","\n","Epoch: 14  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 14  val \n","Loss: 0.0003  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 5 minibatch: 1      time used: 1.7148687839508057\n","minibatch AVG loss: 1.987018176805577e-05\n","Epoch: 15     train index of 5 minibatch: 2      time used: 1.4934122562408447\n","minibatch AVG loss: 2.292243016199791e-05\n","Epoch: 15     train index of 5 minibatch: 3      time used: 1.4939610958099365\n","minibatch AVG loss: 6.707716606797476e-05\n","\n","Epoch: 15  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 15  val \n","Loss: 0.0003  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 5 minibatch: 1      time used: 1.7180089950561523\n","minibatch AVG loss: 4.8149720760193306e-05\n","Epoch: 16     train index of 5 minibatch: 2      time used: 1.4940433502197266\n","minibatch AVG loss: 2.4405611770816905e-05\n","Epoch: 16     train index of 5 minibatch: 3      time used: 1.4932835102081299\n","minibatch AVG loss: 9.701499488983245e-05\n","\n","Epoch: 16  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 16  val \n","Loss: 0.0003  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 5 minibatch: 1      time used: 1.7217020988464355\n","minibatch AVG loss: 1.776713588697021e-05\n","Epoch: 17     train index of 5 minibatch: 2      time used: 1.494077205657959\n","minibatch AVG loss: 0.00031102652815206966\n","Epoch: 17     train index of 5 minibatch: 3      time used: 1.4955143928527832\n","minibatch AVG loss: 7.92567170719849e-05\n","\n","Epoch: 17  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 17  val \n","Loss: 0.0003  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 5 minibatch: 1      time used: 1.7175076007843018\n","minibatch AVG loss: 2.5306707902927884e-05\n","Epoch: 18     train index of 5 minibatch: 2      time used: 1.4925031661987305\n","minibatch AVG loss: 4.378486744371912e-05\n","Epoch: 18     train index of 5 minibatch: 3      time used: 1.494884967803955\n","minibatch AVG loss: 1.1104057011834812e-05\n","\n","Epoch: 18  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 18  val \n","Loss: 0.0003  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 5 minibatch: 1      time used: 1.7175614833831787\n","minibatch AVG loss: 6.969810804093867e-05\n","Epoch: 19     train index of 5 minibatch: 2      time used: 1.4950194358825684\n","minibatch AVG loss: 4.597885099428822e-05\n","Epoch: 19     train index of 5 minibatch: 3      time used: 1.493882656097412\n","minibatch AVG loss: 4.4609770634451705e-05\n","\n","Epoch: 19  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 19  val \n","Loss: 0.0003  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 5 minibatch: 1      time used: 1.7186880111694336\n","minibatch AVG loss: 4.081163019691303e-05\n","Epoch: 20     train index of 5 minibatch: 2      time used: 1.491680383682251\n","minibatch AVG loss: 5.118924236739986e-05\n","Epoch: 20     train index of 5 minibatch: 3      time used: 1.4924345016479492\n","minibatch AVG loss: 5.0385756640025645e-05\n","\n","Epoch: 20  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 20  val \n","Loss: 0.0004  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 5 minibatch: 1      time used: 1.7221930027008057\n","minibatch AVG loss: 1.2492647692852188e-05\n","Epoch: 21     train index of 5 minibatch: 2      time used: 1.4931058883666992\n","minibatch AVG loss: 3.594247050386912e-05\n","Epoch: 21     train index of 5 minibatch: 3      time used: 1.4928820133209229\n","minibatch AVG loss: 1.3535860762203811e-05\n","\n","Epoch: 21  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 21  val \n","Loss: 0.0004  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 5 minibatch: 1      time used: 1.7193994522094727\n","minibatch AVG loss: 5.698631903214846e-05\n","Epoch: 22     train index of 5 minibatch: 2      time used: 1.493992567062378\n","minibatch AVG loss: 1.112160996399325e-05\n","Epoch: 22     train index of 5 minibatch: 3      time used: 1.49381685256958\n","minibatch AVG loss: 2.7387022601033096e-05\n","\n","Epoch: 22  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 22  val \n","Loss: 0.0004  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 5 minibatch: 1      time used: 1.720627784729004\n","minibatch AVG loss: 4.342453125900647e-05\n","Epoch: 23     train index of 5 minibatch: 2      time used: 1.4972436428070068\n","minibatch AVG loss: 7.963095777085983e-06\n","Epoch: 23     train index of 5 minibatch: 3      time used: 1.4917316436767578\n","minibatch AVG loss: 0.00030892205231793925\n","\n","Epoch: 23  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 23  val \n","Loss: 0.0004  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 5 minibatch: 1      time used: 1.7115178108215332\n","minibatch AVG loss: 3.359458801241999e-05\n","Epoch: 24     train index of 5 minibatch: 2      time used: 1.493438482284546\n","minibatch AVG loss: 3.553325441316701e-05\n","Epoch: 24     train index of 5 minibatch: 3      time used: 1.4925110340118408\n","minibatch AVG loss: 0.0057438449757682974\n","\n","Epoch: 24  train \n","Loss: 0.0017  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 24  val \n","Loss: 0.0007  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 5 minibatch: 1      time used: 1.7232825756072998\n","minibatch AVG loss: 2.0032244015055768e-05\n","Epoch: 25     train index of 5 minibatch: 2      time used: 1.492619276046753\n","minibatch AVG loss: 3.137069479635102e-05\n","Epoch: 25     train index of 5 minibatch: 3      time used: 1.4931330680847168\n","minibatch AVG loss: 0.00024571751605435567\n","\n","Epoch: 25  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 25  val \n","Loss: 0.0013  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 5 minibatch: 1      time used: 1.7151248455047607\n","minibatch AVG loss: 2.505637230569846e-05\n","Epoch: 26     train index of 5 minibatch: 2      time used: 1.4944067001342773\n","minibatch AVG loss: 2.277946409776632e-05\n","Epoch: 26     train index of 5 minibatch: 3      time used: 1.4946165084838867\n","minibatch AVG loss: 5.242282550170785e-05\n","\n","Epoch: 26  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 26  val \n","Loss: 0.0013  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 5 minibatch: 1      time used: 1.7293899059295654\n","minibatch AVG loss: 5.2528259402606636e-05\n","Epoch: 27     train index of 5 minibatch: 2      time used: 1.4937045574188232\n","minibatch AVG loss: 1.1336589000165987e-05\n","Epoch: 27     train index of 5 minibatch: 3      time used: 1.492729902267456\n","minibatch AVG loss: 2.1032979657320538e-05\n","\n","Epoch: 27  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 27  val \n","Loss: 0.0011  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 5 minibatch: 1      time used: 1.7186543941497803\n","minibatch AVG loss: 1.3160324897398823e-05\n","Epoch: 28     train index of 5 minibatch: 2      time used: 1.4922034740447998\n","minibatch AVG loss: 8.662247305437631e-05\n","Epoch: 28     train index of 5 minibatch: 3      time used: 1.4932096004486084\n","minibatch AVG loss: 4.5780664504491145e-05\n","\n","Epoch: 28  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 28  val \n","Loss: 0.0011  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 5 minibatch: 1      time used: 1.7231345176696777\n","minibatch AVG loss: 4.4573838022188286e-05\n","Epoch: 29     train index of 5 minibatch: 2      time used: 1.4936652183532715\n","minibatch AVG loss: 0.00010943280231003882\n","Epoch: 29     train index of 5 minibatch: 3      time used: 1.4936811923980713\n","minibatch AVG loss: 7.14049447196885e-06\n","\n","Epoch: 29  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 29  val \n","Loss: 0.0010  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 5 minibatch: 1      time used: 1.7215816974639893\n","minibatch AVG loss: 3.8650385886285224e-05\n","Epoch: 30     train index of 5 minibatch: 2      time used: 1.4939329624176025\n","minibatch AVG loss: 5.7630145420262124e-05\n","Epoch: 30     train index of 5 minibatch: 3      time used: 1.4924561977386475\n","minibatch AVG loss: 4.3717125981856954e-05\n","\n","Epoch: 30  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 30  val \n","Loss: 0.0009  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 5 minibatch: 1      time used: 1.7149689197540283\n","minibatch AVG loss: 3.424926062507438e-05\n","Epoch: 31     train index of 5 minibatch: 2      time used: 1.4942059516906738\n","minibatch AVG loss: 1.4738987169948814e-05\n","Epoch: 31     train index of 5 minibatch: 3      time used: 1.49212646484375\n","minibatch AVG loss: 0.00026897891825683473\n","\n","Epoch: 31  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 31  val \n","Loss: 0.0009  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 5 minibatch: 1      time used: 1.7161931991577148\n","minibatch AVG loss: 0.00014430130449909483\n","Epoch: 32     train index of 5 minibatch: 2      time used: 1.4954619407653809\n","minibatch AVG loss: 1.0347041097702459e-05\n","Epoch: 32     train index of 5 minibatch: 3      time used: 1.4942748546600342\n","minibatch AVG loss: 9.852117573245777e-05\n","\n","Epoch: 32  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 32  val \n","Loss: 0.0008  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 5 minibatch: 1      time used: 1.7202470302581787\n","minibatch AVG loss: 5.829286192238215e-06\n","Epoch: 33     train index of 5 minibatch: 2      time used: 1.4932146072387695\n","minibatch AVG loss: 1.4620638648921157e-05\n","Epoch: 33     train index of 5 minibatch: 3      time used: 1.4912371635437012\n","minibatch AVG loss: 5.144174756424036e-05\n","\n","Epoch: 33  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 33  val \n","Loss: 0.0007  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 5 minibatch: 1      time used: 1.7135679721832275\n","minibatch AVG loss: 1.7099791239161278e-05\n","Epoch: 34     train index of 5 minibatch: 2      time used: 1.4936485290527344\n","minibatch AVG loss: 1.1831306301246513e-05\n","Epoch: 34     train index of 5 minibatch: 3      time used: 1.4940552711486816\n","minibatch AVG loss: 3.137920898552693e-05\n","\n","Epoch: 34  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 34  val \n","Loss: 0.0007  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 5 minibatch: 1      time used: 1.7218806743621826\n","minibatch AVG loss: 2.8768672336809686e-05\n","Epoch: 35     train index of 5 minibatch: 2      time used: 1.49275803565979\n","minibatch AVG loss: 8.989927564471146e-05\n","Epoch: 35     train index of 5 minibatch: 3      time used: 1.4929702281951904\n","minibatch AVG loss: 0.00011443243975008954\n","\n","Epoch: 35  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 35  val \n","Loss: 0.0007  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 5 minibatch: 1      time used: 1.7232980728149414\n","minibatch AVG loss: 2.6403374067740516e-05\n","Epoch: 36     train index of 5 minibatch: 2      time used: 1.4930329322814941\n","minibatch AVG loss: 2.4499604433003696e-05\n","Epoch: 36     train index of 5 minibatch: 3      time used: 1.493067979812622\n","minibatch AVG loss: 3.863313299916627e-05\n","\n","Epoch: 36  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 36  val \n","Loss: 0.0007  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 5 minibatch: 1      time used: 1.7260992527008057\n","minibatch AVG loss: 9.524628603685415e-06\n","Epoch: 37     train index of 5 minibatch: 2      time used: 1.49314284324646\n","minibatch AVG loss: 8.46515746161458e-05\n","Epoch: 37     train index of 5 minibatch: 3      time used: 1.4939959049224854\n","minibatch AVG loss: 3.406946439099556e-05\n","\n","Epoch: 37  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 37  val \n","Loss: 0.0007  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 5 minibatch: 1      time used: 1.7236571311950684\n","minibatch AVG loss: 1.6605317614448723e-05\n","Epoch: 38     train index of 5 minibatch: 2      time used: 1.4933013916015625\n","minibatch AVG loss: 2.5276978794863682e-05\n","Epoch: 38     train index of 5 minibatch: 3      time used: 1.493013620376587\n","minibatch AVG loss: 5.886353119421983e-05\n","\n","Epoch: 38  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 38  val \n","Loss: 0.0007  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 5 minibatch: 1      time used: 1.7283153533935547\n","minibatch AVG loss: 1.3309146925166716e-05\n","Epoch: 39     train index of 5 minibatch: 2      time used: 1.492849349975586\n","minibatch AVG loss: 1.8739040569926146e-05\n","Epoch: 39     train index of 5 minibatch: 3      time used: 1.4925546646118164\n","minibatch AVG loss: 4.403734369589074e-05\n","\n","Epoch: 39  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 39  val \n","Loss: 0.0007  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 5 minibatch: 1      time used: 1.722062110900879\n","minibatch AVG loss: 4.164622887401492e-05\n","Epoch: 40     train index of 5 minibatch: 2      time used: 1.493760585784912\n","minibatch AVG loss: 3.179038967573433e-05\n","Epoch: 40     train index of 5 minibatch: 3      time used: 1.4927234649658203\n","minibatch AVG loss: 9.375655099574943e-06\n","\n","Epoch: 40  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 40  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 5 minibatch: 1      time used: 1.7224652767181396\n","minibatch AVG loss: 9.554453458804347e-06\n","Epoch: 41     train index of 5 minibatch: 2      time used: 1.493727445602417\n","minibatch AVG loss: 0.00022598971572733716\n","Epoch: 41     train index of 5 minibatch: 3      time used: 1.4940805435180664\n","minibatch AVG loss: 2.162936318654829e-05\n","\n","Epoch: 41  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 41  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 5 minibatch: 1      time used: 1.7205328941345215\n","minibatch AVG loss: 4.6416804934779066e-05\n","Epoch: 42     train index of 5 minibatch: 2      time used: 1.4921596050262451\n","minibatch AVG loss: 1.4673999964998075e-05\n","Epoch: 42     train index of 5 minibatch: 3      time used: 1.4933667182922363\n","minibatch AVG loss: 1.5568195794912754e-05\n","\n","Epoch: 42  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 42  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 5 minibatch: 1      time used: 1.71742844581604\n","minibatch AVG loss: 1.3863766980648506e-05\n","Epoch: 43     train index of 5 minibatch: 2      time used: 1.4935312271118164\n","minibatch AVG loss: 0.00012513443039097183\n","Epoch: 43     train index of 5 minibatch: 3      time used: 1.4920532703399658\n","minibatch AVG loss: 2.2391431048163214e-05\n","\n","Epoch: 43  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 43  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 5 minibatch: 1      time used: 1.7277116775512695\n","minibatch AVG loss: 2.9024785681031064e-05\n","Epoch: 44     train index of 5 minibatch: 2      time used: 1.492136001586914\n","minibatch AVG loss: 0.00012037579163006739\n","Epoch: 44     train index of 5 minibatch: 3      time used: 1.4931414127349854\n","minibatch AVG loss: 8.165768122125883e-06\n","\n","Epoch: 44  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 44  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 5 minibatch: 1      time used: 1.7181494235992432\n","minibatch AVG loss: 7.339580272400781e-05\n","Epoch: 45     train index of 5 minibatch: 2      time used: 1.4922399520874023\n","minibatch AVG loss: 4.252490348335414e-05\n","Epoch: 45     train index of 5 minibatch: 3      time used: 1.4930343627929688\n","minibatch AVG loss: 0.00011334298051224323\n","\n","Epoch: 45  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 45  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 5 minibatch: 1      time used: 1.7219128608703613\n","minibatch AVG loss: 3.0299986758564045e-05\n","Epoch: 46     train index of 5 minibatch: 2      time used: 1.495798110961914\n","minibatch AVG loss: 6.111051877724094e-05\n","Epoch: 46     train index of 5 minibatch: 3      time used: 1.4937388896942139\n","minibatch AVG loss: 3.544513001543237e-05\n","\n","Epoch: 46  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 46  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 5 minibatch: 1      time used: 1.717684030532837\n","minibatch AVG loss: 3.016433088305348e-05\n","Epoch: 47     train index of 5 minibatch: 2      time used: 1.4957749843597412\n","minibatch AVG loss: 3.879812802551896e-05\n","Epoch: 47     train index of 5 minibatch: 3      time used: 1.4923722743988037\n","minibatch AVG loss: 4.3736558291129767e-05\n","\n","Epoch: 47  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 47  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 5 minibatch: 1      time used: 1.715343952178955\n","minibatch AVG loss: 7.209557197711547e-05\n","Epoch: 48     train index of 5 minibatch: 2      time used: 1.493539810180664\n","minibatch AVG loss: 1.851863198680803e-05\n","Epoch: 48     train index of 5 minibatch: 3      time used: 1.4938888549804688\n","minibatch AVG loss: 1.6372717391277546e-05\n","\n","Epoch: 48  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 48  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 5 minibatch: 1      time used: 1.724013328552246\n","minibatch AVG loss: 0.0003081092763750348\n","Epoch: 49     train index of 5 minibatch: 2      time used: 1.4919846057891846\n","minibatch AVG loss: 6.131414902483811e-05\n","Epoch: 49     train index of 5 minibatch: 3      time used: 1.4926362037658691\n","minibatch AVG loss: 3.0162635766828316e-05\n","\n","Epoch: 49  train \n","Loss: 0.0001  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 49  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 5 minibatch: 1      time used: 1.7161564826965332\n","minibatch AVG loss: 1.6140215757332042e-05\n","Epoch: 50     train index of 5 minibatch: 2      time used: 1.4946961402893066\n","minibatch AVG loss: 3.593302735680481e-05\n","Epoch: 50     train index of 5 minibatch: 3      time used: 1.4942448139190674\n","minibatch AVG loss: 1.6986783975880826e-05\n","\n","Epoch: 50  train \n","Loss: 0.0000  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 50  val \n","Loss: 0.0006  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Training complete in 5m 2s\n","Best epoch idx:  50\n","Best epoch train Acc: 100.000000\n","Best epoch val Acc: 100.000000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","model trained by GPU (idx:0) has been saved at  /home/MIL_Experiment/saved_models/PC_ViT_384_401_PT_lf05_b4_warwick_CLS.pth\n"]}],"source":["!python Train.py --model_idx ViT_384_401_PT_lf05_b4_warwick_CLS --edge_size 384 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2FSe1lRILyYK","outputId":"1e2b2928-d9d4-4a1d-b0fb-53e1ebc7efaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, att_module='SimAM', attn_drop_rate=0.0, backbone_PT_off=False, batch_size=4, check_minibatch=5, cls_token_off=False, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=False, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=-1, intake_epochs=0, lr=1e-05, lrf=0.05, model_idx='ResNet50_384_401_PT_lf05_b4_warwick_CLS', model_path='/home/MIL_Experiment/saved_models', num_classes=2, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, pos_embedding_off=False)\n","we dont have more GPU idx here, try to use gpu_idx=0\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100% 97.8M/97.8M [00:01<00:00, 57.5MB/s]\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[0.3661, 0.3364]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 192, 192]           9,408\n","       BatchNorm2d-2         [-1, 64, 192, 192]             128\n","              ReLU-3         [-1, 64, 192, 192]               0\n","         MaxPool2d-4           [-1, 64, 96, 96]               0\n","            Conv2d-5           [-1, 64, 96, 96]           4,096\n","       BatchNorm2d-6           [-1, 64, 96, 96]             128\n","              ReLU-7           [-1, 64, 96, 96]               0\n","            Conv2d-8           [-1, 64, 96, 96]          36,864\n","       BatchNorm2d-9           [-1, 64, 96, 96]             128\n","             ReLU-10           [-1, 64, 96, 96]               0\n","           Conv2d-11          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-12          [-1, 256, 96, 96]             512\n","           Conv2d-13          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-14          [-1, 256, 96, 96]             512\n","             ReLU-15          [-1, 256, 96, 96]               0\n","       Bottleneck-16          [-1, 256, 96, 96]               0\n","           Conv2d-17           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-18           [-1, 64, 96, 96]             128\n","             ReLU-19           [-1, 64, 96, 96]               0\n","           Conv2d-20           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-21           [-1, 64, 96, 96]             128\n","             ReLU-22           [-1, 64, 96, 96]               0\n","           Conv2d-23          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-24          [-1, 256, 96, 96]             512\n","             ReLU-25          [-1, 256, 96, 96]               0\n","       Bottleneck-26          [-1, 256, 96, 96]               0\n","           Conv2d-27           [-1, 64, 96, 96]          16,384\n","      BatchNorm2d-28           [-1, 64, 96, 96]             128\n","             ReLU-29           [-1, 64, 96, 96]               0\n","           Conv2d-30           [-1, 64, 96, 96]          36,864\n","      BatchNorm2d-31           [-1, 64, 96, 96]             128\n","             ReLU-32           [-1, 64, 96, 96]               0\n","           Conv2d-33          [-1, 256, 96, 96]          16,384\n","      BatchNorm2d-34          [-1, 256, 96, 96]             512\n","             ReLU-35          [-1, 256, 96, 96]               0\n","       Bottleneck-36          [-1, 256, 96, 96]               0\n","           Conv2d-37          [-1, 128, 96, 96]          32,768\n","      BatchNorm2d-38          [-1, 128, 96, 96]             256\n","             ReLU-39          [-1, 128, 96, 96]               0\n","           Conv2d-40          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-41          [-1, 128, 48, 48]             256\n","             ReLU-42          [-1, 128, 48, 48]               0\n","           Conv2d-43          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-44          [-1, 512, 48, 48]           1,024\n","           Conv2d-45          [-1, 512, 48, 48]         131,072\n","      BatchNorm2d-46          [-1, 512, 48, 48]           1,024\n","             ReLU-47          [-1, 512, 48, 48]               0\n","       Bottleneck-48          [-1, 512, 48, 48]               0\n","           Conv2d-49          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-50          [-1, 128, 48, 48]             256\n","             ReLU-51          [-1, 128, 48, 48]               0\n","           Conv2d-52          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-53          [-1, 128, 48, 48]             256\n","             ReLU-54          [-1, 128, 48, 48]               0\n","           Conv2d-55          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-56          [-1, 512, 48, 48]           1,024\n","             ReLU-57          [-1, 512, 48, 48]               0\n","       Bottleneck-58          [-1, 512, 48, 48]               0\n","           Conv2d-59          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-60          [-1, 128, 48, 48]             256\n","             ReLU-61          [-1, 128, 48, 48]               0\n","           Conv2d-62          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-63          [-1, 128, 48, 48]             256\n","             ReLU-64          [-1, 128, 48, 48]               0\n","           Conv2d-65          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-66          [-1, 512, 48, 48]           1,024\n","             ReLU-67          [-1, 512, 48, 48]               0\n","       Bottleneck-68          [-1, 512, 48, 48]               0\n","           Conv2d-69          [-1, 128, 48, 48]          65,536\n","      BatchNorm2d-70          [-1, 128, 48, 48]             256\n","             ReLU-71          [-1, 128, 48, 48]               0\n","           Conv2d-72          [-1, 128, 48, 48]         147,456\n","      BatchNorm2d-73          [-1, 128, 48, 48]             256\n","             ReLU-74          [-1, 128, 48, 48]               0\n","           Conv2d-75          [-1, 512, 48, 48]          65,536\n","      BatchNorm2d-76          [-1, 512, 48, 48]           1,024\n","             ReLU-77          [-1, 512, 48, 48]               0\n","       Bottleneck-78          [-1, 512, 48, 48]               0\n","           Conv2d-79          [-1, 256, 48, 48]         131,072\n","      BatchNorm2d-80          [-1, 256, 48, 48]             512\n","             ReLU-81          [-1, 256, 48, 48]               0\n","           Conv2d-82          [-1, 256, 24, 24]         589,824\n","      BatchNorm2d-83          [-1, 256, 24, 24]             512\n","             ReLU-84          [-1, 256, 24, 24]               0\n","           Conv2d-85         [-1, 1024, 24, 24]         262,144\n","      BatchNorm2d-86         [-1, 1024, 24, 24]           2,048\n","           Conv2d-87         [-1, 1024, 24, 24]         524,288\n","      BatchNorm2d-88         [-1, 1024, 24, 24]           2,048\n","             ReLU-89         [-1, 1024, 24, 24]               0\n","       Bottleneck-90         [-1, 1024, 24, 24]               0\n","           Conv2d-91          [-1, 256, 24, 24]         262,144\n","      BatchNorm2d-92          [-1, 256, 24, 24]             512\n","             ReLU-93          [-1, 256, 24, 24]               0\n","           Conv2d-94          [-1, 256, 24, 24]         589,824\n","      BatchNorm2d-95          [-1, 256, 24, 24]             512\n","             ReLU-96          [-1, 256, 24, 24]               0\n","           Conv2d-97         [-1, 1024, 24, 24]         262,144\n","      BatchNorm2d-98         [-1, 1024, 24, 24]           2,048\n","             ReLU-99         [-1, 1024, 24, 24]               0\n","      Bottleneck-100         [-1, 1024, 24, 24]               0\n","          Conv2d-101          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-102          [-1, 256, 24, 24]             512\n","            ReLU-103          [-1, 256, 24, 24]               0\n","          Conv2d-104          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-105          [-1, 256, 24, 24]             512\n","            ReLU-106          [-1, 256, 24, 24]               0\n","          Conv2d-107         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-108         [-1, 1024, 24, 24]           2,048\n","            ReLU-109         [-1, 1024, 24, 24]               0\n","      Bottleneck-110         [-1, 1024, 24, 24]               0\n","          Conv2d-111          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-112          [-1, 256, 24, 24]             512\n","            ReLU-113          [-1, 256, 24, 24]               0\n","          Conv2d-114          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-115          [-1, 256, 24, 24]             512\n","            ReLU-116          [-1, 256, 24, 24]               0\n","          Conv2d-117         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-118         [-1, 1024, 24, 24]           2,048\n","            ReLU-119         [-1, 1024, 24, 24]               0\n","      Bottleneck-120         [-1, 1024, 24, 24]               0\n","          Conv2d-121          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-122          [-1, 256, 24, 24]             512\n","            ReLU-123          [-1, 256, 24, 24]               0\n","          Conv2d-124          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-125          [-1, 256, 24, 24]             512\n","            ReLU-126          [-1, 256, 24, 24]               0\n","          Conv2d-127         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-128         [-1, 1024, 24, 24]           2,048\n","            ReLU-129         [-1, 1024, 24, 24]               0\n","      Bottleneck-130         [-1, 1024, 24, 24]               0\n","          Conv2d-131          [-1, 256, 24, 24]         262,144\n","     BatchNorm2d-132          [-1, 256, 24, 24]             512\n","            ReLU-133          [-1, 256, 24, 24]               0\n","          Conv2d-134          [-1, 256, 24, 24]         589,824\n","     BatchNorm2d-135          [-1, 256, 24, 24]             512\n","            ReLU-136          [-1, 256, 24, 24]               0\n","          Conv2d-137         [-1, 1024, 24, 24]         262,144\n","     BatchNorm2d-138         [-1, 1024, 24, 24]           2,048\n","            ReLU-139         [-1, 1024, 24, 24]               0\n","      Bottleneck-140         [-1, 1024, 24, 24]               0\n","          Conv2d-141          [-1, 512, 24, 24]         524,288\n","     BatchNorm2d-142          [-1, 512, 24, 24]           1,024\n","            ReLU-143          [-1, 512, 24, 24]               0\n","          Conv2d-144          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-145          [-1, 512, 12, 12]           1,024\n","            ReLU-146          [-1, 512, 12, 12]               0\n","          Conv2d-147         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-148         [-1, 2048, 12, 12]           4,096\n","          Conv2d-149         [-1, 2048, 12, 12]       2,097,152\n","     BatchNorm2d-150         [-1, 2048, 12, 12]           4,096\n","            ReLU-151         [-1, 2048, 12, 12]               0\n","      Bottleneck-152         [-1, 2048, 12, 12]               0\n","          Conv2d-153          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-154          [-1, 512, 12, 12]           1,024\n","            ReLU-155          [-1, 512, 12, 12]               0\n","          Conv2d-156          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-157          [-1, 512, 12, 12]           1,024\n","            ReLU-158          [-1, 512, 12, 12]               0\n","          Conv2d-159         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-160         [-1, 2048, 12, 12]           4,096\n","            ReLU-161         [-1, 2048, 12, 12]               0\n","      Bottleneck-162         [-1, 2048, 12, 12]               0\n","          Conv2d-163          [-1, 512, 12, 12]       1,048,576\n","     BatchNorm2d-164          [-1, 512, 12, 12]           1,024\n","            ReLU-165          [-1, 512, 12, 12]               0\n","          Conv2d-166          [-1, 512, 12, 12]       2,359,296\n","     BatchNorm2d-167          [-1, 512, 12, 12]           1,024\n","            ReLU-168          [-1, 512, 12, 12]               0\n","          Conv2d-169         [-1, 2048, 12, 12]       1,048,576\n","     BatchNorm2d-170         [-1, 2048, 12, 12]           4,096\n","            ReLU-171         [-1, 2048, 12, 12]               0\n","      Bottleneck-172         [-1, 2048, 12, 12]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                    [-1, 2]           4,098\n","================================================================\n","Total params: 23,512,130\n","Trainable params: 23,512,130\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 842.08\n","Params size (MB): 89.69\n","Estimated Total Size (MB): 933.46\n","----------------------------------------------------------------\n","model : ResNet50_384_401_PT_lf05_b4_warwick_CLS\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 5 minibatch: 1      time used: 0.8006305694580078\n","minibatch AVG loss: 0.678871750831604\n","Epoch: 1     train index of 5 minibatch: 2      time used: 0.5414514541625977\n","minibatch AVG loss: 0.6797195553779602\n","Epoch: 1     train index of 5 minibatch: 3      time used: 0.54183030128479\n","minibatch AVG loss: 0.638395369052887\n","\n","Epoch: 1  train \n","Loss: 0.6657  Acc: 59.4203\n","negative precision: 52.0833  recall: 83.3333\n","negative sensitivity: 83.3333  specificity: 41.0256\n","negative FPR: 58.9744  NPV: 76.1905\n","negative TP: 25.0\n","negative TN: 16.0\n","negative FP: 23.0\n","negative FN: 5.0\n","positive precision: 76.1905  recall: 41.0256\n","positive sensitivity: 41.0256  specificity: 83.3333\n","positive FPR: 16.6667  NPV: 52.0833\n","positive TP: 16.0\n","positive TN: 25.0\n","positive FP: 5.0\n","positive FN: 23.0\n","\n","\n","\n","Epoch: 1  val \n","Loss: 0.5924  Acc: 81.2500\n","negative precision: 83.3333  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 80.0000\n","negative TP: 5.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 2.0\n","positive precision: 80.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 83.3333\n","positive TP: 8.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 5 minibatch: 1      time used: 0.7737720012664795\n","minibatch AVG loss: 0.6135523557662964\n","Epoch: 2     train index of 5 minibatch: 2      time used: 0.5409436225891113\n","minibatch AVG loss: 0.5333118081092835\n","Epoch: 2     train index of 5 minibatch: 3      time used: 0.542320966720581\n","minibatch AVG loss: 0.5377529799938202\n","\n","Epoch: 2  train \n","Loss: 0.5505  Acc: 88.4058\n","negative precision: 86.6667  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 89.7436\n","negative TP: 26.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 4.0\n","positive precision: 89.7436  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 86.6667\n","positive TP: 35.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 2  val \n","Loss: 0.5111  Acc: 75.0000\n","negative precision: 80.0000  recall: 57.1429\n","negative sensitivity: 57.1429  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 72.7273\n","negative TP: 4.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 3.0\n","positive precision: 72.7273  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 57.1429\n","positive FPR: 42.8571  NPV: 80.0000\n","positive TP: 8.0\n","positive TN: 4.0\n","positive FP: 3.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 5 minibatch: 1      time used: 0.7631938457489014\n","minibatch AVG loss: 0.4879451751708984\n","Epoch: 3     train index of 5 minibatch: 2      time used: 0.5417859554290771\n","minibatch AVG loss: 0.5291600465774536\n","Epoch: 3     train index of 5 minibatch: 3      time used: 0.5432920455932617\n","minibatch AVG loss: 0.6186110734939575\n","\n","Epoch: 3  train \n","Loss: 0.5316  Acc: 76.8116\n","negative precision: 76.9231  recall: 66.6667\n","negative sensitivity: 66.6667  specificity: 84.6154\n","negative FPR: 15.3846  NPV: 76.7442\n","negative TP: 20.0\n","negative TN: 33.0\n","negative FP: 6.0\n","negative FN: 10.0\n","positive precision: 76.7442  recall: 84.6154\n","positive sensitivity: 84.6154  specificity: 66.6667\n","positive FPR: 33.3333  NPV: 76.9231\n","positive TP: 33.0\n","positive TN: 20.0\n","positive FP: 10.0\n","positive FN: 6.0\n","\n","\n","\n","Epoch: 3  val \n","Loss: 0.3961  Acc: 81.2500\n","negative precision: 100.0000  recall: 57.1429\n","negative sensitivity: 57.1429  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 75.0000\n","negative TP: 4.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 3.0\n","positive precision: 75.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 57.1429\n","positive FPR: 42.8571  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 4.0\n","positive FP: 3.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 5 minibatch: 1      time used: 0.7745153903961182\n","minibatch AVG loss: 0.3688189685344696\n","Epoch: 4     train index of 5 minibatch: 2      time used: 0.5427043437957764\n","minibatch AVG loss: 0.363959801197052\n","Epoch: 4     train index of 5 minibatch: 3      time used: 0.5409743785858154\n","minibatch AVG loss: 0.5221618831157684\n","\n","Epoch: 4  train \n","Loss: 0.4030  Acc: 88.4058\n","negative precision: 92.3077  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 86.0465\n","negative TP: 24.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 6.0\n","positive precision: 86.0465  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 92.3077\n","positive TP: 37.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 4  val \n","Loss: 0.2969  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 5 minibatch: 1      time used: 0.7614057064056396\n","minibatch AVG loss: 0.35783236026763915\n","Epoch: 5     train index of 5 minibatch: 2      time used: 0.5414309501647949\n","minibatch AVG loss: 0.3087993174791336\n","Epoch: 5     train index of 5 minibatch: 3      time used: 0.5444850921630859\n","minibatch AVG loss: 0.3183931678533554\n","\n","Epoch: 5  train \n","Loss: 0.3256  Acc: 92.7536\n","negative precision: 93.1034  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 92.5000\n","negative TP: 27.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 3.0\n","positive precision: 92.5000  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 93.1034\n","positive TP: 37.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 5  val \n","Loss: 0.2410  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 5 minibatch: 1      time used: 0.7776384353637695\n","minibatch AVG loss: 0.1856746107339859\n","Epoch: 6     train index of 5 minibatch: 2      time used: 0.5427060127258301\n","minibatch AVG loss: 0.27682957947254183\n","Epoch: 6     train index of 5 minibatch: 3      time used: 0.5420100688934326\n","minibatch AVG loss: 0.24757375419139863\n","\n","Epoch: 6  train \n","Loss: 0.2518  Acc: 92.7536\n","negative precision: 93.1034  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 92.5000\n","negative TP: 27.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 3.0\n","positive precision: 92.5000  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 93.1034\n","positive TP: 37.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 6  val \n","Loss: 0.1795  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 5 minibatch: 1      time used: 0.7756514549255371\n","minibatch AVG loss: 0.43675456047058103\n","Epoch: 7     train index of 5 minibatch: 2      time used: 0.5426137447357178\n","minibatch AVG loss: 0.3306456446647644\n","Epoch: 7     train index of 5 minibatch: 3      time used: 0.5434629917144775\n","minibatch AVG loss: 0.37937747985124587\n","\n","Epoch: 7  train \n","Loss: 0.3687  Acc: 85.5072\n","negative precision: 88.4615  recall: 76.6667\n","negative sensitivity: 76.6667  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 83.7209\n","negative TP: 23.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 7.0\n","positive precision: 83.7209  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 76.6667\n","positive FPR: 23.3333  NPV: 88.4615\n","positive TP: 36.0\n","positive TN: 23.0\n","positive FP: 7.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 7  val \n","Loss: 0.1481  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 5 minibatch: 1      time used: 0.7815253734588623\n","minibatch AVG loss: 0.2437174215912819\n","Epoch: 8     train index of 5 minibatch: 2      time used: 0.542273998260498\n","minibatch AVG loss: 0.2516526699066162\n","Epoch: 8     train index of 5 minibatch: 3      time used: 0.5429365634918213\n","minibatch AVG loss: 0.17114905267953873\n","\n","Epoch: 8  train \n","Loss: 0.2105  Acc: 95.6522\n","negative precision: 93.5484  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 97.3684\n","negative TP: 29.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 1.0\n","positive precision: 97.3684  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 93.5484\n","positive TP: 37.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 8  val \n","Loss: 0.1188  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 5 minibatch: 1      time used: 0.7753689289093018\n","minibatch AVG loss: 0.2226440578699112\n","Epoch: 9     train index of 5 minibatch: 2      time used: 0.5466616153717041\n","minibatch AVG loss: 0.25767695605754853\n","Epoch: 9     train index of 5 minibatch: 3      time used: 0.543210506439209\n","minibatch AVG loss: 0.2395440511405468\n","\n","Epoch: 9  train \n","Loss: 0.2235  Acc: 92.7536\n","negative precision: 87.8788  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 97.2222\n","negative TP: 29.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 1.0\n","positive precision: 97.2222  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 87.8788\n","positive TP: 35.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 9  val \n","Loss: 0.1093  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 5 minibatch: 1      time used: 0.7753362655639648\n","minibatch AVG loss: 0.2252091236412525\n","Epoch: 10     train index of 5 minibatch: 2      time used: 0.5399990081787109\n","minibatch AVG loss: 0.17291495725512504\n","Epoch: 10     train index of 5 minibatch: 3      time used: 0.5433182716369629\n","minibatch AVG loss: 0.16176528260111808\n","\n","Epoch: 10  train \n","Loss: 0.1820  Acc: 94.2029\n","negative precision: 96.4286  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 92.6829\n","negative TP: 27.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 3.0\n","positive precision: 92.6829  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 96.4286\n","positive TP: 38.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 10  val \n","Loss: 0.1121  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 5 minibatch: 1      time used: 0.7729012966156006\n","minibatch AVG loss: 0.10575220435857773\n","Epoch: 11     train index of 5 minibatch: 2      time used: 0.5414729118347168\n","minibatch AVG loss: 0.19097862094640733\n","Epoch: 11     train index of 5 minibatch: 3      time used: 0.5421268939971924\n","minibatch AVG loss: 0.18235779255628587\n","\n","Epoch: 11  train \n","Loss: 0.1747  Acc: 91.3043\n","negative precision: 87.5000  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 94.5946\n","negative TP: 28.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 2.0\n","positive precision: 94.5946  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 87.5000\n","positive TP: 35.0\n","positive TN: 28.0\n","positive FP: 2.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 11  val \n","Loss: 0.0932  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 5 minibatch: 1      time used: 0.7877767086029053\n","minibatch AVG loss: 0.5224771872162819\n","Epoch: 12     train index of 5 minibatch: 2      time used: 0.5408611297607422\n","minibatch AVG loss: 0.2743344396352768\n","Epoch: 12     train index of 5 minibatch: 3      time used: 0.5404119491577148\n","minibatch AVG loss: 0.33991946578025817\n","\n","Epoch: 12  train \n","Loss: 0.3775  Acc: 82.6087\n","negative precision: 80.0000  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 84.6154\n","negative FPR: 15.3846  NPV: 84.6154\n","negative TP: 24.0\n","negative TN: 33.0\n","negative FP: 6.0\n","negative FN: 6.0\n","positive precision: 84.6154  recall: 84.6154\n","positive sensitivity: 84.6154  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 80.0000\n","positive TP: 33.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 6.0\n","\n","\n","\n","Epoch: 12  val \n","Loss: 0.0844  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 5 minibatch: 1      time used: 0.7856225967407227\n","minibatch AVG loss: 0.21817764043807983\n","Epoch: 13     train index of 5 minibatch: 2      time used: 0.5462296009063721\n","minibatch AVG loss: 0.19874792844057082\n","Epoch: 13     train index of 5 minibatch: 3      time used: 0.5425338745117188\n","minibatch AVG loss: 0.09224961772561073\n","\n","Epoch: 13  train \n","Loss: 0.1598  Acc: 97.1014\n","negative precision: 96.6667  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 97.4359\n","negative TP: 29.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 1.0\n","positive precision: 97.4359  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 96.6667\n","positive TP: 38.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 13  val \n","Loss: 0.0699  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 5 minibatch: 1      time used: 0.7657620906829834\n","minibatch AVG loss: 0.20182794481515884\n","Epoch: 14     train index of 5 minibatch: 2      time used: 0.5418267250061035\n","minibatch AVG loss: 0.06887316554784775\n","Epoch: 14     train index of 5 minibatch: 3      time used: 0.5410652160644531\n","minibatch AVG loss: 0.08405537605285644\n","\n","Epoch: 14  train \n","Loss: 0.1912  Acc: 94.2029\n","negative precision: 93.3333  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 94.8718\n","negative TP: 28.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 2.0\n","positive precision: 94.8718  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 93.3333\n","positive TP: 37.0\n","positive TN: 28.0\n","positive FP: 2.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 14  val \n","Loss: 0.0749  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 5 minibatch: 1      time used: 0.7760131359100342\n","minibatch AVG loss: 0.13778656274080275\n","Epoch: 15     train index of 5 minibatch: 2      time used: 0.539621114730835\n","minibatch AVG loss: 0.42362453080713747\n","Epoch: 15     train index of 5 minibatch: 3      time used: 0.5430517196655273\n","minibatch AVG loss: 0.2873504884541035\n","\n","Epoch: 15  train \n","Loss: 0.2679  Acc: 91.3043\n","negative precision: 92.8571  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 90.2439\n","negative TP: 26.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 4.0\n","positive precision: 90.2439  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 92.8571\n","positive TP: 37.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 15  val \n","Loss: 0.0625  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 5 minibatch: 1      time used: 0.7887992858886719\n","minibatch AVG loss: 0.05561714433133602\n","Epoch: 16     train index of 5 minibatch: 2      time used: 0.5415101051330566\n","minibatch AVG loss: 0.08718106970191002\n","Epoch: 16     train index of 5 minibatch: 3      time used: 0.540581464767456\n","minibatch AVG loss: 0.06983816027641296\n","\n","Epoch: 16  train \n","Loss: 0.0801  Acc: 98.5507\n","negative precision: 100.0000  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 97.5000\n","negative TP: 29.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 97.5000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 16  val \n","Loss: 0.0654  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 5 minibatch: 1      time used: 0.7702081203460693\n","minibatch AVG loss: 0.3355641011148691\n","Epoch: 17     train index of 5 minibatch: 2      time used: 0.5468597412109375\n","minibatch AVG loss: 0.19126976355910302\n","Epoch: 17     train index of 5 minibatch: 3      time used: 0.5411813259124756\n","minibatch AVG loss: 0.10734320543706417\n","\n","Epoch: 17  train \n","Loss: 0.2793  Acc: 84.0580\n","negative precision: 77.1429  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 79.4872\n","negative FPR: 20.5128  NPV: 91.1765\n","negative TP: 27.0\n","negative TN: 31.0\n","negative FP: 8.0\n","negative FN: 3.0\n","positive precision: 91.1765  recall: 79.4872\n","positive sensitivity: 79.4872  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 77.1429\n","positive TP: 31.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 8.0\n","\n","\n","\n","Epoch: 17  val \n","Loss: 0.0781  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 5 minibatch: 1      time used: 0.7688086032867432\n","minibatch AVG loss: 0.06386107727885246\n","Epoch: 18     train index of 5 minibatch: 2      time used: 0.5428488254547119\n","minibatch AVG loss: 0.22220536433160304\n","Epoch: 18     train index of 5 minibatch: 3      time used: 0.5418045520782471\n","minibatch AVG loss: 0.09029866568744183\n","\n","Epoch: 18  train \n","Loss: 0.1567  Acc: 95.6522\n","negative precision: 90.9091  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 90.9091\n","positive TP: 36.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 18  val \n","Loss: 0.0709  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 5 minibatch: 1      time used: 0.7709767818450928\n","minibatch AVG loss: 0.12390178516507148\n","Epoch: 19     train index of 5 minibatch: 2      time used: 0.545332670211792\n","minibatch AVG loss: 0.07944485619664192\n","Epoch: 19     train index of 5 minibatch: 3      time used: 0.5433049201965332\n","minibatch AVG loss: 0.04604067169129848\n","\n","Epoch: 19  train \n","Loss: 0.1122  Acc: 98.5507\n","negative precision: 96.7742  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 96.7742\n","positive TP: 38.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 19  val \n","Loss: 0.0634  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 5 minibatch: 1      time used: 0.7670552730560303\n","minibatch AVG loss: 0.4516580305993557\n","Epoch: 20     train index of 5 minibatch: 2      time used: 0.541283369064331\n","minibatch AVG loss: 0.12141592763364314\n","Epoch: 20     train index of 5 minibatch: 3      time used: 0.543388843536377\n","minibatch AVG loss: 0.08945225924253464\n","\n","Epoch: 20  train \n","Loss: 0.2166  Acc: 89.8551\n","negative precision: 89.6552  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 90.0000\n","negative TP: 26.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 4.0\n","positive precision: 90.0000  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 89.6552\n","positive TP: 36.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 20  val \n","Loss: 0.0805  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 5 minibatch: 1      time used: 0.7697117328643799\n","minibatch AVG loss: 0.08763335682451726\n","Epoch: 21     train index of 5 minibatch: 2      time used: 0.5453307628631592\n","minibatch AVG loss: 0.44408385790884497\n","Epoch: 21     train index of 5 minibatch: 3      time used: 0.5403265953063965\n","minibatch AVG loss: 0.20967660546302797\n","\n","Epoch: 21  train \n","Loss: 0.3000  Acc: 84.0580\n","negative precision: 85.1852  recall: 76.6667\n","negative sensitivity: 76.6667  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 83.3333\n","negative TP: 23.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 7.0\n","positive precision: 83.3333  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 76.6667\n","positive FPR: 23.3333  NPV: 85.1852\n","positive TP: 35.0\n","positive TN: 23.0\n","positive FP: 7.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 21  val \n","Loss: 0.0619  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 5 minibatch: 1      time used: 0.7574419975280762\n","minibatch AVG loss: 0.05884701944887638\n","Epoch: 22     train index of 5 minibatch: 2      time used: 0.542067289352417\n","minibatch AVG loss: 0.19205590076744555\n","Epoch: 22     train index of 5 minibatch: 3      time used: 0.542266845703125\n","minibatch AVG loss: 0.2535286631435156\n","\n","Epoch: 22  train \n","Loss: 0.1581  Acc: 94.2029\n","negative precision: 96.4286  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 92.6829\n","negative TP: 27.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 3.0\n","positive precision: 92.6829  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 96.4286\n","positive TP: 38.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 22  val \n","Loss: 0.0562  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 5 minibatch: 1      time used: 0.7864453792572021\n","minibatch AVG loss: 0.07566077969968318\n","Epoch: 23     train index of 5 minibatch: 2      time used: 0.543440580368042\n","minibatch AVG loss: 0.25236218702048063\n","Epoch: 23     train index of 5 minibatch: 3      time used: 0.5410051345825195\n","minibatch AVG loss: 0.2746681921184063\n","\n","Epoch: 23  train \n","Loss: 0.1968  Acc: 92.7536\n","negative precision: 96.2963  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 90.4762\n","negative TP: 26.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 4.0\n","positive precision: 90.4762  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 96.2963\n","positive TP: 38.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 23  val \n","Loss: 0.0931  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 5 minibatch: 1      time used: 0.7711920738220215\n","minibatch AVG loss: 0.42382421940565107\n","Epoch: 24     train index of 5 minibatch: 2      time used: 0.5450582504272461\n","minibatch AVG loss: 0.03079785220324993\n","Epoch: 24     train index of 5 minibatch: 3      time used: 0.5416388511657715\n","minibatch AVG loss: 0.251434675604105\n","\n","Epoch: 24  train \n","Loss: 0.2210  Acc: 94.2029\n","negative precision: 96.4286  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 92.6829\n","negative TP: 27.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 3.0\n","positive precision: 92.6829  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 96.4286\n","positive TP: 38.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 24  val \n","Loss: 0.0733  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 5 minibatch: 1      time used: 0.7808451652526855\n","minibatch AVG loss: 0.26288841888308523\n","Epoch: 25     train index of 5 minibatch: 2      time used: 0.5420663356781006\n","minibatch AVG loss: 0.22234635800123215\n","Epoch: 25     train index of 5 minibatch: 3      time used: 0.5426316261291504\n","minibatch AVG loss: 0.46217605844140053\n","\n","Epoch: 25  train \n","Loss: 0.2987  Acc: 85.5072\n","negative precision: 85.7143  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 85.3659\n","negative TP: 24.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 6.0\n","positive precision: 85.3659  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 85.7143\n","positive TP: 35.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 25  val \n","Loss: 0.0890  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 5 minibatch: 1      time used: 0.7630517482757568\n","minibatch AVG loss: 0.1257952641695738\n","Epoch: 26     train index of 5 minibatch: 2      time used: 0.5421102046966553\n","minibatch AVG loss: 0.1441422276198864\n","Epoch: 26     train index of 5 minibatch: 3      time used: 0.5429873466491699\n","minibatch AVG loss: 0.15169377103447915\n","\n","Epoch: 26  train \n","Loss: 0.1385  Acc: 94.2029\n","negative precision: 93.3333  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 94.8718\n","negative TP: 28.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 2.0\n","positive precision: 94.8718  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 93.3333\n","positive TP: 37.0\n","positive TN: 28.0\n","positive FP: 2.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 26  val \n","Loss: 0.0540  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 5 minibatch: 1      time used: 0.7828881740570068\n","minibatch AVG loss: 0.14378360211849212\n","Epoch: 27     train index of 5 minibatch: 2      time used: 0.5408101081848145\n","minibatch AVG loss: 0.07792516462504864\n","Epoch: 27     train index of 5 minibatch: 3      time used: 0.5410909652709961\n","minibatch AVG loss: 0.13257484510540962\n","\n","Epoch: 27  train \n","Loss: 0.1247  Acc: 94.2029\n","negative precision: 90.6250  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 97.2973\n","negative TP: 29.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 97.2973  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 90.6250\n","positive TP: 36.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 27  val \n","Loss: 0.0776  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 5 minibatch: 1      time used: 0.7780239582061768\n","minibatch AVG loss: 0.15383137315511702\n","Epoch: 28     train index of 5 minibatch: 2      time used: 0.5412225723266602\n","minibatch AVG loss: 0.02490024995058775\n","Epoch: 28     train index of 5 minibatch: 3      time used: 0.5418155193328857\n","minibatch AVG loss: 0.2836580455303192\n","\n","Epoch: 28  train \n","Loss: 0.1430  Acc: 94.2029\n","negative precision: 96.4286  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 92.6829\n","negative TP: 27.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 3.0\n","positive precision: 92.6829  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 96.4286\n","positive TP: 38.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 28  val \n","Loss: 0.0600  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 5 minibatch: 1      time used: 0.7727229595184326\n","minibatch AVG loss: 0.1467496979981661\n","Epoch: 29     train index of 5 minibatch: 2      time used: 0.5415689945220947\n","minibatch AVG loss: 0.07042554840445518\n","Epoch: 29     train index of 5 minibatch: 3      time used: 0.5420515537261963\n","minibatch AVG loss: 0.04652149360626936\n","\n","Epoch: 29  train \n","Loss: 0.0987  Acc: 98.5507\n","negative precision: 100.0000  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 97.5000\n","negative TP: 29.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 97.5000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 29  val \n","Loss: 0.0595  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 5 minibatch: 1      time used: 0.7784044742584229\n","minibatch AVG loss: 0.17471143007278442\n","Epoch: 30     train index of 5 minibatch: 2      time used: 0.5409293174743652\n","minibatch AVG loss: 0.03559314720332622\n","Epoch: 30     train index of 5 minibatch: 3      time used: 0.5419771671295166\n","minibatch AVG loss: 0.14877685941755772\n","\n","Epoch: 30  train \n","Loss: 0.1148  Acc: 98.5507\n","negative precision: 96.7742  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 96.7742\n","positive TP: 38.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 30  val \n","Loss: 0.0506  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 5 minibatch: 1      time used: 0.7704298496246338\n","minibatch AVG loss: 0.04040261302143335\n","Epoch: 31     train index of 5 minibatch: 2      time used: 0.5426676273345947\n","minibatch AVG loss: 0.03189927153289318\n","Epoch: 31     train index of 5 minibatch: 3      time used: 0.541973352432251\n","minibatch AVG loss: 0.14822701662778853\n","\n","Epoch: 31  train \n","Loss: 0.0983  Acc: 98.5507\n","negative precision: 96.7742  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 96.7742\n","positive TP: 38.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 31  val \n","Loss: 0.0441  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 5 minibatch: 1      time used: 0.7646257877349854\n","minibatch AVG loss: 0.2623017493635416\n","Epoch: 32     train index of 5 minibatch: 2      time used: 0.5401263236999512\n","minibatch AVG loss: 0.1189373655244708\n","Epoch: 32     train index of 5 minibatch: 3      time used: 0.5412101745605469\n","minibatch AVG loss: 0.025946512073278426\n","\n","Epoch: 32  train \n","Loss: 0.1330  Acc: 97.1014\n","negative precision: 100.0000  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 95.1220\n","negative TP: 28.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 2.0\n","positive precision: 95.1220  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 28.0\n","positive FP: 2.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 32  val \n","Loss: 0.0528  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 5 minibatch: 1      time used: 0.7693636417388916\n","minibatch AVG loss: 0.0673411525785923\n","Epoch: 33     train index of 5 minibatch: 2      time used: 0.5417203903198242\n","minibatch AVG loss: 0.018095606379210948\n","Epoch: 33     train index of 5 minibatch: 3      time used: 0.5413558483123779\n","minibatch AVG loss: 0.01436207527294755\n","\n","Epoch: 33  train \n","Loss: 0.0703  Acc: 98.5507\n","negative precision: 100.0000  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 97.5000\n","negative TP: 29.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 97.5000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 33  val \n","Loss: 0.0554  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 5 minibatch: 1      time used: 0.7656538486480713\n","minibatch AVG loss: 0.037326051667332646\n","Epoch: 34     train index of 5 minibatch: 2      time used: 0.5430319309234619\n","minibatch AVG loss: 0.3387828905135393\n","Epoch: 34     train index of 5 minibatch: 3      time used: 0.543158769607544\n","minibatch AVG loss: 0.05151637736707926\n","\n","Epoch: 34  train \n","Loss: 0.1466  Acc: 94.2029\n","negative precision: 96.4286  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 92.6829\n","negative TP: 27.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 3.0\n","positive precision: 92.6829  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 96.4286\n","positive TP: 38.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 34  val \n","Loss: 0.0527  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 5 minibatch: 1      time used: 0.7732927799224854\n","minibatch AVG loss: 0.03788590542972088\n","Epoch: 35     train index of 5 minibatch: 2      time used: 0.5430848598480225\n","minibatch AVG loss: 0.15407868390902876\n","Epoch: 35     train index of 5 minibatch: 3      time used: 0.5421628952026367\n","minibatch AVG loss: 0.1377858890220523\n","\n","Epoch: 35  train \n","Loss: 0.1074  Acc: 97.1014\n","negative precision: 93.7500  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 93.7500\n","positive TP: 37.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 35  val \n","Loss: 0.0525  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 5 minibatch: 1      time used: 0.7666659355163574\n","minibatch AVG loss: 0.02529195798560977\n","Epoch: 36     train index of 5 minibatch: 2      time used: 0.5428645610809326\n","minibatch AVG loss: 0.31668342277407646\n","Epoch: 36     train index of 5 minibatch: 3      time used: 0.5420715808868408\n","minibatch AVG loss: 0.1291295990347862\n","\n","Epoch: 36  train \n","Loss: 0.1884  Acc: 89.8551\n","negative precision: 87.0968  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 92.1053\n","negative TP: 27.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 3.0\n","positive precision: 92.1053  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 87.0968\n","positive TP: 35.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 36  val \n","Loss: 0.0468  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 5 minibatch: 1      time used: 0.759803295135498\n","minibatch AVG loss: 0.2608851165510714\n","Epoch: 37     train index of 5 minibatch: 2      time used: 0.5429224967956543\n","minibatch AVG loss: 0.036501392163336276\n","Epoch: 37     train index of 5 minibatch: 3      time used: 0.5413157939910889\n","minibatch AVG loss: 0.14204785618931054\n","\n","Epoch: 37  train \n","Loss: 0.1605  Acc: 94.2029\n","negative precision: 93.3333  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 94.8718\n","negative TP: 28.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 2.0\n","positive precision: 94.8718  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 93.3333\n","positive TP: 37.0\n","positive TN: 28.0\n","positive FP: 2.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 37  val \n","Loss: 0.0517  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 5 minibatch: 1      time used: 0.7680931091308594\n","minibatch AVG loss: 0.019688423536717892\n","Epoch: 38     train index of 5 minibatch: 2      time used: 0.5419776439666748\n","minibatch AVG loss: 0.043827902898192404\n","Epoch: 38     train index of 5 minibatch: 3      time used: 0.5422179698944092\n","minibatch AVG loss: 0.12755976570770144\n","\n","Epoch: 38  train \n","Loss: 0.0964  Acc: 97.1014\n","negative precision: 93.7500  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 93.7500\n","positive TP: 37.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 38  val \n","Loss: 0.0484  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 5 minibatch: 1      time used: 0.7701177597045898\n","minibatch AVG loss: 0.2284714424982667\n","Epoch: 39     train index of 5 minibatch: 2      time used: 0.5469005107879639\n","minibatch AVG loss: 0.03026893362402916\n","Epoch: 39     train index of 5 minibatch: 3      time used: 0.5423550605773926\n","minibatch AVG loss: 0.25321703907102344\n","\n","Epoch: 39  train \n","Loss: 0.1890  Acc: 89.8551\n","negative precision: 87.0968  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 92.1053\n","negative TP: 27.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 3.0\n","positive precision: 92.1053  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 87.0968\n","positive TP: 35.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 39  val \n","Loss: 0.0394  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 5 minibatch: 1      time used: 0.7778630256652832\n","minibatch AVG loss: 0.018670388124883176\n","Epoch: 40     train index of 5 minibatch: 2      time used: 0.5441634654998779\n","minibatch AVG loss: 0.021200770139694215\n","Epoch: 40     train index of 5 minibatch: 3      time used: 0.5443544387817383\n","minibatch AVG loss: 0.017401819676160814\n","\n","Epoch: 40  train \n","Loss: 0.0845  Acc: 95.6522\n","negative precision: 96.5517  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 95.0000\n","negative TP: 28.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 2.0\n","positive precision: 95.0000  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 96.5517\n","positive TP: 38.0\n","positive TN: 28.0\n","positive FP: 2.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 40  val \n","Loss: 0.0607  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 5 minibatch: 1      time used: 0.7733511924743652\n","minibatch AVG loss: 0.2139800379052758\n","Epoch: 41     train index of 5 minibatch: 2      time used: 0.5473144054412842\n","minibatch AVG loss: 0.041474857926368715\n","Epoch: 41     train index of 5 minibatch: 3      time used: 0.5428507328033447\n","minibatch AVG loss: 0.23235842119902372\n","\n","Epoch: 41  train \n","Loss: 0.1778  Acc: 91.3043\n","negative precision: 96.1538  recall: 83.3333\n","negative sensitivity: 83.3333  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 88.3721\n","negative TP: 25.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 5.0\n","positive precision: 88.3721  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 83.3333\n","positive FPR: 16.6667  NPV: 96.1538\n","positive TP: 38.0\n","positive TN: 25.0\n","positive FP: 5.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 41  val \n","Loss: 0.0519  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 5 minibatch: 1      time used: 0.76833176612854\n","minibatch AVG loss: 0.23039777502417563\n","Epoch: 42     train index of 5 minibatch: 2      time used: 0.5414903163909912\n","minibatch AVG loss: 0.03534611025825143\n","Epoch: 42     train index of 5 minibatch: 3      time used: 0.5425207614898682\n","minibatch AVG loss: 0.029975759610533715\n","\n","Epoch: 42  train \n","Loss: 0.1006  Acc: 94.2029\n","negative precision: 90.6250  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 97.2973\n","negative TP: 29.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 97.2973  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 90.6250\n","positive TP: 36.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 42  val \n","Loss: 0.0624  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 5 minibatch: 1      time used: 0.771834135055542\n","minibatch AVG loss: 0.1437227688729763\n","Epoch: 43     train index of 5 minibatch: 2      time used: 0.5461528301239014\n","minibatch AVG loss: 0.12796879280358553\n","Epoch: 43     train index of 5 minibatch: 3      time used: 0.5402767658233643\n","minibatch AVG loss: 0.011059272941201926\n","\n","Epoch: 43  train \n","Loss: 0.1002  Acc: 94.2029\n","negative precision: 90.6250  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 97.2973\n","negative TP: 29.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 97.2973  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 90.6250\n","positive TP: 36.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 43  val \n","Loss: 0.0699  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 5 minibatch: 1      time used: 0.7689259052276611\n","minibatch AVG loss: 0.05728997513651848\n","Epoch: 44     train index of 5 minibatch: 2      time used: 0.5413722991943359\n","minibatch AVG loss: 0.022595542855560778\n","Epoch: 44     train index of 5 minibatch: 3      time used: 0.5414502620697021\n","minibatch AVG loss: 0.14749998189508914\n","\n","Epoch: 44  train \n","Loss: 0.0789  Acc: 98.5507\n","negative precision: 96.7742  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 96.7742\n","positive TP: 38.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 44  val \n","Loss: 0.0533  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 5 minibatch: 1      time used: 0.784473180770874\n","minibatch AVG loss: 0.23563554929569364\n","Epoch: 45     train index of 5 minibatch: 2      time used: 0.5401344299316406\n","minibatch AVG loss: 0.027367063984274864\n","Epoch: 45     train index of 5 minibatch: 3      time used: 0.5438187122344971\n","minibatch AVG loss: 0.04838623106479645\n","\n","Epoch: 45  train \n","Loss: 0.1044  Acc: 95.6522\n","negative precision: 100.0000  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 92.8571\n","negative TP: 27.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 3.0\n","positive precision: 92.8571  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 45  val \n","Loss: 0.0686  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 5 minibatch: 1      time used: 0.7782599925994873\n","minibatch AVG loss: 0.15036363173276185\n","Epoch: 46     train index of 5 minibatch: 2      time used: 0.5430099964141846\n","minibatch AVG loss: 0.23526848740875722\n","Epoch: 46     train index of 5 minibatch: 3      time used: 0.5409796237945557\n","minibatch AVG loss: 0.044963860977441074\n","\n","Epoch: 46  train \n","Loss: 0.1403  Acc: 94.2029\n","negative precision: 90.6250  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 97.2973\n","negative TP: 29.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 97.2973  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 90.6250\n","positive TP: 36.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 46  val \n","Loss: 0.0748  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 5 minibatch: 1      time used: 0.7814955711364746\n","minibatch AVG loss: 0.3451418114826083\n","Epoch: 47     train index of 5 minibatch: 2      time used: 0.542426586151123\n","minibatch AVG loss: 0.12579951621592045\n","Epoch: 47     train index of 5 minibatch: 3      time used: 0.5419011116027832\n","minibatch AVG loss: 0.15087792109698056\n","\n","Epoch: 47  train \n","Loss: 0.1915  Acc: 91.3043\n","negative precision: 90.0000  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 92.3077\n","negative TP: 27.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 3.0\n","positive precision: 92.3077  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 90.0000\n","positive TP: 36.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 47  val \n","Loss: 0.0508  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 5 minibatch: 1      time used: 0.7703778743743896\n","minibatch AVG loss: 0.256865013577044\n","Epoch: 48     train index of 5 minibatch: 2      time used: 0.5427494049072266\n","minibatch AVG loss: 0.03104190230369568\n","Epoch: 48     train index of 5 minibatch: 3      time used: 0.5420114994049072\n","minibatch AVG loss: 0.11078068260103464\n","\n","Epoch: 48  train \n","Loss: 0.1630  Acc: 92.7536\n","negative precision: 93.1034  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 92.5000\n","negative TP: 27.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 3.0\n","positive precision: 92.5000  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 93.1034\n","positive TP: 37.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 48  val \n","Loss: 0.0706  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 5 minibatch: 1      time used: 0.7779889106750488\n","minibatch AVG loss: 0.22712557427585126\n","Epoch: 49     train index of 5 minibatch: 2      time used: 0.5419082641601562\n","minibatch AVG loss: 0.10146586075425149\n","Epoch: 49     train index of 5 minibatch: 3      time used: 0.541757345199585\n","minibatch AVG loss: 0.013241343945264817\n","\n","Epoch: 49  train \n","Loss: 0.1184  Acc: 95.6522\n","negative precision: 100.0000  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 92.8571\n","negative TP: 27.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 3.0\n","positive precision: 92.8571  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 49  val \n","Loss: 0.0603  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 5 minibatch: 1      time used: 0.7643623352050781\n","minibatch AVG loss: 0.04230175837874413\n","Epoch: 50     train index of 5 minibatch: 2      time used: 0.5444674491882324\n","minibatch AVG loss: 0.02753503806889057\n","Epoch: 50     train index of 5 minibatch: 3      time used: 0.5426812171936035\n","minibatch AVG loss: 0.10340351443737746\n","\n","Epoch: 50  train \n","Loss: 0.0656  Acc: 98.5507\n","negative precision: 100.0000  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 97.5000\n","negative TP: 29.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 97.5000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 50  val \n","Loss: 0.0601  Acc: 93.7500\n","negative precision: 100.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 90.0000\n","negative TP: 6.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 90.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Training complete in 2m 8s\n","Best epoch idx:  44\n","Best epoch train Acc: 98.550725\n","Best epoch val Acc: 100.000000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","model trained by GPU (idx:0) has been saved at  /home/MIL_Experiment/saved_models/PC_ResNet50_384_401_PT_lf05_b4_warwick_CLS.pth\n"]}],"source":["!python Train.py --model_idx ResNet50_384_401_PT_lf05_b4_warwick_CLS --edge_size 384 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ruKV2IJrSKij","outputId":"c6846654-e7ff-4945-a303-dc34ec9ef271"},"outputs":[{"name":"stdout","output_type":"stream","text":["*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, att_module='SimAM', attn_drop_rate=0.0, backbone_PT_off=False, batch_size=4, check_minibatch=5, cls_token_off=False, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=False, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=-1, intake_epochs=0, lr=1e-05, lrf=0.05, model_idx='ResN50_ViT_384_401_PT_lf05_b4_warwick_CLS', model_path='/home/MIL_Experiment/saved_models', num_classes=2, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, pos_embedding_off=False)\n","we dont have more GPU idx here, try to use gpu_idx=0\n","['vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224']\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_resnet50_384-9fd3c705.pth\" to /root/.cache/torch/hub/checkpoints/jx_vit_base_resnet50_384-9fd3c705.pth\n","test model output： tensor([[0.3191, 0.5060]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","     StdConv2dSame-1         [-1, 64, 192, 192]           9,408\n","              ReLU-2         [-1, 64, 192, 192]               0\n","      GroupNormAct-3         [-1, 64, 192, 192]             128\n","     MaxPool2dSame-4           [-1, 64, 96, 96]               0\n","     StdConv2dSame-5          [-1, 256, 96, 96]          16,384\n","          Identity-6          [-1, 256, 96, 96]               0\n","      GroupNormAct-7          [-1, 256, 96, 96]             512\n","    DownsampleConv-8          [-1, 256, 96, 96]               0\n","     StdConv2dSame-9           [-1, 64, 96, 96]           4,096\n","             ReLU-10           [-1, 64, 96, 96]               0\n","     GroupNormAct-11           [-1, 64, 96, 96]             128\n","    StdConv2dSame-12           [-1, 64, 96, 96]          36,864\n","             ReLU-13           [-1, 64, 96, 96]               0\n","     GroupNormAct-14           [-1, 64, 96, 96]             128\n","    StdConv2dSame-15          [-1, 256, 96, 96]          16,384\n","         Identity-16          [-1, 256, 96, 96]               0\n","     GroupNormAct-17          [-1, 256, 96, 96]             512\n","         Identity-18          [-1, 256, 96, 96]               0\n","             ReLU-19          [-1, 256, 96, 96]               0\n","       Bottleneck-20          [-1, 256, 96, 96]               0\n","    StdConv2dSame-21           [-1, 64, 96, 96]          16,384\n","             ReLU-22           [-1, 64, 96, 96]               0\n","     GroupNormAct-23           [-1, 64, 96, 96]             128\n","    StdConv2dSame-24           [-1, 64, 96, 96]          36,864\n","             ReLU-25           [-1, 64, 96, 96]               0\n","     GroupNormAct-26           [-1, 64, 96, 96]             128\n","    StdConv2dSame-27          [-1, 256, 96, 96]          16,384\n","         Identity-28          [-1, 256, 96, 96]               0\n","     GroupNormAct-29          [-1, 256, 96, 96]             512\n","         Identity-30          [-1, 256, 96, 96]               0\n","             ReLU-31          [-1, 256, 96, 96]               0\n","       Bottleneck-32          [-1, 256, 96, 96]               0\n","    StdConv2dSame-33           [-1, 64, 96, 96]          16,384\n","             ReLU-34           [-1, 64, 96, 96]               0\n","     GroupNormAct-35           [-1, 64, 96, 96]             128\n","    StdConv2dSame-36           [-1, 64, 96, 96]          36,864\n","             ReLU-37           [-1, 64, 96, 96]               0\n","     GroupNormAct-38           [-1, 64, 96, 96]             128\n","    StdConv2dSame-39          [-1, 256, 96, 96]          16,384\n","         Identity-40          [-1, 256, 96, 96]               0\n","     GroupNormAct-41          [-1, 256, 96, 96]             512\n","         Identity-42          [-1, 256, 96, 96]               0\n","             ReLU-43          [-1, 256, 96, 96]               0\n","       Bottleneck-44          [-1, 256, 96, 96]               0\n","      ResNetStage-45          [-1, 256, 96, 96]               0\n","    StdConv2dSame-46          [-1, 512, 48, 48]         131,072\n","         Identity-47          [-1, 512, 48, 48]               0\n","     GroupNormAct-48          [-1, 512, 48, 48]           1,024\n","   DownsampleConv-49          [-1, 512, 48, 48]               0\n","    StdConv2dSame-50          [-1, 128, 96, 96]          32,768\n","             ReLU-51          [-1, 128, 96, 96]               0\n","     GroupNormAct-52          [-1, 128, 96, 96]             256\n","    StdConv2dSame-53          [-1, 128, 48, 48]         147,456\n","             ReLU-54          [-1, 128, 48, 48]               0\n","     GroupNormAct-55          [-1, 128, 48, 48]             256\n","    StdConv2dSame-56          [-1, 512, 48, 48]          65,536\n","         Identity-57          [-1, 512, 48, 48]               0\n","     GroupNormAct-58          [-1, 512, 48, 48]           1,024\n","         Identity-59          [-1, 512, 48, 48]               0\n","             ReLU-60          [-1, 512, 48, 48]               0\n","       Bottleneck-61          [-1, 512, 48, 48]               0\n","    StdConv2dSame-62          [-1, 128, 48, 48]          65,536\n","             ReLU-63          [-1, 128, 48, 48]               0\n","     GroupNormAct-64          [-1, 128, 48, 48]             256\n","    StdConv2dSame-65          [-1, 128, 48, 48]         147,456\n","             ReLU-66          [-1, 128, 48, 48]               0\n","     GroupNormAct-67          [-1, 128, 48, 48]             256\n","    StdConv2dSame-68          [-1, 512, 48, 48]          65,536\n","         Identity-69          [-1, 512, 48, 48]               0\n","     GroupNormAct-70          [-1, 512, 48, 48]           1,024\n","         Identity-71          [-1, 512, 48, 48]               0\n","             ReLU-72          [-1, 512, 48, 48]               0\n","       Bottleneck-73          [-1, 512, 48, 48]               0\n","    StdConv2dSame-74          [-1, 128, 48, 48]          65,536\n","             ReLU-75          [-1, 128, 48, 48]               0\n","     GroupNormAct-76          [-1, 128, 48, 48]             256\n","    StdConv2dSame-77          [-1, 128, 48, 48]         147,456\n","             ReLU-78          [-1, 128, 48, 48]               0\n","     GroupNormAct-79          [-1, 128, 48, 48]             256\n","    StdConv2dSame-80          [-1, 512, 48, 48]          65,536\n","         Identity-81          [-1, 512, 48, 48]               0\n","     GroupNormAct-82          [-1, 512, 48, 48]           1,024\n","         Identity-83          [-1, 512, 48, 48]               0\n","             ReLU-84          [-1, 512, 48, 48]               0\n","       Bottleneck-85          [-1, 512, 48, 48]               0\n","    StdConv2dSame-86          [-1, 128, 48, 48]          65,536\n","             ReLU-87          [-1, 128, 48, 48]               0\n","     GroupNormAct-88          [-1, 128, 48, 48]             256\n","    StdConv2dSame-89          [-1, 128, 48, 48]         147,456\n","             ReLU-90          [-1, 128, 48, 48]               0\n","     GroupNormAct-91          [-1, 128, 48, 48]             256\n","    StdConv2dSame-92          [-1, 512, 48, 48]          65,536\n","         Identity-93          [-1, 512, 48, 48]               0\n","     GroupNormAct-94          [-1, 512, 48, 48]           1,024\n","         Identity-95          [-1, 512, 48, 48]               0\n","             ReLU-96          [-1, 512, 48, 48]               0\n","       Bottleneck-97          [-1, 512, 48, 48]               0\n","      ResNetStage-98          [-1, 512, 48, 48]               0\n","    StdConv2dSame-99         [-1, 1024, 24, 24]         524,288\n","        Identity-100         [-1, 1024, 24, 24]               0\n","    GroupNormAct-101         [-1, 1024, 24, 24]           2,048\n","  DownsampleConv-102         [-1, 1024, 24, 24]               0\n","   StdConv2dSame-103          [-1, 256, 48, 48]         131,072\n","            ReLU-104          [-1, 256, 48, 48]               0\n","    GroupNormAct-105          [-1, 256, 48, 48]             512\n","   StdConv2dSame-106          [-1, 256, 24, 24]         589,824\n","            ReLU-107          [-1, 256, 24, 24]               0\n","    GroupNormAct-108          [-1, 256, 24, 24]             512\n","   StdConv2dSame-109         [-1, 1024, 24, 24]         262,144\n","        Identity-110         [-1, 1024, 24, 24]               0\n","    GroupNormAct-111         [-1, 1024, 24, 24]           2,048\n","        Identity-112         [-1, 1024, 24, 24]               0\n","            ReLU-113         [-1, 1024, 24, 24]               0\n","      Bottleneck-114         [-1, 1024, 24, 24]               0\n","   StdConv2dSame-115          [-1, 256, 24, 24]         262,144\n","            ReLU-116          [-1, 256, 24, 24]               0\n","    GroupNormAct-117          [-1, 256, 24, 24]             512\n","   StdConv2dSame-118          [-1, 256, 24, 24]         589,824\n","            ReLU-119          [-1, 256, 24, 24]               0\n","    GroupNormAct-120          [-1, 256, 24, 24]             512\n","   StdConv2dSame-121         [-1, 1024, 24, 24]         262,144\n","        Identity-122         [-1, 1024, 24, 24]               0\n","    GroupNormAct-123         [-1, 1024, 24, 24]           2,048\n","        Identity-124         [-1, 1024, 24, 24]               0\n","            ReLU-125         [-1, 1024, 24, 24]               0\n","      Bottleneck-126         [-1, 1024, 24, 24]               0\n","   StdConv2dSame-127          [-1, 256, 24, 24]         262,144\n","            ReLU-128          [-1, 256, 24, 24]               0\n","    GroupNormAct-129          [-1, 256, 24, 24]             512\n","   StdConv2dSame-130          [-1, 256, 24, 24]         589,824\n","            ReLU-131          [-1, 256, 24, 24]               0\n","    GroupNormAct-132          [-1, 256, 24, 24]             512\n","   StdConv2dSame-133         [-1, 1024, 24, 24]         262,144\n","        Identity-134         [-1, 1024, 24, 24]               0\n","    GroupNormAct-135         [-1, 1024, 24, 24]           2,048\n","        Identity-136         [-1, 1024, 24, 24]               0\n","            ReLU-137         [-1, 1024, 24, 24]               0\n","      Bottleneck-138         [-1, 1024, 24, 24]               0\n","   StdConv2dSame-139          [-1, 256, 24, 24]         262,144\n","            ReLU-140          [-1, 256, 24, 24]               0\n","    GroupNormAct-141          [-1, 256, 24, 24]             512\n","   StdConv2dSame-142          [-1, 256, 24, 24]         589,824\n","            ReLU-143          [-1, 256, 24, 24]               0\n","    GroupNormAct-144          [-1, 256, 24, 24]             512\n","   StdConv2dSame-145         [-1, 1024, 24, 24]         262,144\n","        Identity-146         [-1, 1024, 24, 24]               0\n","    GroupNormAct-147         [-1, 1024, 24, 24]           2,048\n","        Identity-148         [-1, 1024, 24, 24]               0\n","            ReLU-149         [-1, 1024, 24, 24]               0\n","      Bottleneck-150         [-1, 1024, 24, 24]               0\n","   StdConv2dSame-151          [-1, 256, 24, 24]         262,144\n","            ReLU-152          [-1, 256, 24, 24]               0\n","    GroupNormAct-153          [-1, 256, 24, 24]             512\n","   StdConv2dSame-154          [-1, 256, 24, 24]         589,824\n","            ReLU-155          [-1, 256, 24, 24]               0\n","    GroupNormAct-156          [-1, 256, 24, 24]             512\n","   StdConv2dSame-157         [-1, 1024, 24, 24]         262,144\n","        Identity-158         [-1, 1024, 24, 24]               0\n","    GroupNormAct-159         [-1, 1024, 24, 24]           2,048\n","        Identity-160         [-1, 1024, 24, 24]               0\n","            ReLU-161         [-1, 1024, 24, 24]               0\n","      Bottleneck-162         [-1, 1024, 24, 24]               0\n","   StdConv2dSame-163          [-1, 256, 24, 24]         262,144\n","            ReLU-164          [-1, 256, 24, 24]               0\n","    GroupNormAct-165          [-1, 256, 24, 24]             512\n","   StdConv2dSame-166          [-1, 256, 24, 24]         589,824\n","            ReLU-167          [-1, 256, 24, 24]               0\n","    GroupNormAct-168          [-1, 256, 24, 24]             512\n","   StdConv2dSame-169         [-1, 1024, 24, 24]         262,144\n","        Identity-170         [-1, 1024, 24, 24]               0\n","    GroupNormAct-171         [-1, 1024, 24, 24]           2,048\n","        Identity-172         [-1, 1024, 24, 24]               0\n","            ReLU-173         [-1, 1024, 24, 24]               0\n","      Bottleneck-174         [-1, 1024, 24, 24]               0\n","   StdConv2dSame-175          [-1, 256, 24, 24]         262,144\n","            ReLU-176          [-1, 256, 24, 24]               0\n","    GroupNormAct-177          [-1, 256, 24, 24]             512\n","   StdConv2dSame-178          [-1, 256, 24, 24]         589,824\n","            ReLU-179          [-1, 256, 24, 24]               0\n","    GroupNormAct-180          [-1, 256, 24, 24]             512\n","   StdConv2dSame-181         [-1, 1024, 24, 24]         262,144\n","        Identity-182         [-1, 1024, 24, 24]               0\n","    GroupNormAct-183         [-1, 1024, 24, 24]           2,048\n","        Identity-184         [-1, 1024, 24, 24]               0\n","            ReLU-185         [-1, 1024, 24, 24]               0\n","      Bottleneck-186         [-1, 1024, 24, 24]               0\n","   StdConv2dSame-187          [-1, 256, 24, 24]         262,144\n","            ReLU-188          [-1, 256, 24, 24]               0\n","    GroupNormAct-189          [-1, 256, 24, 24]             512\n","   StdConv2dSame-190          [-1, 256, 24, 24]         589,824\n","            ReLU-191          [-1, 256, 24, 24]               0\n","    GroupNormAct-192          [-1, 256, 24, 24]             512\n","   StdConv2dSame-193         [-1, 1024, 24, 24]         262,144\n","        Identity-194         [-1, 1024, 24, 24]               0\n","    GroupNormAct-195         [-1, 1024, 24, 24]           2,048\n","        Identity-196         [-1, 1024, 24, 24]               0\n","            ReLU-197         [-1, 1024, 24, 24]               0\n","      Bottleneck-198         [-1, 1024, 24, 24]               0\n","   StdConv2dSame-199          [-1, 256, 24, 24]         262,144\n","            ReLU-200          [-1, 256, 24, 24]               0\n","    GroupNormAct-201          [-1, 256, 24, 24]             512\n","   StdConv2dSame-202          [-1, 256, 24, 24]         589,824\n","            ReLU-203          [-1, 256, 24, 24]               0\n","    GroupNormAct-204          [-1, 256, 24, 24]             512\n","   StdConv2dSame-205         [-1, 1024, 24, 24]         262,144\n","        Identity-206         [-1, 1024, 24, 24]               0\n","    GroupNormAct-207         [-1, 1024, 24, 24]           2,048\n","        Identity-208         [-1, 1024, 24, 24]               0\n","            ReLU-209         [-1, 1024, 24, 24]               0\n","      Bottleneck-210         [-1, 1024, 24, 24]               0\n","     ResNetStage-211         [-1, 1024, 24, 24]               0\n","        Identity-212         [-1, 1024, 24, 24]               0\n","        Identity-213         [-1, 1024, 24, 24]               0\n","        Identity-214         [-1, 1024, 24, 24]               0\n","SelectAdaptivePool2d-215         [-1, 1024, 24, 24]               0\n","        Identity-216         [-1, 1024, 24, 24]               0\n","        Identity-217         [-1, 1024, 24, 24]               0\n","  ClassifierHead-218         [-1, 1024, 24, 24]               0\n","        ResNetV2-219         [-1, 1024, 24, 24]               0\n","          Conv2d-220          [-1, 768, 24, 24]         787,200\n","     HybridEmbed-221             [-1, 576, 768]               0\n","         Dropout-222             [-1, 577, 768]               0\n","       LayerNorm-223             [-1, 577, 768]           1,536\n","          Linear-224            [-1, 577, 2304]       1,771,776\n","         Dropout-225         [-1, 12, 577, 577]               0\n","          Linear-226             [-1, 577, 768]         590,592\n","         Dropout-227             [-1, 577, 768]               0\n","       Attention-228             [-1, 577, 768]               0\n","        Identity-229             [-1, 577, 768]               0\n","       LayerNorm-230             [-1, 577, 768]           1,536\n","          Linear-231            [-1, 577, 3072]       2,362,368\n","            GELU-232            [-1, 577, 3072]               0\n","         Dropout-233            [-1, 577, 3072]               0\n","          Linear-234             [-1, 577, 768]       2,360,064\n","         Dropout-235             [-1, 577, 768]               0\n","             Mlp-236             [-1, 577, 768]               0\n","        Identity-237             [-1, 577, 768]               0\n","           Block-238             [-1, 577, 768]               0\n","       LayerNorm-239             [-1, 577, 768]           1,536\n","          Linear-240            [-1, 577, 2304]       1,771,776\n","         Dropout-241         [-1, 12, 577, 577]               0\n","          Linear-242             [-1, 577, 768]         590,592\n","         Dropout-243             [-1, 577, 768]               0\n","       Attention-244             [-1, 577, 768]               0\n","        Identity-245             [-1, 577, 768]               0\n","       LayerNorm-246             [-1, 577, 768]           1,536\n","          Linear-247            [-1, 577, 3072]       2,362,368\n","            GELU-248            [-1, 577, 3072]               0\n","         Dropout-249            [-1, 577, 3072]               0\n","          Linear-250             [-1, 577, 768]       2,360,064\n","         Dropout-251             [-1, 577, 768]               0\n","             Mlp-252             [-1, 577, 768]               0\n","        Identity-253             [-1, 577, 768]               0\n","           Block-254             [-1, 577, 768]               0\n","       LayerNorm-255             [-1, 577, 768]           1,536\n","          Linear-256            [-1, 577, 2304]       1,771,776\n","         Dropout-257         [-1, 12, 577, 577]               0\n","          Linear-258             [-1, 577, 768]         590,592\n","         Dropout-259             [-1, 577, 768]               0\n","       Attention-260             [-1, 577, 768]               0\n","        Identity-261             [-1, 577, 768]               0\n","       LayerNorm-262             [-1, 577, 768]           1,536\n","          Linear-263            [-1, 577, 3072]       2,362,368\n","            GELU-264            [-1, 577, 3072]               0\n","         Dropout-265            [-1, 577, 3072]               0\n","          Linear-266             [-1, 577, 768]       2,360,064\n","         Dropout-267             [-1, 577, 768]               0\n","             Mlp-268             [-1, 577, 768]               0\n","        Identity-269             [-1, 577, 768]               0\n","           Block-270             [-1, 577, 768]               0\n","       LayerNorm-271             [-1, 577, 768]           1,536\n","          Linear-272            [-1, 577, 2304]       1,771,776\n","         Dropout-273         [-1, 12, 577, 577]               0\n","          Linear-274             [-1, 577, 768]         590,592\n","         Dropout-275             [-1, 577, 768]               0\n","       Attention-276             [-1, 577, 768]               0\n","        Identity-277             [-1, 577, 768]               0\n","       LayerNorm-278             [-1, 577, 768]           1,536\n","          Linear-279            [-1, 577, 3072]       2,362,368\n","            GELU-280            [-1, 577, 3072]               0\n","         Dropout-281            [-1, 577, 3072]               0\n","          Linear-282             [-1, 577, 768]       2,360,064\n","         Dropout-283             [-1, 577, 768]               0\n","             Mlp-284             [-1, 577, 768]               0\n","        Identity-285             [-1, 577, 768]               0\n","           Block-286             [-1, 577, 768]               0\n","       LayerNorm-287             [-1, 577, 768]           1,536\n","          Linear-288            [-1, 577, 2304]       1,771,776\n","         Dropout-289         [-1, 12, 577, 577]               0\n","          Linear-290             [-1, 577, 768]         590,592\n","         Dropout-291             [-1, 577, 768]               0\n","       Attention-292             [-1, 577, 768]               0\n","        Identity-293             [-1, 577, 768]               0\n","       LayerNorm-294             [-1, 577, 768]           1,536\n","          Linear-295            [-1, 577, 3072]       2,362,368\n","            GELU-296            [-1, 577, 3072]               0\n","         Dropout-297            [-1, 577, 3072]               0\n","          Linear-298             [-1, 577, 768]       2,360,064\n","         Dropout-299             [-1, 577, 768]               0\n","             Mlp-300             [-1, 577, 768]               0\n","        Identity-301             [-1, 577, 768]               0\n","           Block-302             [-1, 577, 768]               0\n","       LayerNorm-303             [-1, 577, 768]           1,536\n","          Linear-304            [-1, 577, 2304]       1,771,776\n","         Dropout-305         [-1, 12, 577, 577]               0\n","          Linear-306             [-1, 577, 768]         590,592\n","         Dropout-307             [-1, 577, 768]               0\n","       Attention-308             [-1, 577, 768]               0\n","        Identity-309             [-1, 577, 768]               0\n","       LayerNorm-310             [-1, 577, 768]           1,536\n","          Linear-311            [-1, 577, 3072]       2,362,368\n","            GELU-312            [-1, 577, 3072]               0\n","         Dropout-313            [-1, 577, 3072]               0\n","          Linear-314             [-1, 577, 768]       2,360,064\n","         Dropout-315             [-1, 577, 768]               0\n","             Mlp-316             [-1, 577, 768]               0\n","        Identity-317             [-1, 577, 768]               0\n","           Block-318             [-1, 577, 768]               0\n","       LayerNorm-319             [-1, 577, 768]           1,536\n","          Linear-320            [-1, 577, 2304]       1,771,776\n","         Dropout-321         [-1, 12, 577, 577]               0\n","          Linear-322             [-1, 577, 768]         590,592\n","         Dropout-323             [-1, 577, 768]               0\n","       Attention-324             [-1, 577, 768]               0\n","        Identity-325             [-1, 577, 768]               0\n","       LayerNorm-326             [-1, 577, 768]           1,536\n","          Linear-327            [-1, 577, 3072]       2,362,368\n","            GELU-328            [-1, 577, 3072]               0\n","         Dropout-329            [-1, 577, 3072]               0\n","          Linear-330             [-1, 577, 768]       2,360,064\n","         Dropout-331             [-1, 577, 768]               0\n","             Mlp-332             [-1, 577, 768]               0\n","        Identity-333             [-1, 577, 768]               0\n","           Block-334             [-1, 577, 768]               0\n","       LayerNorm-335             [-1, 577, 768]           1,536\n","          Linear-336            [-1, 577, 2304]       1,771,776\n","         Dropout-337         [-1, 12, 577, 577]               0\n","          Linear-338             [-1, 577, 768]         590,592\n","         Dropout-339             [-1, 577, 768]               0\n","       Attention-340             [-1, 577, 768]               0\n","        Identity-341             [-1, 577, 768]               0\n","       LayerNorm-342             [-1, 577, 768]           1,536\n","          Linear-343            [-1, 577, 3072]       2,362,368\n","            GELU-344            [-1, 577, 3072]               0\n","         Dropout-345            [-1, 577, 3072]               0\n","          Linear-346             [-1, 577, 768]       2,360,064\n","         Dropout-347             [-1, 577, 768]               0\n","             Mlp-348             [-1, 577, 768]               0\n","        Identity-349             [-1, 577, 768]               0\n","           Block-350             [-1, 577, 768]               0\n","       LayerNorm-351             [-1, 577, 768]           1,536\n","          Linear-352            [-1, 577, 2304]       1,771,776\n","         Dropout-353         [-1, 12, 577, 577]               0\n","          Linear-354             [-1, 577, 768]         590,592\n","         Dropout-355             [-1, 577, 768]               0\n","       Attention-356             [-1, 577, 768]               0\n","        Identity-357             [-1, 577, 768]               0\n","       LayerNorm-358             [-1, 577, 768]           1,536\n","          Linear-359            [-1, 577, 3072]       2,362,368\n","            GELU-360            [-1, 577, 3072]               0\n","         Dropout-361            [-1, 577, 3072]               0\n","          Linear-362             [-1, 577, 768]       2,360,064\n","         Dropout-363             [-1, 577, 768]               0\n","             Mlp-364             [-1, 577, 768]               0\n","        Identity-365             [-1, 577, 768]               0\n","           Block-366             [-1, 577, 768]               0\n","       LayerNorm-367             [-1, 577, 768]           1,536\n","          Linear-368            [-1, 577, 2304]       1,771,776\n","         Dropout-369         [-1, 12, 577, 577]               0\n","          Linear-370             [-1, 577, 768]         590,592\n","         Dropout-371             [-1, 577, 768]               0\n","       Attention-372             [-1, 577, 768]               0\n","        Identity-373             [-1, 577, 768]               0\n","       LayerNorm-374             [-1, 577, 768]           1,536\n","          Linear-375            [-1, 577, 3072]       2,362,368\n","            GELU-376            [-1, 577, 3072]               0\n","         Dropout-377            [-1, 577, 3072]               0\n","          Linear-378             [-1, 577, 768]       2,360,064\n","         Dropout-379             [-1, 577, 768]               0\n","             Mlp-380             [-1, 577, 768]               0\n","        Identity-381             [-1, 577, 768]               0\n","           Block-382             [-1, 577, 768]               0\n","       LayerNorm-383             [-1, 577, 768]           1,536\n","          Linear-384            [-1, 577, 2304]       1,771,776\n","         Dropout-385         [-1, 12, 577, 577]               0\n","          Linear-386             [-1, 577, 768]         590,592\n","         Dropout-387             [-1, 577, 768]               0\n","       Attention-388             [-1, 577, 768]               0\n","        Identity-389             [-1, 577, 768]               0\n","       LayerNorm-390             [-1, 577, 768]           1,536\n","          Linear-391            [-1, 577, 3072]       2,362,368\n","            GELU-392            [-1, 577, 3072]               0\n","         Dropout-393            [-1, 577, 3072]               0\n","          Linear-394             [-1, 577, 768]       2,360,064\n","         Dropout-395             [-1, 577, 768]               0\n","             Mlp-396             [-1, 577, 768]               0\n","        Identity-397             [-1, 577, 768]               0\n","           Block-398             [-1, 577, 768]               0\n","       LayerNorm-399             [-1, 577, 768]           1,536\n","          Linear-400            [-1, 577, 2304]       1,771,776\n","         Dropout-401         [-1, 12, 577, 577]               0\n","          Linear-402             [-1, 577, 768]         590,592\n","         Dropout-403             [-1, 577, 768]               0\n","       Attention-404             [-1, 577, 768]               0\n","        Identity-405             [-1, 577, 768]               0\n","       LayerNorm-406             [-1, 577, 768]           1,536\n","          Linear-407            [-1, 577, 3072]       2,362,368\n","            GELU-408            [-1, 577, 3072]               0\n","         Dropout-409            [-1, 577, 3072]               0\n","          Linear-410             [-1, 577, 768]       2,360,064\n","         Dropout-411             [-1, 577, 768]               0\n","             Mlp-412             [-1, 577, 768]               0\n","        Identity-413             [-1, 577, 768]               0\n","           Block-414             [-1, 577, 768]               0\n","       LayerNorm-415             [-1, 577, 768]           1,536\n","        Identity-416                  [-1, 768]               0\n","          Linear-417                    [-1, 2]           1,538\n","================================================================\n","Total params: 97,739,586\n","Trainable params: 97,739,586\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 2695.24\n","Params size (MB): 372.85\n","Estimated Total Size (MB): 3069.77\n","----------------------------------------------------------------\n","model : ResN50_ViT_384_401_PT_lf05_b4_warwick_CLS\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 5 minibatch: 1      time used: 2.240488052368164\n","minibatch AVG loss: 0.5598466455936432\n","Epoch: 1     train index of 5 minibatch: 2      time used: 1.9902710914611816\n","minibatch AVG loss: 0.25183155536651614\n","Epoch: 1     train index of 5 minibatch: 3      time used: 1.993391990661621\n","minibatch AVG loss: 0.08659144304692745\n","\n","Epoch: 1  train \n","Loss: 0.2714  Acc: 86.9565\n","negative precision: 92.0000  recall: 76.6667\n","negative sensitivity: 76.6667  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 84.0909\n","negative TP: 23.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 7.0\n","positive precision: 84.0909  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 76.6667\n","positive FPR: 23.3333  NPV: 92.0000\n","positive TP: 37.0\n","positive TN: 23.0\n","positive FP: 7.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 1  val \n","Loss: 0.1087  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 5 minibatch: 1      time used: 2.2133631706237793\n","minibatch AVG loss: 0.023823231272399426\n","Epoch: 2     train index of 5 minibatch: 2      time used: 1.9908816814422607\n","minibatch AVG loss: 0.02051378656178713\n","Epoch: 2     train index of 5 minibatch: 3      time used: 1.99326753616333\n","minibatch AVG loss: 0.019544489681720734\n","\n","Epoch: 2  train \n","Loss: 0.0277  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 2  val \n","Loss: 0.0592  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 5 minibatch: 1      time used: 2.233721971511841\n","minibatch AVG loss: 0.007761880103498697\n","Epoch: 3     train index of 5 minibatch: 2      time used: 1.993103265762329\n","minibatch AVG loss: 0.006727229058742523\n","Epoch: 3     train index of 5 minibatch: 3      time used: 1.9917058944702148\n","minibatch AVG loss: 0.005661915987730026\n","\n","Epoch: 3  train \n","Loss: 0.0072  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 3  val \n","Loss: 0.0559  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 5 minibatch: 1      time used: 2.2254791259765625\n","minibatch AVG loss: 0.008124201302416622\n","Epoch: 4     train index of 5 minibatch: 2      time used: 1.995042324066162\n","minibatch AVG loss: 0.009794247499667109\n","Epoch: 4     train index of 5 minibatch: 3      time used: 1.994680404663086\n","minibatch AVG loss: 0.003798208897933364\n","\n","Epoch: 4  train \n","Loss: 0.0068  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 4  val \n","Loss: 0.0315  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 5 minibatch: 1      time used: 2.2278711795806885\n","minibatch AVG loss: 0.004886569874361158\n","Epoch: 5     train index of 5 minibatch: 2      time used: 1.993117332458496\n","minibatch AVG loss: 0.01387401488609612\n","Epoch: 5     train index of 5 minibatch: 3      time used: 1.9928793907165527\n","minibatch AVG loss: 0.003884643339551985\n","\n","Epoch: 5  train \n","Loss: 0.0073  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 5  val \n","Loss: 0.1147  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 5 minibatch: 1      time used: 2.2161495685577393\n","minibatch AVG loss: 0.005136730056256056\n","Epoch: 6     train index of 5 minibatch: 2      time used: 1.9989094734191895\n","minibatch AVG loss: 0.0038450547493994237\n","Epoch: 6     train index of 5 minibatch: 3      time used: 1.990685224533081\n","minibatch AVG loss: 0.015544963325373829\n","\n","Epoch: 6  train \n","Loss: 0.0074  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 6  val \n","Loss: 0.0243  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 5 minibatch: 1      time used: 2.2306864261627197\n","minibatch AVG loss: 0.005679330369457602\n","Epoch: 7     train index of 5 minibatch: 2      time used: 1.9952418804168701\n","minibatch AVG loss: 0.00465663424693048\n","Epoch: 7     train index of 5 minibatch: 3      time used: 1.9968838691711426\n","minibatch AVG loss: 0.004162643710151315\n","\n","Epoch: 7  train \n","Loss: 0.0044  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 7  val \n","Loss: 0.0264  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 5 minibatch: 1      time used: 2.2151899337768555\n","minibatch AVG loss: 0.003286272240802646\n","Epoch: 8     train index of 5 minibatch: 2      time used: 1.9935054779052734\n","minibatch AVG loss: 0.0023672163020819425\n","Epoch: 8     train index of 5 minibatch: 3      time used: 1.99306058883667\n","minibatch AVG loss: 0.0056110868928954\n","\n","Epoch: 8  train \n","Loss: 0.0036  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 8  val \n","Loss: 0.0304  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 5 minibatch: 1      time used: 2.222317934036255\n","minibatch AVG loss: 0.0037839038763195277\n","Epoch: 9     train index of 5 minibatch: 2      time used: 1.9917185306549072\n","minibatch AVG loss: 0.0036977974465116858\n","Epoch: 9     train index of 5 minibatch: 3      time used: 1.9915518760681152\n","minibatch AVG loss: 0.001982197631150484\n","\n","Epoch: 9  train \n","Loss: 0.0032  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 9  val \n","Loss: 0.0453  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 5 minibatch: 1      time used: 2.234787702560425\n","minibatch AVG loss: 0.0019048474496230483\n","Epoch: 10     train index of 5 minibatch: 2      time used: 1.9922456741333008\n","minibatch AVG loss: 0.0024230834562331436\n","Epoch: 10     train index of 5 minibatch: 3      time used: 1.9947278499603271\n","minibatch AVG loss: 0.00188987678848207\n","\n","Epoch: 10  train \n","Loss: 0.0025  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 10  val \n","Loss: 0.0614  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 5 minibatch: 1      time used: 2.220768690109253\n","minibatch AVG loss: 0.003145506279543042\n","Epoch: 11     train index of 5 minibatch: 2      time used: 1.993241548538208\n","minibatch AVG loss: 0.0033285662299022078\n","Epoch: 11     train index of 5 minibatch: 3      time used: 1.9923741817474365\n","minibatch AVG loss: 0.002082745754159987\n","\n","Epoch: 11  train \n","Loss: 0.0027  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 11  val \n","Loss: 0.0586  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 5 minibatch: 1      time used: 2.217646598815918\n","minibatch AVG loss: 0.002508120401762426\n","Epoch: 12     train index of 5 minibatch: 2      time used: 1.9905891418457031\n","minibatch AVG loss: 0.0018003267934545875\n","Epoch: 12     train index of 5 minibatch: 3      time used: 1.992426872253418\n","minibatch AVG loss: 0.0033036347245797514\n","\n","Epoch: 12  train \n","Loss: 0.0026  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 12  val \n","Loss: 0.0541  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 5 minibatch: 1      time used: 2.218825340270996\n","minibatch AVG loss: 0.001909582526423037\n","Epoch: 13     train index of 5 minibatch: 2      time used: 1.9922914505004883\n","minibatch AVG loss: 0.004018723568879068\n","Epoch: 13     train index of 5 minibatch: 3      time used: 1.991001844406128\n","minibatch AVG loss: 0.004884342197328806\n","\n","Epoch: 13  train \n","Loss: 0.0034  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 13  val \n","Loss: 0.1025  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 5 minibatch: 1      time used: 2.215017318725586\n","minibatch AVG loss: 0.0022255889605730774\n","Epoch: 14     train index of 5 minibatch: 2      time used: 1.9941577911376953\n","minibatch AVG loss: 0.001783231319859624\n","Epoch: 14     train index of 5 minibatch: 3      time used: 1.992833137512207\n","minibatch AVG loss: 0.004351176670752466\n","\n","Epoch: 14  train \n","Loss: 0.0026  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 14  val \n","Loss: 0.0480  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 5 minibatch: 1      time used: 2.2210898399353027\n","minibatch AVG loss: 0.0026844763895496728\n","Epoch: 15     train index of 5 minibatch: 2      time used: 1.992041826248169\n","minibatch AVG loss: 0.0020166004193015396\n","Epoch: 15     train index of 5 minibatch: 3      time used: 1.9906675815582275\n","minibatch AVG loss: 0.0018996178172528745\n","\n","Epoch: 15  train \n","Loss: 0.0023  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 15  val \n","Loss: 0.0273  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 5 minibatch: 1      time used: 2.2193491458892822\n","minibatch AVG loss: 0.0021798687521368265\n","Epoch: 16     train index of 5 minibatch: 2      time used: 1.9932162761688232\n","minibatch AVG loss: 0.0017999285832047463\n","Epoch: 16     train index of 5 minibatch: 3      time used: 1.9943382740020752\n","minibatch AVG loss: 0.0014860016177408396\n","\n","Epoch: 16  train \n","Loss: 0.0022  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 16  val \n","Loss: 0.0467  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 5 minibatch: 1      time used: 2.2159671783447266\n","minibatch AVG loss: 0.0016427973750978708\n","Epoch: 17     train index of 5 minibatch: 2      time used: 1.9950289726257324\n","minibatch AVG loss: 0.0016422811546362936\n","Epoch: 17     train index of 5 minibatch: 3      time used: 1.99196195602417\n","minibatch AVG loss: 0.0018644744995981455\n","\n","Epoch: 17  train \n","Loss: 0.0017  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 17  val \n","Loss: 0.0537  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 5 minibatch: 1      time used: 2.218963146209717\n","minibatch AVG loss: 0.00256276112049818\n","Epoch: 18     train index of 5 minibatch: 2      time used: 1.9915156364440918\n","minibatch AVG loss: 0.0014960663625970482\n","Epoch: 18     train index of 5 minibatch: 3      time used: 1.9930107593536377\n","minibatch AVG loss: 0.0013404481229372322\n","\n","Epoch: 18  train \n","Loss: 0.0020  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 18  val \n","Loss: 0.0761  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 5 minibatch: 1      time used: 2.219468116760254\n","minibatch AVG loss: 0.0011369752231985331\n","Epoch: 19     train index of 5 minibatch: 2      time used: 1.9905147552490234\n","minibatch AVG loss: 0.0016784008010290563\n","Epoch: 19     train index of 5 minibatch: 3      time used: 1.9937570095062256\n","minibatch AVG loss: 0.0017790725221857428\n","\n","Epoch: 19  train \n","Loss: 0.0017  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 19  val \n","Loss: 0.0917  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 5 minibatch: 1      time used: 2.234315872192383\n","minibatch AVG loss: 0.0019243564223870636\n","Epoch: 20     train index of 5 minibatch: 2      time used: 1.9911811351776123\n","minibatch AVG loss: 0.0019987076171673833\n","Epoch: 20     train index of 5 minibatch: 3      time used: 1.9914610385894775\n","minibatch AVG loss: 0.0020829939399845897\n","\n","Epoch: 20  train \n","Loss: 0.0019  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 20  val \n","Loss: 0.0988  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 5 minibatch: 1      time used: 2.220184803009033\n","minibatch AVG loss: 0.0016868299571797252\n","Epoch: 21     train index of 5 minibatch: 2      time used: 1.9949891567230225\n","minibatch AVG loss: 0.0013945012353360653\n","Epoch: 21     train index of 5 minibatch: 3      time used: 1.9913840293884277\n","minibatch AVG loss: 0.0015613187337294222\n","\n","Epoch: 21  train \n","Loss: 0.0015  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 21  val \n","Loss: 0.1074  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 5 minibatch: 1      time used: 2.2184064388275146\n","minibatch AVG loss: 0.001230236585251987\n","Epoch: 22     train index of 5 minibatch: 2      time used: 1.9929592609405518\n","minibatch AVG loss: 0.0023194053675979374\n","Epoch: 22     train index of 5 minibatch: 3      time used: 1.9926800727844238\n","minibatch AVG loss: 0.0012756875366903841\n","\n","Epoch: 22  train \n","Loss: 0.0020  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 22  val \n","Loss: 0.1120  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 5 minibatch: 1      time used: 2.2300477027893066\n","minibatch AVG loss: 0.0010768302017822862\n","Epoch: 23     train index of 5 minibatch: 2      time used: 1.9942612648010254\n","minibatch AVG loss: 0.0009154697530902922\n","Epoch: 23     train index of 5 minibatch: 3      time used: 1.9938068389892578\n","minibatch AVG loss: 0.00196843387093395\n","\n","Epoch: 23  train \n","Loss: 0.0015  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 23  val \n","Loss: 0.1173  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 5 minibatch: 1      time used: 2.2376344203948975\n","minibatch AVG loss: 0.0013196261948905884\n","Epoch: 24     train index of 5 minibatch: 2      time used: 1.9910380840301514\n","minibatch AVG loss: 0.001695389812812209\n","Epoch: 24     train index of 5 minibatch: 3      time used: 1.9920718669891357\n","minibatch AVG loss: 0.0018019188195466996\n","\n","Epoch: 24  train \n","Loss: 0.0016  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 24  val \n","Loss: 0.1374  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 5 minibatch: 1      time used: 2.223451614379883\n","minibatch AVG loss: 0.0012607370037585497\n","Epoch: 25     train index of 5 minibatch: 2      time used: 1.9917197227478027\n","minibatch AVG loss: 0.002494764607399702\n","Epoch: 25     train index of 5 minibatch: 3      time used: 1.9907870292663574\n","minibatch AVG loss: 0.001229021605104208\n","\n","Epoch: 25  train \n","Loss: 0.0016  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 25  val \n","Loss: 0.1742  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 5 minibatch: 1      time used: 2.2177159786224365\n","minibatch AVG loss: 0.0011428251047618688\n","Epoch: 26     train index of 5 minibatch: 2      time used: 1.9921178817749023\n","minibatch AVG loss: 0.0018491067574359476\n","Epoch: 26     train index of 5 minibatch: 3      time used: 1.9932632446289062\n","minibatch AVG loss: 0.0010439941543154418\n","\n","Epoch: 26  train \n","Loss: 0.0013  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 26  val \n","Loss: 0.1718  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 5 minibatch: 1      time used: 2.2200124263763428\n","minibatch AVG loss: 0.0011004376108758151\n","Epoch: 27     train index of 5 minibatch: 2      time used: 1.9922618865966797\n","minibatch AVG loss: 0.001365117309615016\n","Epoch: 27     train index of 5 minibatch: 3      time used: 1.9904420375823975\n","minibatch AVG loss: 0.0009187954477965832\n","\n","Epoch: 27  train \n","Loss: 0.0012  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 27  val \n","Loss: 0.1614  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 5 minibatch: 1      time used: 2.2143585681915283\n","minibatch AVG loss: 0.0007411315338686109\n","Epoch: 28     train index of 5 minibatch: 2      time used: 1.991469144821167\n","minibatch AVG loss: 0.002216486935503781\n","Epoch: 28     train index of 5 minibatch: 3      time used: 1.9926409721374512\n","minibatch AVG loss: 0.0010255732922814786\n","\n","Epoch: 28  train \n","Loss: 0.0014  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 28  val \n","Loss: 0.1831  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 5 minibatch: 1      time used: 2.212630271911621\n","minibatch AVG loss: 0.0012989645125344395\n","Epoch: 29     train index of 5 minibatch: 2      time used: 1.9966201782226562\n","minibatch AVG loss: 0.0008778981980867683\n","Epoch: 29     train index of 5 minibatch: 3      time used: 1.993619441986084\n","minibatch AVG loss: 0.0013206539442762733\n","\n","Epoch: 29  train \n","Loss: 0.0012  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 29  val \n","Loss: 0.1809  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 5 minibatch: 1      time used: 2.2197084426879883\n","minibatch AVG loss: 0.0020014382316730917\n","Epoch: 30     train index of 5 minibatch: 2      time used: 1.9946608543395996\n","minibatch AVG loss: 0.0009135565720498562\n","Epoch: 30     train index of 5 minibatch: 3      time used: 1.9922099113464355\n","minibatch AVG loss: 0.00109219589503482\n","\n","Epoch: 30  train \n","Loss: 0.0013  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 30  val \n","Loss: 0.1784  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 5 minibatch: 1      time used: 2.21601939201355\n","minibatch AVG loss: 0.0010743875522166491\n","Epoch: 31     train index of 5 minibatch: 2      time used: 1.9916512966156006\n","minibatch AVG loss: 0.0009749125863891094\n","Epoch: 31     train index of 5 minibatch: 3      time used: 1.9921929836273193\n","minibatch AVG loss: 0.0011211723554879426\n","\n","Epoch: 31  train \n","Loss: 0.0010  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 31  val \n","Loss: 0.1780  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 5 minibatch: 1      time used: 2.2181262969970703\n","minibatch AVG loss: 0.0007610837346874177\n","Epoch: 32     train index of 5 minibatch: 2      time used: 1.992866039276123\n","minibatch AVG loss: 0.0017690518638119102\n","Epoch: 32     train index of 5 minibatch: 3      time used: 1.9944560527801514\n","minibatch AVG loss: 0.0019775260239839553\n","\n","Epoch: 32  train \n","Loss: 0.0014  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 32  val \n","Loss: 0.1954  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 5 minibatch: 1      time used: 2.221062183380127\n","minibatch AVG loss: 0.0011309453519061207\n","Epoch: 33     train index of 5 minibatch: 2      time used: 1.992457628250122\n","minibatch AVG loss: 0.0012483978411182762\n","Epoch: 33     train index of 5 minibatch: 3      time used: 1.9907994270324707\n","minibatch AVG loss: 0.0008709332323633134\n","\n","Epoch: 33  train \n","Loss: 0.0010  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 33  val \n","Loss: 0.2051  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 5 minibatch: 1      time used: 2.212934970855713\n","minibatch AVG loss: 0.0012506067287176847\n","Epoch: 34     train index of 5 minibatch: 2      time used: 1.9910950660705566\n","minibatch AVG loss: 0.0012718996964395045\n","Epoch: 34     train index of 5 minibatch: 3      time used: 1.9910361766815186\n","minibatch AVG loss: 0.0009093060973100365\n","\n","Epoch: 34  train \n","Loss: 0.0011  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 34  val \n","Loss: 0.2048  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 5 minibatch: 1      time used: 2.2108497619628906\n","minibatch AVG loss: 0.0008295151521451772\n","Epoch: 35     train index of 5 minibatch: 2      time used: 1.9921133518218994\n","minibatch AVG loss: 0.0009272430499549956\n","Epoch: 35     train index of 5 minibatch: 3      time used: 1.992279291152954\n","minibatch AVG loss: 0.0010117815108969808\n","\n","Epoch: 35  train \n","Loss: 0.0009  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 35  val \n","Loss: 0.2075  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 5 minibatch: 1      time used: 2.220083236694336\n","minibatch AVG loss: 0.001023177697788924\n","Epoch: 36     train index of 5 minibatch: 2      time used: 1.9933948516845703\n","minibatch AVG loss: 0.0009139154222793877\n","Epoch: 36     train index of 5 minibatch: 3      time used: 1.991988182067871\n","minibatch AVG loss: 0.0010716516291722656\n","\n","Epoch: 36  train \n","Loss: 0.0010  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 36  val \n","Loss: 0.2063  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 5 minibatch: 1      time used: 2.22031831741333\n","minibatch AVG loss: 0.0009036274626851082\n","Epoch: 37     train index of 5 minibatch: 2      time used: 1.9931485652923584\n","minibatch AVG loss: 0.0015418060007505118\n","Epoch: 37     train index of 5 minibatch: 3      time used: 1.9917824268341064\n","minibatch AVG loss: 0.002123780327383429\n","\n","Epoch: 37  train \n","Loss: 0.0015  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 37  val \n","Loss: 0.2085  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 5 minibatch: 1      time used: 2.2231273651123047\n","minibatch AVG loss: 0.0007000257901381701\n","Epoch: 38     train index of 5 minibatch: 2      time used: 1.9905951023101807\n","minibatch AVG loss: 0.0019460895680822432\n","Epoch: 38     train index of 5 minibatch: 3      time used: 1.9912545680999756\n","minibatch AVG loss: 0.0014655134407803416\n","\n","Epoch: 38  train \n","Loss: 0.0013  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 38  val \n","Loss: 0.2044  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 5 minibatch: 1      time used: 2.220104694366455\n","minibatch AVG loss: 0.0008364961715415121\n","Epoch: 39     train index of 5 minibatch: 2      time used: 1.991955280303955\n","minibatch AVG loss: 0.0007510120049118996\n","Epoch: 39     train index of 5 minibatch: 3      time used: 1.9915554523468018\n","minibatch AVG loss: 0.0007000328332651407\n","\n","Epoch: 39  train \n","Loss: 0.0008  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 39  val \n","Loss: 0.2049  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 5 minibatch: 1      time used: 2.224158763885498\n","minibatch AVG loss: 0.0007594416150823235\n","Epoch: 40     train index of 5 minibatch: 2      time used: 1.994652271270752\n","minibatch AVG loss: 0.0009015466785058379\n","Epoch: 40     train index of 5 minibatch: 3      time used: 1.9932551383972168\n","minibatch AVG loss: 0.0007873262744396925\n","\n","Epoch: 40  train \n","Loss: 0.0009  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 40  val \n","Loss: 0.2074  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 5 minibatch: 1      time used: 2.2185726165771484\n","minibatch AVG loss: 0.0007854758005123585\n","Epoch: 41     train index of 5 minibatch: 2      time used: 1.9924156665802002\n","minibatch AVG loss: 0.001063797512324527\n","Epoch: 41     train index of 5 minibatch: 3      time used: 1.992666244506836\n","minibatch AVG loss: 0.0007996355067007244\n","\n","Epoch: 41  train \n","Loss: 0.0010  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 41  val \n","Loss: 0.2122  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 5 minibatch: 1      time used: 2.224745988845825\n","minibatch AVG loss: 0.000683183188084513\n","Epoch: 42     train index of 5 minibatch: 2      time used: 1.9992287158966064\n","minibatch AVG loss: 0.001019409910077229\n","Epoch: 42     train index of 5 minibatch: 3      time used: 1.9905765056610107\n","minibatch AVG loss: 0.000982323323842138\n","\n","Epoch: 42  train \n","Loss: 0.0009  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 42  val \n","Loss: 0.2160  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 5 minibatch: 1      time used: 2.2233924865722656\n","minibatch AVG loss: 0.0007969339028932154\n","Epoch: 43     train index of 5 minibatch: 2      time used: 1.9912974834442139\n","minibatch AVG loss: 0.000980046729091555\n","Epoch: 43     train index of 5 minibatch: 3      time used: 1.990248680114746\n","minibatch AVG loss: 0.000921482837293297\n","\n","Epoch: 43  train \n","Loss: 0.0009  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 43  val \n","Loss: 0.2172  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 5 minibatch: 1      time used: 2.217926025390625\n","minibatch AVG loss: 0.0010714965290389955\n","Epoch: 44     train index of 5 minibatch: 2      time used: 1.993321418762207\n","minibatch AVG loss: 0.0008581015339586884\n","Epoch: 44     train index of 5 minibatch: 3      time used: 1.9928174018859863\n","minibatch AVG loss: 0.0007639420276973396\n","\n","Epoch: 44  train \n","Loss: 0.0009  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 44  val \n","Loss: 0.2175  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 5 minibatch: 1      time used: 2.222503423690796\n","minibatch AVG loss: 0.0007422695867717266\n","Epoch: 45     train index of 5 minibatch: 2      time used: 1.993143081665039\n","minibatch AVG loss: 0.0007475535559933633\n","Epoch: 45     train index of 5 minibatch: 3      time used: 1.9962217807769775\n","minibatch AVG loss: 0.0010807852610014378\n","\n","Epoch: 45  train \n","Loss: 0.0009  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 45  val \n","Loss: 0.2187  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 5 minibatch: 1      time used: 2.2218034267425537\n","minibatch AVG loss: 0.0009301211568526924\n","Epoch: 46     train index of 5 minibatch: 2      time used: 1.9925897121429443\n","minibatch AVG loss: 0.0008550500904675573\n","Epoch: 46     train index of 5 minibatch: 3      time used: 1.9925203323364258\n","minibatch AVG loss: 0.000761111790779978\n","\n","Epoch: 46  train \n","Loss: 0.0009  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 46  val \n","Loss: 0.2198  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 5 minibatch: 1      time used: 2.231398582458496\n","minibatch AVG loss: 0.0007922605262137949\n","Epoch: 47     train index of 5 minibatch: 2      time used: 1.9922993183135986\n","minibatch AVG loss: 0.0008197822025977075\n","Epoch: 47     train index of 5 minibatch: 3      time used: 1.9938385486602783\n","minibatch AVG loss: 0.0008145797182805836\n","\n","Epoch: 47  train \n","Loss: 0.0008  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 47  val \n","Loss: 0.2200  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 5 minibatch: 1      time used: 2.233842372894287\n","minibatch AVG loss: 0.0006688620720524341\n","Epoch: 48     train index of 5 minibatch: 2      time used: 1.9915111064910889\n","minibatch AVG loss: 0.00062315808609128\n","Epoch: 48     train index of 5 minibatch: 3      time used: 1.9927921295166016\n","minibatch AVG loss: 0.0009903387865051628\n","\n","Epoch: 48  train \n","Loss: 0.0008  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 48  val \n","Loss: 0.2203  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 5 minibatch: 1      time used: 2.2225534915924072\n","minibatch AVG loss: 0.0008314617676660419\n","Epoch: 49     train index of 5 minibatch: 2      time used: 1.9918875694274902\n","minibatch AVG loss: 0.0010562580660916864\n","Epoch: 49     train index of 5 minibatch: 3      time used: 1.9911761283874512\n","minibatch AVG loss: 0.0008777768700383604\n","\n","Epoch: 49  train \n","Loss: 0.0009  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 49  val \n","Loss: 0.2212  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 5 minibatch: 1      time used: 2.216865301132202\n","minibatch AVG loss: 0.0018889859667979181\n","Epoch: 50     train index of 5 minibatch: 2      time used: 1.9926013946533203\n","minibatch AVG loss: 0.0007111233891919256\n","Epoch: 50     train index of 5 minibatch: 3      time used: 1.9918370246887207\n","minibatch AVG loss: 0.0009698235313408077\n","\n","Epoch: 50  train \n","Loss: 0.0011  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 50  val \n","Loss: 0.2204  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Training complete in 6m 36s\n","Best epoch idx:  17\n","Best epoch train Acc: 100.000000\n","Best epoch val Acc: 100.000000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","model trained by GPU (idx:0) has been saved at  /home/MIL_Experiment/saved_models/PC_ResN50_ViT_384_401_PT_lf05_b4_warwick_CLS.pth\n"]}],"source":["!python Train.py --model_idx ResN50_ViT_384_401_PT_lf05_b4_warwick_CLS --edge_size 384 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aU1iyR9aSK1X","outputId":"14e93eed-cec4-4605-cdf6-2d0db7803e93"},"outputs":[{"name":"stdout","output_type":"stream","text":["*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, att_module='SimAM', attn_drop_rate=0.0, backbone_PT_off=False, batch_size=4, check_minibatch=5, cls_token_off=False, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=False, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=-1, intake_epochs=0, lr=1e-05, lrf=0.05, model_idx='efficientnet_b3_384_401_PT_lf05_b4_warwick_CLS', model_path='/home/MIL_Experiment/saved_models', num_classes=2, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, pos_embedding_off=False)\n","we dont have more GPU idx here, try to use gpu_idx=0\n","['efficientnet_b0',\n"," 'efficientnet_b1',\n"," 'efficientnet_b1_pruned',\n"," 'efficientnet_b2',\n"," 'efficientnet_b2_pruned',\n"," 'efficientnet_b2a',\n"," 'efficientnet_b3',\n"," 'efficientnet_b3_pruned',\n"," 'efficientnet_b3a',\n"," 'efficientnet_b4',\n"," 'efficientnet_b5',\n"," 'efficientnet_b6',\n"," 'efficientnet_b7',\n"," 'efficientnet_b8',\n"," 'efficientnet_cc_b0_4e',\n"," 'efficientnet_cc_b0_8e',\n"," 'efficientnet_cc_b1_8e',\n"," 'efficientnet_el',\n"," 'efficientnet_el_pruned',\n"," 'efficientnet_em',\n"," 'efficientnet_es',\n"," 'efficientnet_es_pruned',\n"," 'efficientnet_l2',\n"," 'efficientnet_lite0',\n"," 'efficientnet_lite1',\n"," 'efficientnet_lite2',\n"," 'efficientnet_lite3',\n"," 'efficientnet_lite4',\n"," 'efficientnetv2_l',\n"," 'efficientnetv2_m',\n"," 'efficientnetv2_rw_m',\n"," 'efficientnetv2_rw_s',\n"," 'efficientnetv2_rw_t',\n"," 'efficientnetv2_s',\n"," 'efficientnetv2_xl',\n"," 'gc_efficientnetv2_rw_t',\n"," 'tf_efficientnet_b0',\n"," 'tf_efficientnet_b0_ap',\n"," 'tf_efficientnet_b0_ns',\n"," 'tf_efficientnet_b1',\n"," 'tf_efficientnet_b1_ap',\n"," 'tf_efficientnet_b1_ns',\n"," 'tf_efficientnet_b2',\n"," 'tf_efficientnet_b2_ap',\n"," 'tf_efficientnet_b2_ns',\n"," 'tf_efficientnet_b3',\n"," 'tf_efficientnet_b3_ap',\n"," 'tf_efficientnet_b3_ns',\n"," 'tf_efficientnet_b4',\n"," 'tf_efficientnet_b4_ap',\n"," 'tf_efficientnet_b4_ns',\n"," 'tf_efficientnet_b5',\n"," 'tf_efficientnet_b5_ap',\n"," 'tf_efficientnet_b5_ns',\n"," 'tf_efficientnet_b6',\n"," 'tf_efficientnet_b6_ap',\n"," 'tf_efficientnet_b6_ns',\n"," 'tf_efficientnet_b7',\n"," 'tf_efficientnet_b7_ap',\n"," 'tf_efficientnet_b7_ns',\n"," 'tf_efficientnet_b8',\n"," 'tf_efficientnet_b8_ap',\n"," 'tf_efficientnet_cc_b0_4e',\n"," 'tf_efficientnet_cc_b0_8e',\n"," 'tf_efficientnet_cc_b1_8e',\n"," 'tf_efficientnet_el',\n"," 'tf_efficientnet_em',\n"," 'tf_efficientnet_es',\n"," 'tf_efficientnet_l2_ns',\n"," 'tf_efficientnet_l2_ns_475',\n"," 'tf_efficientnet_lite0',\n"," 'tf_efficientnet_lite1',\n"," 'tf_efficientnet_lite2',\n"," 'tf_efficientnet_lite3',\n"," 'tf_efficientnet_lite4',\n"," 'tf_efficientnetv2_b0',\n"," 'tf_efficientnetv2_b1',\n"," 'tf_efficientnetv2_b2',\n"," 'tf_efficientnetv2_b3',\n"," 'tf_efficientnetv2_l',\n"," 'tf_efficientnetv2_l_in21ft1k',\n"," 'tf_efficientnetv2_l_in21k',\n"," 'tf_efficientnetv2_m',\n"," 'tf_efficientnetv2_m_in21ft1k',\n"," 'tf_efficientnetv2_m_in21k',\n"," 'tf_efficientnetv2_s',\n"," 'tf_efficientnetv2_s_in21ft1k',\n"," 'tf_efficientnetv2_s_in21k',\n"," 'tf_efficientnetv2_xl_in21ft1k',\n"," 'tf_efficientnetv2_xl_in21k']\n","Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b3_ra2-cf984f9c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_ra2-cf984f9c.pth\n","test model output： tensor([[0.1111, 0.7044]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 40, 192, 192]           1,080\n","       BatchNorm2d-2         [-1, 40, 192, 192]              80\n","              SiLU-3         [-1, 40, 192, 192]               0\n","            Conv2d-4         [-1, 40, 192, 192]             360\n","       BatchNorm2d-5         [-1, 40, 192, 192]              80\n","              SiLU-6         [-1, 40, 192, 192]               0\n","            Conv2d-7             [-1, 10, 1, 1]             410\n","              SiLU-8             [-1, 10, 1, 1]               0\n","            Conv2d-9             [-1, 40, 1, 1]             440\n","          Sigmoid-10             [-1, 40, 1, 1]               0\n","    SqueezeExcite-11         [-1, 40, 192, 192]               0\n","           Conv2d-12         [-1, 24, 192, 192]             960\n","      BatchNorm2d-13         [-1, 24, 192, 192]              48\n","         Identity-14         [-1, 24, 192, 192]               0\n","DepthwiseSeparableConv-15         [-1, 24, 192, 192]               0\n","           Conv2d-16         [-1, 24, 192, 192]             216\n","      BatchNorm2d-17         [-1, 24, 192, 192]              48\n","             SiLU-18         [-1, 24, 192, 192]               0\n","           Conv2d-19              [-1, 6, 1, 1]             150\n","             SiLU-20              [-1, 6, 1, 1]               0\n","           Conv2d-21             [-1, 24, 1, 1]             168\n","          Sigmoid-22             [-1, 24, 1, 1]               0\n","    SqueezeExcite-23         [-1, 24, 192, 192]               0\n","           Conv2d-24         [-1, 24, 192, 192]             576\n","      BatchNorm2d-25         [-1, 24, 192, 192]              48\n","         Identity-26         [-1, 24, 192, 192]               0\n","DepthwiseSeparableConv-27         [-1, 24, 192, 192]               0\n","           Conv2d-28        [-1, 144, 192, 192]           3,456\n","      BatchNorm2d-29        [-1, 144, 192, 192]             288\n","             SiLU-30        [-1, 144, 192, 192]               0\n","           Conv2d-31          [-1, 144, 96, 96]           1,296\n","      BatchNorm2d-32          [-1, 144, 96, 96]             288\n","             SiLU-33          [-1, 144, 96, 96]               0\n","           Conv2d-34              [-1, 6, 1, 1]             870\n","             SiLU-35              [-1, 6, 1, 1]               0\n","           Conv2d-36            [-1, 144, 1, 1]           1,008\n","          Sigmoid-37            [-1, 144, 1, 1]               0\n","    SqueezeExcite-38          [-1, 144, 96, 96]               0\n","           Conv2d-39           [-1, 32, 96, 96]           4,608\n","      BatchNorm2d-40           [-1, 32, 96, 96]              64\n"," InvertedResidual-41           [-1, 32, 96, 96]               0\n","           Conv2d-42          [-1, 192, 96, 96]           6,144\n","      BatchNorm2d-43          [-1, 192, 96, 96]             384\n","             SiLU-44          [-1, 192, 96, 96]               0\n","           Conv2d-45          [-1, 192, 96, 96]           1,728\n","      BatchNorm2d-46          [-1, 192, 96, 96]             384\n","             SiLU-47          [-1, 192, 96, 96]               0\n","           Conv2d-48              [-1, 8, 1, 1]           1,544\n","             SiLU-49              [-1, 8, 1, 1]               0\n","           Conv2d-50            [-1, 192, 1, 1]           1,728\n","          Sigmoid-51            [-1, 192, 1, 1]               0\n","    SqueezeExcite-52          [-1, 192, 96, 96]               0\n","           Conv2d-53           [-1, 32, 96, 96]           6,144\n","      BatchNorm2d-54           [-1, 32, 96, 96]              64\n"," InvertedResidual-55           [-1, 32, 96, 96]               0\n","           Conv2d-56          [-1, 192, 96, 96]           6,144\n","      BatchNorm2d-57          [-1, 192, 96, 96]             384\n","             SiLU-58          [-1, 192, 96, 96]               0\n","           Conv2d-59          [-1, 192, 96, 96]           1,728\n","      BatchNorm2d-60          [-1, 192, 96, 96]             384\n","             SiLU-61          [-1, 192, 96, 96]               0\n","           Conv2d-62              [-1, 8, 1, 1]           1,544\n","             SiLU-63              [-1, 8, 1, 1]               0\n","           Conv2d-64            [-1, 192, 1, 1]           1,728\n","          Sigmoid-65            [-1, 192, 1, 1]               0\n","    SqueezeExcite-66          [-1, 192, 96, 96]               0\n","           Conv2d-67           [-1, 32, 96, 96]           6,144\n","      BatchNorm2d-68           [-1, 32, 96, 96]              64\n"," InvertedResidual-69           [-1, 32, 96, 96]               0\n","           Conv2d-70          [-1, 192, 96, 96]           6,144\n","      BatchNorm2d-71          [-1, 192, 96, 96]             384\n","             SiLU-72          [-1, 192, 96, 96]               0\n","           Conv2d-73          [-1, 192, 48, 48]           4,800\n","      BatchNorm2d-74          [-1, 192, 48, 48]             384\n","             SiLU-75          [-1, 192, 48, 48]               0\n","           Conv2d-76              [-1, 8, 1, 1]           1,544\n","             SiLU-77              [-1, 8, 1, 1]               0\n","           Conv2d-78            [-1, 192, 1, 1]           1,728\n","          Sigmoid-79            [-1, 192, 1, 1]               0\n","    SqueezeExcite-80          [-1, 192, 48, 48]               0\n","           Conv2d-81           [-1, 48, 48, 48]           9,216\n","      BatchNorm2d-82           [-1, 48, 48, 48]              96\n"," InvertedResidual-83           [-1, 48, 48, 48]               0\n","           Conv2d-84          [-1, 288, 48, 48]          13,824\n","      BatchNorm2d-85          [-1, 288, 48, 48]             576\n","             SiLU-86          [-1, 288, 48, 48]               0\n","           Conv2d-87          [-1, 288, 48, 48]           7,200\n","      BatchNorm2d-88          [-1, 288, 48, 48]             576\n","             SiLU-89          [-1, 288, 48, 48]               0\n","           Conv2d-90             [-1, 12, 1, 1]           3,468\n","             SiLU-91             [-1, 12, 1, 1]               0\n","           Conv2d-92            [-1, 288, 1, 1]           3,744\n","          Sigmoid-93            [-1, 288, 1, 1]               0\n","    SqueezeExcite-94          [-1, 288, 48, 48]               0\n","           Conv2d-95           [-1, 48, 48, 48]          13,824\n","      BatchNorm2d-96           [-1, 48, 48, 48]              96\n"," InvertedResidual-97           [-1, 48, 48, 48]               0\n","           Conv2d-98          [-1, 288, 48, 48]          13,824\n","      BatchNorm2d-99          [-1, 288, 48, 48]             576\n","            SiLU-100          [-1, 288, 48, 48]               0\n","          Conv2d-101          [-1, 288, 48, 48]           7,200\n","     BatchNorm2d-102          [-1, 288, 48, 48]             576\n","            SiLU-103          [-1, 288, 48, 48]               0\n","          Conv2d-104             [-1, 12, 1, 1]           3,468\n","            SiLU-105             [-1, 12, 1, 1]               0\n","          Conv2d-106            [-1, 288, 1, 1]           3,744\n","         Sigmoid-107            [-1, 288, 1, 1]               0\n","   SqueezeExcite-108          [-1, 288, 48, 48]               0\n","          Conv2d-109           [-1, 48, 48, 48]          13,824\n","     BatchNorm2d-110           [-1, 48, 48, 48]              96\n","InvertedResidual-111           [-1, 48, 48, 48]               0\n","          Conv2d-112          [-1, 288, 48, 48]          13,824\n","     BatchNorm2d-113          [-1, 288, 48, 48]             576\n","            SiLU-114          [-1, 288, 48, 48]               0\n","          Conv2d-115          [-1, 288, 24, 24]           2,592\n","     BatchNorm2d-116          [-1, 288, 24, 24]             576\n","            SiLU-117          [-1, 288, 24, 24]               0\n","          Conv2d-118             [-1, 12, 1, 1]           3,468\n","            SiLU-119             [-1, 12, 1, 1]               0\n","          Conv2d-120            [-1, 288, 1, 1]           3,744\n","         Sigmoid-121            [-1, 288, 1, 1]               0\n","   SqueezeExcite-122          [-1, 288, 24, 24]               0\n","          Conv2d-123           [-1, 96, 24, 24]          27,648\n","     BatchNorm2d-124           [-1, 96, 24, 24]             192\n","InvertedResidual-125           [-1, 96, 24, 24]               0\n","          Conv2d-126          [-1, 576, 24, 24]          55,296\n","     BatchNorm2d-127          [-1, 576, 24, 24]           1,152\n","            SiLU-128          [-1, 576, 24, 24]               0\n","          Conv2d-129          [-1, 576, 24, 24]           5,184\n","     BatchNorm2d-130          [-1, 576, 24, 24]           1,152\n","            SiLU-131          [-1, 576, 24, 24]               0\n","          Conv2d-132             [-1, 24, 1, 1]          13,848\n","            SiLU-133             [-1, 24, 1, 1]               0\n","          Conv2d-134            [-1, 576, 1, 1]          14,400\n","         Sigmoid-135            [-1, 576, 1, 1]               0\n","   SqueezeExcite-136          [-1, 576, 24, 24]               0\n","          Conv2d-137           [-1, 96, 24, 24]          55,296\n","     BatchNorm2d-138           [-1, 96, 24, 24]             192\n","InvertedResidual-139           [-1, 96, 24, 24]               0\n","          Conv2d-140          [-1, 576, 24, 24]          55,296\n","     BatchNorm2d-141          [-1, 576, 24, 24]           1,152\n","            SiLU-142          [-1, 576, 24, 24]               0\n","          Conv2d-143          [-1, 576, 24, 24]           5,184\n","     BatchNorm2d-144          [-1, 576, 24, 24]           1,152\n","            SiLU-145          [-1, 576, 24, 24]               0\n","          Conv2d-146             [-1, 24, 1, 1]          13,848\n","            SiLU-147             [-1, 24, 1, 1]               0\n","          Conv2d-148            [-1, 576, 1, 1]          14,400\n","         Sigmoid-149            [-1, 576, 1, 1]               0\n","   SqueezeExcite-150          [-1, 576, 24, 24]               0\n","          Conv2d-151           [-1, 96, 24, 24]          55,296\n","     BatchNorm2d-152           [-1, 96, 24, 24]             192\n","InvertedResidual-153           [-1, 96, 24, 24]               0\n","          Conv2d-154          [-1, 576, 24, 24]          55,296\n","     BatchNorm2d-155          [-1, 576, 24, 24]           1,152\n","            SiLU-156          [-1, 576, 24, 24]               0\n","          Conv2d-157          [-1, 576, 24, 24]           5,184\n","     BatchNorm2d-158          [-1, 576, 24, 24]           1,152\n","            SiLU-159          [-1, 576, 24, 24]               0\n","          Conv2d-160             [-1, 24, 1, 1]          13,848\n","            SiLU-161             [-1, 24, 1, 1]               0\n","          Conv2d-162            [-1, 576, 1, 1]          14,400\n","         Sigmoid-163            [-1, 576, 1, 1]               0\n","   SqueezeExcite-164          [-1, 576, 24, 24]               0\n","          Conv2d-165           [-1, 96, 24, 24]          55,296\n","     BatchNorm2d-166           [-1, 96, 24, 24]             192\n","InvertedResidual-167           [-1, 96, 24, 24]               0\n","          Conv2d-168          [-1, 576, 24, 24]          55,296\n","     BatchNorm2d-169          [-1, 576, 24, 24]           1,152\n","            SiLU-170          [-1, 576, 24, 24]               0\n","          Conv2d-171          [-1, 576, 24, 24]           5,184\n","     BatchNorm2d-172          [-1, 576, 24, 24]           1,152\n","            SiLU-173          [-1, 576, 24, 24]               0\n","          Conv2d-174             [-1, 24, 1, 1]          13,848\n","            SiLU-175             [-1, 24, 1, 1]               0\n","          Conv2d-176            [-1, 576, 1, 1]          14,400\n","         Sigmoid-177            [-1, 576, 1, 1]               0\n","   SqueezeExcite-178          [-1, 576, 24, 24]               0\n","          Conv2d-179           [-1, 96, 24, 24]          55,296\n","     BatchNorm2d-180           [-1, 96, 24, 24]             192\n","InvertedResidual-181           [-1, 96, 24, 24]               0\n","          Conv2d-182          [-1, 576, 24, 24]          55,296\n","     BatchNorm2d-183          [-1, 576, 24, 24]           1,152\n","            SiLU-184          [-1, 576, 24, 24]               0\n","          Conv2d-185          [-1, 576, 24, 24]          14,400\n","     BatchNorm2d-186          [-1, 576, 24, 24]           1,152\n","            SiLU-187          [-1, 576, 24, 24]               0\n","          Conv2d-188             [-1, 24, 1, 1]          13,848\n","            SiLU-189             [-1, 24, 1, 1]               0\n","          Conv2d-190            [-1, 576, 1, 1]          14,400\n","         Sigmoid-191            [-1, 576, 1, 1]               0\n","   SqueezeExcite-192          [-1, 576, 24, 24]               0\n","          Conv2d-193          [-1, 136, 24, 24]          78,336\n","     BatchNorm2d-194          [-1, 136, 24, 24]             272\n","InvertedResidual-195          [-1, 136, 24, 24]               0\n","          Conv2d-196          [-1, 816, 24, 24]         110,976\n","     BatchNorm2d-197          [-1, 816, 24, 24]           1,632\n","            SiLU-198          [-1, 816, 24, 24]               0\n","          Conv2d-199          [-1, 816, 24, 24]          20,400\n","     BatchNorm2d-200          [-1, 816, 24, 24]           1,632\n","            SiLU-201          [-1, 816, 24, 24]               0\n","          Conv2d-202             [-1, 34, 1, 1]          27,778\n","            SiLU-203             [-1, 34, 1, 1]               0\n","          Conv2d-204            [-1, 816, 1, 1]          28,560\n","         Sigmoid-205            [-1, 816, 1, 1]               0\n","   SqueezeExcite-206          [-1, 816, 24, 24]               0\n","          Conv2d-207          [-1, 136, 24, 24]         110,976\n","     BatchNorm2d-208          [-1, 136, 24, 24]             272\n","InvertedResidual-209          [-1, 136, 24, 24]               0\n","          Conv2d-210          [-1, 816, 24, 24]         110,976\n","     BatchNorm2d-211          [-1, 816, 24, 24]           1,632\n","            SiLU-212          [-1, 816, 24, 24]               0\n","          Conv2d-213          [-1, 816, 24, 24]          20,400\n","     BatchNorm2d-214          [-1, 816, 24, 24]           1,632\n","            SiLU-215          [-1, 816, 24, 24]               0\n","          Conv2d-216             [-1, 34, 1, 1]          27,778\n","            SiLU-217             [-1, 34, 1, 1]               0\n","          Conv2d-218            [-1, 816, 1, 1]          28,560\n","         Sigmoid-219            [-1, 816, 1, 1]               0\n","   SqueezeExcite-220          [-1, 816, 24, 24]               0\n","          Conv2d-221          [-1, 136, 24, 24]         110,976\n","     BatchNorm2d-222          [-1, 136, 24, 24]             272\n","InvertedResidual-223          [-1, 136, 24, 24]               0\n","          Conv2d-224          [-1, 816, 24, 24]         110,976\n","     BatchNorm2d-225          [-1, 816, 24, 24]           1,632\n","            SiLU-226          [-1, 816, 24, 24]               0\n","          Conv2d-227          [-1, 816, 24, 24]          20,400\n","     BatchNorm2d-228          [-1, 816, 24, 24]           1,632\n","            SiLU-229          [-1, 816, 24, 24]               0\n","          Conv2d-230             [-1, 34, 1, 1]          27,778\n","            SiLU-231             [-1, 34, 1, 1]               0\n","          Conv2d-232            [-1, 816, 1, 1]          28,560\n","         Sigmoid-233            [-1, 816, 1, 1]               0\n","   SqueezeExcite-234          [-1, 816, 24, 24]               0\n","          Conv2d-235          [-1, 136, 24, 24]         110,976\n","     BatchNorm2d-236          [-1, 136, 24, 24]             272\n","InvertedResidual-237          [-1, 136, 24, 24]               0\n","          Conv2d-238          [-1, 816, 24, 24]         110,976\n","     BatchNorm2d-239          [-1, 816, 24, 24]           1,632\n","            SiLU-240          [-1, 816, 24, 24]               0\n","          Conv2d-241          [-1, 816, 24, 24]          20,400\n","     BatchNorm2d-242          [-1, 816, 24, 24]           1,632\n","            SiLU-243          [-1, 816, 24, 24]               0\n","          Conv2d-244             [-1, 34, 1, 1]          27,778\n","            SiLU-245             [-1, 34, 1, 1]               0\n","          Conv2d-246            [-1, 816, 1, 1]          28,560\n","         Sigmoid-247            [-1, 816, 1, 1]               0\n","   SqueezeExcite-248          [-1, 816, 24, 24]               0\n","          Conv2d-249          [-1, 136, 24, 24]         110,976\n","     BatchNorm2d-250          [-1, 136, 24, 24]             272\n","InvertedResidual-251          [-1, 136, 24, 24]               0\n","          Conv2d-252          [-1, 816, 24, 24]         110,976\n","     BatchNorm2d-253          [-1, 816, 24, 24]           1,632\n","            SiLU-254          [-1, 816, 24, 24]               0\n","          Conv2d-255          [-1, 816, 12, 12]          20,400\n","     BatchNorm2d-256          [-1, 816, 12, 12]           1,632\n","            SiLU-257          [-1, 816, 12, 12]               0\n","          Conv2d-258             [-1, 34, 1, 1]          27,778\n","            SiLU-259             [-1, 34, 1, 1]               0\n","          Conv2d-260            [-1, 816, 1, 1]          28,560\n","         Sigmoid-261            [-1, 816, 1, 1]               0\n","   SqueezeExcite-262          [-1, 816, 12, 12]               0\n","          Conv2d-263          [-1, 232, 12, 12]         189,312\n","     BatchNorm2d-264          [-1, 232, 12, 12]             464\n","InvertedResidual-265          [-1, 232, 12, 12]               0\n","          Conv2d-266         [-1, 1392, 12, 12]         322,944\n","     BatchNorm2d-267         [-1, 1392, 12, 12]           2,784\n","            SiLU-268         [-1, 1392, 12, 12]               0\n","          Conv2d-269         [-1, 1392, 12, 12]          34,800\n","     BatchNorm2d-270         [-1, 1392, 12, 12]           2,784\n","            SiLU-271         [-1, 1392, 12, 12]               0\n","          Conv2d-272             [-1, 58, 1, 1]          80,794\n","            SiLU-273             [-1, 58, 1, 1]               0\n","          Conv2d-274           [-1, 1392, 1, 1]          82,128\n","         Sigmoid-275           [-1, 1392, 1, 1]               0\n","   SqueezeExcite-276         [-1, 1392, 12, 12]               0\n","          Conv2d-277          [-1, 232, 12, 12]         322,944\n","     BatchNorm2d-278          [-1, 232, 12, 12]             464\n","InvertedResidual-279          [-1, 232, 12, 12]               0\n","          Conv2d-280         [-1, 1392, 12, 12]         322,944\n","     BatchNorm2d-281         [-1, 1392, 12, 12]           2,784\n","            SiLU-282         [-1, 1392, 12, 12]               0\n","          Conv2d-283         [-1, 1392, 12, 12]          34,800\n","     BatchNorm2d-284         [-1, 1392, 12, 12]           2,784\n","            SiLU-285         [-1, 1392, 12, 12]               0\n","          Conv2d-286             [-1, 58, 1, 1]          80,794\n","            SiLU-287             [-1, 58, 1, 1]               0\n","          Conv2d-288           [-1, 1392, 1, 1]          82,128\n","         Sigmoid-289           [-1, 1392, 1, 1]               0\n","   SqueezeExcite-290         [-1, 1392, 12, 12]               0\n","          Conv2d-291          [-1, 232, 12, 12]         322,944\n","     BatchNorm2d-292          [-1, 232, 12, 12]             464\n","InvertedResidual-293          [-1, 232, 12, 12]               0\n","          Conv2d-294         [-1, 1392, 12, 12]         322,944\n","     BatchNorm2d-295         [-1, 1392, 12, 12]           2,784\n","            SiLU-296         [-1, 1392, 12, 12]               0\n","          Conv2d-297         [-1, 1392, 12, 12]          34,800\n","     BatchNorm2d-298         [-1, 1392, 12, 12]           2,784\n","            SiLU-299         [-1, 1392, 12, 12]               0\n","          Conv2d-300             [-1, 58, 1, 1]          80,794\n","            SiLU-301             [-1, 58, 1, 1]               0\n","          Conv2d-302           [-1, 1392, 1, 1]          82,128\n","         Sigmoid-303           [-1, 1392, 1, 1]               0\n","   SqueezeExcite-304         [-1, 1392, 12, 12]               0\n","          Conv2d-305          [-1, 232, 12, 12]         322,944\n","     BatchNorm2d-306          [-1, 232, 12, 12]             464\n","InvertedResidual-307          [-1, 232, 12, 12]               0\n","          Conv2d-308         [-1, 1392, 12, 12]         322,944\n","     BatchNorm2d-309         [-1, 1392, 12, 12]           2,784\n","            SiLU-310         [-1, 1392, 12, 12]               0\n","          Conv2d-311         [-1, 1392, 12, 12]          34,800\n","     BatchNorm2d-312         [-1, 1392, 12, 12]           2,784\n","            SiLU-313         [-1, 1392, 12, 12]               0\n","          Conv2d-314             [-1, 58, 1, 1]          80,794\n","            SiLU-315             [-1, 58, 1, 1]               0\n","          Conv2d-316           [-1, 1392, 1, 1]          82,128\n","         Sigmoid-317           [-1, 1392, 1, 1]               0\n","   SqueezeExcite-318         [-1, 1392, 12, 12]               0\n","          Conv2d-319          [-1, 232, 12, 12]         322,944\n","     BatchNorm2d-320          [-1, 232, 12, 12]             464\n","InvertedResidual-321          [-1, 232, 12, 12]               0\n","          Conv2d-322         [-1, 1392, 12, 12]         322,944\n","     BatchNorm2d-323         [-1, 1392, 12, 12]           2,784\n","            SiLU-324         [-1, 1392, 12, 12]               0\n","          Conv2d-325         [-1, 1392, 12, 12]          34,800\n","     BatchNorm2d-326         [-1, 1392, 12, 12]           2,784\n","            SiLU-327         [-1, 1392, 12, 12]               0\n","          Conv2d-328             [-1, 58, 1, 1]          80,794\n","            SiLU-329             [-1, 58, 1, 1]               0\n","          Conv2d-330           [-1, 1392, 1, 1]          82,128\n","         Sigmoid-331           [-1, 1392, 1, 1]               0\n","   SqueezeExcite-332         [-1, 1392, 12, 12]               0\n","          Conv2d-333          [-1, 232, 12, 12]         322,944\n","     BatchNorm2d-334          [-1, 232, 12, 12]             464\n","InvertedResidual-335          [-1, 232, 12, 12]               0\n","          Conv2d-336         [-1, 1392, 12, 12]         322,944\n","     BatchNorm2d-337         [-1, 1392, 12, 12]           2,784\n","            SiLU-338         [-1, 1392, 12, 12]               0\n","          Conv2d-339         [-1, 1392, 12, 12]          12,528\n","     BatchNorm2d-340         [-1, 1392, 12, 12]           2,784\n","            SiLU-341         [-1, 1392, 12, 12]               0\n","          Conv2d-342             [-1, 58, 1, 1]          80,794\n","            SiLU-343             [-1, 58, 1, 1]               0\n","          Conv2d-344           [-1, 1392, 1, 1]          82,128\n","         Sigmoid-345           [-1, 1392, 1, 1]               0\n","   SqueezeExcite-346         [-1, 1392, 12, 12]               0\n","          Conv2d-347          [-1, 384, 12, 12]         534,528\n","     BatchNorm2d-348          [-1, 384, 12, 12]             768\n","InvertedResidual-349          [-1, 384, 12, 12]               0\n","          Conv2d-350         [-1, 2304, 12, 12]         884,736\n","     BatchNorm2d-351         [-1, 2304, 12, 12]           4,608\n","            SiLU-352         [-1, 2304, 12, 12]               0\n","          Conv2d-353         [-1, 2304, 12, 12]          20,736\n","     BatchNorm2d-354         [-1, 2304, 12, 12]           4,608\n","            SiLU-355         [-1, 2304, 12, 12]               0\n","          Conv2d-356             [-1, 96, 1, 1]         221,280\n","            SiLU-357             [-1, 96, 1, 1]               0\n","          Conv2d-358           [-1, 2304, 1, 1]         223,488\n","         Sigmoid-359           [-1, 2304, 1, 1]               0\n","   SqueezeExcite-360         [-1, 2304, 12, 12]               0\n","          Conv2d-361          [-1, 384, 12, 12]         884,736\n","     BatchNorm2d-362          [-1, 384, 12, 12]             768\n","InvertedResidual-363          [-1, 384, 12, 12]               0\n","          Conv2d-364         [-1, 1536, 12, 12]         589,824\n","     BatchNorm2d-365         [-1, 1536, 12, 12]           3,072\n","            SiLU-366         [-1, 1536, 12, 12]               0\n","AdaptiveAvgPool2d-367           [-1, 1536, 1, 1]               0\n","         Flatten-368                 [-1, 1536]               0\n","SelectAdaptivePool2d-369                 [-1, 1536]               0\n","          Linear-370                    [-1, 2]           3,074\n","================================================================\n","Total params: 10,699,306\n","Trainable params: 10,699,306\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 996.83\n","Params size (MB): 40.81\n","Estimated Total Size (MB): 1039.33\n","----------------------------------------------------------------\n","model : efficientnet_b3_384_401_PT_lf05_b4_warwick_CLS\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 5 minibatch: 1      time used: 0.9802300930023193\n","minibatch AVG loss: 2.410310411453247\n","Epoch: 1     train index of 5 minibatch: 2      time used: 0.7062947750091553\n","minibatch AVG loss: 2.9628233909606934\n","Epoch: 1     train index of 5 minibatch: 3      time used: 0.7061502933502197\n","minibatch AVG loss: 2.8369951486587524\n","\n","Epoch: 1  train \n","Loss: 2.5640  Acc: 36.2319\n","negative precision: 23.0769  recall: 20.0000\n","negative sensitivity: 20.0000  specificity: 48.7179\n","negative FPR: 51.2821  NPV: 44.1860\n","negative TP: 6.0\n","negative TN: 19.0\n","negative FP: 20.0\n","negative FN: 24.0\n","positive precision: 44.1860  recall: 48.7179\n","positive sensitivity: 48.7179  specificity: 20.0000\n","positive FPR: 80.0000  NPV: 23.0769\n","positive TP: 19.0\n","positive TN: 6.0\n","positive FP: 24.0\n","positive FN: 20.0\n","\n","\n","\n","Epoch: 1  val \n","Loss: 2.4276  Acc: 31.2500\n","negative precision: 25.0000  recall: 28.5714\n","negative sensitivity: 28.5714  specificity: 33.3333\n","negative FPR: 66.6667  NPV: 37.5000\n","negative TP: 2.0\n","negative TN: 3.0\n","negative FP: 6.0\n","negative FN: 5.0\n","positive precision: 37.5000  recall: 33.3333\n","positive sensitivity: 33.3333  specificity: 28.5714\n","positive FPR: 71.4286  NPV: 25.0000\n","positive TP: 3.0\n","positive TN: 2.0\n","positive FP: 5.0\n","positive FN: 6.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 5 minibatch: 1      time used: 0.9516794681549072\n","minibatch AVG loss: 1.7587414979934692\n","Epoch: 2     train index of 5 minibatch: 2      time used: 0.7184698581695557\n","minibatch AVG loss: 1.9839859463274478\n","Epoch: 2     train index of 5 minibatch: 3      time used: 0.7130711078643799\n","minibatch AVG loss: 1.5009438246488571\n","\n","Epoch: 2  train \n","Loss: 1.6393  Acc: 52.1739\n","negative precision: 45.4545  recall: 50.0000\n","negative sensitivity: 50.0000  specificity: 53.8462\n","negative FPR: 46.1538  NPV: 58.3333\n","negative TP: 15.0\n","negative TN: 21.0\n","negative FP: 18.0\n","negative FN: 15.0\n","positive precision: 58.3333  recall: 53.8462\n","positive sensitivity: 53.8462  specificity: 50.0000\n","positive FPR: 50.0000  NPV: 45.4545\n","positive TP: 21.0\n","positive TN: 15.0\n","positive FP: 15.0\n","positive FN: 18.0\n","\n","\n","\n","Epoch: 2  val \n","Loss: 1.5722  Acc: 50.0000\n","negative precision: 44.4444  recall: 57.1429\n","negative sensitivity: 57.1429  specificity: 44.4444\n","negative FPR: 55.5556  NPV: 57.1429\n","negative TP: 4.0\n","negative TN: 4.0\n","negative FP: 5.0\n","negative FN: 3.0\n","positive precision: 57.1429  recall: 44.4444\n","positive sensitivity: 44.4444  specificity: 57.1429\n","positive FPR: 42.8571  NPV: 44.4444\n","positive TP: 4.0\n","positive TN: 4.0\n","positive FP: 3.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 5 minibatch: 1      time used: 0.9455816745758057\n","minibatch AVG loss: 1.5847307682037353\n","Epoch: 3     train index of 5 minibatch: 2      time used: 0.7129955291748047\n","minibatch AVG loss: 1.4080913990736008\n","Epoch: 3     train index of 5 minibatch: 3      time used: 0.7009971141815186\n","minibatch AVG loss: 1.6613094329833984\n","\n","Epoch: 3  train \n","Loss: 1.3627  Acc: 62.3188\n","negative precision: 57.1429  recall: 53.3333\n","negative sensitivity: 53.3333  specificity: 69.2308\n","negative FPR: 30.7692  NPV: 65.8537\n","negative TP: 16.0\n","negative TN: 27.0\n","negative FP: 12.0\n","negative FN: 14.0\n","positive precision: 65.8537  recall: 69.2308\n","positive sensitivity: 69.2308  specificity: 53.3333\n","positive FPR: 46.6667  NPV: 57.1429\n","positive TP: 27.0\n","positive TN: 16.0\n","positive FP: 14.0\n","positive FN: 12.0\n","\n","\n","\n","Epoch: 3  val \n","Loss: 1.8605  Acc: 50.0000\n","negative precision: 42.8571  recall: 42.8571\n","negative sensitivity: 42.8571  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 55.5556\n","negative TP: 3.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 4.0\n","positive precision: 55.5556  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 42.8571\n","positive FPR: 57.1429  NPV: 42.8571\n","positive TP: 5.0\n","positive TN: 3.0\n","positive FP: 4.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 5 minibatch: 1      time used: 0.9841735363006592\n","minibatch AVG loss: 1.49195636510849\n","Epoch: 4     train index of 5 minibatch: 2      time used: 0.716099739074707\n","minibatch AVG loss: 1.9484259724617004\n","Epoch: 4     train index of 5 minibatch: 3      time used: 0.7094879150390625\n","minibatch AVG loss: 1.147520622611046\n","\n","Epoch: 4  train \n","Loss: 1.4160  Acc: 56.5217\n","negative precision: 50.0000  recall: 43.3333\n","negative sensitivity: 43.3333  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 60.4651\n","negative TP: 13.0\n","negative TN: 26.0\n","negative FP: 13.0\n","negative FN: 17.0\n","positive precision: 60.4651  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 43.3333\n","positive FPR: 56.6667  NPV: 50.0000\n","positive TP: 26.0\n","positive TN: 13.0\n","positive FP: 17.0\n","positive FN: 13.0\n","\n","\n","\n","Epoch: 4  val \n","Loss: 1.3809  Acc: 62.5000\n","negative precision: 55.5556  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 71.4286\n","negative TP: 5.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 2.0\n","positive precision: 71.4286  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 55.5556\n","positive TP: 5.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 5 minibatch: 1      time used: 0.9384746551513672\n","minibatch AVG loss: 0.4023712486028671\n","Epoch: 5     train index of 5 minibatch: 2      time used: 0.7059187889099121\n","minibatch AVG loss: 1.3793961849063634\n","Epoch: 5     train index of 5 minibatch: 3      time used: 0.6994075775146484\n","minibatch AVG loss: 0.6489801853895187\n","\n","Epoch: 5  train \n","Loss: 0.7414  Acc: 76.8116\n","negative precision: 75.0000  recall: 70.0000\n","negative sensitivity: 70.0000  specificity: 82.0513\n","negative FPR: 17.9487  NPV: 78.0488\n","negative TP: 21.0\n","negative TN: 32.0\n","negative FP: 7.0\n","negative FN: 9.0\n","positive precision: 78.0488  recall: 82.0513\n","positive sensitivity: 82.0513  specificity: 70.0000\n","positive FPR: 30.0000  NPV: 75.0000\n","positive TP: 32.0\n","positive TN: 21.0\n","positive FP: 9.0\n","positive FN: 7.0\n","\n","\n","\n","Epoch: 5  val \n","Loss: 1.6570  Acc: 43.7500\n","negative precision: 40.0000  recall: 57.1429\n","negative sensitivity: 57.1429  specificity: 33.3333\n","negative FPR: 66.6667  NPV: 50.0000\n","negative TP: 4.0\n","negative TN: 3.0\n","negative FP: 6.0\n","negative FN: 3.0\n","positive precision: 50.0000  recall: 33.3333\n","positive sensitivity: 33.3333  specificity: 57.1429\n","positive FPR: 42.8571  NPV: 40.0000\n","positive TP: 3.0\n","positive TN: 4.0\n","positive FP: 3.0\n","positive FN: 6.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 5 minibatch: 1      time used: 0.9534585475921631\n","minibatch AVG loss: 0.9479356415569782\n","Epoch: 6     train index of 5 minibatch: 2      time used: 0.7168662548065186\n","minibatch AVG loss: 0.7650956869125366\n","Epoch: 6     train index of 5 minibatch: 3      time used: 0.7054116725921631\n","minibatch AVG loss: 0.6667137108743191\n","\n","Epoch: 6  train \n","Loss: 0.7286  Acc: 69.5652\n","negative precision: 68.0000  recall: 56.6667\n","negative sensitivity: 56.6667  specificity: 79.4872\n","negative FPR: 20.5128  NPV: 70.4545\n","negative TP: 17.0\n","negative TN: 31.0\n","negative FP: 8.0\n","negative FN: 13.0\n","positive precision: 70.4545  recall: 79.4872\n","positive sensitivity: 79.4872  specificity: 56.6667\n","positive FPR: 43.3333  NPV: 68.0000\n","positive TP: 31.0\n","positive TN: 17.0\n","positive FP: 13.0\n","positive FN: 8.0\n","\n","\n","\n","Epoch: 6  val \n","Loss: 1.7572  Acc: 50.0000\n","negative precision: 44.4444  recall: 57.1429\n","negative sensitivity: 57.1429  specificity: 44.4444\n","negative FPR: 55.5556  NPV: 57.1429\n","negative TP: 4.0\n","negative TN: 4.0\n","negative FP: 5.0\n","negative FN: 3.0\n","positive precision: 57.1429  recall: 44.4444\n","positive sensitivity: 44.4444  specificity: 57.1429\n","positive FPR: 42.8571  NPV: 44.4444\n","positive TP: 4.0\n","positive TN: 4.0\n","positive FP: 3.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 5 minibatch: 1      time used: 0.957892894744873\n","minibatch AVG loss: 1.077706792205572\n","Epoch: 7     train index of 5 minibatch: 2      time used: 0.7195713520050049\n","minibatch AVG loss: 1.3832548074424267\n","Epoch: 7     train index of 5 minibatch: 3      time used: 0.7140095233917236\n","minibatch AVG loss: 0.7523982360959053\n","\n","Epoch: 7  train \n","Loss: 1.1456  Acc: 62.3188\n","negative precision: 56.6667  recall: 56.6667\n","negative sensitivity: 56.6667  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 66.6667\n","negative TP: 17.0\n","negative TN: 26.0\n","negative FP: 13.0\n","negative FN: 13.0\n","positive precision: 66.6667  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 56.6667\n","positive FPR: 43.3333  NPV: 56.6667\n","positive TP: 26.0\n","positive TN: 17.0\n","positive FP: 13.0\n","positive FN: 13.0\n","\n","\n","\n","Epoch: 7  val \n","Loss: 1.1928  Acc: 43.7500\n","negative precision: 37.5000  recall: 42.8571\n","negative sensitivity: 42.8571  specificity: 44.4444\n","negative FPR: 55.5556  NPV: 50.0000\n","negative TP: 3.0\n","negative TN: 4.0\n","negative FP: 5.0\n","negative FN: 4.0\n","positive precision: 50.0000  recall: 44.4444\n","positive sensitivity: 44.4444  specificity: 42.8571\n","positive FPR: 57.1429  NPV: 37.5000\n","positive TP: 4.0\n","positive TN: 3.0\n","positive FP: 4.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 5 minibatch: 1      time used: 0.9564285278320312\n","minibatch AVG loss: 0.45760601218789815\n","Epoch: 8     train index of 5 minibatch: 2      time used: 0.7223970890045166\n","minibatch AVG loss: 1.2398601949214936\n","Epoch: 8     train index of 5 minibatch: 3      time used: 0.7102756500244141\n","minibatch AVG loss: 1.0950034856796265\n","\n","Epoch: 8  train \n","Loss: 0.9118  Acc: 68.1159\n","negative precision: 62.5000  recall: 66.6667\n","negative sensitivity: 66.6667  specificity: 69.2308\n","negative FPR: 30.7692  NPV: 72.9730\n","negative TP: 20.0\n","negative TN: 27.0\n","negative FP: 12.0\n","negative FN: 10.0\n","positive precision: 72.9730  recall: 69.2308\n","positive sensitivity: 69.2308  specificity: 66.6667\n","positive FPR: 33.3333  NPV: 62.5000\n","positive TP: 27.0\n","positive TN: 20.0\n","positive FP: 10.0\n","positive FN: 12.0\n","\n","\n","\n","Epoch: 8  val \n","Loss: 0.9393  Acc: 56.2500\n","negative precision: 50.0000  recall: 57.1429\n","negative sensitivity: 57.1429  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 62.5000\n","negative TP: 4.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 3.0\n","positive precision: 62.5000  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 57.1429\n","positive FPR: 42.8571  NPV: 50.0000\n","positive TP: 5.0\n","positive TN: 4.0\n","positive FP: 3.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 5 minibatch: 1      time used: 0.9309835433959961\n","minibatch AVG loss: 0.35004555694758893\n","Epoch: 9     train index of 5 minibatch: 2      time used: 0.7033617496490479\n","minibatch AVG loss: 0.7644126042723656\n","Epoch: 9     train index of 5 minibatch: 3      time used: 0.705482006072998\n","minibatch AVG loss: 0.6735442072153092\n","\n","Epoch: 9  train \n","Loss: 0.5751  Acc: 75.3623\n","negative precision: 69.6970  recall: 76.6667\n","negative sensitivity: 76.6667  specificity: 74.3590\n","negative FPR: 25.6410  NPV: 80.5556\n","negative TP: 23.0\n","negative TN: 29.0\n","negative FP: 10.0\n","negative FN: 7.0\n","positive precision: 80.5556  recall: 74.3590\n","positive sensitivity: 74.3590  specificity: 76.6667\n","positive FPR: 23.3333  NPV: 69.6970\n","positive TP: 29.0\n","positive TN: 23.0\n","positive FP: 7.0\n","positive FN: 10.0\n","\n","\n","\n","Epoch: 9  val \n","Loss: 0.9942  Acc: 62.5000\n","negative precision: 55.5556  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 71.4286\n","negative TP: 5.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 2.0\n","positive precision: 71.4286  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 55.5556\n","positive TP: 5.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 5 minibatch: 1      time used: 0.9477198123931885\n","minibatch AVG loss: 0.6549426659941673\n","Epoch: 10     train index of 5 minibatch: 2      time used: 0.7033998966217041\n","minibatch AVG loss: 0.5719591461122036\n","Epoch: 10     train index of 5 minibatch: 3      time used: 0.6996092796325684\n","minibatch AVG loss: 0.6598685942590237\n","\n","Epoch: 10  train \n","Loss: 0.5784  Acc: 79.7101\n","negative precision: 76.6667  recall: 76.6667\n","negative sensitivity: 76.6667  specificity: 82.0513\n","negative FPR: 17.9487  NPV: 82.0513\n","negative TP: 23.0\n","negative TN: 32.0\n","negative FP: 7.0\n","negative FN: 7.0\n","positive precision: 82.0513  recall: 82.0513\n","positive sensitivity: 82.0513  specificity: 76.6667\n","positive FPR: 23.3333  NPV: 76.6667\n","positive TP: 32.0\n","positive TN: 23.0\n","positive FP: 7.0\n","positive FN: 7.0\n","\n","\n","\n","Epoch: 10  val \n","Loss: 0.8257  Acc: 56.2500\n","negative precision: 50.0000  recall: 57.1429\n","negative sensitivity: 57.1429  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 62.5000\n","negative TP: 4.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 3.0\n","positive precision: 62.5000  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 57.1429\n","positive FPR: 42.8571  NPV: 50.0000\n","positive TP: 5.0\n","positive TN: 4.0\n","positive FP: 3.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 5 minibatch: 1      time used: 0.9551506042480469\n","minibatch AVG loss: 1.0483607657253742\n","Epoch: 11     train index of 5 minibatch: 2      time used: 0.7060022354125977\n","minibatch AVG loss: 0.21653176173567773\n","Epoch: 11     train index of 5 minibatch: 3      time used: 0.7020211219787598\n","minibatch AVG loss: 0.6863748475909233\n","\n","Epoch: 11  train \n","Loss: 0.6174  Acc: 79.7101\n","negative precision: 80.7692  recall: 70.0000\n","negative sensitivity: 70.0000  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 79.0698\n","negative TP: 21.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 9.0\n","positive precision: 79.0698  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 70.0000\n","positive FPR: 30.0000  NPV: 80.7692\n","positive TP: 34.0\n","positive TN: 21.0\n","positive FP: 9.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 11  val \n","Loss: 1.0655  Acc: 68.7500\n","negative precision: 62.5000  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 75.0000\n","negative TP: 5.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 2.0\n","positive precision: 75.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 62.5000\n","positive TP: 6.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 5 minibatch: 1      time used: 0.9398813247680664\n","minibatch AVG loss: 0.3112336441874504\n","Epoch: 12     train index of 5 minibatch: 2      time used: 0.7099900245666504\n","minibatch AVG loss: 0.9818929187953472\n","Epoch: 12     train index of 5 minibatch: 3      time used: 0.6999409198760986\n","minibatch AVG loss: 0.9796304058283567\n","\n","Epoch: 12  train \n","Loss: 0.6904  Acc: 81.1594\n","negative precision: 79.3103  recall: 76.6667\n","negative sensitivity: 76.6667  specificity: 84.6154\n","negative FPR: 15.3846  NPV: 82.5000\n","negative TP: 23.0\n","negative TN: 33.0\n","negative FP: 6.0\n","negative FN: 7.0\n","positive precision: 82.5000  recall: 84.6154\n","positive sensitivity: 84.6154  specificity: 76.6667\n","positive FPR: 23.3333  NPV: 79.3103\n","positive TP: 33.0\n","positive TN: 23.0\n","positive FP: 7.0\n","positive FN: 6.0\n","\n","\n","\n","Epoch: 12  val \n","Loss: 0.9257  Acc: 68.7500\n","negative precision: 62.5000  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 75.0000\n","negative TP: 5.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 2.0\n","positive precision: 75.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 62.5000\n","positive TP: 6.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 5 minibatch: 1      time used: 0.9408817291259766\n","minibatch AVG loss: 0.16620483845472336\n","Epoch: 13     train index of 5 minibatch: 2      time used: 0.7156977653503418\n","minibatch AVG loss: 0.3755542105063796\n","Epoch: 13     train index of 5 minibatch: 3      time used: 0.7057645320892334\n","minibatch AVG loss: 0.6062726221978665\n","\n","Epoch: 13  train \n","Loss: 0.3444  Acc: 85.5072\n","negative precision: 85.7143  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 85.3659\n","negative TP: 24.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 6.0\n","positive precision: 85.3659  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 85.7143\n","positive TP: 35.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 13  val \n","Loss: 0.9512  Acc: 62.5000\n","negative precision: 55.5556  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 71.4286\n","negative TP: 5.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 2.0\n","positive precision: 71.4286  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 55.5556\n","positive TP: 5.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 5 minibatch: 1      time used: 0.9335501194000244\n","minibatch AVG loss: 0.983877545595169\n","Epoch: 14     train index of 5 minibatch: 2      time used: 0.7112915515899658\n","minibatch AVG loss: 0.3282375218346715\n","Epoch: 14     train index of 5 minibatch: 3      time used: 0.7100870609283447\n","minibatch AVG loss: 0.16948100682348013\n","\n","Epoch: 14  train \n","Loss: 0.4773  Acc: 78.2609\n","negative precision: 77.7778  recall: 70.0000\n","negative sensitivity: 70.0000  specificity: 84.6154\n","negative FPR: 15.3846  NPV: 78.5714\n","negative TP: 21.0\n","negative TN: 33.0\n","negative FP: 6.0\n","negative FN: 9.0\n","positive precision: 78.5714  recall: 84.6154\n","positive sensitivity: 84.6154  specificity: 70.0000\n","positive FPR: 30.0000  NPV: 77.7778\n","positive TP: 33.0\n","positive TN: 21.0\n","positive FP: 9.0\n","positive FN: 6.0\n","\n","\n","\n","Epoch: 14  val \n","Loss: 0.7675  Acc: 75.0000\n","negative precision: 63.6364  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 63.6364\n","positive TP: 5.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 5 minibatch: 1      time used: 0.9486033916473389\n","minibatch AVG loss: 1.0133042864501476\n","Epoch: 15     train index of 5 minibatch: 2      time used: 0.7103517055511475\n","minibatch AVG loss: 0.5924898969009519\n","Epoch: 15     train index of 5 minibatch: 3      time used: 0.7069013118743896\n","minibatch AVG loss: 0.11125229448080062\n","\n","Epoch: 15  train \n","Loss: 0.5422  Acc: 84.0580\n","negative precision: 82.7586  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 85.0000\n","negative TP: 24.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 6.0\n","positive precision: 85.0000  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 82.7586\n","positive TP: 34.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 15  val \n","Loss: 0.3793  Acc: 87.5000\n","negative precision: 85.7143  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 88.8889\n","negative TP: 6.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 1.0\n","positive precision: 88.8889  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 85.7143\n","positive TP: 8.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 5 minibatch: 1      time used: 0.9413719177246094\n","minibatch AVG loss: 0.6798612520098686\n","Epoch: 16     train index of 5 minibatch: 2      time used: 0.7061727046966553\n","minibatch AVG loss: 0.2974946377798915\n","Epoch: 16     train index of 5 minibatch: 3      time used: 0.7112104892730713\n","minibatch AVG loss: 0.9538199938833714\n","\n","Epoch: 16  train \n","Loss: 0.6052  Acc: 84.0580\n","negative precision: 85.1852  recall: 76.6667\n","negative sensitivity: 76.6667  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 83.3333\n","negative TP: 23.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 7.0\n","positive precision: 83.3333  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 76.6667\n","positive FPR: 23.3333  NPV: 85.1852\n","positive TP: 35.0\n","positive TN: 23.0\n","positive FP: 7.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 16  val \n","Loss: 0.3839  Acc: 75.0000\n","negative precision: 71.4286  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 77.7778\n","negative FPR: 22.2222  NPV: 77.7778\n","negative TP: 5.0\n","negative TN: 7.0\n","negative FP: 2.0\n","negative FN: 2.0\n","positive precision: 77.7778  recall: 77.7778\n","positive sensitivity: 77.7778  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 71.4286\n","positive TP: 7.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 5 minibatch: 1      time used: 0.9545872211456299\n","minibatch AVG loss: 0.41840397026389836\n","Epoch: 17     train index of 5 minibatch: 2      time used: 0.7048051357269287\n","minibatch AVG loss: 0.26176716610789297\n","Epoch: 17     train index of 5 minibatch: 3      time used: 0.7063841819763184\n","minibatch AVG loss: 0.5571517277508974\n","\n","Epoch: 17  train \n","Loss: 0.5317  Acc: 76.8116\n","negative precision: 73.3333  recall: 73.3333\n","negative sensitivity: 73.3333  specificity: 79.4872\n","negative FPR: 20.5128  NPV: 79.4872\n","negative TP: 22.0\n","negative TN: 31.0\n","negative FP: 8.0\n","negative FN: 8.0\n","positive precision: 79.4872  recall: 79.4872\n","positive sensitivity: 79.4872  specificity: 73.3333\n","positive FPR: 26.6667  NPV: 73.3333\n","positive TP: 31.0\n","positive TN: 22.0\n","positive FP: 8.0\n","positive FN: 8.0\n","\n","\n","\n","Epoch: 17  val \n","Loss: 0.7110  Acc: 62.5000\n","negative precision: 55.5556  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 71.4286\n","negative TP: 5.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 2.0\n","positive precision: 71.4286  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 55.5556\n","positive TP: 5.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 5 minibatch: 1      time used: 0.9511332511901855\n","minibatch AVG loss: 0.12968377233482897\n","Epoch: 18     train index of 5 minibatch: 2      time used: 0.7110836505889893\n","minibatch AVG loss: 0.2837560587562621\n","Epoch: 18     train index of 5 minibatch: 3      time used: 0.715191125869751\n","minibatch AVG loss: 0.2567027471261099\n","\n","Epoch: 18  train \n","Loss: 0.1991  Acc: 89.8551\n","negative precision: 87.0968  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 92.1053\n","negative TP: 27.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 3.0\n","positive precision: 92.1053  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 87.0968\n","positive TP: 35.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 18  val \n","Loss: 0.7130  Acc: 68.7500\n","negative precision: 60.0000  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 83.3333\n","negative TP: 6.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 1.0\n","positive precision: 83.3333  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 60.0000\n","positive TP: 5.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 5 minibatch: 1      time used: 0.9477243423461914\n","minibatch AVG loss: 0.3961308941245079\n","Epoch: 19     train index of 5 minibatch: 2      time used: 0.7100508213043213\n","minibatch AVG loss: 0.5591788785532117\n","Epoch: 19     train index of 5 minibatch: 3      time used: 0.7023830413818359\n","minibatch AVG loss: 0.4059081896673888\n","\n","Epoch: 19  train \n","Loss: 0.4297  Acc: 85.5072\n","negative precision: 81.2500  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 84.6154\n","negative FPR: 15.3846  NPV: 89.1892\n","negative TP: 26.0\n","negative TN: 33.0\n","negative FP: 6.0\n","negative FN: 4.0\n","positive precision: 89.1892  recall: 84.6154\n","positive sensitivity: 84.6154  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 81.2500\n","positive TP: 33.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 6.0\n","\n","\n","\n","Epoch: 19  val \n","Loss: 0.5958  Acc: 75.0000\n","negative precision: 66.6667  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 85.7143\n","negative TP: 6.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 85.7143  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 66.6667\n","positive TP: 6.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 5 minibatch: 1      time used: 0.9475347995758057\n","minibatch AVG loss: 0.6287229895591736\n","Epoch: 20     train index of 5 minibatch: 2      time used: 0.715240478515625\n","minibatch AVG loss: 0.31866584792733194\n","Epoch: 20     train index of 5 minibatch: 3      time used: 0.706660270690918\n","minibatch AVG loss: 0.6368658389896155\n","\n","Epoch: 20  train \n","Loss: 0.4785  Acc: 84.0580\n","negative precision: 80.6452  recall: 83.3333\n","negative sensitivity: 83.3333  specificity: 84.6154\n","negative FPR: 15.3846  NPV: 86.8421\n","negative TP: 25.0\n","negative TN: 33.0\n","negative FP: 6.0\n","negative FN: 5.0\n","positive precision: 86.8421  recall: 84.6154\n","positive sensitivity: 84.6154  specificity: 83.3333\n","positive FPR: 16.6667  NPV: 80.6452\n","positive TP: 33.0\n","positive TN: 25.0\n","positive FP: 5.0\n","positive FN: 6.0\n","\n","\n","\n","Epoch: 20  val \n","Loss: 0.5087  Acc: 75.0000\n","negative precision: 66.6667  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 85.7143\n","negative TP: 6.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 85.7143  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 66.6667\n","positive TP: 6.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 5 minibatch: 1      time used: 0.945720911026001\n","minibatch AVG loss: 0.3445448995102197\n","Epoch: 21     train index of 5 minibatch: 2      time used: 0.7062227725982666\n","minibatch AVG loss: 0.31869428865611554\n","Epoch: 21     train index of 5 minibatch: 3      time used: 0.702033281326294\n","minibatch AVG loss: 0.2841323633911088\n","\n","Epoch: 21  train \n","Loss: 0.3048  Acc: 88.4058\n","negative precision: 86.6667  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 89.7436\n","negative TP: 26.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 4.0\n","positive precision: 89.7436  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 86.6667\n","positive TP: 35.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 21  val \n","Loss: 0.4605  Acc: 81.2500\n","negative precision: 70.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 70.0000\n","positive TP: 6.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 5 minibatch: 1      time used: 0.9541919231414795\n","minibatch AVG loss: 0.4770964469760656\n","Epoch: 22     train index of 5 minibatch: 2      time used: 0.7058978080749512\n","minibatch AVG loss: 0.7383672626689076\n","Epoch: 22     train index of 5 minibatch: 3      time used: 0.7087557315826416\n","minibatch AVG loss: 0.3200307788327336\n","\n","Epoch: 22  train \n","Loss: 0.4660  Acc: 82.6087\n","negative precision: 82.1429  recall: 76.6667\n","negative sensitivity: 76.6667  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 82.9268\n","negative TP: 23.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 7.0\n","positive precision: 82.9268  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 76.6667\n","positive FPR: 23.3333  NPV: 82.1429\n","positive TP: 34.0\n","positive TN: 23.0\n","positive FP: 7.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 22  val \n","Loss: 0.4113  Acc: 75.0000\n","negative precision: 63.6364  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 63.6364\n","positive TP: 5.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 5 minibatch: 1      time used: 0.9558398723602295\n","minibatch AVG loss: 0.3265631631016731\n","Epoch: 23     train index of 5 minibatch: 2      time used: 0.7124590873718262\n","minibatch AVG loss: 0.11211353726685047\n","Epoch: 23     train index of 5 minibatch: 3      time used: 0.7166101932525635\n","minibatch AVG loss: 0.2753061383962631\n","\n","Epoch: 23  train \n","Loss: 0.2260  Acc: 92.7536\n","negative precision: 90.3226  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 94.7368\n","negative TP: 28.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 2.0\n","positive precision: 94.7368  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 90.3226\n","positive TP: 36.0\n","positive TN: 28.0\n","positive FP: 2.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 23  val \n","Loss: 0.4616  Acc: 68.7500\n","negative precision: 62.5000  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 75.0000\n","negative TP: 5.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 2.0\n","positive precision: 75.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 62.5000\n","positive TP: 6.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 5 minibatch: 1      time used: 1.0292644500732422\n","minibatch AVG loss: 1.0100371301174165\n","Epoch: 24     train index of 5 minibatch: 2      time used: 0.6988017559051514\n","minibatch AVG loss: 0.10807929337024688\n","Epoch: 24     train index of 5 minibatch: 3      time used: 0.7058837413787842\n","minibatch AVG loss: 0.41087481416761873\n","\n","Epoch: 24  train \n","Loss: 0.4738  Acc: 86.9565\n","negative precision: 83.8710  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 89.4737\n","negative TP: 26.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 4.0\n","positive precision: 89.4737  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 83.8710\n","positive TP: 34.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 24  val \n","Loss: 0.4440  Acc: 75.0000\n","negative precision: 80.0000  recall: 57.1429\n","negative sensitivity: 57.1429  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 72.7273\n","negative TP: 4.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 3.0\n","positive precision: 72.7273  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 57.1429\n","positive FPR: 42.8571  NPV: 80.0000\n","positive TP: 8.0\n","positive TN: 4.0\n","positive FP: 3.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 5 minibatch: 1      time used: 1.033522367477417\n","minibatch AVG loss: 0.1965833527036011\n","Epoch: 25     train index of 5 minibatch: 2      time used: 0.7094488143920898\n","minibatch AVG loss: 0.32793390601873396\n","Epoch: 25     train index of 5 minibatch: 3      time used: 0.6998343467712402\n","minibatch AVG loss: 0.629382376279682\n","\n","Epoch: 25  train \n","Loss: 0.3907  Acc: 84.0580\n","negative precision: 85.1852  recall: 76.6667\n","negative sensitivity: 76.6667  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 83.3333\n","negative TP: 23.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 7.0\n","positive precision: 83.3333  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 76.6667\n","positive FPR: 23.3333  NPV: 85.1852\n","positive TP: 35.0\n","positive TN: 23.0\n","positive FP: 7.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 25  val \n","Loss: 0.4473  Acc: 75.0000\n","negative precision: 66.6667  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 85.7143\n","negative TP: 6.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 85.7143  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 66.6667\n","positive TP: 6.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 5 minibatch: 1      time used: 1.0247678756713867\n","minibatch AVG loss: 0.31340377060696484\n","Epoch: 26     train index of 5 minibatch: 2      time used: 0.7051026821136475\n","minibatch AVG loss: 0.26742716766893865\n","Epoch: 26     train index of 5 minibatch: 3      time used: 0.704810380935669\n","minibatch AVG loss: 0.3869900892546866\n","\n","Epoch: 26  train \n","Loss: 0.3723  Acc: 88.4058\n","negative precision: 84.3750  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 91.8919\n","negative TP: 27.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 3.0\n","positive precision: 91.8919  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 84.3750\n","positive TP: 34.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 26  val \n","Loss: 0.5904  Acc: 81.2500\n","negative precision: 70.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 70.0000\n","positive TP: 6.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 5 minibatch: 1      time used: 1.0331180095672607\n","minibatch AVG loss: 0.25477624088525774\n","Epoch: 27     train index of 5 minibatch: 2      time used: 0.7161474227905273\n","minibatch AVG loss: 0.1345471448265016\n","Epoch: 27     train index of 5 minibatch: 3      time used: 0.7101025581359863\n","minibatch AVG loss: 0.273923198133707\n","\n","Epoch: 27  train \n","Loss: 0.2128  Acc: 86.9565\n","negative precision: 83.8710  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 89.4737\n","negative TP: 26.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 4.0\n","positive precision: 89.4737  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 83.8710\n","positive TP: 34.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 27  val \n","Loss: 0.5980  Acc: 62.5000\n","negative precision: 54.5455  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 44.4444\n","negative FPR: 55.5556  NPV: 80.0000\n","negative TP: 6.0\n","negative TN: 4.0\n","negative FP: 5.0\n","negative FN: 1.0\n","positive precision: 80.0000  recall: 44.4444\n","positive sensitivity: 44.4444  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 54.5455\n","positive TP: 4.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 5 minibatch: 1      time used: 1.0341393947601318\n","minibatch AVG loss: 0.2433668216690421\n","Epoch: 28     train index of 5 minibatch: 2      time used: 0.7126080989837646\n","minibatch AVG loss: 0.05408108236151747\n","Epoch: 28     train index of 5 minibatch: 3      time used: 0.7092959880828857\n","minibatch AVG loss: 0.3561524746008217\n","\n","Epoch: 28  train \n","Loss: 0.2394  Acc: 89.8551\n","negative precision: 89.6552  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 90.0000\n","negative TP: 26.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 4.0\n","positive precision: 90.0000  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 89.6552\n","positive TP: 36.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 28  val \n","Loss: 0.6658  Acc: 75.0000\n","negative precision: 66.6667  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 85.7143\n","negative TP: 6.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 85.7143  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 66.6667\n","positive TP: 6.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 5 minibatch: 1      time used: 1.0443830490112305\n","minibatch AVG loss: 0.7526536908000707\n","Epoch: 29     train index of 5 minibatch: 2      time used: 0.7133359909057617\n","minibatch AVG loss: 0.8650241216644645\n","Epoch: 29     train index of 5 minibatch: 3      time used: 0.7085559368133545\n","minibatch AVG loss: 0.1329904834739864\n","\n","Epoch: 29  train \n","Loss: 0.5151  Acc: 85.5072\n","negative precision: 85.7143  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 85.3659\n","negative TP: 24.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 6.0\n","positive precision: 85.3659  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 85.7143\n","positive TP: 35.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 29  val \n","Loss: 0.5307  Acc: 75.0000\n","negative precision: 66.6667  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 85.7143\n","negative TP: 6.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 85.7143  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 66.6667\n","positive TP: 6.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 5 minibatch: 1      time used: 1.0577716827392578\n","minibatch AVG loss: 0.41253729797899724\n","Epoch: 30     train index of 5 minibatch: 2      time used: 0.716240406036377\n","minibatch AVG loss: 0.045818517729640004\n","Epoch: 30     train index of 5 minibatch: 3      time used: 0.710756778717041\n","minibatch AVG loss: 0.169835053011775\n","\n","Epoch: 30  train \n","Loss: 0.2371  Acc: 86.9565\n","negative precision: 86.2069  recall: 83.3333\n","negative sensitivity: 83.3333  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 87.5000\n","negative TP: 25.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 5.0\n","positive precision: 87.5000  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 83.3333\n","positive FPR: 16.6667  NPV: 86.2069\n","positive TP: 35.0\n","positive TN: 25.0\n","positive FP: 5.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 30  val \n","Loss: 0.4446  Acc: 87.5000\n","negative precision: 77.7778  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 77.7778\n","negative FPR: 22.2222  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 7.0\n","negative FP: 2.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 77.7778\n","positive sensitivity: 77.7778  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 77.7778\n","positive TP: 7.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 5 minibatch: 1      time used: 0.946143388748169\n","minibatch AVG loss: 0.21070765778422357\n","Epoch: 31     train index of 5 minibatch: 2      time used: 0.7061614990234375\n","minibatch AVG loss: 0.5111701539717615\n","Epoch: 31     train index of 5 minibatch: 3      time used: 0.7072947025299072\n","minibatch AVG loss: 0.11425474053248763\n","\n","Epoch: 31  train \n","Loss: 0.2487  Acc: 89.8551\n","negative precision: 87.0968  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 92.1053\n","negative TP: 27.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 3.0\n","positive precision: 92.1053  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 87.0968\n","positive TP: 35.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 31  val \n","Loss: 0.6097  Acc: 75.0000\n","negative precision: 66.6667  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 85.7143\n","negative TP: 6.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 85.7143  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 66.6667\n","positive TP: 6.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 5 minibatch: 1      time used: 0.9474525451660156\n","minibatch AVG loss: 0.06758483499288559\n","Epoch: 32     train index of 5 minibatch: 2      time used: 0.7140862941741943\n","minibatch AVG loss: 0.3268769094720483\n","Epoch: 32     train index of 5 minibatch: 3      time used: 0.7173855304718018\n","minibatch AVG loss: 0.09634122364223004\n","\n","Epoch: 32  train \n","Loss: 0.1732  Acc: 91.3043\n","negative precision: 90.0000  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 92.3077\n","negative TP: 27.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 3.0\n","positive precision: 92.3077  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 90.0000\n","positive TP: 36.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 32  val \n","Loss: 0.3616  Acc: 87.5000\n","negative precision: 77.7778  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 77.7778\n","negative FPR: 22.2222  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 7.0\n","negative FP: 2.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 77.7778\n","positive sensitivity: 77.7778  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 77.7778\n","positive TP: 7.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 5 minibatch: 1      time used: 0.9716792106628418\n","minibatch AVG loss: 0.4922400204464793\n","Epoch: 33     train index of 5 minibatch: 2      time used: 0.7080783843994141\n","minibatch AVG loss: 0.6254019029438496\n","Epoch: 33     train index of 5 minibatch: 3      time used: 0.7054579257965088\n","minibatch AVG loss: 0.2069286584854126\n","\n","Epoch: 33  train \n","Loss: 0.4473  Acc: 86.9565\n","negative precision: 88.8889  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 85.7143\n","negative TP: 24.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 6.0\n","positive precision: 85.7143  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 88.8889\n","positive TP: 36.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 33  val \n","Loss: 0.4085  Acc: 75.0000\n","negative precision: 66.6667  recall: 85.7143\n","negative sensitivity: 85.7143  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 85.7143\n","negative TP: 6.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 1.0\n","positive precision: 85.7143  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 85.7143\n","positive FPR: 14.2857  NPV: 66.6667\n","positive TP: 6.0\n","positive TN: 6.0\n","positive FP: 1.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 5 minibatch: 1      time used: 0.9521536827087402\n","minibatch AVG loss: 0.2464615455828607\n","Epoch: 34     train index of 5 minibatch: 2      time used: 0.7163362503051758\n","minibatch AVG loss: 0.18301194412633776\n","Epoch: 34     train index of 5 minibatch: 3      time used: 0.7093191146850586\n","minibatch AVG loss: 0.2846713168313727\n","\n","Epoch: 34  train \n","Loss: 0.3366  Acc: 86.9565\n","negative precision: 83.8710  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 89.4737\n","negative TP: 26.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 4.0\n","positive precision: 89.4737  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 83.8710\n","positive TP: 34.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 34  val \n","Loss: 0.5737  Acc: 75.0000\n","negative precision: 63.6364  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 63.6364\n","positive TP: 5.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 5 minibatch: 1      time used: 0.9536521434783936\n","minibatch AVG loss: 0.15008131740614772\n","Epoch: 35     train index of 5 minibatch: 2      time used: 0.7066357135772705\n","minibatch AVG loss: 0.18160864040255548\n","Epoch: 35     train index of 5 minibatch: 3      time used: 0.7074108123779297\n","minibatch AVG loss: 0.3146623827517033\n","\n","Epoch: 35  train \n","Loss: 0.2179  Acc: 88.4058\n","negative precision: 89.2857  recall: 83.3333\n","negative sensitivity: 83.3333  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 87.8049\n","negative TP: 25.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 5.0\n","positive precision: 87.8049  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 83.3333\n","positive FPR: 16.6667  NPV: 89.2857\n","positive TP: 36.0\n","positive TN: 25.0\n","positive FP: 5.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 35  val \n","Loss: 0.5436  Acc: 81.2500\n","negative precision: 70.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 70.0000\n","positive TP: 6.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 5 minibatch: 1      time used: 0.9488143920898438\n","minibatch AVG loss: 0.6313804395496845\n","Epoch: 36     train index of 5 minibatch: 2      time used: 0.7068758010864258\n","minibatch AVG loss: 0.07643123316811398\n","Epoch: 36     train index of 5 minibatch: 3      time used: 0.7024095058441162\n","minibatch AVG loss: 0.12186324623180553\n","\n","Epoch: 36  train \n","Loss: 0.2759  Acc: 92.7536\n","negative precision: 93.1034  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 92.5000\n","negative TP: 27.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 3.0\n","positive precision: 92.5000  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 93.1034\n","positive TP: 37.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 36  val \n","Loss: 0.5996  Acc: 81.2500\n","negative precision: 70.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 70.0000\n","positive TP: 6.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 5 minibatch: 1      time used: 0.9439232349395752\n","minibatch AVG loss: 0.2697993929730728\n","Epoch: 37     train index of 5 minibatch: 2      time used: 0.717799186706543\n","minibatch AVG loss: 0.3370068950622226\n","Epoch: 37     train index of 5 minibatch: 3      time used: 0.6956932544708252\n","minibatch AVG loss: 0.2664653092622757\n","\n","Epoch: 37  train \n","Loss: 0.2629  Acc: 92.7536\n","negative precision: 93.1034  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 92.5000\n","negative TP: 27.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 3.0\n","positive precision: 92.5000  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 93.1034\n","positive TP: 37.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 37  val \n","Loss: 0.4734  Acc: 75.0000\n","negative precision: 71.4286  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 77.7778\n","negative FPR: 22.2222  NPV: 77.7778\n","negative TP: 5.0\n","negative TN: 7.0\n","negative FP: 2.0\n","negative FN: 2.0\n","positive precision: 77.7778  recall: 77.7778\n","positive sensitivity: 77.7778  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 71.4286\n","positive TP: 7.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 5 minibatch: 1      time used: 0.9497947692871094\n","minibatch AVG loss: 0.3400552487699315\n","Epoch: 38     train index of 5 minibatch: 2      time used: 0.7072618007659912\n","minibatch AVG loss: 0.1356051571201533\n","Epoch: 38     train index of 5 minibatch: 3      time used: 0.702711820602417\n","minibatch AVG loss: 0.9370750175788999\n","\n","Epoch: 38  train \n","Loss: 0.4240  Acc: 89.8551\n","negative precision: 84.8485  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 94.4444\n","negative TP: 28.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 2.0\n","positive precision: 94.4444  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 84.8485\n","positive TP: 34.0\n","positive TN: 28.0\n","positive FP: 2.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 38  val \n","Loss: 0.2574  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 5 minibatch: 1      time used: 0.9502360820770264\n","minibatch AVG loss: 0.12964516412466764\n","Epoch: 39     train index of 5 minibatch: 2      time used: 0.7023634910583496\n","minibatch AVG loss: 0.08614494744688272\n","Epoch: 39     train index of 5 minibatch: 3      time used: 0.7164177894592285\n","minibatch AVG loss: 0.11978968428447842\n","\n","Epoch: 39  train \n","Loss: 0.1140  Acc: 94.2029\n","negative precision: 93.3333  recall: 93.3333\n","negative sensitivity: 93.3333  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 94.8718\n","negative TP: 28.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 2.0\n","positive precision: 94.8718  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 93.3333\n","positive FPR: 6.6667  NPV: 93.3333\n","positive TP: 37.0\n","positive TN: 28.0\n","positive FP: 2.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 39  val \n","Loss: 0.2518  Acc: 87.5000\n","negative precision: 77.7778  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 77.7778\n","negative FPR: 22.2222  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 7.0\n","negative FP: 2.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 77.7778\n","positive sensitivity: 77.7778  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 77.7778\n","positive TP: 7.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 5 minibatch: 1      time used: 0.9600687026977539\n","minibatch AVG loss: 0.4427723125554621\n","Epoch: 40     train index of 5 minibatch: 2      time used: 0.706618070602417\n","minibatch AVG loss: 0.14755374193191528\n","Epoch: 40     train index of 5 minibatch: 3      time used: 0.7026970386505127\n","minibatch AVG loss: 0.44549983288161454\n","\n","Epoch: 40  train \n","Loss: 0.3144  Acc: 89.8551\n","negative precision: 89.6552  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 90.0000\n","negative TP: 26.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 4.0\n","positive precision: 90.0000  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 89.6552\n","positive TP: 36.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 40  val \n","Loss: 0.2582  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 5 minibatch: 1      time used: 0.9620654582977295\n","minibatch AVG loss: 0.2122972534969449\n","Epoch: 41     train index of 5 minibatch: 2      time used: 0.7190485000610352\n","minibatch AVG loss: 0.7667643576860428\n","Epoch: 41     train index of 5 minibatch: 3      time used: 0.714641809463501\n","minibatch AVG loss: 0.6433787108398974\n","\n","Epoch: 41  train \n","Loss: 0.4994  Acc: 84.0580\n","negative precision: 82.7586  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 85.0000\n","negative TP: 24.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 6.0\n","positive precision: 85.0000  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 82.7586\n","positive TP: 34.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 41  val \n","Loss: 0.2568  Acc: 81.2500\n","negative precision: 70.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 70.0000\n","positive TP: 6.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 5 minibatch: 1      time used: 0.9597322940826416\n","minibatch AVG loss: 0.3129670374619309\n","Epoch: 42     train index of 5 minibatch: 2      time used: 0.7083265781402588\n","minibatch AVG loss: 0.35842560495948417\n","Epoch: 42     train index of 5 minibatch: 3      time used: 0.7143385410308838\n","minibatch AVG loss: 0.3648306503891945\n","\n","Epoch: 42  train \n","Loss: 0.3227  Acc: 86.9565\n","negative precision: 88.8889  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 92.3077\n","negative FPR: 7.6923  NPV: 85.7143\n","negative TP: 24.0\n","negative TN: 36.0\n","negative FP: 3.0\n","negative FN: 6.0\n","positive precision: 85.7143  recall: 92.3077\n","positive sensitivity: 92.3077  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 88.8889\n","positive TP: 36.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch: 42  val \n","Loss: 0.6327  Acc: 75.0000\n","negative precision: 63.6364  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 63.6364\n","positive TP: 5.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 5 minibatch: 1      time used: 0.9529421329498291\n","minibatch AVG loss: 0.2355412353761494\n","Epoch: 43     train index of 5 minibatch: 2      time used: 0.7158677577972412\n","minibatch AVG loss: 0.5318341757229064\n","Epoch: 43     train index of 5 minibatch: 3      time used: 0.7087736129760742\n","minibatch AVG loss: 0.2456863908097148\n","\n","Epoch: 43  train \n","Loss: 0.4042  Acc: 84.0580\n","negative precision: 80.6452  recall: 83.3333\n","negative sensitivity: 83.3333  specificity: 84.6154\n","negative FPR: 15.3846  NPV: 86.8421\n","negative TP: 25.0\n","negative TN: 33.0\n","negative FP: 6.0\n","negative FN: 5.0\n","positive precision: 86.8421  recall: 84.6154\n","positive sensitivity: 84.6154  specificity: 83.3333\n","positive FPR: 16.6667  NPV: 80.6452\n","positive TP: 33.0\n","positive TN: 25.0\n","positive FP: 5.0\n","positive FN: 6.0\n","\n","\n","\n","Epoch: 43  val \n","Loss: 0.3761  Acc: 75.0000\n","negative precision: 63.6364  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 55.5556\n","negative FPR: 44.4444  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 5.0\n","negative FP: 4.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 55.5556\n","positive sensitivity: 55.5556  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 63.6364\n","positive TP: 5.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 5 minibatch: 1      time used: 0.9711952209472656\n","minibatch AVG loss: 0.03658212395384908\n","Epoch: 44     train index of 5 minibatch: 2      time used: 0.7219622135162354\n","minibatch AVG loss: 0.38768925950862465\n","Epoch: 44     train index of 5 minibatch: 3      time used: 0.7111430168151855\n","minibatch AVG loss: 0.5508095613564364\n","\n","Epoch: 44  train \n","Loss: 0.2899  Acc: 88.4058\n","negative precision: 86.6667  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 89.7436\n","negative FPR: 10.2564  NPV: 89.7436\n","negative TP: 26.0\n","negative TN: 35.0\n","negative FP: 4.0\n","negative FN: 4.0\n","positive precision: 89.7436  recall: 89.7436\n","positive sensitivity: 89.7436  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 86.6667\n","positive TP: 35.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 4.0\n","\n","\n","\n","Epoch: 44  val \n","Loss: 0.5674  Acc: 81.2500\n","negative precision: 70.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 70.0000\n","positive TP: 6.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 5 minibatch: 1      time used: 0.9430773258209229\n","minibatch AVG loss: 0.4150947866379283\n","Epoch: 45     train index of 5 minibatch: 2      time used: 0.7111284732818604\n","minibatch AVG loss: 0.056307581934379416\n","Epoch: 45     train index of 5 minibatch: 3      time used: 0.7147860527038574\n","minibatch AVG loss: 0.08865854074247181\n","\n","Epoch: 45  train \n","Loss: 0.1693  Acc: 92.7536\n","negative precision: 93.1034  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 92.5000\n","negative TP: 27.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 3.0\n","positive precision: 92.5000  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 93.1034\n","positive TP: 37.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 45  val \n","Loss: 0.5336  Acc: 81.2500\n","negative precision: 70.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 70.0000\n","positive TP: 6.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 5 minibatch: 1      time used: 0.9536447525024414\n","minibatch AVG loss: 0.06625763298943639\n","Epoch: 46     train index of 5 minibatch: 2      time used: 0.7102768421173096\n","minibatch AVG loss: 0.27169930227100847\n","Epoch: 46     train index of 5 minibatch: 3      time used: 0.7162210941314697\n","minibatch AVG loss: 0.7928435450419784\n","\n","Epoch: 46  train \n","Loss: 0.3496  Acc: 86.9565\n","negative precision: 83.8710  recall: 86.6667\n","negative sensitivity: 86.6667  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 89.4737\n","negative TP: 26.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 4.0\n","positive precision: 89.4737  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 86.6667\n","positive FPR: 13.3333  NPV: 83.8710\n","positive TP: 34.0\n","positive TN: 26.0\n","positive FP: 4.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 46  val \n","Loss: 0.1942  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 5 minibatch: 1      time used: 0.9509477615356445\n","minibatch AVG loss: 0.28411259427666663\n","Epoch: 47     train index of 5 minibatch: 2      time used: 0.7049267292022705\n","minibatch AVG loss: 0.20065955258905888\n","Epoch: 47     train index of 5 minibatch: 3      time used: 0.7116761207580566\n","minibatch AVG loss: 0.4210637414827943\n","\n","Epoch: 47  train \n","Loss: 0.2672  Acc: 88.4058\n","negative precision: 84.3750  recall: 90.0000\n","negative sensitivity: 90.0000  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 91.8919\n","negative TP: 27.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 3.0\n","positive precision: 91.8919  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 90.0000\n","positive FPR: 10.0000  NPV: 84.3750\n","positive TP: 34.0\n","positive TN: 27.0\n","positive FP: 3.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 47  val \n","Loss: 0.3644  Acc: 81.2500\n","negative precision: 70.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 70.0000\n","positive TP: 6.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 5 minibatch: 1      time used: 0.9415953159332275\n","minibatch AVG loss: 0.462239421159029\n","Epoch: 48     train index of 5 minibatch: 2      time used: 0.7091691493988037\n","minibatch AVG loss: 0.07130563855171204\n","Epoch: 48     train index of 5 minibatch: 3      time used: 0.7091481685638428\n","minibatch AVG loss: 0.9958389922976494\n","\n","Epoch: 48  train \n","Loss: 0.4668  Acc: 88.4058\n","negative precision: 92.3077  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 86.0465\n","negative TP: 24.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 6.0\n","positive precision: 86.0465  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 92.3077\n","positive TP: 37.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 48  val \n","Loss: 0.2206  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 5 minibatch: 1      time used: 0.9456765651702881\n","minibatch AVG loss: 0.5753015097230673\n","Epoch: 49     train index of 5 minibatch: 2      time used: 0.7091200351715088\n","minibatch AVG loss: 0.5631982461782172\n","Epoch: 49     train index of 5 minibatch: 3      time used: 0.6993722915649414\n","minibatch AVG loss: 0.6142224716022611\n","\n","Epoch: 49  train \n","Loss: 0.5812  Acc: 81.1594\n","negative precision: 81.4815  recall: 73.3333\n","negative sensitivity: 73.3333  specificity: 87.1795\n","negative FPR: 12.8205  NPV: 80.9524\n","negative TP: 22.0\n","negative TN: 34.0\n","negative FP: 5.0\n","negative FN: 8.0\n","positive precision: 80.9524  recall: 87.1795\n","positive sensitivity: 87.1795  specificity: 73.3333\n","positive FPR: 26.6667  NPV: 81.4815\n","positive TP: 34.0\n","positive TN: 22.0\n","positive FP: 8.0\n","positive FN: 5.0\n","\n","\n","\n","Epoch: 49  val \n","Loss: 0.4294  Acc: 81.2500\n","negative precision: 70.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 70.0000\n","positive TP: 6.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 5 minibatch: 1      time used: 0.9489943981170654\n","minibatch AVG loss: 0.3444565434387187\n","Epoch: 50     train index of 5 minibatch: 2      time used: 0.7167809009552002\n","minibatch AVG loss: 0.7499624598305672\n","Epoch: 50     train index of 5 minibatch: 3      time used: 0.7146859169006348\n","minibatch AVG loss: 0.675446192920208\n","\n","Epoch: 50  train \n","Loss: 0.5653  Acc: 82.6087\n","negative precision: 80.0000  recall: 80.0000\n","negative sensitivity: 80.0000  specificity: 84.6154\n","negative FPR: 15.3846  NPV: 84.6154\n","negative TP: 24.0\n","negative TN: 33.0\n","negative FP: 6.0\n","negative FN: 6.0\n","positive precision: 84.6154  recall: 84.6154\n","positive sensitivity: 84.6154  specificity: 80.0000\n","positive FPR: 20.0000  NPV: 80.0000\n","positive TP: 33.0\n","positive TN: 24.0\n","positive FP: 6.0\n","positive FN: 6.0\n","\n","\n","\n","Epoch: 50  val \n","Loss: 0.4460  Acc: 81.2500\n","negative precision: 70.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 66.6667\n","negative FPR: 33.3333  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 6.0\n","negative FP: 3.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 66.6667\n","positive sensitivity: 66.6667  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 70.0000\n","positive TP: 6.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 3.0\n","\n","\n","\n","Training complete in 2m 40s\n","Best epoch idx:  46\n","Best epoch train Acc: 86.956522\n","Best epoch val Acc: 100.000000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","model trained by GPU (idx:0) has been saved at  /home/MIL_Experiment/saved_models/PC_efficientnet_b3_384_401_PT_lf05_b4_warwick_CLS.pth\n"]}],"source":["!python Train.py --model_idx efficientnet_b3_384_401_PT_lf05_b4_warwick_CLS --edge_size 384 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Z2jo4ttKTTNL","outputId":"b904545d-271e-44e4-caea-543058cae369"},"outputs":[{"name":"stdout","output_type":"stream","text":["*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, att_module='SimAM', attn_drop_rate=0.0, backbone_PT_off=False, batch_size=4, check_minibatch=5, cls_token_off=False, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=False, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, gpu_idx=-1, intake_epochs=0, lr=1e-05, lrf=0.05, model_idx='swin_b_384_401_PT_lf05_b4_warwick_CLS', model_path='/home/MIL_Experiment/saved_models', num_classes=2, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, pos_embedding_off=False)\n","we dont have more GPU idx here, try to use gpu_idx=0\n","['swin_base_patch4_window7_224',\n"," 'swin_base_patch4_window7_224_in22k',\n"," 'swin_base_patch4_window12_384',\n"," 'swin_base_patch4_window12_384_in22k',\n"," 'swin_large_patch4_window7_224',\n"," 'swin_large_patch4_window7_224_in22k',\n"," 'swin_large_patch4_window12_384',\n"," 'swin_large_patch4_window12_384_in22k',\n"," 'swin_small_patch4_window7_224',\n"," 'swin_tiny_patch4_window7_224']\n","Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22kto1k.pth\" to /root/.cache/torch/hub/checkpoints/swin_base_patch4_window12_384_22kto1k.pth\n","test model output： tensor([[ 0.1480, -0.0498]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 128, 96, 96]           6,272\n","         LayerNorm-2            [-1, 9216, 128]             256\n","        PatchEmbed-3            [-1, 9216, 128]               0\n","           Dropout-4            [-1, 9216, 128]               0\n","         LayerNorm-5            [-1, 9216, 128]             256\n","            Linear-6             [-1, 144, 384]          49,536\n","           Softmax-7          [-1, 4, 144, 144]               0\n","           Dropout-8          [-1, 4, 144, 144]               0\n","            Linear-9             [-1, 144, 128]          16,512\n","          Dropout-10             [-1, 144, 128]               0\n","  WindowAttention-11             [-1, 144, 128]               0\n","         Identity-12            [-1, 9216, 128]               0\n","        LayerNorm-13            [-1, 9216, 128]             256\n","           Linear-14            [-1, 9216, 512]          66,048\n","             GELU-15            [-1, 9216, 512]               0\n","          Dropout-16            [-1, 9216, 512]               0\n","           Linear-17            [-1, 9216, 128]          65,664\n","          Dropout-18            [-1, 9216, 128]               0\n","              Mlp-19            [-1, 9216, 128]               0\n","         Identity-20            [-1, 9216, 128]               0\n","SwinTransformerBlock-21            [-1, 9216, 128]               0\n","        LayerNorm-22            [-1, 9216, 128]             256\n","           Linear-23             [-1, 144, 384]          49,536\n","          Softmax-24          [-1, 4, 144, 144]               0\n","          Dropout-25          [-1, 4, 144, 144]               0\n","           Linear-26             [-1, 144, 128]          16,512\n","          Dropout-27             [-1, 144, 128]               0\n","  WindowAttention-28             [-1, 144, 128]               0\n","         DropPath-29            [-1, 9216, 128]               0\n","        LayerNorm-30            [-1, 9216, 128]             256\n","           Linear-31            [-1, 9216, 512]          66,048\n","             GELU-32            [-1, 9216, 512]               0\n","          Dropout-33            [-1, 9216, 512]               0\n","           Linear-34            [-1, 9216, 128]          65,664\n","          Dropout-35            [-1, 9216, 128]               0\n","              Mlp-36            [-1, 9216, 128]               0\n","         DropPath-37            [-1, 9216, 128]               0\n","SwinTransformerBlock-38            [-1, 9216, 128]               0\n","        LayerNorm-39            [-1, 2304, 512]           1,024\n","           Linear-40            [-1, 2304, 256]         131,072\n","     PatchMerging-41            [-1, 2304, 256]               0\n","       BasicLayer-42            [-1, 2304, 256]               0\n","        LayerNorm-43            [-1, 2304, 256]             512\n","           Linear-44             [-1, 144, 768]         197,376\n","          Softmax-45          [-1, 8, 144, 144]               0\n","          Dropout-46          [-1, 8, 144, 144]               0\n","           Linear-47             [-1, 144, 256]          65,792\n","          Dropout-48             [-1, 144, 256]               0\n","  WindowAttention-49             [-1, 144, 256]               0\n","         DropPath-50            [-1, 2304, 256]               0\n","        LayerNorm-51            [-1, 2304, 256]             512\n","           Linear-52           [-1, 2304, 1024]         263,168\n","             GELU-53           [-1, 2304, 1024]               0\n","          Dropout-54           [-1, 2304, 1024]               0\n","           Linear-55            [-1, 2304, 256]         262,400\n","          Dropout-56            [-1, 2304, 256]               0\n","              Mlp-57            [-1, 2304, 256]               0\n","         DropPath-58            [-1, 2304, 256]               0\n","SwinTransformerBlock-59            [-1, 2304, 256]               0\n","        LayerNorm-60            [-1, 2304, 256]             512\n","           Linear-61             [-1, 144, 768]         197,376\n","          Softmax-62          [-1, 8, 144, 144]               0\n","          Dropout-63          [-1, 8, 144, 144]               0\n","           Linear-64             [-1, 144, 256]          65,792\n","          Dropout-65             [-1, 144, 256]               0\n","  WindowAttention-66             [-1, 144, 256]               0\n","         DropPath-67            [-1, 2304, 256]               0\n","        LayerNorm-68            [-1, 2304, 256]             512\n","           Linear-69           [-1, 2304, 1024]         263,168\n","             GELU-70           [-1, 2304, 1024]               0\n","          Dropout-71           [-1, 2304, 1024]               0\n","           Linear-72            [-1, 2304, 256]         262,400\n","          Dropout-73            [-1, 2304, 256]               0\n","              Mlp-74            [-1, 2304, 256]               0\n","         DropPath-75            [-1, 2304, 256]               0\n","SwinTransformerBlock-76            [-1, 2304, 256]               0\n","        LayerNorm-77            [-1, 576, 1024]           2,048\n","           Linear-78             [-1, 576, 512]         524,288\n","     PatchMerging-79             [-1, 576, 512]               0\n","       BasicLayer-80             [-1, 576, 512]               0\n","        LayerNorm-81             [-1, 576, 512]           1,024\n","           Linear-82            [-1, 144, 1536]         787,968\n","          Softmax-83         [-1, 16, 144, 144]               0\n","          Dropout-84         [-1, 16, 144, 144]               0\n","           Linear-85             [-1, 144, 512]         262,656\n","          Dropout-86             [-1, 144, 512]               0\n","  WindowAttention-87             [-1, 144, 512]               0\n","         DropPath-88             [-1, 576, 512]               0\n","        LayerNorm-89             [-1, 576, 512]           1,024\n","           Linear-90            [-1, 576, 2048]       1,050,624\n","             GELU-91            [-1, 576, 2048]               0\n","          Dropout-92            [-1, 576, 2048]               0\n","           Linear-93             [-1, 576, 512]       1,049,088\n","          Dropout-94             [-1, 576, 512]               0\n","              Mlp-95             [-1, 576, 512]               0\n","         DropPath-96             [-1, 576, 512]               0\n","SwinTransformerBlock-97             [-1, 576, 512]               0\n","        LayerNorm-98             [-1, 576, 512]           1,024\n","           Linear-99            [-1, 144, 1536]         787,968\n","         Softmax-100         [-1, 16, 144, 144]               0\n","         Dropout-101         [-1, 16, 144, 144]               0\n","          Linear-102             [-1, 144, 512]         262,656\n","         Dropout-103             [-1, 144, 512]               0\n"," WindowAttention-104             [-1, 144, 512]               0\n","        DropPath-105             [-1, 576, 512]               0\n","       LayerNorm-106             [-1, 576, 512]           1,024\n","          Linear-107            [-1, 576, 2048]       1,050,624\n","            GELU-108            [-1, 576, 2048]               0\n","         Dropout-109            [-1, 576, 2048]               0\n","          Linear-110             [-1, 576, 512]       1,049,088\n","         Dropout-111             [-1, 576, 512]               0\n","             Mlp-112             [-1, 576, 512]               0\n","        DropPath-113             [-1, 576, 512]               0\n","SwinTransformerBlock-114             [-1, 576, 512]               0\n","       LayerNorm-115             [-1, 576, 512]           1,024\n","          Linear-116            [-1, 144, 1536]         787,968\n","         Softmax-117         [-1, 16, 144, 144]               0\n","         Dropout-118         [-1, 16, 144, 144]               0\n","          Linear-119             [-1, 144, 512]         262,656\n","         Dropout-120             [-1, 144, 512]               0\n"," WindowAttention-121             [-1, 144, 512]               0\n","        DropPath-122             [-1, 576, 512]               0\n","       LayerNorm-123             [-1, 576, 512]           1,024\n","          Linear-124            [-1, 576, 2048]       1,050,624\n","            GELU-125            [-1, 576, 2048]               0\n","         Dropout-126            [-1, 576, 2048]               0\n","          Linear-127             [-1, 576, 512]       1,049,088\n","         Dropout-128             [-1, 576, 512]               0\n","             Mlp-129             [-1, 576, 512]               0\n","        DropPath-130             [-1, 576, 512]               0\n","SwinTransformerBlock-131             [-1, 576, 512]               0\n","       LayerNorm-132             [-1, 576, 512]           1,024\n","          Linear-133            [-1, 144, 1536]         787,968\n","         Softmax-134         [-1, 16, 144, 144]               0\n","         Dropout-135         [-1, 16, 144, 144]               0\n","          Linear-136             [-1, 144, 512]         262,656\n","         Dropout-137             [-1, 144, 512]               0\n"," WindowAttention-138             [-1, 144, 512]               0\n","        DropPath-139             [-1, 576, 512]               0\n","       LayerNorm-140             [-1, 576, 512]           1,024\n","          Linear-141            [-1, 576, 2048]       1,050,624\n","            GELU-142            [-1, 576, 2048]               0\n","         Dropout-143            [-1, 576, 2048]               0\n","          Linear-144             [-1, 576, 512]       1,049,088\n","         Dropout-145             [-1, 576, 512]               0\n","             Mlp-146             [-1, 576, 512]               0\n","        DropPath-147             [-1, 576, 512]               0\n","SwinTransformerBlock-148             [-1, 576, 512]               0\n","       LayerNorm-149             [-1, 576, 512]           1,024\n","          Linear-150            [-1, 144, 1536]         787,968\n","         Softmax-151         [-1, 16, 144, 144]               0\n","         Dropout-152         [-1, 16, 144, 144]               0\n","          Linear-153             [-1, 144, 512]         262,656\n","         Dropout-154             [-1, 144, 512]               0\n"," WindowAttention-155             [-1, 144, 512]               0\n","        DropPath-156             [-1, 576, 512]               0\n","       LayerNorm-157             [-1, 576, 512]           1,024\n","          Linear-158            [-1, 576, 2048]       1,050,624\n","            GELU-159            [-1, 576, 2048]               0\n","         Dropout-160            [-1, 576, 2048]               0\n","          Linear-161             [-1, 576, 512]       1,049,088\n","         Dropout-162             [-1, 576, 512]               0\n","             Mlp-163             [-1, 576, 512]               0\n","        DropPath-164             [-1, 576, 512]               0\n","SwinTransformerBlock-165             [-1, 576, 512]               0\n","       LayerNorm-166             [-1, 576, 512]           1,024\n","          Linear-167            [-1, 144, 1536]         787,968\n","         Softmax-168         [-1, 16, 144, 144]               0\n","         Dropout-169         [-1, 16, 144, 144]               0\n","          Linear-170             [-1, 144, 512]         262,656\n","         Dropout-171             [-1, 144, 512]               0\n"," WindowAttention-172             [-1, 144, 512]               0\n","        DropPath-173             [-1, 576, 512]               0\n","       LayerNorm-174             [-1, 576, 512]           1,024\n","          Linear-175            [-1, 576, 2048]       1,050,624\n","            GELU-176            [-1, 576, 2048]               0\n","         Dropout-177            [-1, 576, 2048]               0\n","          Linear-178             [-1, 576, 512]       1,049,088\n","         Dropout-179             [-1, 576, 512]               0\n","             Mlp-180             [-1, 576, 512]               0\n","        DropPath-181             [-1, 576, 512]               0\n","SwinTransformerBlock-182             [-1, 576, 512]               0\n","       LayerNorm-183             [-1, 576, 512]           1,024\n","          Linear-184            [-1, 144, 1536]         787,968\n","         Softmax-185         [-1, 16, 144, 144]               0\n","         Dropout-186         [-1, 16, 144, 144]               0\n","          Linear-187             [-1, 144, 512]         262,656\n","         Dropout-188             [-1, 144, 512]               0\n"," WindowAttention-189             [-1, 144, 512]               0\n","        DropPath-190             [-1, 576, 512]               0\n","       LayerNorm-191             [-1, 576, 512]           1,024\n","          Linear-192            [-1, 576, 2048]       1,050,624\n","            GELU-193            [-1, 576, 2048]               0\n","         Dropout-194            [-1, 576, 2048]               0\n","          Linear-195             [-1, 576, 512]       1,049,088\n","         Dropout-196             [-1, 576, 512]               0\n","             Mlp-197             [-1, 576, 512]               0\n","        DropPath-198             [-1, 576, 512]               0\n","SwinTransformerBlock-199             [-1, 576, 512]               0\n","       LayerNorm-200             [-1, 576, 512]           1,024\n","          Linear-201            [-1, 144, 1536]         787,968\n","         Softmax-202         [-1, 16, 144, 144]               0\n","         Dropout-203         [-1, 16, 144, 144]               0\n","          Linear-204             [-1, 144, 512]         262,656\n","         Dropout-205             [-1, 144, 512]               0\n"," WindowAttention-206             [-1, 144, 512]               0\n","        DropPath-207             [-1, 576, 512]               0\n","       LayerNorm-208             [-1, 576, 512]           1,024\n","          Linear-209            [-1, 576, 2048]       1,050,624\n","            GELU-210            [-1, 576, 2048]               0\n","         Dropout-211            [-1, 576, 2048]               0\n","          Linear-212             [-1, 576, 512]       1,049,088\n","         Dropout-213             [-1, 576, 512]               0\n","             Mlp-214             [-1, 576, 512]               0\n","        DropPath-215             [-1, 576, 512]               0\n","SwinTransformerBlock-216             [-1, 576, 512]               0\n","       LayerNorm-217             [-1, 576, 512]           1,024\n","          Linear-218            [-1, 144, 1536]         787,968\n","         Softmax-219         [-1, 16, 144, 144]               0\n","         Dropout-220         [-1, 16, 144, 144]               0\n","          Linear-221             [-1, 144, 512]         262,656\n","         Dropout-222             [-1, 144, 512]               0\n"," WindowAttention-223             [-1, 144, 512]               0\n","        DropPath-224             [-1, 576, 512]               0\n","       LayerNorm-225             [-1, 576, 512]           1,024\n","          Linear-226            [-1, 576, 2048]       1,050,624\n","            GELU-227            [-1, 576, 2048]               0\n","         Dropout-228            [-1, 576, 2048]               0\n","          Linear-229             [-1, 576, 512]       1,049,088\n","         Dropout-230             [-1, 576, 512]               0\n","             Mlp-231             [-1, 576, 512]               0\n","        DropPath-232             [-1, 576, 512]               0\n","SwinTransformerBlock-233             [-1, 576, 512]               0\n","       LayerNorm-234             [-1, 576, 512]           1,024\n","          Linear-235            [-1, 144, 1536]         787,968\n","         Softmax-236         [-1, 16, 144, 144]               0\n","         Dropout-237         [-1, 16, 144, 144]               0\n","          Linear-238             [-1, 144, 512]         262,656\n","         Dropout-239             [-1, 144, 512]               0\n"," WindowAttention-240             [-1, 144, 512]               0\n","        DropPath-241             [-1, 576, 512]               0\n","       LayerNorm-242             [-1, 576, 512]           1,024\n","          Linear-243            [-1, 576, 2048]       1,050,624\n","            GELU-244            [-1, 576, 2048]               0\n","         Dropout-245            [-1, 576, 2048]               0\n","          Linear-246             [-1, 576, 512]       1,049,088\n","         Dropout-247             [-1, 576, 512]               0\n","             Mlp-248             [-1, 576, 512]               0\n","        DropPath-249             [-1, 576, 512]               0\n","SwinTransformerBlock-250             [-1, 576, 512]               0\n","       LayerNorm-251             [-1, 576, 512]           1,024\n","          Linear-252            [-1, 144, 1536]         787,968\n","         Softmax-253         [-1, 16, 144, 144]               0\n","         Dropout-254         [-1, 16, 144, 144]               0\n","          Linear-255             [-1, 144, 512]         262,656\n","         Dropout-256             [-1, 144, 512]               0\n"," WindowAttention-257             [-1, 144, 512]               0\n","        DropPath-258             [-1, 576, 512]               0\n","       LayerNorm-259             [-1, 576, 512]           1,024\n","          Linear-260            [-1, 576, 2048]       1,050,624\n","            GELU-261            [-1, 576, 2048]               0\n","         Dropout-262            [-1, 576, 2048]               0\n","          Linear-263             [-1, 576, 512]       1,049,088\n","         Dropout-264             [-1, 576, 512]               0\n","             Mlp-265             [-1, 576, 512]               0\n","        DropPath-266             [-1, 576, 512]               0\n","SwinTransformerBlock-267             [-1, 576, 512]               0\n","       LayerNorm-268             [-1, 576, 512]           1,024\n","          Linear-269            [-1, 144, 1536]         787,968\n","         Softmax-270         [-1, 16, 144, 144]               0\n","         Dropout-271         [-1, 16, 144, 144]               0\n","          Linear-272             [-1, 144, 512]         262,656\n","         Dropout-273             [-1, 144, 512]               0\n"," WindowAttention-274             [-1, 144, 512]               0\n","        DropPath-275             [-1, 576, 512]               0\n","       LayerNorm-276             [-1, 576, 512]           1,024\n","          Linear-277            [-1, 576, 2048]       1,050,624\n","            GELU-278            [-1, 576, 2048]               0\n","         Dropout-279            [-1, 576, 2048]               0\n","          Linear-280             [-1, 576, 512]       1,049,088\n","         Dropout-281             [-1, 576, 512]               0\n","             Mlp-282             [-1, 576, 512]               0\n","        DropPath-283             [-1, 576, 512]               0\n","SwinTransformerBlock-284             [-1, 576, 512]               0\n","       LayerNorm-285             [-1, 576, 512]           1,024\n","          Linear-286            [-1, 144, 1536]         787,968\n","         Softmax-287         [-1, 16, 144, 144]               0\n","         Dropout-288         [-1, 16, 144, 144]               0\n","          Linear-289             [-1, 144, 512]         262,656\n","         Dropout-290             [-1, 144, 512]               0\n"," WindowAttention-291             [-1, 144, 512]               0\n","        DropPath-292             [-1, 576, 512]               0\n","       LayerNorm-293             [-1, 576, 512]           1,024\n","          Linear-294            [-1, 576, 2048]       1,050,624\n","            GELU-295            [-1, 576, 2048]               0\n","         Dropout-296            [-1, 576, 2048]               0\n","          Linear-297             [-1, 576, 512]       1,049,088\n","         Dropout-298             [-1, 576, 512]               0\n","             Mlp-299             [-1, 576, 512]               0\n","        DropPath-300             [-1, 576, 512]               0\n","SwinTransformerBlock-301             [-1, 576, 512]               0\n","       LayerNorm-302             [-1, 576, 512]           1,024\n","          Linear-303            [-1, 144, 1536]         787,968\n","         Softmax-304         [-1, 16, 144, 144]               0\n","         Dropout-305         [-1, 16, 144, 144]               0\n","          Linear-306             [-1, 144, 512]         262,656\n","         Dropout-307             [-1, 144, 512]               0\n"," WindowAttention-308             [-1, 144, 512]               0\n","        DropPath-309             [-1, 576, 512]               0\n","       LayerNorm-310             [-1, 576, 512]           1,024\n","          Linear-311            [-1, 576, 2048]       1,050,624\n","            GELU-312            [-1, 576, 2048]               0\n","         Dropout-313            [-1, 576, 2048]               0\n","          Linear-314             [-1, 576, 512]       1,049,088\n","         Dropout-315             [-1, 576, 512]               0\n","             Mlp-316             [-1, 576, 512]               0\n","        DropPath-317             [-1, 576, 512]               0\n","SwinTransformerBlock-318             [-1, 576, 512]               0\n","       LayerNorm-319             [-1, 576, 512]           1,024\n","          Linear-320            [-1, 144, 1536]         787,968\n","         Softmax-321         [-1, 16, 144, 144]               0\n","         Dropout-322         [-1, 16, 144, 144]               0\n","          Linear-323             [-1, 144, 512]         262,656\n","         Dropout-324             [-1, 144, 512]               0\n"," WindowAttention-325             [-1, 144, 512]               0\n","        DropPath-326             [-1, 576, 512]               0\n","       LayerNorm-327             [-1, 576, 512]           1,024\n","          Linear-328            [-1, 576, 2048]       1,050,624\n","            GELU-329            [-1, 576, 2048]               0\n","         Dropout-330            [-1, 576, 2048]               0\n","          Linear-331             [-1, 576, 512]       1,049,088\n","         Dropout-332             [-1, 576, 512]               0\n","             Mlp-333             [-1, 576, 512]               0\n","        DropPath-334             [-1, 576, 512]               0\n","SwinTransformerBlock-335             [-1, 576, 512]               0\n","       LayerNorm-336             [-1, 576, 512]           1,024\n","          Linear-337            [-1, 144, 1536]         787,968\n","         Softmax-338         [-1, 16, 144, 144]               0\n","         Dropout-339         [-1, 16, 144, 144]               0\n","          Linear-340             [-1, 144, 512]         262,656\n","         Dropout-341             [-1, 144, 512]               0\n"," WindowAttention-342             [-1, 144, 512]               0\n","        DropPath-343             [-1, 576, 512]               0\n","       LayerNorm-344             [-1, 576, 512]           1,024\n","          Linear-345            [-1, 576, 2048]       1,050,624\n","            GELU-346            [-1, 576, 2048]               0\n","         Dropout-347            [-1, 576, 2048]               0\n","          Linear-348             [-1, 576, 512]       1,049,088\n","         Dropout-349             [-1, 576, 512]               0\n","             Mlp-350             [-1, 576, 512]               0\n","        DropPath-351             [-1, 576, 512]               0\n","SwinTransformerBlock-352             [-1, 576, 512]               0\n","       LayerNorm-353             [-1, 576, 512]           1,024\n","          Linear-354            [-1, 144, 1536]         787,968\n","         Softmax-355         [-1, 16, 144, 144]               0\n","         Dropout-356         [-1, 16, 144, 144]               0\n","          Linear-357             [-1, 144, 512]         262,656\n","         Dropout-358             [-1, 144, 512]               0\n"," WindowAttention-359             [-1, 144, 512]               0\n","        DropPath-360             [-1, 576, 512]               0\n","       LayerNorm-361             [-1, 576, 512]           1,024\n","          Linear-362            [-1, 576, 2048]       1,050,624\n","            GELU-363            [-1, 576, 2048]               0\n","         Dropout-364            [-1, 576, 2048]               0\n","          Linear-365             [-1, 576, 512]       1,049,088\n","         Dropout-366             [-1, 576, 512]               0\n","             Mlp-367             [-1, 576, 512]               0\n","        DropPath-368             [-1, 576, 512]               0\n","SwinTransformerBlock-369             [-1, 576, 512]               0\n","       LayerNorm-370             [-1, 576, 512]           1,024\n","          Linear-371            [-1, 144, 1536]         787,968\n","         Softmax-372         [-1, 16, 144, 144]               0\n","         Dropout-373         [-1, 16, 144, 144]               0\n","          Linear-374             [-1, 144, 512]         262,656\n","         Dropout-375             [-1, 144, 512]               0\n"," WindowAttention-376             [-1, 144, 512]               0\n","        DropPath-377             [-1, 576, 512]               0\n","       LayerNorm-378             [-1, 576, 512]           1,024\n","          Linear-379            [-1, 576, 2048]       1,050,624\n","            GELU-380            [-1, 576, 2048]               0\n","         Dropout-381            [-1, 576, 2048]               0\n","          Linear-382             [-1, 576, 512]       1,049,088\n","         Dropout-383             [-1, 576, 512]               0\n","             Mlp-384             [-1, 576, 512]               0\n","        DropPath-385             [-1, 576, 512]               0\n","SwinTransformerBlock-386             [-1, 576, 512]               0\n","       LayerNorm-387            [-1, 144, 2048]           4,096\n","          Linear-388            [-1, 144, 1024]       2,097,152\n","    PatchMerging-389            [-1, 144, 1024]               0\n","      BasicLayer-390            [-1, 144, 1024]               0\n","       LayerNorm-391            [-1, 144, 1024]           2,048\n","          Linear-392            [-1, 144, 3072]       3,148,800\n","         Softmax-393         [-1, 32, 144, 144]               0\n","         Dropout-394         [-1, 32, 144, 144]               0\n","          Linear-395            [-1, 144, 1024]       1,049,600\n","         Dropout-396            [-1, 144, 1024]               0\n"," WindowAttention-397            [-1, 144, 1024]               0\n","        DropPath-398            [-1, 144, 1024]               0\n","       LayerNorm-399            [-1, 144, 1024]           2,048\n","          Linear-400            [-1, 144, 4096]       4,198,400\n","            GELU-401            [-1, 144, 4096]               0\n","         Dropout-402            [-1, 144, 4096]               0\n","          Linear-403            [-1, 144, 1024]       4,195,328\n","         Dropout-404            [-1, 144, 1024]               0\n","             Mlp-405            [-1, 144, 1024]               0\n","        DropPath-406            [-1, 144, 1024]               0\n","SwinTransformerBlock-407            [-1, 144, 1024]               0\n","       LayerNorm-408            [-1, 144, 1024]           2,048\n","          Linear-409            [-1, 144, 3072]       3,148,800\n","         Softmax-410         [-1, 32, 144, 144]               0\n","         Dropout-411         [-1, 32, 144, 144]               0\n","          Linear-412            [-1, 144, 1024]       1,049,600\n","         Dropout-413            [-1, 144, 1024]               0\n"," WindowAttention-414            [-1, 144, 1024]               0\n","        DropPath-415            [-1, 144, 1024]               0\n","       LayerNorm-416            [-1, 144, 1024]           2,048\n","          Linear-417            [-1, 144, 4096]       4,198,400\n","            GELU-418            [-1, 144, 4096]               0\n","         Dropout-419            [-1, 144, 4096]               0\n","          Linear-420            [-1, 144, 1024]       4,195,328\n","         Dropout-421            [-1, 144, 1024]               0\n","             Mlp-422            [-1, 144, 1024]               0\n","        DropPath-423            [-1, 144, 1024]               0\n","SwinTransformerBlock-424            [-1, 144, 1024]               0\n","      BasicLayer-425            [-1, 144, 1024]               0\n","       LayerNorm-426            [-1, 144, 1024]           2,048\n","AdaptiveAvgPool1d-427              [-1, 1024, 1]               0\n","          Linear-428                    [-1, 2]           2,050\n","================================================================\n","Total params: 86,681,730\n","Trainable params: 86,681,730\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 1670.91\n","Params size (MB): 330.66\n","Estimated Total Size (MB): 2003.27\n","----------------------------------------------------------------\n","model : swin_b_384_401_PT_lf05_b4_warwick_CLS\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 5 minibatch: 1      time used: 1.9353322982788086\n","minibatch AVG loss: 0.7315783619880676\n","Epoch: 1     train index of 5 minibatch: 2      time used: 1.6703014373779297\n","minibatch AVG loss: 0.6807432055473328\n","Epoch: 1     train index of 5 minibatch: 3      time used: 1.6708447933197021\n","minibatch AVG loss: 0.5977079391479492\n","\n","Epoch: 1  train \n","Loss: 0.6603  Acc: 60.8696\n","negative precision: 54.2857  recall: 63.3333\n","negative sensitivity: 63.3333  specificity: 58.9744\n","negative FPR: 41.0256  NPV: 67.6471\n","negative TP: 19.0\n","negative TN: 23.0\n","negative FP: 16.0\n","negative FN: 11.0\n","positive precision: 67.6471  recall: 58.9744\n","positive sensitivity: 58.9744  specificity: 63.3333\n","positive FPR: 36.6667  NPV: 54.2857\n","positive TP: 23.0\n","positive TN: 19.0\n","positive FP: 11.0\n","positive FN: 16.0\n","\n","\n","\n","Epoch: 1  val \n","Loss: 0.6098  Acc: 62.5000\n","negative precision: 100.0000  recall: 14.2857\n","negative sensitivity: 14.2857  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 60.0000\n","negative TP: 1.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 6.0\n","positive precision: 60.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 14.2857\n","positive FPR: 85.7143  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 1.0\n","positive FP: 6.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 5 minibatch: 1      time used: 1.902055025100708\n","minibatch AVG loss: 0.5115102112293244\n","Epoch: 2     train index of 5 minibatch: 2      time used: 1.6721856594085693\n","minibatch AVG loss: 0.5004451930522918\n","Epoch: 2     train index of 5 minibatch: 3      time used: 1.6712722778320312\n","minibatch AVG loss: 0.5101230204105377\n","\n","Epoch: 2  train \n","Loss: 0.4904  Acc: 84.0580\n","negative precision: 91.3043  recall: 70.0000\n","negative sensitivity: 70.0000  specificity: 94.8718\n","negative FPR: 5.1282  NPV: 80.4348\n","negative TP: 21.0\n","negative TN: 37.0\n","negative FP: 2.0\n","negative FN: 9.0\n","positive precision: 80.4348  recall: 94.8718\n","positive sensitivity: 94.8718  specificity: 70.0000\n","positive FPR: 30.0000  NPV: 91.3043\n","positive TP: 37.0\n","positive TN: 21.0\n","positive FP: 9.0\n","positive FN: 2.0\n","\n","\n","\n","Epoch: 2  val \n","Loss: 0.4622  Acc: 87.5000\n","negative precision: 100.0000  recall: 71.4286\n","negative sensitivity: 71.4286  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 81.8182\n","negative TP: 5.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 2.0\n","positive precision: 81.8182  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 71.4286\n","positive FPR: 28.5714  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 5.0\n","positive FP: 2.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 5 minibatch: 1      time used: 1.9010729789733887\n","minibatch AVG loss: 0.3509943664073944\n","Epoch: 3     train index of 5 minibatch: 2      time used: 1.6733713150024414\n","minibatch AVG loss: 0.1896710842847824\n","Epoch: 3     train index of 5 minibatch: 3      time used: 1.6687004566192627\n","minibatch AVG loss: 0.29704325199127196\n","\n","Epoch: 3  train \n","Loss: 0.2566  Acc: 97.1014\n","negative precision: 96.6667  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 97.4359\n","negative FPR: 2.5641  NPV: 97.4359\n","negative TP: 29.0\n","negative TN: 38.0\n","negative FP: 1.0\n","negative FN: 1.0\n","positive precision: 97.4359  recall: 97.4359\n","positive sensitivity: 97.4359  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 96.6667\n","positive TP: 38.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch: 3  val \n","Loss: 0.2386  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 5 minibatch: 1      time used: 1.9041554927825928\n","minibatch AVG loss: 0.1846047729253769\n","Epoch: 4     train index of 5 minibatch: 2      time used: 1.6707420349121094\n","minibatch AVG loss: 0.09390889704227448\n","Epoch: 4     train index of 5 minibatch: 3      time used: 1.6713471412658691\n","minibatch AVG loss: 0.10028770193457603\n","\n","Epoch: 4  train \n","Loss: 0.1225  Acc: 98.5507\n","negative precision: 100.0000  recall: 96.6667\n","negative sensitivity: 96.6667  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 97.5000\n","negative TP: 29.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 1.0\n","positive precision: 97.5000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 96.6667\n","positive FPR: 3.3333  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 29.0\n","positive FP: 1.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 4  val \n","Loss: 0.1165  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 5 minibatch: 1      time used: 1.89640212059021\n","minibatch AVG loss: 0.040532104671001434\n","Epoch: 5     train index of 5 minibatch: 2      time used: 1.670485496520996\n","minibatch AVG loss: 0.03668762408196926\n","Epoch: 5     train index of 5 minibatch: 3      time used: 1.6733636856079102\n","minibatch AVG loss: 0.06454912796616555\n","\n","Epoch: 5  train \n","Loss: 0.0467  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 5  val \n","Loss: 0.0852  Acc: 93.7500\n","negative precision: 87.5000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 88.8889\n","negative FPR: 11.1111  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 8.0\n","negative FP: 1.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 88.8889\n","positive sensitivity: 88.8889  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 87.5000\n","positive TP: 8.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 1.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 5 minibatch: 1      time used: 1.9026637077331543\n","minibatch AVG loss: 0.025700241886079313\n","Epoch: 6     train index of 5 minibatch: 2      time used: 1.6746723651885986\n","minibatch AVG loss: 0.014341892208904028\n","Epoch: 6     train index of 5 minibatch: 3      time used: 1.6715872287750244\n","minibatch AVG loss: 0.03705736566334963\n","\n","Epoch: 6  train \n","Loss: 0.0266  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 6  val \n","Loss: 0.0339  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 5 minibatch: 1      time used: 1.9066615104675293\n","minibatch AVG loss: 0.017514684773050248\n","Epoch: 7     train index of 5 minibatch: 2      time used: 1.6725234985351562\n","minibatch AVG loss: 0.013986192457377911\n","Epoch: 7     train index of 5 minibatch: 3      time used: 1.6711430549621582\n","minibatch AVG loss: 0.019370251195505263\n","\n","Epoch: 7  train \n","Loss: 0.0166  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 7  val \n","Loss: 0.0200  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 5 minibatch: 1      time used: 1.899291753768921\n","minibatch AVG loss: 0.004117023549042642\n","Epoch: 8     train index of 5 minibatch: 2      time used: 1.676227331161499\n","minibatch AVG loss: 0.006283348053693771\n","Epoch: 8     train index of 5 minibatch: 3      time used: 1.672182321548462\n","minibatch AVG loss: 0.02325768582522869\n","\n","Epoch: 8  train \n","Loss: 0.0109  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 8  val \n","Loss: 0.0176  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 5 minibatch: 1      time used: 1.8965070247650146\n","minibatch AVG loss: 0.005442643444985152\n","Epoch: 9     train index of 5 minibatch: 2      time used: 1.6705505847930908\n","minibatch AVG loss: 0.017873835004866123\n","Epoch: 9     train index of 5 minibatch: 3      time used: 1.6731719970703125\n","minibatch AVG loss: 0.013208367023617029\n","\n","Epoch: 9  train \n","Loss: 0.0117  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 9  val \n","Loss: 0.0282  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 5 minibatch: 1      time used: 1.8966448307037354\n","minibatch AVG loss: 0.006202014116570354\n","Epoch: 10     train index of 5 minibatch: 2      time used: 1.6723628044128418\n","minibatch AVG loss: 0.006156514398753643\n","Epoch: 10     train index of 5 minibatch: 3      time used: 1.6707661151885986\n","minibatch AVG loss: 0.007348832301795482\n","\n","Epoch: 10  train \n","Loss: 0.0083  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 10  val \n","Loss: 0.0163  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 5 minibatch: 1      time used: 1.9004693031311035\n","minibatch AVG loss: 0.010926812747493386\n","Epoch: 11     train index of 5 minibatch: 2      time used: 1.669736623764038\n","minibatch AVG loss: 0.006685072323307395\n","Epoch: 11     train index of 5 minibatch: 3      time used: 1.6724793910980225\n","minibatch AVG loss: 0.00987744175363332\n","\n","Epoch: 11  train \n","Loss: 0.0098  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 11  val \n","Loss: 0.0152  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 5 minibatch: 1      time used: 1.898470401763916\n","minibatch AVG loss: 0.009055119100958109\n","Epoch: 12     train index of 5 minibatch: 2      time used: 1.6762442588806152\n","minibatch AVG loss: 0.012563554476946593\n","Epoch: 12     train index of 5 minibatch: 3      time used: 1.6686034202575684\n","minibatch AVG loss: 0.007748308521695435\n","\n","Epoch: 12  train \n","Loss: 0.0096  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 12  val \n","Loss: 0.0156  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 5 minibatch: 1      time used: 1.9001708030700684\n","minibatch AVG loss: 0.010079450905323029\n","Epoch: 13     train index of 5 minibatch: 2      time used: 1.671186923980713\n","minibatch AVG loss: 0.004774610558524728\n","Epoch: 13     train index of 5 minibatch: 3      time used: 1.6743597984313965\n","minibatch AVG loss: 0.0030422987882047893\n","\n","Epoch: 13  train \n","Loss: 0.0060  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 13  val \n","Loss: 0.0159  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 5 minibatch: 1      time used: 1.9016780853271484\n","minibatch AVG loss: 0.0026600302895531057\n","Epoch: 14     train index of 5 minibatch: 2      time used: 1.6715941429138184\n","minibatch AVG loss: 0.008627438056282698\n","Epoch: 14     train index of 5 minibatch: 3      time used: 1.6670732498168945\n","minibatch AVG loss: 0.0046638364903628824\n","\n","Epoch: 14  train \n","Loss: 0.0050  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 14  val \n","Loss: 0.0187  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 5 minibatch: 1      time used: 1.896977186203003\n","minibatch AVG loss: 0.02008740238379687\n","Epoch: 15     train index of 5 minibatch: 2      time used: 1.6728990077972412\n","minibatch AVG loss: 0.003983353264629841\n","Epoch: 15     train index of 5 minibatch: 3      time used: 1.6803267002105713\n","minibatch AVG loss: 0.006403510924428701\n","\n","Epoch: 15  train \n","Loss: 0.0092  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 15  val \n","Loss: 0.0285  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 5 minibatch: 1      time used: 1.9010207653045654\n","minibatch AVG loss: 0.005306759150698781\n","Epoch: 16     train index of 5 minibatch: 2      time used: 1.675790548324585\n","minibatch AVG loss: 0.013549760077148676\n","Epoch: 16     train index of 5 minibatch: 3      time used: 1.6792361736297607\n","minibatch AVG loss: 0.01101609282195568\n","\n","Epoch: 16  train \n","Loss: 0.0095  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 16  val \n","Loss: 0.0185  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 5 minibatch: 1      time used: 1.899209976196289\n","minibatch AVG loss: 0.010348846227861941\n","Epoch: 17     train index of 5 minibatch: 2      time used: 1.6703476905822754\n","minibatch AVG loss: 0.01096459279069677\n","Epoch: 17     train index of 5 minibatch: 3      time used: 1.6660890579223633\n","minibatch AVG loss: 0.003952903137542307\n","\n","Epoch: 17  train \n","Loss: 0.0077  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 17  val \n","Loss: 0.0199  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 5 minibatch: 1      time used: 1.8973898887634277\n","minibatch AVG loss: 0.004106076876632869\n","Epoch: 18     train index of 5 minibatch: 2      time used: 1.6752252578735352\n","minibatch AVG loss: 0.0032884262269362806\n","Epoch: 18     train index of 5 minibatch: 3      time used: 1.6729872226715088\n","minibatch AVG loss: 0.003993695741519332\n","\n","Epoch: 18  train \n","Loss: 0.0038  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 18  val \n","Loss: 0.0167  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 5 minibatch: 1      time used: 1.8987271785736084\n","minibatch AVG loss: 0.00464234814280644\n","Epoch: 19     train index of 5 minibatch: 2      time used: 1.6801645755767822\n","minibatch AVG loss: 0.00720203707460314\n","Epoch: 19     train index of 5 minibatch: 3      time used: 1.6723227500915527\n","minibatch AVG loss: 0.003941403608769179\n","\n","Epoch: 19  train \n","Loss: 0.0050  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 19  val \n","Loss: 0.0168  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 5 minibatch: 1      time used: 1.994640588760376\n","minibatch AVG loss: 0.0037860587413888424\n","Epoch: 20     train index of 5 minibatch: 2      time used: 1.6742112636566162\n","minibatch AVG loss: 0.0027230478590354323\n","Epoch: 20     train index of 5 minibatch: 3      time used: 1.6762051582336426\n","minibatch AVG loss: 0.004941393970511854\n","\n","Epoch: 20  train \n","Loss: 0.0039  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 20  val \n","Loss: 0.0209  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 5 minibatch: 1      time used: 1.8983747959136963\n","minibatch AVG loss: 0.00220603346824646\n","Epoch: 21     train index of 5 minibatch: 2      time used: 1.6703243255615234\n","minibatch AVG loss: 0.0032994426321238278\n","Epoch: 21     train index of 5 minibatch: 3      time used: 1.6742618083953857\n","minibatch AVG loss: 0.003483584919013083\n","\n","Epoch: 21  train \n","Loss: 0.0029  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 21  val \n","Loss: 0.0213  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 5 minibatch: 1      time used: 1.89886474609375\n","minibatch AVG loss: 0.0035094605293124912\n","Epoch: 22     train index of 5 minibatch: 2      time used: 1.6766600608825684\n","minibatch AVG loss: 0.006066303607076407\n","Epoch: 22     train index of 5 minibatch: 3      time used: 1.6768162250518799\n","minibatch AVG loss: 0.007203488098457456\n","\n","Epoch: 22  train \n","Loss: 0.0057  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 22  val \n","Loss: 0.0186  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 5 minibatch: 1      time used: 1.9062082767486572\n","minibatch AVG loss: 0.003801255184225738\n","Epoch: 23     train index of 5 minibatch: 2      time used: 1.677945613861084\n","minibatch AVG loss: 0.010147827723994852\n","Epoch: 23     train index of 5 minibatch: 3      time used: 1.6739189624786377\n","minibatch AVG loss: 0.01044258582405746\n","\n","Epoch: 23  train \n","Loss: 0.0074  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 23  val \n","Loss: 0.0192  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 5 minibatch: 1      time used: 1.9067702293395996\n","minibatch AVG loss: 0.002622326649725437\n","Epoch: 24     train index of 5 minibatch: 2      time used: 1.6726398468017578\n","minibatch AVG loss: 0.0036184784024953843\n","Epoch: 24     train index of 5 minibatch: 3      time used: 1.6727895736694336\n","minibatch AVG loss: 0.007705538417212665\n","\n","Epoch: 24  train \n","Loss: 0.0044  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 24  val \n","Loss: 0.0166  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 5 minibatch: 1      time used: 1.899202585220337\n","minibatch AVG loss: 0.002627421636134386\n","Epoch: 25     train index of 5 minibatch: 2      time used: 1.6699388027191162\n","minibatch AVG loss: 0.004107029782608152\n","Epoch: 25     train index of 5 minibatch: 3      time used: 1.6713602542877197\n","minibatch AVG loss: 0.0012497461691964417\n","\n","Epoch: 25  train \n","Loss: 0.0038  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 25  val \n","Loss: 0.0149  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 5 minibatch: 1      time used: 1.9862473011016846\n","minibatch AVG loss: 0.0017034946591593324\n","Epoch: 26     train index of 5 minibatch: 2      time used: 1.6688196659088135\n","minibatch AVG loss: 0.00678262603469193\n","Epoch: 26     train index of 5 minibatch: 3      time used: 1.6678740978240967\n","minibatch AVG loss: 0.0037484071915969254\n","\n","Epoch: 26  train \n","Loss: 0.0037  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 26  val \n","Loss: 0.0255  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 5 minibatch: 1      time used: 1.898660659790039\n","minibatch AVG loss: 0.0030208299984224142\n","Epoch: 27     train index of 5 minibatch: 2      time used: 1.6700174808502197\n","minibatch AVG loss: 0.012375476723536848\n","Epoch: 27     train index of 5 minibatch: 3      time used: 1.6784265041351318\n","minibatch AVG loss: 0.003927088703494519\n","\n","Epoch: 27  train \n","Loss: 0.0059  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 27  val \n","Loss: 0.0157  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 5 minibatch: 1      time used: 1.9010071754455566\n","minibatch AVG loss: 0.022670270246453583\n","Epoch: 28     train index of 5 minibatch: 2      time used: 1.6815967559814453\n","minibatch AVG loss: 0.006068031140603125\n","Epoch: 28     train index of 5 minibatch: 3      time used: 1.6891891956329346\n","minibatch AVG loss: 0.003635510883759707\n","\n","Epoch: 28  train \n","Loss: 0.0122  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 28  val \n","Loss: 0.0098  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 5 minibatch: 1      time used: 1.9016640186309814\n","minibatch AVG loss: 0.0035674006678164004\n","Epoch: 29     train index of 5 minibatch: 2      time used: 1.676750659942627\n","minibatch AVG loss: 0.0019997172988951207\n","Epoch: 29     train index of 5 minibatch: 3      time used: 1.6723272800445557\n","minibatch AVG loss: 0.0018316099653020502\n","\n","Epoch: 29  train \n","Loss: 0.0027  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 29  val \n","Loss: 0.0108  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 5 minibatch: 1      time used: 1.9142563343048096\n","minibatch AVG loss: 0.0017847159295342862\n","Epoch: 30     train index of 5 minibatch: 2      time used: 1.6722691059112549\n","minibatch AVG loss: 0.003173060470726341\n","Epoch: 30     train index of 5 minibatch: 3      time used: 1.6717448234558105\n","minibatch AVG loss: 0.0012491586268879474\n","\n","Epoch: 30  train \n","Loss: 0.0020  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 30  val \n","Loss: 0.0118  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 5 minibatch: 1      time used: 1.9039711952209473\n","minibatch AVG loss: 0.011087293736636639\n","Epoch: 31     train index of 5 minibatch: 2      time used: 1.6758537292480469\n","minibatch AVG loss: 0.0028386910329572857\n","Epoch: 31     train index of 5 minibatch: 3      time used: 1.6764779090881348\n","minibatch AVG loss: 0.005470804974902421\n","\n","Epoch: 31  train \n","Loss: 0.0058  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 31  val \n","Loss: 0.0086  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 5 minibatch: 1      time used: 1.900348424911499\n","minibatch AVG loss: 0.003281637909822166\n","Epoch: 32     train index of 5 minibatch: 2      time used: 1.674180030822754\n","minibatch AVG loss: 0.004950595297850668\n","Epoch: 32     train index of 5 minibatch: 3      time used: 1.668184757232666\n","minibatch AVG loss: 0.0009485083981417119\n","\n","Epoch: 32  train \n","Loss: 0.0028  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 32  val \n","Loss: 0.0083  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 5 minibatch: 1      time used: 1.9008305072784424\n","minibatch AVG loss: 0.0061403322266414765\n","Epoch: 33     train index of 5 minibatch: 2      time used: 1.677849531173706\n","minibatch AVG loss: 0.00408973807352595\n","Epoch: 33     train index of 5 minibatch: 3      time used: 1.669553279876709\n","minibatch AVG loss: 0.0011973539483733475\n","\n","Epoch: 33  train \n","Loss: 0.0039  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 33  val \n","Loss: 0.0080  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 5 minibatch: 1      time used: 1.912940263748169\n","minibatch AVG loss: 0.003926900087390095\n","Epoch: 34     train index of 5 minibatch: 2      time used: 1.6714823246002197\n","minibatch AVG loss: 0.00210159266134724\n","Epoch: 34     train index of 5 minibatch: 3      time used: 1.6717488765716553\n","minibatch AVG loss: 0.0015525330149102957\n","\n","Epoch: 34  train \n","Loss: 0.0025  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 34  val \n","Loss: 0.0084  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 5 minibatch: 1      time used: 1.903785228729248\n","minibatch AVG loss: 0.0015384821803309024\n","Epoch: 35     train index of 5 minibatch: 2      time used: 1.6744086742401123\n","minibatch AVG loss: 0.006010833033360541\n","Epoch: 35     train index of 5 minibatch: 3      time used: 1.6748802661895752\n","minibatch AVG loss: 0.003237309609539807\n","\n","Epoch: 35  train \n","Loss: 0.0032  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 35  val \n","Loss: 0.0084  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 5 minibatch: 1      time used: 1.8938524723052979\n","minibatch AVG loss: 0.002198252733796835\n","Epoch: 36     train index of 5 minibatch: 2      time used: 1.6686687469482422\n","minibatch AVG loss: 0.0016472236369736494\n","Epoch: 36     train index of 5 minibatch: 3      time used: 1.667130708694458\n","minibatch AVG loss: 0.002204267028719187\n","\n","Epoch: 36  train \n","Loss: 0.0020  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 36  val \n","Loss: 0.0086  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 5 minibatch: 1      time used: 1.9047644138336182\n","minibatch AVG loss: 0.004088875034358353\n","Epoch: 37     train index of 5 minibatch: 2      time used: 1.6745223999023438\n","minibatch AVG loss: 0.003609445720212534\n","Epoch: 37     train index of 5 minibatch: 3      time used: 1.6690027713775635\n","minibatch AVG loss: 0.004156425758264959\n","\n","Epoch: 37  train \n","Loss: 0.0036  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 37  val \n","Loss: 0.0090  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 5 minibatch: 1      time used: 1.9028332233428955\n","minibatch AVG loss: 0.002806819468969479\n","Epoch: 38     train index of 5 minibatch: 2      time used: 1.6775076389312744\n","minibatch AVG loss: 0.003031693131197244\n","Epoch: 38     train index of 5 minibatch: 3      time used: 1.6693549156188965\n","minibatch AVG loss: 0.012237486091908067\n","\n","Epoch: 38  train \n","Loss: 0.0055  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 38  val \n","Loss: 0.0085  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 5 minibatch: 1      time used: 1.9006695747375488\n","minibatch AVG loss: 0.0023601031163707374\n","Epoch: 39     train index of 5 minibatch: 2      time used: 1.6768286228179932\n","minibatch AVG loss: 0.001586272259010002\n","Epoch: 39     train index of 5 minibatch: 3      time used: 1.6758716106414795\n","minibatch AVG loss: 0.0031463058665394785\n","\n","Epoch: 39  train \n","Loss: 0.0027  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 39  val \n","Loss: 0.0085  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 5 minibatch: 1      time used: 1.909637212753296\n","minibatch AVG loss: 0.0020414274418726563\n","Epoch: 40     train index of 5 minibatch: 2      time used: 1.6724755764007568\n","minibatch AVG loss: 0.003520987194497138\n","Epoch: 40     train index of 5 minibatch: 3      time used: 1.6785268783569336\n","minibatch AVG loss: 0.0014681706263218075\n","\n","Epoch: 40  train \n","Loss: 0.0027  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 40  val \n","Loss: 0.0084  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 5 minibatch: 1      time used: 1.9053120613098145\n","minibatch AVG loss: 0.0015230934601277112\n","Epoch: 41     train index of 5 minibatch: 2      time used: 1.6738779544830322\n","minibatch AVG loss: 0.0016431435360573232\n","Epoch: 41     train index of 5 minibatch: 3      time used: 1.676419734954834\n","minibatch AVG loss: 0.00231521021341905\n","\n","Epoch: 41  train \n","Loss: 0.0020  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 41  val \n","Loss: 0.0085  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 5 minibatch: 1      time used: 1.9038097858428955\n","minibatch AVG loss: 0.0021367420617025346\n","Epoch: 42     train index of 5 minibatch: 2      time used: 1.6770389080047607\n","minibatch AVG loss: 0.004679477133322507\n","Epoch: 42     train index of 5 minibatch: 3      time used: 1.6754260063171387\n","minibatch AVG loss: 0.0015698077477281913\n","\n","Epoch: 42  train \n","Loss: 0.0032  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 42  val \n","Loss: 0.0086  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 5 minibatch: 1      time used: 1.90803861618042\n","minibatch AVG loss: 0.005458194925449788\n","Epoch: 43     train index of 5 minibatch: 2      time used: 1.6768531799316406\n","minibatch AVG loss: 0.0020109800272621213\n","Epoch: 43     train index of 5 minibatch: 3      time used: 1.675734281539917\n","minibatch AVG loss: 0.0033967726631090045\n","\n","Epoch: 43  train \n","Loss: 0.0034  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 43  val \n","Loss: 0.0086  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 5 minibatch: 1      time used: 1.8972840309143066\n","minibatch AVG loss: 0.0022108846809715033\n","Epoch: 44     train index of 5 minibatch: 2      time used: 1.6745870113372803\n","minibatch AVG loss: 0.0029729958507232366\n","Epoch: 44     train index of 5 minibatch: 3      time used: 1.6732590198516846\n","minibatch AVG loss: 0.0019577652390580626\n","\n","Epoch: 44  train \n","Loss: 0.0027  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 44  val \n","Loss: 0.0088  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 5 minibatch: 1      time used: 1.8969571590423584\n","minibatch AVG loss: 0.0049434913322329525\n","Epoch: 45     train index of 5 minibatch: 2      time used: 1.6708812713623047\n","minibatch AVG loss: 0.00220100391888991\n","Epoch: 45     train index of 5 minibatch: 3      time used: 1.6710543632507324\n","minibatch AVG loss: 0.0011951567779760809\n","\n","Epoch: 45  train \n","Loss: 0.0026  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 45  val \n","Loss: 0.0085  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 5 minibatch: 1      time used: 1.9038879871368408\n","minibatch AVG loss: 0.0015707321232184767\n","Epoch: 46     train index of 5 minibatch: 2      time used: 1.6797425746917725\n","minibatch AVG loss: 0.002877866162452847\n","Epoch: 46     train index of 5 minibatch: 3      time used: 1.6730029582977295\n","minibatch AVG loss: 0.0018078177934512496\n","\n","Epoch: 46  train \n","Loss: 0.0020  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 46  val \n","Loss: 0.0085  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 5 minibatch: 1      time used: 1.906153917312622\n","minibatch AVG loss: 0.001970301498658955\n","Epoch: 47     train index of 5 minibatch: 2      time used: 1.6733334064483643\n","minibatch AVG loss: 0.0014226297498680651\n","Epoch: 47     train index of 5 minibatch: 3      time used: 1.671175241470337\n","minibatch AVG loss: 0.002442139474442229\n","\n","Epoch: 47  train \n","Loss: 0.0019  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 47  val \n","Loss: 0.0085  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 5 minibatch: 1      time used: 1.8983514308929443\n","minibatch AVG loss: 0.0017830920522101223\n","Epoch: 48     train index of 5 minibatch: 2      time used: 1.6757867336273193\n","minibatch AVG loss: 0.0009482143563218415\n","Epoch: 48     train index of 5 minibatch: 3      time used: 1.6715269088745117\n","minibatch AVG loss: 0.0067382147535681725\n","\n","Epoch: 48  train \n","Loss: 0.0033  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 48  val \n","Loss: 0.0085  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 5 minibatch: 1      time used: 1.9016895294189453\n","minibatch AVG loss: 0.0011548015289008617\n","Epoch: 49     train index of 5 minibatch: 2      time used: 1.6744658946990967\n","minibatch AVG loss: 0.0021057834848761557\n","Epoch: 49     train index of 5 minibatch: 3      time used: 1.6755330562591553\n","minibatch AVG loss: 0.0013213409518357366\n","\n","Epoch: 49  train \n","Loss: 0.0018  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 49  val \n","Loss: 0.0085  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 5 minibatch: 1      time used: 1.9048709869384766\n","minibatch AVG loss: 0.001984409126453102\n","Epoch: 50     train index of 5 minibatch: 2      time used: 1.6758441925048828\n","minibatch AVG loss: 0.0013980448478832842\n","Epoch: 50     train index of 5 minibatch: 3      time used: 1.679086446762085\n","minibatch AVG loss: 0.001341241633053869\n","\n","Epoch: 50  train \n","Loss: 0.0018  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 30.0\n","negative TN: 39.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 39.0\n","positive TN: 30.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Epoch: 50  val \n","Loss: 0.0086  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 7.0\n","negative TN: 9.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 9.0\n","positive TN: 7.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","\n","Training complete in 5m 38s\n","Best epoch idx:  50\n","Best epoch train Acc: 100.000000\n","Best epoch val Acc: 100.000000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","model trained by GPU (idx:0) has been saved at  /home/MIL_Experiment/saved_models/PC_swin_b_384_401_PT_lf05_b4_warwick_CLS.pth\n"]}],"source":["!python Train.py --model_idx swin_b_384_401_PT_lf05_b4_warwick_CLS --edge_size 384 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"]},{"cell_type":"markdown","metadata":{"id":"9A2NqlIySHZo"},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9a_q06xzYk-0","outputId":"a34e94f4-e9d1-46df-e6db-e5a363badeff"},"outputs":[{"name":"stdout","output_type":"stream","text":["['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_384',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_sam_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_sam_224',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[-1.1951, -0.2866]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf05_b4_warwick_CLS\n","*********************************setting*************************************\n","Namespace(att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=5, cls_token_off=False, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='ViT_384_401_PT_lf05_b4_warwick_CLS', model_path='/home/MIL_Experiment/saved_models', num_classes=2, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 5 minibatch: 1      time used: 0.23815488815307617\n","minibatch AVG loss: 0.002351038172128028\n","/home/MIL_Experiment/code/utils/visual_usage.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 5 minibatch: 2      time used: 0.13852953910827637\n","minibatch AVG loss: 2.3507558671553853e-05\n","Epoch: test     test index of 5 minibatch: 3      time used: 0.141312837600708\n","minibatch AVG loss: 2.0575031851421954e-05\n","Epoch: test     test index of 5 minibatch: 4      time used: 0.14018487930297852\n","minibatch AVG loss: 0.0007499968534716572\n","Epoch: test     test index of 5 minibatch: 5      time used: 0.13911843299865723\n","minibatch AVG loss: 0.0003696687224859829\n","Epoch: test     test index of 5 minibatch: 6      time used: 0.13876605033874512\n","minibatch AVG loss: 9.761038991200622e-05\n","Epoch: test     test index of 5 minibatch: 7      time used: 0.13827013969421387\n","minibatch AVG loss: 5.841213965140923e-06\n","Epoch: test     test index of 5 minibatch: 8      time used: 0.13885235786437988\n","minibatch AVG loss: 0.0002316058408950994\n","Epoch: test     test index of 5 minibatch: 9      time used: 0.13865447044372559\n","minibatch AVG loss: 0.00024000223565963098\n","Epoch: test     test index of 5 minibatch: 10      time used: 0.1402263641357422\n","minibatch AVG loss: 0.0003425530497224827\n","Epoch: test     test index of 5 minibatch: 11      time used: 0.1384432315826416\n","minibatch AVG loss: 0.0003464711408014409\n","Epoch: test     test index of 5 minibatch: 12      time used: 0.1386246681213379\n","minibatch AVG loss: 0.00017208788340212778\n","Epoch: test     test index of 5 minibatch: 13      time used: 0.13917160034179688\n","minibatch AVG loss: 0.0017349675435070822\n","Epoch: test     test index of 5 minibatch: 14      time used: 0.13949847221374512\n","minibatch AVG loss: 0.0006112334199769975\n","Epoch: test     test index of 5 minibatch: 15      time used: 0.13852643966674805\n","minibatch AVG loss: 1.2850653365603649e-05\n","Epoch: test     test index of 5 minibatch: 16      time used: 0.13904404640197754\n","minibatch AVG loss: 0.049326088866109785\n","\n","Epoch:  test \n","Loss: 0.0035  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 37.0\n","negative TN: 43.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 43.0\n","positive TN: 37.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","Testing complete in 0m 45s\n"]}],"source":["!python Test.py --model_idx ViT_384_401_PT_lf05_b4_warwick_CLS --edge_size 384 --enable_attention_check --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RtBaK8ZdL1X7","outputId":"406dda73-49b9-4599-d20a-3cf1034e3aba"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[0.8139, 0.0185]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : ResNet50_384_401_PT_lf05_b4_warwick_CLS\n","*********************************setting*************************************\n","Namespace(att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=5, cls_token_off=False, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='ResNet50_384_401_PT_lf05_b4_warwick_CLS', model_path='/home/MIL_Experiment/saved_models', num_classes=2, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 5 minibatch: 1      time used: 0.19839882850646973\n","minibatch AVG loss: 0.019409131505381084\n","/home/MIL_Experiment/code/utils/visual_usage.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 5 minibatch: 2      time used: 0.07022953033447266\n","minibatch AVG loss: 0.005001455049932701\n","Epoch: test     test index of 5 minibatch: 3      time used: 0.07023262977600098\n","minibatch AVG loss: 0.014803644039784559\n","Epoch: test     test index of 5 minibatch: 4      time used: 0.07279467582702637\n","minibatch AVG loss: 0.01205115370976273\n","Epoch: test     test index of 5 minibatch: 5      time used: 0.0722658634185791\n","minibatch AVG loss: 0.012771110252288054\n","Epoch: test     test index of 5 minibatch: 6      time used: 0.07069802284240723\n","minibatch AVG loss: 0.018213588799153514\n","Epoch: test     test index of 5 minibatch: 7      time used: 0.07175493240356445\n","minibatch AVG loss: 0.0027796987891633763\n","Epoch: test     test index of 5 minibatch: 8      time used: 0.07110953330993652\n","minibatch AVG loss: 0.02134870275622234\n","Epoch: test     test index of 5 minibatch: 9      time used: 0.0700228214263916\n","minibatch AVG loss: 0.03667989643290639\n","Epoch: test     test index of 5 minibatch: 10      time used: 0.0716860294342041\n","minibatch AVG loss: 0.028316833765711636\n","Epoch: test     test index of 5 minibatch: 11      time used: 0.07133841514587402\n","minibatch AVG loss: 0.02915305709466338\n","Epoch: test     test index of 5 minibatch: 12      time used: 0.07131004333496094\n","minibatch AVG loss: 0.045850066794082524\n","Epoch: test     test index of 5 minibatch: 13      time used: 0.07183361053466797\n","minibatch AVG loss: 0.010461243521422147\n","Epoch: test     test index of 5 minibatch: 14      time used: 0.06825137138366699\n","minibatch AVG loss: 0.025165854301303626\n","Epoch: test     test index of 5 minibatch: 15      time used: 0.0682675838470459\n","minibatch AVG loss: 0.01325110886245966\n","Epoch: test     test index of 5 minibatch: 16      time used: 0.06984424591064453\n","minibatch AVG loss: 0.018081658519804478\n","\n","Epoch:  test \n","Loss: 0.0196  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 37.0\n","negative TN: 43.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 43.0\n","positive TN: 37.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","Testing complete in 0m 41s\n"]}],"source":["!python Test.py --model_idx ResNet50_384_401_PT_lf05_b4_warwick_CLS --edge_size 384 --enable_attention_check --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"cpO0kpfrSLNH","outputId":"fe22092f-4d97-420b-b78d-a23db4972d9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["['vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224']\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","test model output： tensor([[ 0.2782, -0.6109]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : ResN50_ViT_384_401_PT_lf05_b4_warwick_CLS\n","*********************************setting*************************************\n","Namespace(att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=5, cls_token_off=False, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='ResN50_ViT_384_401_PT_lf05_b4_warwick_CLS', model_path='/home/MIL_Experiment/saved_models', num_classes=2, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 5 minibatch: 1      time used: 0.36986517906188965\n","minibatch AVG loss: 0.014710775623098016\n","/home/MIL_Experiment/code/utils/visual_usage.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 5 minibatch: 2      time used: 0.21730279922485352\n","minibatch AVG loss: 0.013126469193957746\n","Epoch: test     test index of 5 minibatch: 3      time used: 0.2200019359588623\n","minibatch AVG loss: 0.004578301031142473\n","Epoch: test     test index of 5 minibatch: 4      time used: 0.21907949447631836\n","minibatch AVG loss: 0.007310552452690899\n","Epoch: test     test index of 5 minibatch: 5      time used: 0.21928858757019043\n","minibatch AVG loss: 0.006481046299450099\n","Epoch: test     test index of 5 minibatch: 6      time used: 0.22002410888671875\n","minibatch AVG loss: 0.002280737063847482\n","Epoch: test     test index of 5 minibatch: 7      time used: 0.22241806983947754\n","minibatch AVG loss: 0.0027775733498856424\n","Epoch: test     test index of 5 minibatch: 8      time used: 0.21799063682556152\n","minibatch AVG loss: 0.010510157607495785\n","Epoch: test     test index of 5 minibatch: 9      time used: 0.2282242774963379\n","minibatch AVG loss: 0.01212683217599988\n","Epoch: test     test index of 5 minibatch: 10      time used: 0.22382164001464844\n","minibatch AVG loss: 0.006822993094101548\n","Epoch: test     test index of 5 minibatch: 11      time used: 0.21975493431091309\n","minibatch AVG loss: 0.027180349547415973\n","Epoch: test     test index of 5 minibatch: 12      time used: 0.22314834594726562\n","minibatch AVG loss: 0.025090277125127614\n","Epoch: test     test index of 5 minibatch: 13      time used: 0.2217555046081543\n","minibatch AVG loss: 0.0037356377579271793\n","Epoch: test     test index of 5 minibatch: 14      time used: 0.21898531913757324\n","minibatch AVG loss: 0.0021083718398585915\n","Epoch: test     test index of 5 minibatch: 15      time used: 0.21985673904418945\n","minibatch AVG loss: 0.0017399528063833714\n","Epoch: test     test index of 5 minibatch: 16      time used: 0.22082066535949707\n","minibatch AVG loss: 0.003558771382085979\n","\n","Epoch:  test \n","Loss: 0.0090  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 37.0\n","negative TN: 43.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 43.0\n","positive TN: 37.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","Testing complete in 0m 47s\n"]}],"source":["!python Test.py --model_idx ResN50_ViT_384_401_PT_lf05_b4_warwick_CLS --edge_size 384 --enable_attention_check --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WIrMFuz5SLd9","outputId":"295204a5-5b26-4100-feec-1adece665386"},"outputs":[{"name":"stdout","output_type":"stream","text":["['efficientnet_b0',\n"," 'efficientnet_b1',\n"," 'efficientnet_b1_pruned',\n"," 'efficientnet_b2',\n"," 'efficientnet_b2_pruned',\n"," 'efficientnet_b2a',\n"," 'efficientnet_b3',\n"," 'efficientnet_b3_pruned',\n"," 'efficientnet_b3a',\n"," 'efficientnet_b4',\n"," 'efficientnet_b5',\n"," 'efficientnet_b6',\n"," 'efficientnet_b7',\n"," 'efficientnet_b8',\n"," 'efficientnet_cc_b0_4e',\n"," 'efficientnet_cc_b0_8e',\n"," 'efficientnet_cc_b1_8e',\n"," 'efficientnet_el',\n"," 'efficientnet_el_pruned',\n"," 'efficientnet_em',\n"," 'efficientnet_es',\n"," 'efficientnet_es_pruned',\n"," 'efficientnet_l2',\n"," 'efficientnet_lite0',\n"," 'efficientnet_lite1',\n"," 'efficientnet_lite2',\n"," 'efficientnet_lite3',\n"," 'efficientnet_lite4',\n"," 'efficientnetv2_l',\n"," 'efficientnetv2_m',\n"," 'efficientnetv2_rw_m',\n"," 'efficientnetv2_rw_s',\n"," 'efficientnetv2_rw_t',\n"," 'efficientnetv2_s',\n"," 'efficientnetv2_xl',\n"," 'gc_efficientnetv2_rw_t',\n"," 'tf_efficientnet_b0',\n"," 'tf_efficientnet_b0_ap',\n"," 'tf_efficientnet_b0_ns',\n"," 'tf_efficientnet_b1',\n"," 'tf_efficientnet_b1_ap',\n"," 'tf_efficientnet_b1_ns',\n"," 'tf_efficientnet_b2',\n"," 'tf_efficientnet_b2_ap',\n"," 'tf_efficientnet_b2_ns',\n"," 'tf_efficientnet_b3',\n"," 'tf_efficientnet_b3_ap',\n"," 'tf_efficientnet_b3_ns',\n"," 'tf_efficientnet_b4',\n"," 'tf_efficientnet_b4_ap',\n"," 'tf_efficientnet_b4_ns',\n"," 'tf_efficientnet_b5',\n"," 'tf_efficientnet_b5_ap',\n"," 'tf_efficientnet_b5_ns',\n"," 'tf_efficientnet_b6',\n"," 'tf_efficientnet_b6_ap',\n"," 'tf_efficientnet_b6_ns',\n"," 'tf_efficientnet_b7',\n"," 'tf_efficientnet_b7_ap',\n"," 'tf_efficientnet_b7_ns',\n"," 'tf_efficientnet_b8',\n"," 'tf_efficientnet_b8_ap',\n"," 'tf_efficientnet_cc_b0_4e',\n"," 'tf_efficientnet_cc_b0_8e',\n"," 'tf_efficientnet_cc_b1_8e',\n"," 'tf_efficientnet_el',\n"," 'tf_efficientnet_em',\n"," 'tf_efficientnet_es',\n"," 'tf_efficientnet_l2_ns',\n"," 'tf_efficientnet_l2_ns_475',\n"," 'tf_efficientnet_lite0',\n"," 'tf_efficientnet_lite1',\n"," 'tf_efficientnet_lite2',\n"," 'tf_efficientnet_lite3',\n"," 'tf_efficientnet_lite4',\n"," 'tf_efficientnetv2_b0',\n"," 'tf_efficientnetv2_b1',\n"," 'tf_efficientnetv2_b2',\n"," 'tf_efficientnetv2_b3',\n"," 'tf_efficientnetv2_l',\n"," 'tf_efficientnetv2_l_in21ft1k',\n"," 'tf_efficientnetv2_l_in21k',\n"," 'tf_efficientnetv2_m',\n"," 'tf_efficientnetv2_m_in21ft1k',\n"," 'tf_efficientnetv2_m_in21k',\n"," 'tf_efficientnetv2_s',\n"," 'tf_efficientnetv2_s_in21ft1k',\n"," 'tf_efficientnetv2_s_in21k',\n"," 'tf_efficientnetv2_xl_in21ft1k',\n"," 'tf_efficientnetv2_xl_in21k']\n","test model output： tensor([[ 2.1423, -1.5588]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : efficientnet_b3_384_401_PT_lf05_b4_warwick_CLS\n","*********************************setting*************************************\n","Namespace(att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=5, cls_token_off=False, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='efficientnet_b3_384_401_PT_lf05_b4_warwick_CLS', model_path='/home/MIL_Experiment/saved_models', num_classes=2, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 5 minibatch: 1      time used: 0.2964804172515869\n","minibatch AVG loss: 0.9021471260581165\n","/home/MIL_Experiment/code/utils/visual_usage.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 5 minibatch: 2      time used: 0.14416241645812988\n","minibatch AVG loss: 0.03690957422368228\n","Epoch: test     test index of 5 minibatch: 3      time used: 0.14154911041259766\n","minibatch AVG loss: 0.18211662655230612\n","Epoch: test     test index of 5 minibatch: 4      time used: 0.14612913131713867\n","minibatch AVG loss: 0.16131858588487374\n","Epoch: test     test index of 5 minibatch: 5      time used: 0.14687395095825195\n","minibatch AVG loss: 1.0113932136213406\n","Epoch: test     test index of 5 minibatch: 6      time used: 0.14464163780212402\n","minibatch AVG loss: 0.9298785488652357\n","Epoch: test     test index of 5 minibatch: 7      time used: 0.1415696144104004\n","minibatch AVG loss: 0.5819664319855746\n","Epoch: test     test index of 5 minibatch: 8      time used: 0.14569592475891113\n","minibatch AVG loss: 0.0014089699454416405\n","Epoch: test     test index of 5 minibatch: 9      time used: 0.14692473411560059\n","minibatch AVG loss: 0.7814238706370134\n","Epoch: test     test index of 5 minibatch: 10      time used: 0.1433093547821045\n","minibatch AVG loss: 0.038367336224473546\n","Epoch: test     test index of 5 minibatch: 11      time used: 0.1520681381225586\n","minibatch AVG loss: 0.025676552683580666\n","Epoch: test     test index of 5 minibatch: 12      time used: 0.14575862884521484\n","minibatch AVG loss: 0.021401329361833633\n","Epoch: test     test index of 5 minibatch: 13      time used: 0.1396045684814453\n","minibatch AVG loss: 0.014017322097060969\n","Epoch: test     test index of 5 minibatch: 14      time used: 0.14496111869812012\n","minibatch AVG loss: 0.2200904717319645\n","Epoch: test     test index of 5 minibatch: 15      time used: 0.14528203010559082\n","minibatch AVG loss: 0.01880015503993491\n","Epoch: test     test index of 5 minibatch: 16      time used: 0.14343547821044922\n","minibatch AVG loss: 0.023014431564752157\n","\n","Epoch:  test \n","Loss: 0.3094  Acc: 88.7500\n","negative precision: 93.7500  recall: 81.0811\n","negative sensitivity: 81.0811  specificity: 95.3488\n","negative FPR: 4.6512  NPV: 85.4167\n","negative TP: 30.0\n","negative TN: 41.0\n","negative FP: 2.0\n","negative FN: 7.0\n","positive precision: 85.4167  recall: 95.3488\n","positive sensitivity: 95.3488  specificity: 81.0811\n","positive FPR: 18.9189  NPV: 93.7500\n","positive TP: 41.0\n","positive TN: 30.0\n","positive FP: 7.0\n","positive FN: 2.0\n","\n","\n","Testing complete in 0m 44s\n"]}],"source":["!python Test.py --model_idx efficientnet_b3_384_401_PT_lf05_b4_warwick_CLS --edge_size 384 --enable_attention_check --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oEQ8PIN4TUxi","outputId":"343c79b7-c0ee-4f51-c3cd-e1444d04e611"},"outputs":[{"name":"stdout","output_type":"stream","text":["['swin_base_patch4_window7_224',\n"," 'swin_base_patch4_window7_224_in22k',\n"," 'swin_base_patch4_window12_384',\n"," 'swin_base_patch4_window12_384_in22k',\n"," 'swin_large_patch4_window7_224',\n"," 'swin_large_patch4_window7_224_in22k',\n"," 'swin_large_patch4_window12_384',\n"," 'swin_large_patch4_window12_384_in22k',\n"," 'swin_small_patch4_window7_224',\n"," 'swin_tiny_patch4_window7_224']\n","test model output： tensor([[0.1134, 0.6528]], grad_fn=<AddmmBackward>)\n","model is ready now!\n","model loaded\n","model : swin_b_384_401_PT_lf05_b4_warwick_CLS\n","*********************************setting*************************************\n","Namespace(att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=5, cls_token_off=False, dataroot='/data/MIL_Experiment/dataset/warwick_CLS', draw_root='/home/MIL_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='swin_b_384_401_PT_lf05_b4_warwick_CLS', model_path='/home/MIL_Experiment/saved_models', num_classes=2, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 5 minibatch: 1      time used: 0.3287532329559326\n","minibatch AVG loss: 0.021663253533188254\n","/home/MIL_Experiment/code/utils/visual_usage.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 5 minibatch: 2      time used: 0.16344976425170898\n","minibatch AVG loss: 0.0006716582662193105\n","Epoch: test     test index of 5 minibatch: 3      time used: 0.1627357006072998\n","minibatch AVG loss: 0.021096713657607326\n","Epoch: test     test index of 5 minibatch: 4      time used: 0.1625075340270996\n","minibatch AVG loss: 0.004879389010602609\n","Epoch: test     test index of 5 minibatch: 5      time used: 0.16296982765197754\n","minibatch AVG loss: 0.01709892582439352\n","Epoch: test     test index of 5 minibatch: 6      time used: 0.1630110740661621\n","minibatch AVG loss: 0.0002985039995110128\n","Epoch: test     test index of 5 minibatch: 7      time used: 0.1629199981689453\n","minibatch AVG loss: 0.0016744468404795044\n","Epoch: test     test index of 5 minibatch: 8      time used: 0.16320180892944336\n","minibatch AVG loss: 0.0005703569389879703\n","Epoch: test     test index of 5 minibatch: 9      time used: 0.16348671913146973\n","minibatch AVG loss: 0.00396982990205288\n","Epoch: test     test index of 5 minibatch: 10      time used: 0.16342687606811523\n","minibatch AVG loss: 0.001590458958526142\n","Epoch: test     test index of 5 minibatch: 11      time used: 0.1625213623046875\n","minibatch AVG loss: 0.010568930860608816\n","Epoch: test     test index of 5 minibatch: 12      time used: 0.16283535957336426\n","minibatch AVG loss: 0.006765476730652154\n","Epoch: test     test index of 5 minibatch: 13      time used: 0.16262459754943848\n","minibatch AVG loss: 0.027036692001274787\n","Epoch: test     test index of 5 minibatch: 14      time used: 0.16319942474365234\n","minibatch AVG loss: 0.01185331454325933\n","Epoch: test     test index of 5 minibatch: 15      time used: 0.16365885734558105\n","minibatch AVG loss: 0.0010890563717111945\n","Epoch: test     test index of 5 minibatch: 16      time used: 0.16299867630004883\n","minibatch AVG loss: 0.023983902728650718\n","\n","Epoch:  test \n","Loss: 0.0097  Acc: 100.0000\n","negative precision: 100.0000  recall: 100.0000\n","negative sensitivity: 100.0000  specificity: 100.0000\n","negative FPR: 0.0000  NPV: 100.0000\n","negative TP: 37.0\n","negative TN: 43.0\n","negative FP: 0.0\n","negative FN: 0.0\n","positive precision: 100.0000  recall: 100.0000\n","positive sensitivity: 100.0000  specificity: 100.0000\n","positive FPR: 0.0000  NPV: 100.0000\n","positive TP: 43.0\n","positive TN: 37.0\n","positive FP: 0.0\n","positive FN: 0.0\n","\n","\n","Testing complete in 0m 46s\n"]}],"source":["!python Test.py --model_idx swin_b_384_401_PT_lf05_b4_warwick_CLS --edge_size 384 --enable_attention_check --check_minibatch 5 --dataroot /data/MIL_Experiment/dataset/warwick_CLS --model_path /home/MIL_Experiment/saved_models --draw_root /home/MIL_Experiment/runs"]},{"cell_type":"markdown","metadata":{"id":"32lV43PnKVJx"},"source":["# Synchronize files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mCZDUffdQep4"},"outputs":[],"source":["# change working dir\n","import os\n","os.chdir(\"/home/MIL_Experiment/code/utils\")\n","!python check_log_json.py --draw_root /home/MIL_Experiment/runs --record_dir /home/MIL_Experiment/CSV_logs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_Wx0ymiiEuyS","outputId":"1a20ac90-7982-428b-a239-970438762b66"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/MIL_SI_sample’: File exists\n","results copy completed!\n"]}],"source":["# create path on google drive\n","!mkdir /content/drive/MyDrive/MIL_SI_sample\n","# copy the results\n","!/bin/cp -rf /home/MIL_Experiment/* /content/drive/MyDrive/MIL_SI_sample/\n","print('results copy completed!')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9lzAtLIhnGe5","executionInfo":{"status":"ok","timestamp":1656337191857,"user_tz":-480,"elapsed":726,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"}},"outputId":"64ddd4dc-3dc3-4a20-da94-5ca5ab765711"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jun 27 21:39:50 UTC 2022\n"]}],"source":["!date --date='+8 hour'  # CST time zone"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"OpenSourse Sample MICCAI 2015_CLS Experiment 384 401 lf05 Counterparts Train.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}